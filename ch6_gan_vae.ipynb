{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch6_gan_vae.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lblogan14/Python_Deep_Learning/blob/master/ch6_gan_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpBgPE6HwD9Q",
        "colab_type": "text"
      },
      "source": [
        "#Intuition and Justification of Generative Models\n",
        "The neural networks introduced so far are used as **discriminative models**, which means that given input data, a discriminative model will map it to a certain label (a classification). A discriminative model gives the probability of $y$ (class), given $x$ (input), $P(Y|X=x)$.\n",
        "\n",
        "A **generative model** learns the distribution of the classes, which is the opposite of what the discriminative model does. Instead of predicting the class probability $y$, given certain input features, it tries to predict the probability of the input features, given a class $y$, $Y(X|Y=y)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY9nZUWzxIJh",
        "colab_type": "text"
      },
      "source": [
        "#Variational Autoencoders\n",
        "An autoencoder is a feed-forward neural network that tries to reproduce its input. The target value (label) of an autoencoder is equal to the input data, $y^i=x^i$, where $i$ is the sample index. It tries to learn an identity function, $h_{w,w'}(x)=x$. The autoencoder is an unsupervised algorithm and represent as below:\n",
        "\n",
        "![](https://github.com/lblogan14/Python_Deep_Learning/blob/master/img/ch6/autoencoder.PNG?raw=true)\n",
        "\n",
        "An autoencoder consists of an input, hidden (or bottleneck), and output layers. Although it's a single network, it can be treated as a virtual composition of two components:\n",
        "* **Encoder**: Maps the input data to the network's internal representation.\n",
        "* **Decoder**: Tries to reconstruct the input from the network's internal data representation.\n",
        "\n",
        "The autoencoder is trained by minimizing a loss function called **reconstruction error** $\\mathcal{L}=(x,x')$, which measures the distance between the original input and its reconstruction. The distance measures can be MSE or binary cross-entropy.\n",
        "\n",
        "The autoencoder gains significance due to its internal data representation, known as representation in the **latent space**. The latent space contains hidden data features, which are not directly observed, but are inferred by the algorithm instead. The key is that the bottleneck layer has fewer neurons than the input/output ones.\n",
        "* Because the network tries to reconstruct its input from a smaller feature space, it learns a compact representation of the data.\n",
        "* By using fewer neurons, the network is foced to learn only the most important features of the data.\n",
        "\n",
        "The encoder maps each input sample to the latent space and each attribute of the latent representation has a discrete value. That means that an input sample can have only one latent representation. Therefore, the decoder can reconstruct the input in only one possible way.\n",
        "\n",
        "A VAE can describe the latent representation in probabilistic terms. Instead of discrete values, a probability distribution is obtained for each latent attribute, making the latent space continuous. For example, to encode an image of a vehicle and the latent representation is asked to have $n$ attributes ($n$ neurons in the bottleneck layer). Each attribute represents one vehicle property, such as length, height, and width, as shown below\n",
        "\n",
        "![](https://github.com/lblogan14/Python_Deep_Learning/blob/master/img/ch6/vae_example.PNG?raw=true)\n",
        "\n",
        "Assume the average vehicle length is 4 meters. Instead of the fixed value, the VAE can decode this property as a normal distribution with a mean of 4. Then the decoder can choose to sample a latent variable from the range of its distribution. It may reconstruct a longer and lower vehicle, compared to the input. In this way, the VAE can generate an unlimited number of modified versions of the input.\n",
        "\n",
        "Formalism:\n",
        "* Denote the encoder with $q_{\\phi}(z|x)$, where $\\phi$ are the weights and biases of the network, $x$ is the input, and $z$ is the latent space representation. The encoder output is a distribution (for example, Gaussian) over the possible values of $z$, which could have generated $x$.\n",
        "* Denote the decoder with $p_{\\theta}(x|z)$, where $\\theta$ are the decoder weights and biases. First, $z$ is sampled stochastically (randomly) from the distribution. Then, it's sent through the decoder, whose output is a distribution over the possible corresponding values of $x$.\n",
        "* The VAE uses a special type of loss function with two terms:\n",
        "$$L(\\theta,\\phi;x)=-D_{KL}(q_{\\phi}(z|x)|p_{\\theta}(z)) + E_{q_{\\phi}(z|x)}[\\log(p_{\\theta}(x|z))]$$\n",
        "The first is the **Kullback-Leibler divergence** between the probability distribution $q_{\\phi}(z|x)$ and the expected probability distribution, $p(z)$. It measures how much information is lost, when $q_{\\phi}(z|x)$ is used to represent $p(z)$ (how close the two distributions are). It encourages the autoencoder to explore different reconstructions. \\\\\n",
        "The second is the reconstruction loss, which measures the difference between the original input and its reconstruction. The more they differ, the more it increases. Therefore, it encourages the autoencoder to better reconstruct the data.\n",
        "\n",
        "To implement this, the bottleneck layer will not directly output the latent state variables. Instead, it will output two vectors, which describe the **mean** and **variance** of the distribution of each latent variable:\n",
        "\n",
        "![](https://github.com/lblogan14/Python_Deep_Learning/blob/master/img/ch6/vae_sampling.PNG?raw=true)\n",
        "\n",
        "Once the mean and variance distributions are available, a state $z$ can be sampled from the latent variable distributions and passed through the decoder for reconstruction. However, the backpropagation does not work over  random processes such as here. Hence, this has to be solved with **reparameterization trick**. \\\\\n",
        "First, sample a random vector $\\epsilon$ with the same dimensions as $z$ from a Gaussian distribution as shown in the figure above. Then shift it by the latent distribution's mean $\\mu$ and scale it by the latent distribution's variance $\\sigma$:\n",
        "$$z=\\mu + \\sigma \\odot \\epsilon$$\n",
        "In this way, the mean and variance can be optimized (shown in red arrows in the figure above) and the random generator can be omitted from the backward pass. At the same time, the sampled data will have the properties of the original distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4NU-5wN5xrY",
        "colab_type": "text"
      },
      "source": [
        "##VAE with MNIST\n",
        "A VAE can generate new digits for the MNIST dataset.\n",
        "\n",
        "Keras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht9X7sTv6B-B",
        "colab_type": "code",
        "outputId": "63437893-1842-4d93-e2d2-e77c12e5de6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.markers import MarkerStyle\n",
        "import numpy as np\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Lambda, Input, Dense\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.models import Model\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C_NdsMPxQWb",
        "colab_type": "text"
      },
      "source": [
        "Instantiate the MNIST dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIhBF9yg6T1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PS3INNl6bL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = x_train.shape[1] * x_train.shape[2]\n",
        "x_train = np.reshape(x_train, [-1, image_size])\n",
        "x_test = np.reshape(x_test, [-1, image_size])\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSZ6qrPyxUBX",
        "colab_type": "text"
      },
      "source": [
        "Implement the `build_vae` function\n",
        "* separate the access to the encoder,decoder, and the full network.\n",
        "* The bottleneck layer will have only 2 neurons (2 latent variables) so as to display the latent distribution as a 2D plot.\n",
        "* The encoder/decoder will contain a single intermediate (hidden) fully-connected layer with 512 neurons. This is not a convolutional network.\n",
        "* Use cross-entropy reconstruction loss and KL divergence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viGjA8yR61oU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vae(intermediate_dim=512, latent_dim=2):\n",
        "  '''\n",
        "  Build VAE\n",
        "  :param intermediate_dim: size of hidden layers of the encoder/decoder\n",
        "  :param latent_dim: latent space size\n",
        "  :returns tuple: the encoder, the decoder, and the full VAE \n",
        "  '''\n",
        "\n",
        "  # Encoder first\n",
        "  inputs = Input(shape=(image_size,), name='encoder_input')\n",
        "  x = Dense(intermediate_dim, activation='relu')(inputs)\n",
        "\n",
        "  # Latent mean and variance\n",
        "  z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "  z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
        "\n",
        "  # Reparametrization trick for random sampling\n",
        "  # Note the use of the Lambda layer\n",
        "  # At runtime, it will call the sampling function\n",
        "  z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "\n",
        "  # Full encoder model\n",
        "  encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "  encoder.summary()\n",
        "\n",
        "  # Decoder\n",
        "  latent_inputs = Input(shape=(latent_dim,),\n",
        "                        name='z_sampling')\n",
        "  x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
        "  outputs = Dense(image_size, activation='sigmoid')(x)\n",
        "\n",
        "  # Full decoder model\n",
        "  decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "  decoder.summary()\n",
        "\n",
        "  # VAE model\n",
        "  outputs = decoder(encoder(inputs)[2])\n",
        "  vae = Model(inputs, outputs, name='vae')\n",
        "\n",
        "  # Loss function\n",
        "  # start with the reconstruction loss\n",
        "  reconstruction_loss = binary_crossentropy(inputs, outputs) * image_size\n",
        "\n",
        "  # next is the KL divergence\n",
        "  kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "  kl_loss = K.sum(kl_loss, axis=-1)\n",
        "  kl_loss *= -0.5\n",
        "\n",
        "  # combine them in a total loss\n",
        "  vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "  vae.add_loss(vae_loss)\n",
        "\n",
        "  return encoder, decoder, vae"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrB-e427x1lG",
        "colab_type": "text"
      },
      "source": [
        "The `sampling` function implements the random sampling of latent vectors `z`, using the reparameterization trick"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGX5Ys2ak14x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sampling(args: tuple):\n",
        "  '''\n",
        "  Reparameterization trick by sampling z from unit Gaussian\n",
        "  :param args: (tensor, tensor) mean and log of variance of q(z|x)\n",
        "  :returns tensor: sampled latent vector z\n",
        "  '''\n",
        "\n",
        "  # Unpack the input tuple\n",
        "  z_mean, z_log_var = args\n",
        "\n",
        "  # Mini-batch size\n",
        "  mb_size = K.shape(z_mean)[0]\n",
        "\n",
        "  # Latent space size\n",
        "  dim = K.int_shape(z_mean)[1]\n",
        "\n",
        "  # Random normal vector with mean=0 and std=1.0\n",
        "  epsilon = K.random_normal(shape=(mb_size, dim))\n",
        "\n",
        "  return z_mean + K.exp(0.5 * z_log_var) * epsilon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj0Jkfwvx_yV",
        "colab_type": "text"
      },
      "source": [
        "The `plot_latent_distribution` function collects the latent representations of all images in the test set and displays them over a 2D plot. The two latent variables `z1` and `z2` are the axes of 2D plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKjN8pB8pGbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_latent_distribution(encoder, x_test, y_test, batch_size=128):\n",
        "  '''\n",
        "  Display a 2D plot of the digit classes in the latent space.\n",
        "  Interested only in z, so only need the encoder here.\n",
        "  :param encoder: the encoder network\n",
        "  :param x_test: test images\n",
        "  :param y_test: test labels\n",
        "  :param batch_size: size of the mini-batch\n",
        "  '''\n",
        "\n",
        "  z_mean, _, _ = encoder.predict(x_test, batch_size=batch_size)\n",
        "  plt.figure(figsize=(6, 6))\n",
        "\n",
        "  markers = ('o', 'x', '^', '<', '>', '*', 'h', 'H', 'D', 'd', 'P', 'X', '8', 's', 'p')\n",
        "\n",
        "  for i in np.unique(y_test):\n",
        "    plt.scatter(z_mean[y_test == i, 0], z_mean[y_test == i, 1],\n",
        "                marker=MarkerStyle(markers[i], fillstyle='none'),\n",
        "                edgecolors='black')\n",
        "  plt.xlabel('z[0]')\n",
        "  plt.ylabel('z[1]')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3pHiGSeyR4l",
        "colab_type": "text"
      },
      "source": [
        "The `plot_generated_images` function will sample `n*n` vectors `z` in a `[-4, 4]` range for each of the two latent variables. Then it generates images based on the sampled vectors and it will display them in a 2D grid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezx9a8wPrWyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_generated_images(decoder):\n",
        "  '''\n",
        "  Display a 2D plot of the generated images.\n",
        "  Only need the decoder, because manually sample the distribution z\n",
        "  :param decoder: the decoder network\n",
        "  '''\n",
        "\n",
        "  # Display a nxn 2D manifold of digits\n",
        "  n = 15\n",
        "  digit_size = 28\n",
        "\n",
        "  figure = np.zeros((digit_size * n, digit_size * n))\n",
        "  # Linearly spaced coordinates corresponding to the 2D plot\n",
        "  # of digit classes in the latent space\n",
        "  grid_x = np.linspace(-4, 4, n)\n",
        "  grid_y = np.linspace(-4, 4, n)[::-1]\n",
        "\n",
        "  # Start sampling z1 and z2 in the ranges grid_x and grid_y\n",
        "  for i, yi in enumerate(grid_y):\n",
        "    for j, xi in enumerate(grid_x):\n",
        "      z_sample = np.array([[xi, yi]])\n",
        "      x_decoded = decoder.predict(z_sample)\n",
        "      digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "      slice_i = slice(i * digit_size, (i+1)* digit_size)\n",
        "      slice_j = slice(j * digit_size, (j+1)* digit_size)\n",
        "      figure[slice_i, slice_j] = digit\n",
        "\n",
        "  # Plot the results\n",
        "  plt.figure(figsize=(6,5))\n",
        "  start_range = digit_size // 2\n",
        "  end_range = n * digit_size + start_range + 1\n",
        "  pixel_range = np.arange(start_range, end_range, digit_size)\n",
        "  sample_range_x = np.round(grid_x, 1)\n",
        "  sample_range_y = np.round(grid_y, 1)\n",
        "  plt.xticks(pixel_range, sample_range_x)\n",
        "  plt.yticks(pixel_range, sample_range_y)\n",
        "  plt.xlabel('z[0]')\n",
        "  plt.ylabel('z[1]')\n",
        "  plt.imshow(figure, cmap='Greys_r')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uoaMkzkyoyQ",
        "colab_type": "text"
      },
      "source": [
        "Run the whole thing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4krWBeU2vIlr",
        "colab_type": "code",
        "outputId": "a328e1ce-8d2d-4097-c50a-e1067ee713f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        }
      },
      "source": [
        "encoder, decoder, vae = build_vae()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      (None, 784)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          401920      encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "z_mean (Dense)                  (None, 2)            1026        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "z_log_var (Dense)               (None, 2)            1026        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "z (Lambda)                      (None, 2)            0           z_mean[0][0]                     \n",
            "                                                                 z_log_var[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 403,972\n",
            "Trainable params: 403,972\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_sampling (InputLayer)      (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               1536      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 784)               402192    \n",
            "=================================================================\n",
            "Total params: 403,728\n",
            "Trainable params: 403,728\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD5q0DY7vMeS",
        "colab_type": "code",
        "outputId": "7e46d417-728a-44b6-b383-ace8c675312d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "vae.compile(optimizer='adam')\n",
        "vae.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"vae\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              [(None, 2), (None, 2), (N 403972    \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 784)               403728    \n",
            "=================================================================\n",
            "Total params: 807,700\n",
            "Trainable params: 807,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0tDFPgQv6Vr",
        "colab_type": "code",
        "outputId": "e3f3ef42-ad3e-48f0-8a62-a0c2da90ed6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "vae.fit(x_train,\n",
        "        epochs=50,\n",
        "        batch_size=128,\n",
        "        validation_data=(x_test, None))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 196.3053 - val_loss: 172.0399\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 168.9813 - val_loss: 167.0516\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 165.1400 - val_loss: 164.3521\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 162.7370 - val_loss: 162.2884\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 160.7351 - val_loss: 159.9844\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 159.0909 - val_loss: 158.8742\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 157.8449 - val_loss: 157.8623\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 156.9415 - val_loss: 157.0237\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 156.1392 - val_loss: 156.3515\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 155.4687 - val_loss: 155.7376\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 154.9021 - val_loss: 155.3997\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 154.4041 - val_loss: 155.0542\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 153.9066 - val_loss: 154.4394\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 153.5083 - val_loss: 154.2817\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 153.1378 - val_loss: 153.9740\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 152.8252 - val_loss: 153.5700\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 152.4830 - val_loss: 153.3487\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 152.1702 - val_loss: 153.2998\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 151.8972 - val_loss: 153.0616\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 151.6451 - val_loss: 152.8905\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 151.3953 - val_loss: 152.7355\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 151.1786 - val_loss: 152.3900\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 150.9233 - val_loss: 152.3378\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 150.7384 - val_loss: 152.5806\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 150.5635 - val_loss: 152.1381\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 150.3162 - val_loss: 152.0611\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 150.1428 - val_loss: 151.9506\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 149.9679 - val_loss: 151.8559\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 149.8436 - val_loss: 151.8285\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 149.6676 - val_loss: 151.8209\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 149.4943 - val_loss: 151.6064\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 149.3383 - val_loss: 151.5507\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 149.1772 - val_loss: 151.4310\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 149.0327 - val_loss: 151.3486\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 148.8901 - val_loss: 151.3390\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 148.7290 - val_loss: 151.3848\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 148.5500 - val_loss: 151.1114\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 148.4229 - val_loss: 151.0592\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 148.3148 - val_loss: 150.9972\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 148.1401 - val_loss: 150.8594\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 148.0025 - val_loss: 150.8063\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 147.9243 - val_loss: 150.7525\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 147.7528 - val_loss: 151.1175\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 147.6624 - val_loss: 150.7102\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 147.4892 - val_loss: 150.7175\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 147.3720 - val_loss: 150.5721\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 147.2719 - val_loss: 150.4180\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 147.1503 - val_loss: 150.3132\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 147.0573 - val_loss: 150.1685\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 146.9497 - val_loss: 150.3402\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f24ad3634a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n-IXT1HyvAJ",
        "colab_type": "text"
      },
      "source": [
        "The plot below is the latent distribution for each digit class for all test images. The left and bottom axes represent the $z_1$ and $z_2$ latent variables. Different marker shapes represent different digit classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKI5kpEowA5Q",
        "colab_type": "code",
        "outputId": "92d11c10-4a64-4801-9f74-e18df9091396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "plot_latent_distribution(encoder,\n",
        "                         x_test,\n",
        "                         y_test,\n",
        "                         batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAF3CAYAAACluzxkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPRET-MQzw6L",
        "colab_type": "text"
      },
      "source": [
        "The `plot_generated_images` function displays the images. The axes represent the particular latent distribution `z` used for each image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhKW3kMswHuT",
        "colab_type": "code",
        "outputId": "882c2b0a-73c2-4f59-8ee7-6162468b7908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "plot_generated_images(decoder)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFACAYAAADasjVjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCy0Kwxxz7P1",
        "colab_type": "text"
      },
      "source": [
        "#Generative Adversarial Networks\n",
        "![](https://github.com/lblogan14/Python_Deep_Learning/blob/master/img/ch6/gan.PNG?raw=true)\n",
        "\n",
        "A GAN is a system of two components:\n",
        "* **Generator**: This is the generative model itself. It takes a probability distribution (random noise) as input and tries to generate a realistic output image. Its purpose is similar to the decoder part of the VAE.\n",
        "* **Discriminator**: This takes two alternating inputs: the real images of the training dataset or the generated fake samples from the generator. It tries to determine whether the input image comes from the real images or the generated ones.\n",
        "\n",
        "The two networks are trained together as a system. On the one hand, the discriminator tries to get better at distinguishing between the real and fake images. On the other hand, the generator tries to output more realistic images, so it could \"deceive\" the discriminator into thinking that the generated image is real. The ultimate goal of the system is to make the generator so good that the discriminator wouldn't be able to distinguish between the real and fake images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxvUZKjB18kk",
        "colab_type": "text"
      },
      "source": [
        "##Training GANs\n",
        "The generator and the discriminator are trained separately and sequentially (one after the other), and alternate between the two phases multiple times.\n",
        "\n",
        "![](https://github.com/lblogan14/Python_Deep_Learning/blob/master/img/ch6/gan_details.PNG?raw=true)\n",
        "\n",
        "* The genearator is denoted with $G(z,\\theta_g)$, where $\\theta_g$ are the network weights, and $z$ is the latent vector, which serves as an input to the generator. $z$ is treated as a random seed value to kickstart the image-generation process, similar to the latent vector in the VAEs. $z$ has a probability distribution $p_z(z)$, which is usually random normal or random uniform. The generator outputs fake samples $x$ with a probability distribution of $p_g(x)$. This $p_g(x)$ is thought of as the probability distribution of the real data according to the generator.\n",
        "* The discriminator is denoted with $D(x,\\theta_d)$, where $\\theta_d$ are the network weights. It takes as input either the real data with the $x\\sim p_{data}(x)$ distribution, or the generated samples $x\\sim p_g(x)$. The discriminator is a binary classifier, which outputs whether the input image is part of the real (network output 1) or the generated data (network output 0).\n",
        "* During training, the discriminator and generator loss functions with $J^{(D)}$ and $J^{(G)}$, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i83G-k4FCX9n",
        "colab_type": "text"
      },
      "source": [
        "GAN training is different compared to the training of a regular DNN, because there are two networks. This process can be thought of as a sequential minimax zero-sum game of two players (generator and discriminator):\n",
        "* **Sequential**: Players take turns after one another. First, the discriminator tries to minimize $J^{(D)}$, but it can only do so by adjusting the weights $\\theta_d$. Next, the generator tries to minimize $J^{(G)}$, but it can only adjust the weights $\\theta_g$. This process is repeated multiple times.\n",
        "* **Zero-sum**: The gains and losses of one player are exactly balanced by the gains or losses of the opposite player. That is, the sum of the generators's loss and the discriminator's loss is always 0:\n",
        "$$J^{(G)}=-J^{(D)}$$\n",
        "* **Minimax**: The strategy of the first player (generator) is to **minimize** the opponent's (discriminator) **maximum** score (hence the name). When the discriminator is trained, it becomes better at distinguishing between real and fake samples (minimizing $J^{(D)}$). Next, when the generator is trained, it tries to step up to the level of the newly-improved discriminator (minimizing $J^{(G)}$ is equivalent to maximizing $J^{(D)}$). The two networks are in constant competition. The cost function of the minimax game is denoted as $V$\n",
        "$$\\min_G\\max_D V(G,D)$$\n",
        "Assume both $J^{(G)}$ and $J^{(D)}$ will be at some local minimum after a number of training steps. Then, the solution to the minimax game is called the Nash equilibrium. A Nash equilibrium happens when one of the actors doesn't change its action, regardless of what the other actor may do. A Nash equilibrium in a GAN framework happens when the generator becomes so good that the discriminator is no longer able to distinguish between the generated and real samples. That is, the discriminator output will always be $\\frac{1}{2}$ regardless of the presented input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xktJuAOYK9lF",
        "colab_type": "text"
      },
      "source": [
        "###Training the discriminator\n",
        "The discriminator is a classification neural network and it can be trained in the usual way using graident descent and backpropagation. However, the training set is composed of equal parts real and generated samples. During the training process,\n",
        "1. Depending on the input sample (real or fake), there are two paths:\n",
        "  * Select the sample from the real data $x\\sim p_{data}$, and use it to produce $D(x)$.\n",
        "  * Generate fake samples $x\\sim p_g$. Here, generator and discriminator work as a single network. Start with a random vector $z$, which is used to produce the generated sample $G(z)$. Then, it is used as input to the discriminator to produce the final output, $D(G(z))$.\n",
        "2. Compute the loss function, which reflects the duality of the training data.\n",
        "3. Backpropagate the error gradient and update the weights. the two\n",
        "networks work together, the generator weights $\\theta_g$ will be locked and only the discriminator weights $\\theta_d$ will get update. This ensures the training process improves the discriminator performance by making it better, as opposed to making the generator worse.\n",
        "\n",
        "Recall the formula for the cross-entropy loss:\n",
        "$$H(p,q)=-\\sum_{i=1}^{n}p_i(x)\\log(q_i(x))$$\n",
        "where $q_i(x)$ is the estimated probability of the output belonging to the $i$ class (out of $n$ total classes) and $p_i(x)$ is the actual probability. For simplicity, here the formula is only applied over a single training sample. In the case of binary classification, \n",
        "$$H(p,q)=-(p(x)\\log q(x) + (1-p(x))\\log(1-q(x)))$$\n",
        "For a mini-batch of m samples,\n",
        "$$H(p,q)=-\\frac{1}{m}\\sum_{j=1}^{m}(p(x_j)\\log(q(x_j)) + (1-p(x_j))\\log(1-q(x_j)))$$\n",
        "Define the discriminator loss:\n",
        "$$J^{(D)}=-\\frac{1}{2}\\mathbb{E}_{x\\sim p_{data}}\\log(D(x)) - \\frac{1}{2}\\mathbb{E}_z\\log(1-D(G(z)))$$\n",
        "This is just a cross-entropy loss for a binary classifier with some GAN-specific bells and whistles:\n",
        "* The two components of the loss reflect the two possible classes (real or fake), which are in equal number in the training set.\n",
        "* $\\frac{1}{2}\\mathbb{E}_{x\\sim p_{data}}\\log D(x)$ is the loss when the input is sampled from the real data. Ideally, in such cases, $D(x)=1$.\n",
        "* $\\mathbb{E}_{x\\sim p_{data}}$ (expectation) implies that the $x$ is samples from $p_{data}$. This part of the loss means \"when sampled from $p_{data}$, the discriminator output is expected to be $D(x)=1$\". The $\\frac{1}{2}$ is the cumulative class probability of the real data $p(x)$, since it comprises exactly half of the whole set.\n",
        "* $\\frac{1}{2}\\mathbb{E}_z\\log(1-D(G(z)))$ is the loss, when the input is sampled from the generated data. This term is maximized when $D(G(z))=0$.\n",
        "\n",
        "To summarize, the discriminator loss will be zero when $D(x)=1$ for all $x\\sim p_{data}$ and $D(x)=0$ for all generated $x\\sim p_g$ (or $x=G(z)$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tlu6XfEnTPSj",
        "colab_type": "text"
      },
      "source": [
        "###Training the generator\n",
        "The generator is trained by making it better at deceiving the discriminator:\n",
        "1. Start with a random latent vector $z$, and feed it through both the generator and discriminator to produce the output $D(G(z))$.\n",
        "2. The loss function is the same as the discriminator loss. However, the goal here is to maximize it, rather than minimize it.\n",
        "3. In the backward pass, the discriminator weights $\\theta_d$ are locked and only the generator weights $\\theta_g$ get adjusted. This forces to maximize the discriminator loss by making the generator better, instead of making the discriminator worse.\n",
        "\n",
        "In this phase only the generated data are used. The part of the loss function that deals with real data will always be 0. Therefore, it can be simplified to\n",
        "$$J^{(G)}=\\mathbb{E}_z\\log(1-D(G(z)))$$\n",
        "The gradient of this formula is $-\\frac{1}{1-D(G(z))}$ as shown below.\n",
        "\n",
        "![](https://github.com/lblogan14/Python_Deep_Learning/blob/master/img/ch6/generator_grad.PNG?raw=true)\n",
        "\n",
        "There is a limitation on the training. Early on, when the discriminator can easily distinguish between real and fake samples ($D(G(z))\\approx 0$), the gradient will be close to zero. This would result in little learning of the weights $\\theta_g$. (Known as diminished gradient). To solve this issue, use a different loss function:\n",
        "$$J^{(G)}=-\\mathbb{E}_z\\log(D(G(z))$$\n",
        "which is the dashed line shown above. This loss is still minimized when $D(G(z))\\approx 1$ and at the same time the gradient is large when the generator underperforms. With this loss, the game is no longer zero-sum but this will not have a practical effect on the GAN framework. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtohWLQuYwF-",
        "colab_type": "text"
      },
      "source": [
        "###Put it all together\n",
        "Define the minimax objective in full:\n",
        "$$\\min_G\\max_D V(G,D)=\\frac{1}{2}\\mathbb{E}_{x\\sim p_{data}}\\log(D(x))+\\frac{1}{2}\\mathbb{E}_z\\log(1-D(G(z)))$$\n",
        "The generator tries to minimize the objective, while the discriminator tries to maximize it. While the discriminator should minimize its loss, the minimax objective is a negative of the discriminator loss, and therefore the discriminator has to maximize it.\n",
        "\n",
        "GAN training algorithm: \\\\\n",
        "Repeat for a number of iterations:\n",
        "1. Repeat for $k$ steps, where $k$ is a hyperparameter:\n",
        "  * Sample a mini-batch of $m$ random samples from the latent space, $\\{z^{(1)},z^{(2)},...,z^{(m)}\\}\\sim p_g(z)$.\n",
        "  * Sample a mini-batch of $m$ samples from the real data, $\\{x^{(1)},x^{(2)},...,x^{(m)}\\}\\sim p_{data}(x)$.\n",
        "  * Update the discriminator weights $\\theta_d$, by ascending the stochastic gradient of its loss:\n",
        "  $$\\nabla_{\\theta_d}\\frac{1}{m}\\sum_{i=1}^{m}\\left[\\log(D(x^{(i)}))+\\log(1-D(G(z^{(i)})))\\right]$$\n",
        "2. Sample a mini-batch of $m$ random samples from the latent space, $\\{z^{(1)},z^{(2)},...,z^{(m)}\\}\\sim p_g(z)$.\n",
        "3. Update the generator by descending the stochastic gradient of its loss:\n",
        "$$\\nabla_{\\theta_g}\\frac{1}{m}\\sum_{i=1}^{m}\\log(1-D(G(z^{(i)})))$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw9A_JYMbgi8",
        "colab_type": "text"
      },
      "source": [
        "#Types of GANs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz1Kia42blUj",
        "colab_type": "text"
      },
      "source": [
        "##DCGAN\n",
        "DCGAN stands for **Deep Convolutional Generative Adversarial networks**. In this new architecture, both the generator and the discriminator are convolutional networks. They have some constraints, which help to stabilize the training:\n",
        "* The discriminator uses strided convolutions instead of pooling layers.\n",
        "* The generator is a special type of CNN, which uses fractional-strided convolutions to increase the size of the images.\n",
        "* Both networks use batch normalization.\n",
        "* No fully-connected layers, with the exception of the last layer of the discriminator.\n",
        "* LeaklyReLU activations for all layers of the generator, except the output, which uses tanh function.\n",
        "* LeakyReLU activations for all layers of the discriminator, except the output, which uses signoid."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmvbfQSycQoW",
        "colab_type": "text"
      },
      "source": [
        "###The generator in DCGAN\n",
        "The generator starts with a random latent vector $z$. To transform it into an image, use a network with a special type of convolution operation, called transposed convolution (also known as deconvolution or fractionally-strided convolution). The transposed convolution is an opposite of the regular convolution. Just like convolution, there are input, output, and a filter with weights, but here, the filter is applied over a single input neuron to produce multiple outputs. The following figure is an example of a simple 1D transposed convolution:\n",
        "\n",
        "![](https://github.com/lblogan14/Python_Deep_Learning/blob/master/img/ch6/transposed_convolution.PNG?raw=true)\n",
        "\n",
        "By setting the stride larger than 1, the output size is increased, compared to the input. Let the size of the input slice be $I$, the size of the filter $F$, the stride $S$, and the input padding $P$. Then, the size $O$ of the output slice is given by\n",
        "$$O=S(I-1)+F-2P$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUBMhW0ceBXF",
        "colab_type": "text"
      },
      "source": [
        "##Conditional GANs\n",
        "Both the generator and discriminator receive some addtional conditioning input information $y$ in CGANs.\n",
        "\n",
        "![](https://github.com/lblogan14/Python_Deep_Learning/blob/master/img/ch6/cgan.PNG?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etoWeL0KfJvq",
        "colab_type": "text"
      },
      "source": [
        "##GANs with MNIST\n",
        "Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeGfh_M8fM73",
        "colab_type": "code",
        "outputId": "bcc92276-f4fe-47f4-e1c7-45e7fc4e2df0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import BatchNormalization, Input, Dense, Reshape, Flatten\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wSEzoFJLWfX",
        "colab_type": "text"
      },
      "source": [
        "Implement the `build_generator` function. Use a simple fully-connected generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPYVdhB3fjWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(latent_dim: int):\n",
        "  '''\n",
        "  Build discriminator network\n",
        "  :param latent_dim: latent vector size\n",
        "  '''\n",
        "\n",
        "  model = Sequential([\n",
        "                      Dense(128, input_dim=latent_dim),\n",
        "                      LeakyReLU(alpha=0.2),\n",
        "                      BatchNormalization(momentum=0.8),\n",
        "                      Dense(256),\n",
        "                      LeakyReLU(alpha=0.2),\n",
        "                      BatchNormalization(momentum=0.8),\n",
        "                      Dense(512),\n",
        "                      LeakyReLU(alpha=0.2),\n",
        "                      BatchNormalization(momentum=0.8),\n",
        "                      Dense(np.prod((28,28,1)), activation='tanh'),\n",
        "                      # reshape to MNIST image size\n",
        "                      Reshape((28,28,1))\n",
        "  ])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  # the latent input vector z\n",
        "  z = Input(shape=(latent_dim,))\n",
        "  generated = model(z)\n",
        "\n",
        "  # build model from the input and output\n",
        "  return Model(z, generated)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3Ftq2GKLd4j",
        "colab_type": "text"
      },
      "source": [
        "Build the discriminator. A simple fully-connected network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOZmgZD6gZot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator():\n",
        "  '''\n",
        "  Build discriminator network\n",
        "  '''\n",
        "\n",
        "  model = Sequential([\n",
        "                      Flatten(input_shape=(28,28,1)),\n",
        "                      Dense(256),\n",
        "                      LeakyReLU(alpha=0.2),\n",
        "                      Dense(128),\n",
        "                      LeakyReLU(alpha=0.2),\n",
        "                      Dense(1, activation='sigmoid')\n",
        "  ], name='discriminator')\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  image = Input(shape=(28,28,1))\n",
        "  output = model(image)\n",
        "\n",
        "  return Model(image, output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJOaEIPILjS5",
        "colab_type": "text"
      },
      "source": [
        "Implement the `train` function with the actual GAN training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BOLaf-XhDrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(generator, discriminator, combined, steps, batch_size):\n",
        "  '''\n",
        "  Train the GAN system\n",
        "  :param generator: generator\n",
        "  :param discriminator: discriminator\n",
        "  :param combined:stacked generator and discrimiantor\n",
        "  use the combined network when training the generator\n",
        "  :param steps: number of alternating steps for training\n",
        "  :param batch_size: size of the minibatch\n",
        "  '''\n",
        "\n",
        "  # Load the dataset\n",
        "  (x_train, _), _ = mnist.load_data()\n",
        "\n",
        "  # Rescale in [-1, 1] range\n",
        "  x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
        "  x_train = np.expand_dims(x_train, axis=-1)\n",
        "\n",
        "  # Discriminator ground truths\n",
        "  real = np.ones((batch_size, 1))\n",
        "  fake = np.zeros((batch_size, 1))\n",
        "\n",
        "  latent_dim = generator.input_shape[1]\n",
        "\n",
        "  for step in range(steps):\n",
        "    # Training the discriminator\n",
        "    # Select a random batch of images\n",
        "    real_images = x_train[np.random.randint(0, x_train.shape[0], batch_size)]\n",
        "\n",
        "    # Random batch of noise\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "    # Generate a batch of new images\n",
        "    generated_images = generator.predict(noise)\n",
        "\n",
        "    # Train the discriminator\n",
        "    discriminator_real_loss = discriminator.train_on_batch(real_images, real)\n",
        "    discriminator_fake_loss = discriminator.train_on_batch(generated_images, fake)\n",
        "    discriminator_loss = 0.5 * np.add(discriminator_real_loss, discriminator_fake_loss)\n",
        "\n",
        "    # Training the generator\n",
        "    # random latent vector z\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "    # Train the generator\n",
        "    # Note that the \"valid\" labels is for the generalted images\n",
        "    # because the goal is to maximize the discriminator loss\n",
        "    generator_loss = combined.train_on_batch(noise, real)\n",
        "\n",
        "    # Display progress\n",
        "    print('%d [Discriminator loss: %.4f%%, acc.: %.2f%%] [Generator loss: %.4f%%]' %\n",
        "          (step, discriminator_loss[0], 100 * discriminator_loss[1], generator_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI-pZSKULpEv",
        "colab_type": "text"
      },
      "source": [
        "Implement a boilerplate function, `plot_generated_images`, to display some generated images after the training is finished:\n",
        "1. Create an `nxn` grid (the `figure` viriable)\n",
        "2. Create `nxn` random latent vectors (the `noise` variable), one for each generated image.\n",
        "3. Generate the images and place them in the grid cells.\n",
        "4. Display the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TeBjE-ty24X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_generated_images(generator):\n",
        "  '''\n",
        "  Display a nxn 2D manifold of digits\n",
        "  :param generator: the generator\n",
        "  '''\n",
        "\n",
        "  n = 10\n",
        "  digit_size = 28\n",
        "\n",
        "  # big array containing all images\n",
        "  figure = np.zeros((digit_size * n, digit_size * n))\n",
        "\n",
        "  latent_dim = generator.input_shape[1]\n",
        "\n",
        "  # n*n random latent distributions\n",
        "  noise = np.random.normal(0, 1, (n*n, latent_dim))\n",
        "\n",
        "  # generate the images\n",
        "  generated_images = generator.predict(noise)\n",
        "\n",
        "  # fill the big array with images\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      slice_i = slice(i * digit_size, (i+1) * digit_size)\n",
        "      slice_j = slice(j * digit_size, (j+1) * digit_size)\n",
        "      figure[slice_i, slice_j] = np.reshape(generated_images[i * n + j], (28,28))\n",
        "\n",
        "  # plot the results\n",
        "  plt.figure(figsize=(6,5))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(figure, cmap='Greys_r')\n",
        "  plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gMerURIL9qn",
        "colab_type": "text"
      },
      "source": [
        "Build the generator, discriminator, and the combined network. Run the training for 15,000 steps using the Adam optimizer, and plot the results once it's done:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOmV9-BCzquy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMIXfUqmzu18",
        "colab_type": "code",
        "outputId": "38dd5a7b-788f-4135-b8cd-9560f9b11a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "source": [
        "# Build and compile the discriminator\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "                      optimizer=Adam(lr=0.0002, beta_1=0.5),\n",
        "                      metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 233,985\n",
            "Trainable params: 233,985\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8Q1Toxx0TyG",
        "colab_type": "code",
        "outputId": "9d699147-5ea9-480e-d2b9-a98f4caeb3ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "source": [
        "# Build the generator\n",
        "generator = build_generator(latent_dim)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 784)               402192    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 578,704\n",
            "Trainable params: 576,912\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pyyi5Usz8Od",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generator input z\n",
        "z = Input(shape=(latent_dim,))\n",
        "generated_images = generator(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8zjDrBW0Lui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Only train the generator for the combined model\n",
        "discriminator.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jupyxQGx0gQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The discriminator takes generated image as input and determines validity\n",
        "real_or_fake = discriminator(generated_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlmqyCH70mbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stack the generator and discriminator in a combined model\n",
        "# Train the generator to deceive the discriminator\n",
        "combined = Model(z, real_or_fake)\n",
        "combined.compile(loss='binary_crossentropy',\n",
        "                 optimizer=Adam(lr=0.0002, beta_1=0.5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD7tbo4i00fC",
        "colab_type": "code",
        "outputId": "a5e88595-8e78-473f-d855-1f307105b38a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the GAN system\n",
        "train(generator=generator,\n",
        "      discriminator=discriminator,\n",
        "      combined=combined,\n",
        "      steps=15000,\n",
        "      batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 [Discriminator loss: 1.1583%, acc.: 42.97%] [Generator loss: 0.9051%]\n",
            "1 [Discriminator loss: 0.6469%, acc.: 58.20%] [Generator loss: 0.8883%]\n",
            "2 [Discriminator loss: 0.4428%, acc.: 84.38%] [Generator loss: 0.8870%]\n",
            "3 [Discriminator loss: 0.3859%, acc.: 82.42%] [Generator loss: 0.8968%]\n",
            "4 [Discriminator loss: 0.3469%, acc.: 86.33%] [Generator loss: 0.8747%]\n",
            "5 [Discriminator loss: 0.3264%, acc.: 85.55%] [Generator loss: 0.8846%]\n",
            "6 [Discriminator loss: 0.3119%, acc.: 87.11%] [Generator loss: 0.9200%]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7 [Discriminator loss: 0.3062%, acc.: 89.06%] [Generator loss: 0.9515%]\n",
            "8 [Discriminator loss: 0.2809%, acc.: 91.41%] [Generator loss: 0.9376%]\n",
            "9 [Discriminator loss: 0.2890%, acc.: 89.45%] [Generator loss: 0.9478%]\n",
            "10 [Discriminator loss: 0.2814%, acc.: 91.02%] [Generator loss: 0.9833%]\n",
            "11 [Discriminator loss: 0.2828%, acc.: 90.23%] [Generator loss: 1.0025%]\n",
            "12 [Discriminator loss: 0.2504%, acc.: 96.48%] [Generator loss: 1.0362%]\n",
            "13 [Discriminator loss: 0.2498%, acc.: 94.14%] [Generator loss: 1.0971%]\n",
            "14 [Discriminator loss: 0.2660%, acc.: 93.75%] [Generator loss: 1.0881%]\n",
            "15 [Discriminator loss: 0.2491%, acc.: 94.92%] [Generator loss: 1.1120%]\n",
            "16 [Discriminator loss: 0.2261%, acc.: 95.70%] [Generator loss: 1.1172%]\n",
            "17 [Discriminator loss: 0.2128%, acc.: 98.05%] [Generator loss: 1.1508%]\n",
            "18 [Discriminator loss: 0.2241%, acc.: 96.88%] [Generator loss: 1.1986%]\n",
            "19 [Discriminator loss: 0.2171%, acc.: 98.05%] [Generator loss: 1.2015%]\n",
            "20 [Discriminator loss: 0.2086%, acc.: 97.66%] [Generator loss: 1.2471%]\n",
            "21 [Discriminator loss: 0.1999%, acc.: 98.05%] [Generator loss: 1.2197%]\n",
            "22 [Discriminator loss: 0.2017%, acc.: 98.05%] [Generator loss: 1.2885%]\n",
            "23 [Discriminator loss: 0.1801%, acc.: 98.44%] [Generator loss: 1.3322%]\n",
            "24 [Discriminator loss: 0.1911%, acc.: 98.44%] [Generator loss: 1.3592%]\n",
            "25 [Discriminator loss: 0.1728%, acc.: 99.61%] [Generator loss: 1.3600%]\n",
            "26 [Discriminator loss: 0.1766%, acc.: 98.44%] [Generator loss: 1.3941%]\n",
            "27 [Discriminator loss: 0.1609%, acc.: 99.22%] [Generator loss: 1.4613%]\n",
            "28 [Discriminator loss: 0.1539%, acc.: 99.61%] [Generator loss: 1.4407%]\n",
            "29 [Discriminator loss: 0.1562%, acc.: 99.61%] [Generator loss: 1.5277%]\n",
            "30 [Discriminator loss: 0.1528%, acc.: 99.22%] [Generator loss: 1.5790%]\n",
            "31 [Discriminator loss: 0.1492%, acc.: 99.61%] [Generator loss: 1.5988%]\n",
            "32 [Discriminator loss: 0.1401%, acc.: 99.61%] [Generator loss: 1.6143%]\n",
            "33 [Discriminator loss: 0.1373%, acc.: 100.00%] [Generator loss: 1.5899%]\n",
            "34 [Discriminator loss: 0.1405%, acc.: 100.00%] [Generator loss: 1.6401%]\n",
            "35 [Discriminator loss: 0.1267%, acc.: 100.00%] [Generator loss: 1.6824%]\n",
            "36 [Discriminator loss: 0.1193%, acc.: 100.00%] [Generator loss: 1.7058%]\n",
            "37 [Discriminator loss: 0.1175%, acc.: 100.00%] [Generator loss: 1.7543%]\n",
            "38 [Discriminator loss: 0.1090%, acc.: 100.00%] [Generator loss: 1.7138%]\n",
            "39 [Discriminator loss: 0.1118%, acc.: 100.00%] [Generator loss: 1.7965%]\n",
            "40 [Discriminator loss: 0.1108%, acc.: 100.00%] [Generator loss: 1.8117%]\n",
            "41 [Discriminator loss: 0.1007%, acc.: 100.00%] [Generator loss: 1.8705%]\n",
            "42 [Discriminator loss: 0.1079%, acc.: 100.00%] [Generator loss: 1.8855%]\n",
            "43 [Discriminator loss: 0.1078%, acc.: 100.00%] [Generator loss: 1.8822%]\n",
            "44 [Discriminator loss: 0.0979%, acc.: 100.00%] [Generator loss: 1.9341%]\n",
            "45 [Discriminator loss: 0.0948%, acc.: 100.00%] [Generator loss: 2.0171%]\n",
            "46 [Discriminator loss: 0.0886%, acc.: 100.00%] [Generator loss: 1.9793%]\n",
            "47 [Discriminator loss: 0.0880%, acc.: 100.00%] [Generator loss: 2.0139%]\n",
            "48 [Discriminator loss: 0.0869%, acc.: 100.00%] [Generator loss: 2.0351%]\n",
            "49 [Discriminator loss: 0.0896%, acc.: 100.00%] [Generator loss: 2.0527%]\n",
            "50 [Discriminator loss: 0.0899%, acc.: 100.00%] [Generator loss: 2.0659%]\n",
            "51 [Discriminator loss: 0.0816%, acc.: 100.00%] [Generator loss: 2.1563%]\n",
            "52 [Discriminator loss: 0.0904%, acc.: 100.00%] [Generator loss: 2.1624%]\n",
            "53 [Discriminator loss: 0.0728%, acc.: 100.00%] [Generator loss: 2.1497%]\n",
            "54 [Discriminator loss: 0.0736%, acc.: 100.00%] [Generator loss: 2.1787%]\n",
            "55 [Discriminator loss: 0.0760%, acc.: 100.00%] [Generator loss: 2.2098%]\n",
            "56 [Discriminator loss: 0.0776%, acc.: 100.00%] [Generator loss: 2.2177%]\n",
            "57 [Discriminator loss: 0.0728%, acc.: 100.00%] [Generator loss: 2.2821%]\n",
            "58 [Discriminator loss: 0.0723%, acc.: 100.00%] [Generator loss: 2.2568%]\n",
            "59 [Discriminator loss: 0.0682%, acc.: 100.00%] [Generator loss: 2.2624%]\n",
            "60 [Discriminator loss: 0.0669%, acc.: 100.00%] [Generator loss: 2.3090%]\n",
            "61 [Discriminator loss: 0.0699%, acc.: 100.00%] [Generator loss: 2.3218%]\n",
            "62 [Discriminator loss: 0.0688%, acc.: 100.00%] [Generator loss: 2.3554%]\n",
            "63 [Discriminator loss: 0.0646%, acc.: 100.00%] [Generator loss: 2.3853%]\n",
            "64 [Discriminator loss: 0.0653%, acc.: 100.00%] [Generator loss: 2.3895%]\n",
            "65 [Discriminator loss: 0.0639%, acc.: 100.00%] [Generator loss: 2.4548%]\n",
            "66 [Discriminator loss: 0.0642%, acc.: 100.00%] [Generator loss: 2.4046%]\n",
            "67 [Discriminator loss: 0.0652%, acc.: 100.00%] [Generator loss: 2.4818%]\n",
            "68 [Discriminator loss: 0.0580%, acc.: 100.00%] [Generator loss: 2.4702%]\n",
            "69 [Discriminator loss: 0.0593%, acc.: 100.00%] [Generator loss: 2.4968%]\n",
            "70 [Discriminator loss: 0.0602%, acc.: 100.00%] [Generator loss: 2.4835%]\n",
            "71 [Discriminator loss: 0.0618%, acc.: 100.00%] [Generator loss: 2.4975%]\n",
            "72 [Discriminator loss: 0.0591%, acc.: 100.00%] [Generator loss: 2.4995%]\n",
            "73 [Discriminator loss: 0.0548%, acc.: 100.00%] [Generator loss: 2.4828%]\n",
            "74 [Discriminator loss: 0.0637%, acc.: 100.00%] [Generator loss: 2.5434%]\n",
            "75 [Discriminator loss: 0.0597%, acc.: 100.00%] [Generator loss: 2.5793%]\n",
            "76 [Discriminator loss: 0.0515%, acc.: 100.00%] [Generator loss: 2.5690%]\n",
            "77 [Discriminator loss: 0.0586%, acc.: 100.00%] [Generator loss: 2.4964%]\n",
            "78 [Discriminator loss: 0.0540%, acc.: 100.00%] [Generator loss: 2.5450%]\n",
            "79 [Discriminator loss: 0.0557%, acc.: 100.00%] [Generator loss: 2.5402%]\n",
            "80 [Discriminator loss: 0.0510%, acc.: 100.00%] [Generator loss: 2.5002%]\n",
            "81 [Discriminator loss: 0.0548%, acc.: 100.00%] [Generator loss: 2.6325%]\n",
            "82 [Discriminator loss: 0.0546%, acc.: 100.00%] [Generator loss: 2.6020%]\n",
            "83 [Discriminator loss: 0.0552%, acc.: 100.00%] [Generator loss: 2.6358%]\n",
            "84 [Discriminator loss: 0.0559%, acc.: 100.00%] [Generator loss: 2.5845%]\n",
            "85 [Discriminator loss: 0.0569%, acc.: 100.00%] [Generator loss: 2.6577%]\n",
            "86 [Discriminator loss: 0.0549%, acc.: 100.00%] [Generator loss: 2.6385%]\n",
            "87 [Discriminator loss: 0.0469%, acc.: 100.00%] [Generator loss: 2.6518%]\n",
            "88 [Discriminator loss: 0.0555%, acc.: 100.00%] [Generator loss: 2.6680%]\n",
            "89 [Discriminator loss: 0.0525%, acc.: 100.00%] [Generator loss: 2.6849%]\n",
            "90 [Discriminator loss: 0.0508%, acc.: 100.00%] [Generator loss: 2.6981%]\n",
            "91 [Discriminator loss: 0.0557%, acc.: 100.00%] [Generator loss: 2.6985%]\n",
            "92 [Discriminator loss: 0.0479%, acc.: 100.00%] [Generator loss: 2.7520%]\n",
            "93 [Discriminator loss: 0.0551%, acc.: 100.00%] [Generator loss: 2.6808%]\n",
            "94 [Discriminator loss: 0.0542%, acc.: 100.00%] [Generator loss: 2.7020%]\n",
            "95 [Discriminator loss: 0.0527%, acc.: 100.00%] [Generator loss: 2.6987%]\n",
            "96 [Discriminator loss: 0.0522%, acc.: 100.00%] [Generator loss: 2.7380%]\n",
            "97 [Discriminator loss: 0.0458%, acc.: 100.00%] [Generator loss: 2.7277%]\n",
            "98 [Discriminator loss: 0.0481%, acc.: 100.00%] [Generator loss: 2.6767%]\n",
            "99 [Discriminator loss: 0.0460%, acc.: 100.00%] [Generator loss: 2.7048%]\n",
            "100 [Discriminator loss: 0.0494%, acc.: 100.00%] [Generator loss: 2.7718%]\n",
            "101 [Discriminator loss: 0.0561%, acc.: 100.00%] [Generator loss: 2.6873%]\n",
            "102 [Discriminator loss: 0.0528%, acc.: 100.00%] [Generator loss: 2.7765%]\n",
            "103 [Discriminator loss: 0.0491%, acc.: 100.00%] [Generator loss: 2.7066%]\n",
            "104 [Discriminator loss: 0.0462%, acc.: 100.00%] [Generator loss: 2.8495%]\n",
            "105 [Discriminator loss: 0.0461%, acc.: 100.00%] [Generator loss: 2.8029%]\n",
            "106 [Discriminator loss: 0.0521%, acc.: 100.00%] [Generator loss: 2.7788%]\n",
            "107 [Discriminator loss: 0.0487%, acc.: 100.00%] [Generator loss: 2.8196%]\n",
            "108 [Discriminator loss: 0.0508%, acc.: 100.00%] [Generator loss: 2.7897%]\n",
            "109 [Discriminator loss: 0.0517%, acc.: 100.00%] [Generator loss: 2.8537%]\n",
            "110 [Discriminator loss: 0.0503%, acc.: 100.00%] [Generator loss: 2.8288%]\n",
            "111 [Discriminator loss: 0.0439%, acc.: 100.00%] [Generator loss: 2.8170%]\n",
            "112 [Discriminator loss: 0.0476%, acc.: 100.00%] [Generator loss: 2.7997%]\n",
            "113 [Discriminator loss: 0.0436%, acc.: 100.00%] [Generator loss: 2.8671%]\n",
            "114 [Discriminator loss: 0.0509%, acc.: 100.00%] [Generator loss: 2.8260%]\n",
            "115 [Discriminator loss: 0.0540%, acc.: 100.00%] [Generator loss: 2.8190%]\n",
            "116 [Discriminator loss: 0.0546%, acc.: 100.00%] [Generator loss: 2.9289%]\n",
            "117 [Discriminator loss: 0.0517%, acc.: 100.00%] [Generator loss: 2.8350%]\n",
            "118 [Discriminator loss: 0.0535%, acc.: 100.00%] [Generator loss: 2.9189%]\n",
            "119 [Discriminator loss: 0.0475%, acc.: 100.00%] [Generator loss: 2.8821%]\n",
            "120 [Discriminator loss: 0.0552%, acc.: 100.00%] [Generator loss: 2.8764%]\n",
            "121 [Discriminator loss: 0.0455%, acc.: 100.00%] [Generator loss: 2.8614%]\n",
            "122 [Discriminator loss: 0.0509%, acc.: 100.00%] [Generator loss: 2.8562%]\n",
            "123 [Discriminator loss: 0.0477%, acc.: 100.00%] [Generator loss: 2.8754%]\n",
            "124 [Discriminator loss: 0.0490%, acc.: 100.00%] [Generator loss: 2.8631%]\n",
            "125 [Discriminator loss: 0.0572%, acc.: 100.00%] [Generator loss: 2.9223%]\n",
            "126 [Discriminator loss: 0.0527%, acc.: 100.00%] [Generator loss: 2.9161%]\n",
            "127 [Discriminator loss: 0.0519%, acc.: 100.00%] [Generator loss: 2.9490%]\n",
            "128 [Discriminator loss: 0.0657%, acc.: 100.00%] [Generator loss: 2.9647%]\n",
            "129 [Discriminator loss: 0.0568%, acc.: 100.00%] [Generator loss: 2.7983%]\n",
            "130 [Discriminator loss: 0.0657%, acc.: 100.00%] [Generator loss: 2.8631%]\n",
            "131 [Discriminator loss: 0.0618%, acc.: 100.00%] [Generator loss: 2.9305%]\n",
            "132 [Discriminator loss: 0.0661%, acc.: 100.00%] [Generator loss: 2.8991%]\n",
            "133 [Discriminator loss: 0.0538%, acc.: 100.00%] [Generator loss: 2.9014%]\n",
            "134 [Discriminator loss: 0.0531%, acc.: 99.61%] [Generator loss: 2.9857%]\n",
            "135 [Discriminator loss: 0.0650%, acc.: 99.22%] [Generator loss: 2.9846%]\n",
            "136 [Discriminator loss: 0.0626%, acc.: 100.00%] [Generator loss: 2.9632%]\n",
            "137 [Discriminator loss: 0.0661%, acc.: 99.22%] [Generator loss: 2.9368%]\n",
            "138 [Discriminator loss: 0.0660%, acc.: 99.61%] [Generator loss: 2.9859%]\n",
            "139 [Discriminator loss: 0.0570%, acc.: 100.00%] [Generator loss: 2.9053%]\n",
            "140 [Discriminator loss: 0.0693%, acc.: 99.61%] [Generator loss: 2.9015%]\n",
            "141 [Discriminator loss: 0.0648%, acc.: 99.22%] [Generator loss: 2.9796%]\n",
            "142 [Discriminator loss: 0.0725%, acc.: 99.61%] [Generator loss: 2.7642%]\n",
            "143 [Discriminator loss: 0.0716%, acc.: 99.22%] [Generator loss: 2.8602%]\n",
            "144 [Discriminator loss: 0.0914%, acc.: 98.44%] [Generator loss: 2.7501%]\n",
            "145 [Discriminator loss: 0.0696%, acc.: 100.00%] [Generator loss: 2.8491%]\n",
            "146 [Discriminator loss: 0.0799%, acc.: 100.00%] [Generator loss: 2.8914%]\n",
            "147 [Discriminator loss: 0.0835%, acc.: 99.22%] [Generator loss: 2.8259%]\n",
            "148 [Discriminator loss: 0.0936%, acc.: 97.66%] [Generator loss: 2.8554%]\n",
            "149 [Discriminator loss: 0.0749%, acc.: 99.61%] [Generator loss: 2.6486%]\n",
            "150 [Discriminator loss: 0.0989%, acc.: 98.05%] [Generator loss: 2.7404%]\n",
            "151 [Discriminator loss: 0.1027%, acc.: 98.05%] [Generator loss: 2.8907%]\n",
            "152 [Discriminator loss: 0.1488%, acc.: 95.70%] [Generator loss: 2.6348%]\n",
            "153 [Discriminator loss: 0.0790%, acc.: 98.44%] [Generator loss: 2.8183%]\n",
            "154 [Discriminator loss: 0.1305%, acc.: 96.88%] [Generator loss: 2.6331%]\n",
            "155 [Discriminator loss: 0.0931%, acc.: 98.83%] [Generator loss: 2.7736%]\n",
            "156 [Discriminator loss: 0.0981%, acc.: 98.05%] [Generator loss: 2.6495%]\n",
            "157 [Discriminator loss: 0.0870%, acc.: 98.44%] [Generator loss: 2.8222%]\n",
            "158 [Discriminator loss: 0.1116%, acc.: 98.44%] [Generator loss: 2.8112%]\n",
            "159 [Discriminator loss: 0.1514%, acc.: 96.48%] [Generator loss: 2.6314%]\n",
            "160 [Discriminator loss: 0.0720%, acc.: 99.61%] [Generator loss: 2.7053%]\n",
            "161 [Discriminator loss: 0.1188%, acc.: 96.88%] [Generator loss: 2.6540%]\n",
            "162 [Discriminator loss: 0.1011%, acc.: 98.44%] [Generator loss: 2.6680%]\n",
            "163 [Discriminator loss: 0.1573%, acc.: 95.31%] [Generator loss: 2.5310%]\n",
            "164 [Discriminator loss: 0.0947%, acc.: 97.66%] [Generator loss: 2.7250%]\n",
            "165 [Discriminator loss: 0.1556%, acc.: 96.09%] [Generator loss: 2.5094%]\n",
            "166 [Discriminator loss: 0.1369%, acc.: 96.48%] [Generator loss: 2.8106%]\n",
            "167 [Discriminator loss: 0.1618%, acc.: 95.31%] [Generator loss: 2.4261%]\n",
            "168 [Discriminator loss: 0.0898%, acc.: 98.83%] [Generator loss: 2.5381%]\n",
            "169 [Discriminator loss: 0.1491%, acc.: 94.92%] [Generator loss: 2.5798%]\n",
            "170 [Discriminator loss: 0.1651%, acc.: 94.14%] [Generator loss: 2.5192%]\n",
            "171 [Discriminator loss: 0.1170%, acc.: 97.27%] [Generator loss: 2.5771%]\n",
            "172 [Discriminator loss: 0.1734%, acc.: 94.92%] [Generator loss: 2.4172%]\n",
            "173 [Discriminator loss: 0.1147%, acc.: 96.88%] [Generator loss: 2.5247%]\n",
            "174 [Discriminator loss: 0.1486%, acc.: 96.48%] [Generator loss: 2.2430%]\n",
            "175 [Discriminator loss: 0.1315%, acc.: 96.48%] [Generator loss: 2.4981%]\n",
            "176 [Discriminator loss: 0.1725%, acc.: 94.53%] [Generator loss: 2.2956%]\n",
            "177 [Discriminator loss: 0.1431%, acc.: 96.09%] [Generator loss: 2.5052%]\n",
            "178 [Discriminator loss: 0.1803%, acc.: 93.75%] [Generator loss: 2.4021%]\n",
            "179 [Discriminator loss: 0.1850%, acc.: 95.31%] [Generator loss: 2.2938%]\n",
            "180 [Discriminator loss: 0.1094%, acc.: 98.44%] [Generator loss: 2.3126%]\n",
            "181 [Discriminator loss: 0.1429%, acc.: 95.70%] [Generator loss: 2.4046%]\n",
            "182 [Discriminator loss: 0.1535%, acc.: 95.70%] [Generator loss: 2.1770%]\n",
            "183 [Discriminator loss: 0.1769%, acc.: 93.36%] [Generator loss: 2.2922%]\n",
            "184 [Discriminator loss: 0.1622%, acc.: 96.48%] [Generator loss: 2.3075%]\n",
            "185 [Discriminator loss: 0.1663%, acc.: 94.14%] [Generator loss: 2.3364%]\n",
            "186 [Discriminator loss: 0.2074%, acc.: 89.45%] [Generator loss: 2.3557%]\n",
            "187 [Discriminator loss: 0.2105%, acc.: 93.36%] [Generator loss: 2.3195%]\n",
            "188 [Discriminator loss: 0.1544%, acc.: 95.31%] [Generator loss: 2.2961%]\n",
            "189 [Discriminator loss: 0.1371%, acc.: 97.27%] [Generator loss: 2.3376%]\n",
            "190 [Discriminator loss: 0.1915%, acc.: 94.14%] [Generator loss: 2.2726%]\n",
            "191 [Discriminator loss: 0.1528%, acc.: 95.70%] [Generator loss: 2.2902%]\n",
            "192 [Discriminator loss: 0.1575%, acc.: 94.92%] [Generator loss: 2.2764%]\n",
            "193 [Discriminator loss: 0.1610%, acc.: 94.53%] [Generator loss: 2.5335%]\n",
            "194 [Discriminator loss: 0.2213%, acc.: 91.41%] [Generator loss: 2.2941%]\n",
            "195 [Discriminator loss: 0.1745%, acc.: 94.14%] [Generator loss: 2.5182%]\n",
            "196 [Discriminator loss: 0.4938%, acc.: 78.52%] [Generator loss: 1.8787%]\n",
            "197 [Discriminator loss: 0.2255%, acc.: 85.94%] [Generator loss: 2.1700%]\n",
            "198 [Discriminator loss: 0.0955%, acc.: 100.00%] [Generator loss: 2.4200%]\n",
            "199 [Discriminator loss: 0.1835%, acc.: 94.53%] [Generator loss: 2.2549%]\n",
            "200 [Discriminator loss: 0.1664%, acc.: 94.14%] [Generator loss: 2.3996%]\n",
            "201 [Discriminator loss: 0.2548%, acc.: 91.02%] [Generator loss: 2.0472%]\n",
            "202 [Discriminator loss: 0.1659%, acc.: 91.80%] [Generator loss: 2.1485%]\n",
            "203 [Discriminator loss: 0.1690%, acc.: 93.36%] [Generator loss: 2.4028%]\n",
            "204 [Discriminator loss: 0.2458%, acc.: 90.23%] [Generator loss: 2.1364%]\n",
            "205 [Discriminator loss: 0.1702%, acc.: 94.53%] [Generator loss: 2.3598%]\n",
            "206 [Discriminator loss: 0.1660%, acc.: 94.92%] [Generator loss: 2.0937%]\n",
            "207 [Discriminator loss: 0.1500%, acc.: 96.09%] [Generator loss: 2.2732%]\n",
            "208 [Discriminator loss: 0.1532%, acc.: 94.92%] [Generator loss: 2.2380%]\n",
            "209 [Discriminator loss: 0.2009%, acc.: 91.80%] [Generator loss: 2.1372%]\n",
            "210 [Discriminator loss: 0.1653%, acc.: 92.58%] [Generator loss: 2.4366%]\n",
            "211 [Discriminator loss: 0.2446%, acc.: 91.02%] [Generator loss: 2.2016%]\n",
            "212 [Discriminator loss: 0.1398%, acc.: 96.88%] [Generator loss: 2.2541%]\n",
            "213 [Discriminator loss: 0.2078%, acc.: 92.19%] [Generator loss: 2.2588%]\n",
            "214 [Discriminator loss: 0.1636%, acc.: 94.14%] [Generator loss: 2.3693%]\n",
            "215 [Discriminator loss: 0.1912%, acc.: 93.36%] [Generator loss: 2.2222%]\n",
            "216 [Discriminator loss: 0.1908%, acc.: 92.19%] [Generator loss: 2.2640%]\n",
            "217 [Discriminator loss: 0.2346%, acc.: 90.62%] [Generator loss: 2.2218%]\n",
            "218 [Discriminator loss: 0.1791%, acc.: 94.14%] [Generator loss: 2.3603%]\n",
            "219 [Discriminator loss: 0.2003%, acc.: 92.19%] [Generator loss: 2.1776%]\n",
            "220 [Discriminator loss: 0.1760%, acc.: 94.92%] [Generator loss: 2.3919%]\n",
            "221 [Discriminator loss: 0.2021%, acc.: 92.97%] [Generator loss: 2.3391%]\n",
            "222 [Discriminator loss: 0.1757%, acc.: 95.31%] [Generator loss: 2.3306%]\n",
            "223 [Discriminator loss: 0.1865%, acc.: 94.14%] [Generator loss: 2.2938%]\n",
            "224 [Discriminator loss: 0.2267%, acc.: 91.02%] [Generator loss: 2.0881%]\n",
            "225 [Discriminator loss: 0.1554%, acc.: 96.48%] [Generator loss: 2.4521%]\n",
            "226 [Discriminator loss: 0.2157%, acc.: 91.80%] [Generator loss: 2.1071%]\n",
            "227 [Discriminator loss: 0.1491%, acc.: 97.27%] [Generator loss: 2.2801%]\n",
            "228 [Discriminator loss: 0.2523%, acc.: 88.67%] [Generator loss: 2.0826%]\n",
            "229 [Discriminator loss: 0.1490%, acc.: 96.48%] [Generator loss: 2.4330%]\n",
            "230 [Discriminator loss: 0.2216%, acc.: 91.41%] [Generator loss: 2.2305%]\n",
            "231 [Discriminator loss: 0.1517%, acc.: 96.09%] [Generator loss: 2.1367%]\n",
            "232 [Discriminator loss: 0.2104%, acc.: 90.23%] [Generator loss: 2.3282%]\n",
            "233 [Discriminator loss: 0.2297%, acc.: 91.02%] [Generator loss: 2.3101%]\n",
            "234 [Discriminator loss: 0.1425%, acc.: 97.27%] [Generator loss: 2.3605%]\n",
            "235 [Discriminator loss: 0.2135%, acc.: 92.58%] [Generator loss: 2.1938%]\n",
            "236 [Discriminator loss: 0.1362%, acc.: 96.88%] [Generator loss: 2.4421%]\n",
            "237 [Discriminator loss: 0.2364%, acc.: 90.62%] [Generator loss: 2.0951%]\n",
            "238 [Discriminator loss: 0.1637%, acc.: 94.53%] [Generator loss: 2.4883%]\n",
            "239 [Discriminator loss: 0.2071%, acc.: 93.36%] [Generator loss: 2.2940%]\n",
            "240 [Discriminator loss: 0.1654%, acc.: 96.09%] [Generator loss: 2.4695%]\n",
            "241 [Discriminator loss: 0.2708%, acc.: 86.33%] [Generator loss: 2.2031%]\n",
            "242 [Discriminator loss: 0.1553%, acc.: 94.53%] [Generator loss: 2.5973%]\n",
            "243 [Discriminator loss: 0.3130%, acc.: 86.72%] [Generator loss: 2.2556%]\n",
            "244 [Discriminator loss: 0.1467%, acc.: 95.31%] [Generator loss: 2.6938%]\n",
            "245 [Discriminator loss: 0.1935%, acc.: 93.36%] [Generator loss: 2.4623%]\n",
            "246 [Discriminator loss: 0.1439%, acc.: 95.70%] [Generator loss: 2.3545%]\n",
            "247 [Discriminator loss: 0.1430%, acc.: 96.88%] [Generator loss: 2.4601%]\n",
            "248 [Discriminator loss: 0.2320%, acc.: 89.06%] [Generator loss: 2.4147%]\n",
            "249 [Discriminator loss: 0.1473%, acc.: 95.70%] [Generator loss: 2.6464%]\n",
            "250 [Discriminator loss: 0.3273%, acc.: 84.38%] [Generator loss: 2.2338%]\n",
            "251 [Discriminator loss: 0.1575%, acc.: 93.75%] [Generator loss: 2.6981%]\n",
            "252 [Discriminator loss: 0.3244%, acc.: 85.55%] [Generator loss: 2.0211%]\n",
            "253 [Discriminator loss: 0.1495%, acc.: 93.36%] [Generator loss: 2.4578%]\n",
            "254 [Discriminator loss: 0.1419%, acc.: 96.48%] [Generator loss: 2.5467%]\n",
            "255 [Discriminator loss: 0.2723%, acc.: 85.94%] [Generator loss: 2.4453%]\n",
            "256 [Discriminator loss: 0.1894%, acc.: 93.36%] [Generator loss: 2.3890%]\n",
            "257 [Discriminator loss: 0.2407%, acc.: 88.28%] [Generator loss: 2.3201%]\n",
            "258 [Discriminator loss: 0.2172%, acc.: 91.02%] [Generator loss: 2.2577%]\n",
            "259 [Discriminator loss: 0.2013%, acc.: 92.19%] [Generator loss: 2.3403%]\n",
            "260 [Discriminator loss: 0.2651%, acc.: 88.28%] [Generator loss: 2.1325%]\n",
            "261 [Discriminator loss: 0.1431%, acc.: 95.70%] [Generator loss: 2.5363%]\n",
            "262 [Discriminator loss: 0.2980%, acc.: 84.77%] [Generator loss: 2.1319%]\n",
            "263 [Discriminator loss: 0.1299%, acc.: 95.31%] [Generator loss: 2.6803%]\n",
            "264 [Discriminator loss: 0.1739%, acc.: 96.88%] [Generator loss: 2.5031%]\n",
            "265 [Discriminator loss: 0.1983%, acc.: 92.97%] [Generator loss: 2.4776%]\n",
            "266 [Discriminator loss: 0.1708%, acc.: 95.70%] [Generator loss: 2.3685%]\n",
            "267 [Discriminator loss: 0.1852%, acc.: 91.41%] [Generator loss: 2.4174%]\n",
            "268 [Discriminator loss: 0.2122%, acc.: 91.02%] [Generator loss: 2.2269%]\n",
            "269 [Discriminator loss: 0.1828%, acc.: 91.80%] [Generator loss: 2.5846%]\n",
            "270 [Discriminator loss: 0.2579%, acc.: 89.06%] [Generator loss: 2.3644%]\n",
            "271 [Discriminator loss: 0.1966%, acc.: 92.19%] [Generator loss: 2.5683%]\n",
            "272 [Discriminator loss: 0.2839%, acc.: 87.89%] [Generator loss: 2.2882%]\n",
            "273 [Discriminator loss: 0.1789%, acc.: 93.36%] [Generator loss: 2.5984%]\n",
            "274 [Discriminator loss: 0.2547%, acc.: 91.02%] [Generator loss: 2.3081%]\n",
            "275 [Discriminator loss: 0.1890%, acc.: 90.23%] [Generator loss: 2.6975%]\n",
            "276 [Discriminator loss: 0.2711%, acc.: 88.67%] [Generator loss: 2.1288%]\n",
            "277 [Discriminator loss: 0.1594%, acc.: 95.31%] [Generator loss: 2.5592%]\n",
            "278 [Discriminator loss: 0.2071%, acc.: 94.14%] [Generator loss: 2.4940%]\n",
            "279 [Discriminator loss: 0.1712%, acc.: 95.70%] [Generator loss: 2.4257%]\n",
            "280 [Discriminator loss: 0.2131%, acc.: 92.19%] [Generator loss: 2.3606%]\n",
            "281 [Discriminator loss: 0.2185%, acc.: 91.41%] [Generator loss: 2.4376%]\n",
            "282 [Discriminator loss: 0.2570%, acc.: 87.89%] [Generator loss: 2.3122%]\n",
            "283 [Discriminator loss: 0.1791%, acc.: 94.14%] [Generator loss: 2.7321%]\n",
            "284 [Discriminator loss: 0.3003%, acc.: 87.11%] [Generator loss: 2.1196%]\n",
            "285 [Discriminator loss: 0.1893%, acc.: 90.23%] [Generator loss: 2.9021%]\n",
            "286 [Discriminator loss: 0.2881%, acc.: 84.77%] [Generator loss: 2.2987%]\n",
            "287 [Discriminator loss: 0.1363%, acc.: 96.48%] [Generator loss: 2.6942%]\n",
            "288 [Discriminator loss: 0.2820%, acc.: 87.50%] [Generator loss: 2.2128%]\n",
            "289 [Discriminator loss: 0.1763%, acc.: 92.58%] [Generator loss: 2.9648%]\n",
            "290 [Discriminator loss: 0.3176%, acc.: 85.94%] [Generator loss: 2.1237%]\n",
            "291 [Discriminator loss: 0.1441%, acc.: 95.70%] [Generator loss: 2.5660%]\n",
            "292 [Discriminator loss: 0.2007%, acc.: 92.19%] [Generator loss: 2.3438%]\n",
            "293 [Discriminator loss: 0.2510%, acc.: 89.06%] [Generator loss: 2.5057%]\n",
            "294 [Discriminator loss: 0.1874%, acc.: 92.97%] [Generator loss: 2.5807%]\n",
            "295 [Discriminator loss: 0.3150%, acc.: 84.77%] [Generator loss: 2.1568%]\n",
            "296 [Discriminator loss: 0.1590%, acc.: 93.36%] [Generator loss: 2.6103%]\n",
            "297 [Discriminator loss: 0.3167%, acc.: 85.55%] [Generator loss: 2.2263%]\n",
            "298 [Discriminator loss: 0.1897%, acc.: 90.62%] [Generator loss: 2.6721%]\n",
            "299 [Discriminator loss: 0.2860%, acc.: 85.16%] [Generator loss: 2.3478%]\n",
            "300 [Discriminator loss: 0.1563%, acc.: 95.31%] [Generator loss: 2.5509%]\n",
            "301 [Discriminator loss: 0.2774%, acc.: 87.89%] [Generator loss: 2.0973%]\n",
            "302 [Discriminator loss: 0.2046%, acc.: 91.80%] [Generator loss: 2.5958%]\n",
            "303 [Discriminator loss: 0.2519%, acc.: 90.23%] [Generator loss: 2.4690%]\n",
            "304 [Discriminator loss: 0.2418%, acc.: 89.45%] [Generator loss: 2.4757%]\n",
            "305 [Discriminator loss: 0.1740%, acc.: 94.14%] [Generator loss: 2.4765%]\n",
            "306 [Discriminator loss: 0.2951%, acc.: 84.38%] [Generator loss: 2.2390%]\n",
            "307 [Discriminator loss: 0.1546%, acc.: 96.88%] [Generator loss: 2.6087%]\n",
            "308 [Discriminator loss: 0.2557%, acc.: 89.84%] [Generator loss: 2.3631%]\n",
            "309 [Discriminator loss: 0.1856%, acc.: 97.27%] [Generator loss: 2.5203%]\n",
            "310 [Discriminator loss: 0.3705%, acc.: 80.47%] [Generator loss: 1.9914%]\n",
            "311 [Discriminator loss: 0.1753%, acc.: 91.41%] [Generator loss: 2.7479%]\n",
            "312 [Discriminator loss: 0.4161%, acc.: 78.52%] [Generator loss: 1.7981%]\n",
            "313 [Discriminator loss: 0.2105%, acc.: 89.45%] [Generator loss: 2.5051%]\n",
            "314 [Discriminator loss: 0.1460%, acc.: 99.61%] [Generator loss: 2.9009%]\n",
            "315 [Discriminator loss: 0.3170%, acc.: 85.94%] [Generator loss: 2.1919%]\n",
            "316 [Discriminator loss: 0.1689%, acc.: 91.02%] [Generator loss: 2.6577%]\n",
            "317 [Discriminator loss: 0.1843%, acc.: 94.53%] [Generator loss: 2.7020%]\n",
            "318 [Discriminator loss: 0.2299%, acc.: 89.84%] [Generator loss: 2.5693%]\n",
            "319 [Discriminator loss: 0.1793%, acc.: 93.36%] [Generator loss: 2.4267%]\n",
            "320 [Discriminator loss: 0.2144%, acc.: 90.62%] [Generator loss: 2.4375%]\n",
            "321 [Discriminator loss: 0.3025%, acc.: 84.77%] [Generator loss: 2.1526%]\n",
            "322 [Discriminator loss: 0.2013%, acc.: 89.06%] [Generator loss: 2.7626%]\n",
            "323 [Discriminator loss: 0.3014%, acc.: 85.16%] [Generator loss: 2.0676%]\n",
            "324 [Discriminator loss: 0.1943%, acc.: 90.62%] [Generator loss: 2.7835%]\n",
            "325 [Discriminator loss: 0.2981%, acc.: 85.55%] [Generator loss: 2.0642%]\n",
            "326 [Discriminator loss: 0.1631%, acc.: 93.75%] [Generator loss: 2.5254%]\n",
            "327 [Discriminator loss: 0.1786%, acc.: 94.53%] [Generator loss: 2.5476%]\n",
            "328 [Discriminator loss: 0.2662%, acc.: 87.50%] [Generator loss: 2.2695%]\n",
            "329 [Discriminator loss: 0.1813%, acc.: 94.53%] [Generator loss: 2.6761%]\n",
            "330 [Discriminator loss: 0.3237%, acc.: 83.59%] [Generator loss: 2.2051%]\n",
            "331 [Discriminator loss: 0.1567%, acc.: 95.70%] [Generator loss: 2.5856%]\n",
            "332 [Discriminator loss: 0.2833%, acc.: 86.33%] [Generator loss: 2.3194%]\n",
            "333 [Discriminator loss: 0.2190%, acc.: 90.62%] [Generator loss: 2.5481%]\n",
            "334 [Discriminator loss: 0.3206%, acc.: 85.55%] [Generator loss: 2.2209%]\n",
            "335 [Discriminator loss: 0.1887%, acc.: 92.58%] [Generator loss: 2.6603%]\n",
            "336 [Discriminator loss: 0.2786%, acc.: 89.45%] [Generator loss: 1.9923%]\n",
            "337 [Discriminator loss: 0.2160%, acc.: 88.28%] [Generator loss: 2.6519%]\n",
            "338 [Discriminator loss: 0.3393%, acc.: 82.42%] [Generator loss: 2.1687%]\n",
            "339 [Discriminator loss: 0.1793%, acc.: 96.09%] [Generator loss: 2.6719%]\n",
            "340 [Discriminator loss: 0.3620%, acc.: 81.25%] [Generator loss: 2.0388%]\n",
            "341 [Discriminator loss: 0.1745%, acc.: 94.14%] [Generator loss: 2.7037%]\n",
            "342 [Discriminator loss: 0.3456%, acc.: 83.98%] [Generator loss: 2.0995%]\n",
            "343 [Discriminator loss: 0.1872%, acc.: 94.14%] [Generator loss: 2.5497%]\n",
            "344 [Discriminator loss: 0.2653%, acc.: 90.62%] [Generator loss: 2.3143%]\n",
            "345 [Discriminator loss: 0.2133%, acc.: 91.41%] [Generator loss: 2.7171%]\n",
            "346 [Discriminator loss: 0.3882%, acc.: 80.47%] [Generator loss: 1.9385%]\n",
            "347 [Discriminator loss: 0.1900%, acc.: 92.19%] [Generator loss: 2.6903%]\n",
            "348 [Discriminator loss: 0.1940%, acc.: 95.70%] [Generator loss: 2.4102%]\n",
            "349 [Discriminator loss: 0.1965%, acc.: 96.48%] [Generator loss: 2.5299%]\n",
            "350 [Discriminator loss: 0.2290%, acc.: 91.02%] [Generator loss: 2.2197%]\n",
            "351 [Discriminator loss: 0.1971%, acc.: 92.97%] [Generator loss: 2.7512%]\n",
            "352 [Discriminator loss: 0.3231%, acc.: 85.16%] [Generator loss: 2.1584%]\n",
            "353 [Discriminator loss: 0.1881%, acc.: 95.31%] [Generator loss: 2.6288%]\n",
            "354 [Discriminator loss: 0.3235%, acc.: 82.81%] [Generator loss: 2.0809%]\n",
            "355 [Discriminator loss: 0.1925%, acc.: 91.41%] [Generator loss: 2.7948%]\n",
            "356 [Discriminator loss: 0.3951%, acc.: 80.86%] [Generator loss: 1.7391%]\n",
            "357 [Discriminator loss: 0.2406%, acc.: 85.16%] [Generator loss: 2.3641%]\n",
            "358 [Discriminator loss: 0.1611%, acc.: 99.61%] [Generator loss: 2.9039%]\n",
            "359 [Discriminator loss: 0.3577%, acc.: 78.91%] [Generator loss: 2.0454%]\n",
            "360 [Discriminator loss: 0.1883%, acc.: 94.14%] [Generator loss: 2.6227%]\n",
            "361 [Discriminator loss: 0.2178%, acc.: 93.75%] [Generator loss: 2.4775%]\n",
            "362 [Discriminator loss: 0.2892%, acc.: 89.06%] [Generator loss: 2.2943%]\n",
            "363 [Discriminator loss: 0.2567%, acc.: 88.28%] [Generator loss: 2.4700%]\n",
            "364 [Discriminator loss: 0.2098%, acc.: 91.41%] [Generator loss: 2.4360%]\n",
            "365 [Discriminator loss: 0.3498%, acc.: 80.47%] [Generator loss: 2.1984%]\n",
            "366 [Discriminator loss: 0.2854%, acc.: 86.72%] [Generator loss: 2.3887%]\n",
            "367 [Discriminator loss: 0.3058%, acc.: 85.16%] [Generator loss: 2.4301%]\n",
            "368 [Discriminator loss: 0.2806%, acc.: 87.50%] [Generator loss: 2.3744%]\n",
            "369 [Discriminator loss: 0.2708%, acc.: 87.89%] [Generator loss: 2.3073%]\n",
            "370 [Discriminator loss: 0.3161%, acc.: 81.64%] [Generator loss: 2.5517%]\n",
            "371 [Discriminator loss: 0.3033%, acc.: 87.89%] [Generator loss: 2.2312%]\n",
            "372 [Discriminator loss: 0.2590%, acc.: 87.11%] [Generator loss: 2.5438%]\n",
            "373 [Discriminator loss: 0.5053%, acc.: 73.44%] [Generator loss: 1.8146%]\n",
            "374 [Discriminator loss: 0.2244%, acc.: 86.33%] [Generator loss: 2.8037%]\n",
            "375 [Discriminator loss: 0.4247%, acc.: 75.78%] [Generator loss: 1.9387%]\n",
            "376 [Discriminator loss: 0.2461%, acc.: 85.55%] [Generator loss: 2.6366%]\n",
            "377 [Discriminator loss: 0.3479%, acc.: 83.59%] [Generator loss: 2.1674%]\n",
            "378 [Discriminator loss: 0.2557%, acc.: 87.89%] [Generator loss: 2.5228%]\n",
            "379 [Discriminator loss: 0.4209%, acc.: 76.95%] [Generator loss: 2.1485%]\n",
            "380 [Discriminator loss: 0.2414%, acc.: 89.06%] [Generator loss: 2.4834%]\n",
            "381 [Discriminator loss: 0.4105%, acc.: 77.73%] [Generator loss: 1.7607%]\n",
            "382 [Discriminator loss: 0.2565%, acc.: 84.77%] [Generator loss: 2.7188%]\n",
            "383 [Discriminator loss: 0.5596%, acc.: 70.31%] [Generator loss: 1.6854%]\n",
            "384 [Discriminator loss: 0.2056%, acc.: 89.84%] [Generator loss: 2.6675%]\n",
            "385 [Discriminator loss: 0.3177%, acc.: 87.50%] [Generator loss: 2.3845%]\n",
            "386 [Discriminator loss: 0.2682%, acc.: 85.16%] [Generator loss: 2.4527%]\n",
            "387 [Discriminator loss: 0.3439%, acc.: 84.38%] [Generator loss: 1.9677%]\n",
            "388 [Discriminator loss: 0.2333%, acc.: 89.45%] [Generator loss: 2.6413%]\n",
            "389 [Discriminator loss: 0.4483%, acc.: 77.73%] [Generator loss: 1.7093%]\n",
            "390 [Discriminator loss: 0.2268%, acc.: 88.67%] [Generator loss: 2.4617%]\n",
            "391 [Discriminator loss: 0.4354%, acc.: 79.69%] [Generator loss: 1.9594%]\n",
            "392 [Discriminator loss: 0.2678%, acc.: 87.11%] [Generator loss: 2.6101%]\n",
            "393 [Discriminator loss: 0.4454%, acc.: 76.17%] [Generator loss: 1.8244%]\n",
            "394 [Discriminator loss: 0.2329%, acc.: 88.67%] [Generator loss: 2.4817%]\n",
            "395 [Discriminator loss: 0.3810%, acc.: 80.08%] [Generator loss: 1.9679%]\n",
            "396 [Discriminator loss: 0.2557%, acc.: 85.55%] [Generator loss: 2.5886%]\n",
            "397 [Discriminator loss: 0.3823%, acc.: 79.69%] [Generator loss: 1.8676%]\n",
            "398 [Discriminator loss: 0.2117%, acc.: 92.97%] [Generator loss: 2.3293%]\n",
            "399 [Discriminator loss: 0.3769%, acc.: 80.08%] [Generator loss: 2.0289%]\n",
            "400 [Discriminator loss: 0.2649%, acc.: 86.72%] [Generator loss: 2.5169%]\n",
            "401 [Discriminator loss: 0.4810%, acc.: 73.83%] [Generator loss: 1.6136%]\n",
            "402 [Discriminator loss: 0.2441%, acc.: 88.67%] [Generator loss: 2.4729%]\n",
            "403 [Discriminator loss: 0.4364%, acc.: 75.78%] [Generator loss: 1.8998%]\n",
            "404 [Discriminator loss: 0.2470%, acc.: 89.45%] [Generator loss: 2.5859%]\n",
            "405 [Discriminator loss: 0.5055%, acc.: 71.88%] [Generator loss: 1.6892%]\n",
            "406 [Discriminator loss: 0.2338%, acc.: 88.67%] [Generator loss: 2.6254%]\n",
            "407 [Discriminator loss: 0.4058%, acc.: 79.30%] [Generator loss: 1.9990%]\n",
            "408 [Discriminator loss: 0.2731%, acc.: 85.16%] [Generator loss: 2.2925%]\n",
            "409 [Discriminator loss: 0.2741%, acc.: 91.02%] [Generator loss: 2.2024%]\n",
            "410 [Discriminator loss: 0.2899%, acc.: 86.33%] [Generator loss: 2.1904%]\n",
            "411 [Discriminator loss: 0.2888%, acc.: 85.16%] [Generator loss: 2.0643%]\n",
            "412 [Discriminator loss: 0.2834%, acc.: 84.77%] [Generator loss: 2.2770%]\n",
            "413 [Discriminator loss: 0.4039%, acc.: 78.12%] [Generator loss: 1.9492%]\n",
            "414 [Discriminator loss: 0.2512%, acc.: 87.89%] [Generator loss: 2.5482%]\n",
            "415 [Discriminator loss: 0.6888%, acc.: 63.28%] [Generator loss: 1.2804%]\n",
            "416 [Discriminator loss: 0.2688%, acc.: 83.20%] [Generator loss: 2.1997%]\n",
            "417 [Discriminator loss: 0.2668%, acc.: 94.92%] [Generator loss: 2.2501%]\n",
            "418 [Discriminator loss: 0.3394%, acc.: 82.03%] [Generator loss: 2.0739%]\n",
            "419 [Discriminator loss: 0.2718%, acc.: 89.06%] [Generator loss: 2.2859%]\n",
            "420 [Discriminator loss: 0.4385%, acc.: 79.30%] [Generator loss: 1.6784%]\n",
            "421 [Discriminator loss: 0.2674%, acc.: 87.11%] [Generator loss: 2.3284%]\n",
            "422 [Discriminator loss: 0.3904%, acc.: 78.91%] [Generator loss: 1.9613%]\n",
            "423 [Discriminator loss: 0.3128%, acc.: 82.42%] [Generator loss: 2.3130%]\n",
            "424 [Discriminator loss: 0.3963%, acc.: 80.47%] [Generator loss: 2.1001%]\n",
            "425 [Discriminator loss: 0.3679%, acc.: 79.30%] [Generator loss: 1.9946%]\n",
            "426 [Discriminator loss: 0.3962%, acc.: 77.73%] [Generator loss: 1.9374%]\n",
            "427 [Discriminator loss: 0.3437%, acc.: 85.16%] [Generator loss: 2.1123%]\n",
            "428 [Discriminator loss: 0.3649%, acc.: 83.98%] [Generator loss: 1.9817%]\n",
            "429 [Discriminator loss: 0.3485%, acc.: 82.42%] [Generator loss: 2.0742%]\n",
            "430 [Discriminator loss: 0.3493%, acc.: 85.55%] [Generator loss: 2.0431%]\n",
            "431 [Discriminator loss: 0.3212%, acc.: 83.59%] [Generator loss: 1.9742%]\n",
            "432 [Discriminator loss: 0.3651%, acc.: 80.47%] [Generator loss: 2.3880%]\n",
            "433 [Discriminator loss: 0.4224%, acc.: 77.34%] [Generator loss: 1.8217%]\n",
            "434 [Discriminator loss: 0.3098%, acc.: 84.38%] [Generator loss: 2.2610%]\n",
            "435 [Discriminator loss: 0.4665%, acc.: 75.39%] [Generator loss: 1.7440%]\n",
            "436 [Discriminator loss: 0.2827%, acc.: 86.72%] [Generator loss: 2.1310%]\n",
            "437 [Discriminator loss: 0.4361%, acc.: 77.73%] [Generator loss: 1.6824%]\n",
            "438 [Discriminator loss: 0.2821%, acc.: 87.50%] [Generator loss: 2.2718%]\n",
            "439 [Discriminator loss: 0.3902%, acc.: 80.08%] [Generator loss: 1.7664%]\n",
            "440 [Discriminator loss: 0.2874%, acc.: 86.72%] [Generator loss: 2.2100%]\n",
            "441 [Discriminator loss: 0.4133%, acc.: 80.08%] [Generator loss: 1.8989%]\n",
            "442 [Discriminator loss: 0.3045%, acc.: 85.94%] [Generator loss: 2.3004%]\n",
            "443 [Discriminator loss: 0.4447%, acc.: 76.56%] [Generator loss: 1.8190%]\n",
            "444 [Discriminator loss: 0.2808%, acc.: 84.38%] [Generator loss: 2.4206%]\n",
            "445 [Discriminator loss: 0.4673%, acc.: 75.00%] [Generator loss: 1.7157%]\n",
            "446 [Discriminator loss: 0.2719%, acc.: 88.28%] [Generator loss: 2.2490%]\n",
            "447 [Discriminator loss: 0.4060%, acc.: 78.12%] [Generator loss: 1.8820%]\n",
            "448 [Discriminator loss: 0.3020%, acc.: 86.72%] [Generator loss: 1.9919%]\n",
            "449 [Discriminator loss: 0.3546%, acc.: 82.03%] [Generator loss: 1.9619%]\n",
            "450 [Discriminator loss: 0.3660%, acc.: 83.20%] [Generator loss: 2.1031%]\n",
            "451 [Discriminator loss: 0.3386%, acc.: 83.59%] [Generator loss: 1.9578%]\n",
            "452 [Discriminator loss: 0.3781%, acc.: 80.47%] [Generator loss: 1.9646%]\n",
            "453 [Discriminator loss: 0.3937%, acc.: 76.95%] [Generator loss: 1.9605%]\n",
            "454 [Discriminator loss: 0.3654%, acc.: 79.69%] [Generator loss: 2.0630%]\n",
            "455 [Discriminator loss: 0.4113%, acc.: 78.52%] [Generator loss: 1.8663%]\n",
            "456 [Discriminator loss: 0.3709%, acc.: 80.08%] [Generator loss: 1.9979%]\n",
            "457 [Discriminator loss: 0.4294%, acc.: 78.52%] [Generator loss: 2.0308%]\n",
            "458 [Discriminator loss: 0.3366%, acc.: 82.03%] [Generator loss: 2.2749%]\n",
            "459 [Discriminator loss: 0.4265%, acc.: 77.73%] [Generator loss: 1.9193%]\n",
            "460 [Discriminator loss: 0.3935%, acc.: 78.91%] [Generator loss: 2.0654%]\n",
            "461 [Discriminator loss: 0.3892%, acc.: 78.52%] [Generator loss: 2.0587%]\n",
            "462 [Discriminator loss: 0.4768%, acc.: 71.48%] [Generator loss: 1.8962%]\n",
            "463 [Discriminator loss: 0.3699%, acc.: 81.25%] [Generator loss: 1.9783%]\n",
            "464 [Discriminator loss: 0.4487%, acc.: 75.78%] [Generator loss: 1.9172%]\n",
            "465 [Discriminator loss: 0.3614%, acc.: 83.20%] [Generator loss: 1.8434%]\n",
            "466 [Discriminator loss: 0.3773%, acc.: 82.42%] [Generator loss: 2.0870%]\n",
            "467 [Discriminator loss: 0.3861%, acc.: 82.81%] [Generator loss: 1.8515%]\n",
            "468 [Discriminator loss: 0.3357%, acc.: 82.03%] [Generator loss: 2.1180%]\n",
            "469 [Discriminator loss: 0.4480%, acc.: 76.17%] [Generator loss: 1.9437%]\n",
            "470 [Discriminator loss: 0.3515%, acc.: 80.08%] [Generator loss: 2.0483%]\n",
            "471 [Discriminator loss: 0.5413%, acc.: 67.58%] [Generator loss: 1.6236%]\n",
            "472 [Discriminator loss: 0.2996%, acc.: 86.72%] [Generator loss: 2.1246%]\n",
            "473 [Discriminator loss: 0.5659%, acc.: 68.36%] [Generator loss: 1.6740%]\n",
            "474 [Discriminator loss: 0.3115%, acc.: 88.28%] [Generator loss: 2.1353%]\n",
            "475 [Discriminator loss: 0.4194%, acc.: 77.34%] [Generator loss: 1.9784%]\n",
            "476 [Discriminator loss: 0.3335%, acc.: 85.16%] [Generator loss: 1.9964%]\n",
            "477 [Discriminator loss: 0.4222%, acc.: 76.56%] [Generator loss: 1.6973%]\n",
            "478 [Discriminator loss: 0.3122%, acc.: 84.77%] [Generator loss: 2.0860%]\n",
            "479 [Discriminator loss: 0.4855%, acc.: 75.78%] [Generator loss: 1.7105%]\n",
            "480 [Discriminator loss: 0.3310%, acc.: 80.47%] [Generator loss: 2.2792%]\n",
            "481 [Discriminator loss: 0.5584%, acc.: 71.88%] [Generator loss: 1.5784%]\n",
            "482 [Discriminator loss: 0.3367%, acc.: 80.86%] [Generator loss: 2.2155%]\n",
            "483 [Discriminator loss: 0.6157%, acc.: 64.84%] [Generator loss: 1.3364%]\n",
            "484 [Discriminator loss: 0.3429%, acc.: 80.08%] [Generator loss: 2.1397%]\n",
            "485 [Discriminator loss: 0.5496%, acc.: 66.02%] [Generator loss: 1.5514%]\n",
            "486 [Discriminator loss: 0.3586%, acc.: 80.86%] [Generator loss: 1.8555%]\n",
            "487 [Discriminator loss: 0.5251%, acc.: 72.27%] [Generator loss: 1.5861%]\n",
            "488 [Discriminator loss: 0.3650%, acc.: 80.47%] [Generator loss: 1.8624%]\n",
            "489 [Discriminator loss: 0.4789%, acc.: 74.61%] [Generator loss: 1.5181%]\n",
            "490 [Discriminator loss: 0.3993%, acc.: 78.12%] [Generator loss: 1.7490%]\n",
            "491 [Discriminator loss: 0.4225%, acc.: 77.34%] [Generator loss: 1.8537%]\n",
            "492 [Discriminator loss: 0.4374%, acc.: 76.95%] [Generator loss: 1.6619%]\n",
            "493 [Discriminator loss: 0.4279%, acc.: 76.56%] [Generator loss: 1.7761%]\n",
            "494 [Discriminator loss: 0.4690%, acc.: 74.22%] [Generator loss: 1.5644%]\n",
            "495 [Discriminator loss: 0.3892%, acc.: 80.86%] [Generator loss: 1.8532%]\n",
            "496 [Discriminator loss: 0.5507%, acc.: 68.75%] [Generator loss: 1.4482%]\n",
            "497 [Discriminator loss: 0.3606%, acc.: 79.69%] [Generator loss: 1.7902%]\n",
            "498 [Discriminator loss: 0.5513%, acc.: 72.27%] [Generator loss: 1.3290%]\n",
            "499 [Discriminator loss: 0.3372%, acc.: 80.47%] [Generator loss: 1.9068%]\n",
            "500 [Discriminator loss: 0.4529%, acc.: 79.30%] [Generator loss: 1.5927%]\n",
            "501 [Discriminator loss: 0.4101%, acc.: 75.39%] [Generator loss: 1.7772%]\n",
            "502 [Discriminator loss: 0.4160%, acc.: 80.86%] [Generator loss: 1.7398%]\n",
            "503 [Discriminator loss: 0.4292%, acc.: 78.12%] [Generator loss: 1.7202%]\n",
            "504 [Discriminator loss: 0.4183%, acc.: 79.69%] [Generator loss: 1.7593%]\n",
            "505 [Discriminator loss: 0.4711%, acc.: 76.95%] [Generator loss: 1.4907%]\n",
            "506 [Discriminator loss: 0.4162%, acc.: 78.52%] [Generator loss: 1.8028%]\n",
            "507 [Discriminator loss: 0.4999%, acc.: 78.12%] [Generator loss: 1.4574%]\n",
            "508 [Discriminator loss: 0.4093%, acc.: 80.86%] [Generator loss: 1.6167%]\n",
            "509 [Discriminator loss: 0.5042%, acc.: 72.27%] [Generator loss: 1.5934%]\n",
            "510 [Discriminator loss: 0.4157%, acc.: 82.81%] [Generator loss: 1.6016%]\n",
            "511 [Discriminator loss: 0.4981%, acc.: 73.05%] [Generator loss: 1.4910%]\n",
            "512 [Discriminator loss: 0.4514%, acc.: 77.73%] [Generator loss: 1.6529%]\n",
            "513 [Discriminator loss: 0.4484%, acc.: 75.39%] [Generator loss: 1.6699%]\n",
            "514 [Discriminator loss: 0.4788%, acc.: 74.61%] [Generator loss: 1.4777%]\n",
            "515 [Discriminator loss: 0.4397%, acc.: 79.30%] [Generator loss: 1.6340%]\n",
            "516 [Discriminator loss: 0.4777%, acc.: 76.56%] [Generator loss: 1.5880%]\n",
            "517 [Discriminator loss: 0.4465%, acc.: 78.52%] [Generator loss: 1.6343%]\n",
            "518 [Discriminator loss: 0.4418%, acc.: 77.73%] [Generator loss: 1.6053%]\n",
            "519 [Discriminator loss: 0.5145%, acc.: 72.27%] [Generator loss: 1.4935%]\n",
            "520 [Discriminator loss: 0.4693%, acc.: 78.52%] [Generator loss: 1.5639%]\n",
            "521 [Discriminator loss: 0.5365%, acc.: 69.53%] [Generator loss: 1.4010%]\n",
            "522 [Discriminator loss: 0.4771%, acc.: 75.78%] [Generator loss: 1.5611%]\n",
            "523 [Discriminator loss: 0.5319%, acc.: 69.53%] [Generator loss: 1.5618%]\n",
            "524 [Discriminator loss: 0.4598%, acc.: 76.95%] [Generator loss: 1.6556%]\n",
            "525 [Discriminator loss: 0.5754%, acc.: 68.75%] [Generator loss: 1.4130%]\n",
            "526 [Discriminator loss: 0.4739%, acc.: 76.17%] [Generator loss: 1.6112%]\n",
            "527 [Discriminator loss: 0.5426%, acc.: 74.61%] [Generator loss: 1.5288%]\n",
            "528 [Discriminator loss: 0.4874%, acc.: 77.34%] [Generator loss: 1.5692%]\n",
            "529 [Discriminator loss: 0.4882%, acc.: 73.05%] [Generator loss: 1.5912%]\n",
            "530 [Discriminator loss: 0.5207%, acc.: 72.27%] [Generator loss: 1.5508%]\n",
            "531 [Discriminator loss: 0.5612%, acc.: 67.97%] [Generator loss: 1.4454%]\n",
            "532 [Discriminator loss: 0.5415%, acc.: 71.09%] [Generator loss: 1.4378%]\n",
            "533 [Discriminator loss: 0.4694%, acc.: 75.78%] [Generator loss: 1.5779%]\n",
            "534 [Discriminator loss: 0.5705%, acc.: 63.28%] [Generator loss: 1.3858%]\n",
            "535 [Discriminator loss: 0.4692%, acc.: 76.56%] [Generator loss: 1.4933%]\n",
            "536 [Discriminator loss: 0.5447%, acc.: 70.31%] [Generator loss: 1.3383%]\n",
            "537 [Discriminator loss: 0.5159%, acc.: 75.00%] [Generator loss: 1.5366%]\n",
            "538 [Discriminator loss: 0.4886%, acc.: 76.17%] [Generator loss: 1.5132%]\n",
            "539 [Discriminator loss: 0.5166%, acc.: 71.09%] [Generator loss: 1.4491%]\n",
            "540 [Discriminator loss: 0.5459%, acc.: 69.14%] [Generator loss: 1.3582%]\n",
            "541 [Discriminator loss: 0.4925%, acc.: 73.05%] [Generator loss: 1.4669%]\n",
            "542 [Discriminator loss: 0.5827%, acc.: 61.33%] [Generator loss: 1.3642%]\n",
            "543 [Discriminator loss: 0.5115%, acc.: 74.22%] [Generator loss: 1.5323%]\n",
            "544 [Discriminator loss: 0.5326%, acc.: 71.88%] [Generator loss: 1.3579%]\n",
            "545 [Discriminator loss: 0.5504%, acc.: 70.31%] [Generator loss: 1.3396%]\n",
            "546 [Discriminator loss: 0.4772%, acc.: 75.39%] [Generator loss: 1.5365%]\n",
            "547 [Discriminator loss: 0.6332%, acc.: 59.77%] [Generator loss: 1.2656%]\n",
            "548 [Discriminator loss: 0.5144%, acc.: 72.66%] [Generator loss: 1.4080%]\n",
            "549 [Discriminator loss: 0.6005%, acc.: 65.62%] [Generator loss: 1.3079%]\n",
            "550 [Discriminator loss: 0.5295%, acc.: 73.83%] [Generator loss: 1.3994%]\n",
            "551 [Discriminator loss: 0.5679%, acc.: 65.62%] [Generator loss: 1.4158%]\n",
            "552 [Discriminator loss: 0.5476%, acc.: 70.31%] [Generator loss: 1.3459%]\n",
            "553 [Discriminator loss: 0.5657%, acc.: 71.09%] [Generator loss: 1.2954%]\n",
            "554 [Discriminator loss: 0.5418%, acc.: 69.92%] [Generator loss: 1.3375%]\n",
            "555 [Discriminator loss: 0.6582%, acc.: 54.69%] [Generator loss: 1.1429%]\n",
            "556 [Discriminator loss: 0.5265%, acc.: 62.89%] [Generator loss: 1.3298%]\n",
            "557 [Discriminator loss: 0.5743%, acc.: 61.33%] [Generator loss: 1.3071%]\n",
            "558 [Discriminator loss: 0.5981%, acc.: 65.62%] [Generator loss: 1.1887%]\n",
            "559 [Discriminator loss: 0.5487%, acc.: 69.53%] [Generator loss: 1.3105%]\n",
            "560 [Discriminator loss: 0.5671%, acc.: 68.75%] [Generator loss: 1.1779%]\n",
            "561 [Discriminator loss: 0.5782%, acc.: 65.62%] [Generator loss: 1.3073%]\n",
            "562 [Discriminator loss: 0.5791%, acc.: 66.41%] [Generator loss: 1.3152%]\n",
            "563 [Discriminator loss: 0.6028%, acc.: 65.23%] [Generator loss: 1.2304%]\n",
            "564 [Discriminator loss: 0.5593%, acc.: 67.19%] [Generator loss: 1.2762%]\n",
            "565 [Discriminator loss: 0.6043%, acc.: 65.23%] [Generator loss: 1.1836%]\n",
            "566 [Discriminator loss: 0.5719%, acc.: 67.97%] [Generator loss: 1.3243%]\n",
            "567 [Discriminator loss: 0.5957%, acc.: 63.67%] [Generator loss: 1.2835%]\n",
            "568 [Discriminator loss: 0.5748%, acc.: 66.80%] [Generator loss: 1.2030%]\n",
            "569 [Discriminator loss: 0.5727%, acc.: 66.80%] [Generator loss: 1.2872%]\n",
            "570 [Discriminator loss: 0.6264%, acc.: 61.72%] [Generator loss: 1.2330%]\n",
            "571 [Discriminator loss: 0.6183%, acc.: 63.28%] [Generator loss: 1.2215%]\n",
            "572 [Discriminator loss: 0.5947%, acc.: 64.84%] [Generator loss: 1.2477%]\n",
            "573 [Discriminator loss: 0.5781%, acc.: 68.36%] [Generator loss: 1.2898%]\n",
            "574 [Discriminator loss: 0.6391%, acc.: 61.33%] [Generator loss: 1.2288%]\n",
            "575 [Discriminator loss: 0.5192%, acc.: 73.44%] [Generator loss: 1.3701%]\n",
            "576 [Discriminator loss: 0.6230%, acc.: 63.28%] [Generator loss: 1.2031%]\n",
            "577 [Discriminator loss: 0.5542%, acc.: 67.97%] [Generator loss: 1.3413%]\n",
            "578 [Discriminator loss: 0.6180%, acc.: 59.77%] [Generator loss: 1.2284%]\n",
            "579 [Discriminator loss: 0.6229%, acc.: 60.94%] [Generator loss: 1.1994%]\n",
            "580 [Discriminator loss: 0.6140%, acc.: 58.20%] [Generator loss: 1.2349%]\n",
            "581 [Discriminator loss: 0.6706%, acc.: 52.34%] [Generator loss: 1.1131%]\n",
            "582 [Discriminator loss: 0.6022%, acc.: 59.77%] [Generator loss: 1.1562%]\n",
            "583 [Discriminator loss: 0.6036%, acc.: 62.50%] [Generator loss: 1.1441%]\n",
            "584 [Discriminator loss: 0.6251%, acc.: 62.11%] [Generator loss: 1.2177%]\n",
            "585 [Discriminator loss: 0.5847%, acc.: 67.19%] [Generator loss: 1.1558%]\n",
            "586 [Discriminator loss: 0.6063%, acc.: 63.67%] [Generator loss: 1.1253%]\n",
            "587 [Discriminator loss: 0.6245%, acc.: 58.98%] [Generator loss: 1.1165%]\n",
            "588 [Discriminator loss: 0.6120%, acc.: 60.94%] [Generator loss: 1.1489%]\n",
            "589 [Discriminator loss: 0.6388%, acc.: 58.20%] [Generator loss: 1.1013%]\n",
            "590 [Discriminator loss: 0.5885%, acc.: 65.23%] [Generator loss: 1.0900%]\n",
            "591 [Discriminator loss: 0.6030%, acc.: 64.06%] [Generator loss: 1.1304%]\n",
            "592 [Discriminator loss: 0.6269%, acc.: 58.98%] [Generator loss: 1.0681%]\n",
            "593 [Discriminator loss: 0.6523%, acc.: 55.08%] [Generator loss: 1.0380%]\n",
            "594 [Discriminator loss: 0.6081%, acc.: 59.77%] [Generator loss: 1.0975%]\n",
            "595 [Discriminator loss: 0.6770%, acc.: 48.83%] [Generator loss: 0.9692%]\n",
            "596 [Discriminator loss: 0.6721%, acc.: 48.05%] [Generator loss: 0.9529%]\n",
            "597 [Discriminator loss: 0.6253%, acc.: 59.38%] [Generator loss: 1.0590%]\n",
            "598 [Discriminator loss: 0.6689%, acc.: 52.34%] [Generator loss: 1.0048%]\n",
            "599 [Discriminator loss: 0.6590%, acc.: 49.22%] [Generator loss: 0.9984%]\n",
            "600 [Discriminator loss: 0.6329%, acc.: 50.39%] [Generator loss: 1.0114%]\n",
            "601 [Discriminator loss: 0.6775%, acc.: 46.48%] [Generator loss: 0.9352%]\n",
            "602 [Discriminator loss: 0.6728%, acc.: 45.70%] [Generator loss: 0.9499%]\n",
            "603 [Discriminator loss: 0.6317%, acc.: 50.39%] [Generator loss: 1.0661%]\n",
            "604 [Discriminator loss: 0.6643%, acc.: 46.88%] [Generator loss: 1.0138%]\n",
            "605 [Discriminator loss: 0.6423%, acc.: 44.14%] [Generator loss: 0.9864%]\n",
            "606 [Discriminator loss: 0.6677%, acc.: 42.97%] [Generator loss: 0.9641%]\n",
            "607 [Discriminator loss: 0.6607%, acc.: 43.75%] [Generator loss: 0.9734%]\n",
            "608 [Discriminator loss: 0.6403%, acc.: 48.05%] [Generator loss: 1.0124%]\n",
            "609 [Discriminator loss: 0.6940%, acc.: 47.66%] [Generator loss: 0.9185%]\n",
            "610 [Discriminator loss: 0.6470%, acc.: 46.48%] [Generator loss: 0.9554%]\n",
            "611 [Discriminator loss: 0.6835%, acc.: 42.58%] [Generator loss: 0.9078%]\n",
            "612 [Discriminator loss: 0.6641%, acc.: 46.88%] [Generator loss: 0.9557%]\n",
            "613 [Discriminator loss: 0.6371%, acc.: 52.34%] [Generator loss: 0.9560%]\n",
            "614 [Discriminator loss: 0.6665%, acc.: 46.88%] [Generator loss: 0.9503%]\n",
            "615 [Discriminator loss: 0.6887%, acc.: 44.14%] [Generator loss: 0.9169%]\n",
            "616 [Discriminator loss: 0.6703%, acc.: 45.31%] [Generator loss: 0.9056%]\n",
            "617 [Discriminator loss: 0.6373%, acc.: 50.39%] [Generator loss: 0.9399%]\n",
            "618 [Discriminator loss: 0.6426%, acc.: 54.30%] [Generator loss: 0.9405%]\n",
            "619 [Discriminator loss: 0.6709%, acc.: 48.83%] [Generator loss: 0.9128%]\n",
            "620 [Discriminator loss: 0.6327%, acc.: 55.47%] [Generator loss: 0.9279%]\n",
            "621 [Discriminator loss: 0.6249%, acc.: 53.91%] [Generator loss: 0.9494%]\n",
            "622 [Discriminator loss: 0.6315%, acc.: 58.98%] [Generator loss: 0.9636%]\n",
            "623 [Discriminator loss: 0.6356%, acc.: 55.08%] [Generator loss: 0.9481%]\n",
            "624 [Discriminator loss: 0.6502%, acc.: 50.78%] [Generator loss: 0.9370%]\n",
            "625 [Discriminator loss: 0.6080%, acc.: 64.06%] [Generator loss: 0.9686%]\n",
            "626 [Discriminator loss: 0.6631%, acc.: 58.59%] [Generator loss: 0.9161%]\n",
            "627 [Discriminator loss: 0.6205%, acc.: 61.33%] [Generator loss: 0.9635%]\n",
            "628 [Discriminator loss: 0.6285%, acc.: 63.67%] [Generator loss: 0.9636%]\n",
            "629 [Discriminator loss: 0.6260%, acc.: 62.11%] [Generator loss: 0.9424%]\n",
            "630 [Discriminator loss: 0.6325%, acc.: 61.72%] [Generator loss: 0.9283%]\n",
            "631 [Discriminator loss: 0.6297%, acc.: 58.98%] [Generator loss: 0.9464%]\n",
            "632 [Discriminator loss: 0.6110%, acc.: 64.45%] [Generator loss: 0.9384%]\n",
            "633 [Discriminator loss: 0.6336%, acc.: 60.94%] [Generator loss: 0.9122%]\n",
            "634 [Discriminator loss: 0.6440%, acc.: 57.42%] [Generator loss: 0.9247%]\n",
            "635 [Discriminator loss: 0.6804%, acc.: 51.17%] [Generator loss: 0.9038%]\n",
            "636 [Discriminator loss: 0.6507%, acc.: 53.91%] [Generator loss: 0.8921%]\n",
            "637 [Discriminator loss: 0.6464%, acc.: 52.73%] [Generator loss: 0.9194%]\n",
            "638 [Discriminator loss: 0.6419%, acc.: 54.69%] [Generator loss: 0.8992%]\n",
            "639 [Discriminator loss: 0.6676%, acc.: 47.27%] [Generator loss: 0.8919%]\n",
            "640 [Discriminator loss: 0.6481%, acc.: 48.83%] [Generator loss: 0.9056%]\n",
            "641 [Discriminator loss: 0.6581%, acc.: 48.83%] [Generator loss: 0.9252%]\n",
            "642 [Discriminator loss: 0.6754%, acc.: 44.53%] [Generator loss: 0.8777%]\n",
            "643 [Discriminator loss: 0.6402%, acc.: 51.56%] [Generator loss: 0.9118%]\n",
            "644 [Discriminator loss: 0.6492%, acc.: 52.34%] [Generator loss: 0.9203%]\n",
            "645 [Discriminator loss: 0.6713%, acc.: 50.39%] [Generator loss: 0.8913%]\n",
            "646 [Discriminator loss: 0.6259%, acc.: 54.30%] [Generator loss: 0.9374%]\n",
            "647 [Discriminator loss: 0.6773%, acc.: 48.44%] [Generator loss: 0.9104%]\n",
            "648 [Discriminator loss: 0.7083%, acc.: 41.41%] [Generator loss: 0.8397%]\n",
            "649 [Discriminator loss: 0.6471%, acc.: 50.00%] [Generator loss: 0.9066%]\n",
            "650 [Discriminator loss: 0.6393%, acc.: 57.42%] [Generator loss: 0.9206%]\n",
            "651 [Discriminator loss: 0.6969%, acc.: 46.88%] [Generator loss: 0.8798%]\n",
            "652 [Discriminator loss: 0.6473%, acc.: 52.73%] [Generator loss: 0.9080%]\n",
            "653 [Discriminator loss: 0.6807%, acc.: 48.83%] [Generator loss: 0.8842%]\n",
            "654 [Discriminator loss: 0.6493%, acc.: 53.52%] [Generator loss: 0.9114%]\n",
            "655 [Discriminator loss: 0.6706%, acc.: 48.44%] [Generator loss: 0.8930%]\n",
            "656 [Discriminator loss: 0.6738%, acc.: 46.48%] [Generator loss: 0.8925%]\n",
            "657 [Discriminator loss: 0.6748%, acc.: 47.66%] [Generator loss: 0.8607%]\n",
            "658 [Discriminator loss: 0.6450%, acc.: 48.83%] [Generator loss: 0.9127%]\n",
            "659 [Discriminator loss: 0.7045%, acc.: 43.36%] [Generator loss: 0.8578%]\n",
            "660 [Discriminator loss: 0.6850%, acc.: 43.75%] [Generator loss: 0.8706%]\n",
            "661 [Discriminator loss: 0.6670%, acc.: 43.36%] [Generator loss: 0.8855%]\n",
            "662 [Discriminator loss: 0.6741%, acc.: 47.66%] [Generator loss: 0.8773%]\n",
            "663 [Discriminator loss: 0.6632%, acc.: 48.83%] [Generator loss: 0.8802%]\n",
            "664 [Discriminator loss: 0.6538%, acc.: 48.83%] [Generator loss: 0.9042%]\n",
            "665 [Discriminator loss: 0.6721%, acc.: 46.48%] [Generator loss: 0.8864%]\n",
            "666 [Discriminator loss: 0.6571%, acc.: 46.09%] [Generator loss: 0.9135%]\n",
            "667 [Discriminator loss: 0.6576%, acc.: 46.88%] [Generator loss: 0.9131%]\n",
            "668 [Discriminator loss: 0.6693%, acc.: 44.53%] [Generator loss: 0.9146%]\n",
            "669 [Discriminator loss: 0.6705%, acc.: 45.31%] [Generator loss: 0.8924%]\n",
            "670 [Discriminator loss: 0.6664%, acc.: 47.66%] [Generator loss: 0.9061%]\n",
            "671 [Discriminator loss: 0.6559%, acc.: 49.61%] [Generator loss: 0.9291%]\n",
            "672 [Discriminator loss: 0.6812%, acc.: 45.31%] [Generator loss: 0.8920%]\n",
            "673 [Discriminator loss: 0.6642%, acc.: 45.70%] [Generator loss: 0.9013%]\n",
            "674 [Discriminator loss: 0.6677%, acc.: 47.27%] [Generator loss: 0.8919%]\n",
            "675 [Discriminator loss: 0.6528%, acc.: 49.22%] [Generator loss: 0.8984%]\n",
            "676 [Discriminator loss: 0.6682%, acc.: 44.53%] [Generator loss: 0.9180%]\n",
            "677 [Discriminator loss: 0.6580%, acc.: 45.31%] [Generator loss: 0.8978%]\n",
            "678 [Discriminator loss: 0.6568%, acc.: 45.70%] [Generator loss: 0.9116%]\n",
            "679 [Discriminator loss: 0.6601%, acc.: 46.88%] [Generator loss: 0.9056%]\n",
            "680 [Discriminator loss: 0.6263%, acc.: 55.86%] [Generator loss: 0.9355%]\n",
            "681 [Discriminator loss: 0.6587%, acc.: 47.66%] [Generator loss: 0.9190%]\n",
            "682 [Discriminator loss: 0.6411%, acc.: 52.73%] [Generator loss: 0.9226%]\n",
            "683 [Discriminator loss: 0.6908%, acc.: 42.58%] [Generator loss: 0.8863%]\n",
            "684 [Discriminator loss: 0.6471%, acc.: 46.48%] [Generator loss: 0.9117%]\n",
            "685 [Discriminator loss: 0.6518%, acc.: 48.05%] [Generator loss: 0.9095%]\n",
            "686 [Discriminator loss: 0.6905%, acc.: 41.02%] [Generator loss: 0.8720%]\n",
            "687 [Discriminator loss: 0.6505%, acc.: 49.61%] [Generator loss: 0.8894%]\n",
            "688 [Discriminator loss: 0.6571%, acc.: 50.39%] [Generator loss: 0.9135%]\n",
            "689 [Discriminator loss: 0.6592%, acc.: 44.92%] [Generator loss: 0.9115%]\n",
            "690 [Discriminator loss: 0.6488%, acc.: 48.05%] [Generator loss: 0.8989%]\n",
            "691 [Discriminator loss: 0.6567%, acc.: 48.83%] [Generator loss: 0.8971%]\n",
            "692 [Discriminator loss: 0.6497%, acc.: 49.22%] [Generator loss: 0.9127%]\n",
            "693 [Discriminator loss: 0.6760%, acc.: 46.88%] [Generator loss: 0.9003%]\n",
            "694 [Discriminator loss: 0.6809%, acc.: 50.78%] [Generator loss: 0.8843%]\n",
            "695 [Discriminator loss: 0.6702%, acc.: 45.31%] [Generator loss: 0.8990%]\n",
            "696 [Discriminator loss: 0.6838%, acc.: 42.58%] [Generator loss: 0.8760%]\n",
            "697 [Discriminator loss: 0.6792%, acc.: 42.19%] [Generator loss: 0.8783%]\n",
            "698 [Discriminator loss: 0.6740%, acc.: 42.97%] [Generator loss: 0.8929%]\n",
            "699 [Discriminator loss: 0.6901%, acc.: 42.58%] [Generator loss: 0.8823%]\n",
            "700 [Discriminator loss: 0.6747%, acc.: 41.41%] [Generator loss: 0.8797%]\n",
            "701 [Discriminator loss: 0.6624%, acc.: 50.39%] [Generator loss: 0.8979%]\n",
            "702 [Discriminator loss: 0.6673%, acc.: 46.88%] [Generator loss: 0.8953%]\n",
            "703 [Discriminator loss: 0.6817%, acc.: 42.19%] [Generator loss: 0.8858%]\n",
            "704 [Discriminator loss: 0.6830%, acc.: 44.53%] [Generator loss: 0.8787%]\n",
            "705 [Discriminator loss: 0.6647%, acc.: 48.05%] [Generator loss: 0.8915%]\n",
            "706 [Discriminator loss: 0.6781%, acc.: 45.31%] [Generator loss: 0.8879%]\n",
            "707 [Discriminator loss: 0.6929%, acc.: 46.09%] [Generator loss: 0.8835%]\n",
            "708 [Discriminator loss: 0.7207%, acc.: 37.11%] [Generator loss: 0.8524%]\n",
            "709 [Discriminator loss: 0.6735%, acc.: 44.92%] [Generator loss: 0.8871%]\n",
            "710 [Discriminator loss: 0.6663%, acc.: 41.41%] [Generator loss: 0.8931%]\n",
            "711 [Discriminator loss: 0.6936%, acc.: 39.06%] [Generator loss: 0.8749%]\n",
            "712 [Discriminator loss: 0.7127%, acc.: 35.55%] [Generator loss: 0.8555%]\n",
            "713 [Discriminator loss: 0.6817%, acc.: 41.41%] [Generator loss: 0.8831%]\n",
            "714 [Discriminator loss: 0.6853%, acc.: 42.97%] [Generator loss: 0.9012%]\n",
            "715 [Discriminator loss: 0.7096%, acc.: 39.45%] [Generator loss: 0.8666%]\n",
            "716 [Discriminator loss: 0.7039%, acc.: 40.23%] [Generator loss: 0.8671%]\n",
            "717 [Discriminator loss: 0.6663%, acc.: 43.75%] [Generator loss: 0.8979%]\n",
            "718 [Discriminator loss: 0.6960%, acc.: 39.84%] [Generator loss: 0.8813%]\n",
            "719 [Discriminator loss: 0.7119%, acc.: 36.72%] [Generator loss: 0.8612%]\n",
            "720 [Discriminator loss: 0.6747%, acc.: 42.97%] [Generator loss: 0.8700%]\n",
            "721 [Discriminator loss: 0.7038%, acc.: 41.02%] [Generator loss: 0.8715%]\n",
            "722 [Discriminator loss: 0.6871%, acc.: 40.62%] [Generator loss: 0.8775%]\n",
            "723 [Discriminator loss: 0.7049%, acc.: 40.23%] [Generator loss: 0.8557%]\n",
            "724 [Discriminator loss: 0.6996%, acc.: 41.41%] [Generator loss: 0.8575%]\n",
            "725 [Discriminator loss: 0.6840%, acc.: 42.19%] [Generator loss: 0.8710%]\n",
            "726 [Discriminator loss: 0.7021%, acc.: 37.89%] [Generator loss: 0.8637%]\n",
            "727 [Discriminator loss: 0.7013%, acc.: 40.23%] [Generator loss: 0.8470%]\n",
            "728 [Discriminator loss: 0.6608%, acc.: 44.14%] [Generator loss: 0.8818%]\n",
            "729 [Discriminator loss: 0.6889%, acc.: 41.80%] [Generator loss: 0.8683%]\n",
            "730 [Discriminator loss: 0.7156%, acc.: 38.67%] [Generator loss: 0.8536%]\n",
            "731 [Discriminator loss: 0.6911%, acc.: 38.28%] [Generator loss: 0.8649%]\n",
            "732 [Discriminator loss: 0.6906%, acc.: 37.50%] [Generator loss: 0.8650%]\n",
            "733 [Discriminator loss: 0.6886%, acc.: 40.62%] [Generator loss: 0.8604%]\n",
            "734 [Discriminator loss: 0.6895%, acc.: 41.02%] [Generator loss: 0.8584%]\n",
            "735 [Discriminator loss: 0.7118%, acc.: 37.11%] [Generator loss: 0.8309%]\n",
            "736 [Discriminator loss: 0.7061%, acc.: 41.41%] [Generator loss: 0.8415%]\n",
            "737 [Discriminator loss: 0.6995%, acc.: 38.67%] [Generator loss: 0.8473%]\n",
            "738 [Discriminator loss: 0.6906%, acc.: 44.14%] [Generator loss: 0.8625%]\n",
            "739 [Discriminator loss: 0.7082%, acc.: 39.84%] [Generator loss: 0.8523%]\n",
            "740 [Discriminator loss: 0.6925%, acc.: 42.19%] [Generator loss: 0.8478%]\n",
            "741 [Discriminator loss: 0.7050%, acc.: 37.50%] [Generator loss: 0.8509%]\n",
            "742 [Discriminator loss: 0.6955%, acc.: 41.02%] [Generator loss: 0.8620%]\n",
            "743 [Discriminator loss: 0.6863%, acc.: 44.14%] [Generator loss: 0.8605%]\n",
            "744 [Discriminator loss: 0.6944%, acc.: 40.23%] [Generator loss: 0.8538%]\n",
            "745 [Discriminator loss: 0.6960%, acc.: 41.02%] [Generator loss: 0.8593%]\n",
            "746 [Discriminator loss: 0.6837%, acc.: 43.36%] [Generator loss: 0.8697%]\n",
            "747 [Discriminator loss: 0.6969%, acc.: 39.84%] [Generator loss: 0.8540%]\n",
            "748 [Discriminator loss: 0.6866%, acc.: 42.97%] [Generator loss: 0.8615%]\n",
            "749 [Discriminator loss: 0.6865%, acc.: 50.00%] [Generator loss: 0.8574%]\n",
            "750 [Discriminator loss: 0.6936%, acc.: 50.78%] [Generator loss: 0.8548%]\n",
            "751 [Discriminator loss: 0.6919%, acc.: 43.36%] [Generator loss: 0.8575%]\n",
            "752 [Discriminator loss: 0.6887%, acc.: 42.19%] [Generator loss: 0.8601%]\n",
            "753 [Discriminator loss: 0.7033%, acc.: 39.06%] [Generator loss: 0.8539%]\n",
            "754 [Discriminator loss: 0.6897%, acc.: 42.97%] [Generator loss: 0.8596%]\n",
            "755 [Discriminator loss: 0.6794%, acc.: 44.92%] [Generator loss: 0.8763%]\n",
            "756 [Discriminator loss: 0.6894%, acc.: 42.97%] [Generator loss: 0.8612%]\n",
            "757 [Discriminator loss: 0.6758%, acc.: 44.53%] [Generator loss: 0.8691%]\n",
            "758 [Discriminator loss: 0.6839%, acc.: 44.53%] [Generator loss: 0.8661%]\n",
            "759 [Discriminator loss: 0.7026%, acc.: 39.06%] [Generator loss: 0.8519%]\n",
            "760 [Discriminator loss: 0.6923%, acc.: 43.36%] [Generator loss: 0.8549%]\n",
            "761 [Discriminator loss: 0.7161%, acc.: 36.72%] [Generator loss: 0.8430%]\n",
            "762 [Discriminator loss: 0.6976%, acc.: 42.19%] [Generator loss: 0.8271%]\n",
            "763 [Discriminator loss: 0.6912%, acc.: 41.80%] [Generator loss: 0.8367%]\n",
            "764 [Discriminator loss: 0.6852%, acc.: 43.75%] [Generator loss: 0.8559%]\n",
            "765 [Discriminator loss: 0.6998%, acc.: 39.06%] [Generator loss: 0.8457%]\n",
            "766 [Discriminator loss: 0.6923%, acc.: 41.80%] [Generator loss: 0.8493%]\n",
            "767 [Discriminator loss: 0.6866%, acc.: 46.48%] [Generator loss: 0.8495%]\n",
            "768 [Discriminator loss: 0.7117%, acc.: 37.50%] [Generator loss: 0.8404%]\n",
            "769 [Discriminator loss: 0.6981%, acc.: 39.45%] [Generator loss: 0.8440%]\n",
            "770 [Discriminator loss: 0.6947%, acc.: 41.80%] [Generator loss: 0.8477%]\n",
            "771 [Discriminator loss: 0.6960%, acc.: 40.23%] [Generator loss: 0.8417%]\n",
            "772 [Discriminator loss: 0.6999%, acc.: 42.58%] [Generator loss: 0.8451%]\n",
            "773 [Discriminator loss: 0.6924%, acc.: 42.58%] [Generator loss: 0.8469%]\n",
            "774 [Discriminator loss: 0.6900%, acc.: 43.36%] [Generator loss: 0.8511%]\n",
            "775 [Discriminator loss: 0.6985%, acc.: 42.58%] [Generator loss: 0.8390%]\n",
            "776 [Discriminator loss: 0.6866%, acc.: 42.19%] [Generator loss: 0.8461%]\n",
            "777 [Discriminator loss: 0.7032%, acc.: 42.58%] [Generator loss: 0.8304%]\n",
            "778 [Discriminator loss: 0.6742%, acc.: 52.34%] [Generator loss: 0.8445%]\n",
            "779 [Discriminator loss: 0.6886%, acc.: 46.88%] [Generator loss: 0.8576%]\n",
            "780 [Discriminator loss: 0.6841%, acc.: 52.73%] [Generator loss: 0.8603%]\n",
            "781 [Discriminator loss: 0.6944%, acc.: 44.14%] [Generator loss: 0.8498%]\n",
            "782 [Discriminator loss: 0.6861%, acc.: 46.88%] [Generator loss: 0.8407%]\n",
            "783 [Discriminator loss: 0.6879%, acc.: 46.09%] [Generator loss: 0.8505%]\n",
            "784 [Discriminator loss: 0.6708%, acc.: 52.73%] [Generator loss: 0.8554%]\n",
            "785 [Discriminator loss: 0.6939%, acc.: 50.39%] [Generator loss: 0.8479%]\n",
            "786 [Discriminator loss: 0.6852%, acc.: 52.73%] [Generator loss: 0.8468%]\n",
            "787 [Discriminator loss: 0.6707%, acc.: 54.69%] [Generator loss: 0.8572%]\n",
            "788 [Discriminator loss: 0.6847%, acc.: 51.17%] [Generator loss: 0.8675%]\n",
            "789 [Discriminator loss: 0.6822%, acc.: 49.22%] [Generator loss: 0.8549%]\n",
            "790 [Discriminator loss: 0.6914%, acc.: 44.14%] [Generator loss: 0.8596%]\n",
            "791 [Discriminator loss: 0.6829%, acc.: 43.75%] [Generator loss: 0.8522%]\n",
            "792 [Discriminator loss: 0.6781%, acc.: 42.19%] [Generator loss: 0.8483%]\n",
            "793 [Discriminator loss: 0.6914%, acc.: 42.58%] [Generator loss: 0.8396%]\n",
            "794 [Discriminator loss: 0.6815%, acc.: 46.48%] [Generator loss: 0.8425%]\n",
            "795 [Discriminator loss: 0.6856%, acc.: 44.14%] [Generator loss: 0.8513%]\n",
            "796 [Discriminator loss: 0.6834%, acc.: 43.75%] [Generator loss: 0.8551%]\n",
            "797 [Discriminator loss: 0.6895%, acc.: 43.75%] [Generator loss: 0.8485%]\n",
            "798 [Discriminator loss: 0.6771%, acc.: 46.09%] [Generator loss: 0.8587%]\n",
            "799 [Discriminator loss: 0.6924%, acc.: 41.41%] [Generator loss: 0.8588%]\n",
            "800 [Discriminator loss: 0.6997%, acc.: 40.62%] [Generator loss: 0.8533%]\n",
            "801 [Discriminator loss: 0.6776%, acc.: 49.22%] [Generator loss: 0.8572%]\n",
            "802 [Discriminator loss: 0.6959%, acc.: 46.48%] [Generator loss: 0.8486%]\n",
            "803 [Discriminator loss: 0.6849%, acc.: 48.83%] [Generator loss: 0.8568%]\n",
            "804 [Discriminator loss: 0.7095%, acc.: 38.28%] [Generator loss: 0.8409%]\n",
            "805 [Discriminator loss: 0.6916%, acc.: 43.75%] [Generator loss: 0.8437%]\n",
            "806 [Discriminator loss: 0.6890%, acc.: 42.97%] [Generator loss: 0.8535%]\n",
            "807 [Discriminator loss: 0.7029%, acc.: 39.06%] [Generator loss: 0.8489%]\n",
            "808 [Discriminator loss: 0.7013%, acc.: 42.97%] [Generator loss: 0.8473%]\n",
            "809 [Discriminator loss: 0.6976%, acc.: 44.14%] [Generator loss: 0.8551%]\n",
            "810 [Discriminator loss: 0.6965%, acc.: 43.36%] [Generator loss: 0.8562%]\n",
            "811 [Discriminator loss: 0.7079%, acc.: 40.62%] [Generator loss: 0.8421%]\n",
            "812 [Discriminator loss: 0.6993%, acc.: 43.75%] [Generator loss: 0.8506%]\n",
            "813 [Discriminator loss: 0.7090%, acc.: 39.45%] [Generator loss: 0.8371%]\n",
            "814 [Discriminator loss: 0.7053%, acc.: 40.23%] [Generator loss: 0.8272%]\n",
            "815 [Discriminator loss: 0.6894%, acc.: 42.97%] [Generator loss: 0.8466%]\n",
            "816 [Discriminator loss: 0.6919%, acc.: 44.14%] [Generator loss: 0.8471%]\n",
            "817 [Discriminator loss: 0.7092%, acc.: 41.80%] [Generator loss: 0.8428%]\n",
            "818 [Discriminator loss: 0.6899%, acc.: 44.14%] [Generator loss: 0.8413%]\n",
            "819 [Discriminator loss: 0.7080%, acc.: 39.06%] [Generator loss: 0.8378%]\n",
            "820 [Discriminator loss: 0.6988%, acc.: 41.80%] [Generator loss: 0.8398%]\n",
            "821 [Discriminator loss: 0.6968%, acc.: 42.58%] [Generator loss: 0.8394%]\n",
            "822 [Discriminator loss: 0.6810%, acc.: 49.22%] [Generator loss: 0.8470%]\n",
            "823 [Discriminator loss: 0.6983%, acc.: 46.09%] [Generator loss: 0.8422%]\n",
            "824 [Discriminator loss: 0.6934%, acc.: 48.83%] [Generator loss: 0.8525%]\n",
            "825 [Discriminator loss: 0.7212%, acc.: 42.97%] [Generator loss: 0.8383%]\n",
            "826 [Discriminator loss: 0.6866%, acc.: 51.95%] [Generator loss: 0.8475%]\n",
            "827 [Discriminator loss: 0.6990%, acc.: 47.66%] [Generator loss: 0.8413%]\n",
            "828 [Discriminator loss: 0.6941%, acc.: 49.22%] [Generator loss: 0.8346%]\n",
            "829 [Discriminator loss: 0.7118%, acc.: 44.92%] [Generator loss: 0.8312%]\n",
            "830 [Discriminator loss: 0.7019%, acc.: 46.48%] [Generator loss: 0.8319%]\n",
            "831 [Discriminator loss: 0.7013%, acc.: 43.36%] [Generator loss: 0.8489%]\n",
            "832 [Discriminator loss: 0.6849%, acc.: 47.66%] [Generator loss: 0.8541%]\n",
            "833 [Discriminator loss: 0.7052%, acc.: 40.62%] [Generator loss: 0.8497%]\n",
            "834 [Discriminator loss: 0.6928%, acc.: 49.22%] [Generator loss: 0.8466%]\n",
            "835 [Discriminator loss: 0.6985%, acc.: 44.53%] [Generator loss: 0.8533%]\n",
            "836 [Discriminator loss: 0.6977%, acc.: 44.92%] [Generator loss: 0.8679%]\n",
            "837 [Discriminator loss: 0.6984%, acc.: 42.58%] [Generator loss: 0.8729%]\n",
            "838 [Discriminator loss: 0.6959%, acc.: 47.27%] [Generator loss: 0.8576%]\n",
            "839 [Discriminator loss: 0.6901%, acc.: 44.53%] [Generator loss: 0.8627%]\n",
            "840 [Discriminator loss: 0.6986%, acc.: 44.14%] [Generator loss: 0.8594%]\n",
            "841 [Discriminator loss: 0.7049%, acc.: 44.92%] [Generator loss: 0.8459%]\n",
            "842 [Discriminator loss: 0.6924%, acc.: 43.36%] [Generator loss: 0.8594%]\n",
            "843 [Discriminator loss: 0.6980%, acc.: 44.53%] [Generator loss: 0.8534%]\n",
            "844 [Discriminator loss: 0.6970%, acc.: 44.14%] [Generator loss: 0.8551%]\n",
            "845 [Discriminator loss: 0.6780%, acc.: 48.44%] [Generator loss: 0.8658%]\n",
            "846 [Discriminator loss: 0.7077%, acc.: 42.97%] [Generator loss: 0.8472%]\n",
            "847 [Discriminator loss: 0.6751%, acc.: 55.47%] [Generator loss: 0.8653%]\n",
            "848 [Discriminator loss: 0.6923%, acc.: 46.88%] [Generator loss: 0.8730%]\n",
            "849 [Discriminator loss: 0.6929%, acc.: 48.83%] [Generator loss: 0.8597%]\n",
            "850 [Discriminator loss: 0.6895%, acc.: 51.17%] [Generator loss: 0.8598%]\n",
            "851 [Discriminator loss: 0.7032%, acc.: 48.83%] [Generator loss: 0.8521%]\n",
            "852 [Discriminator loss: 0.6875%, acc.: 42.58%] [Generator loss: 0.8583%]\n",
            "853 [Discriminator loss: 0.6712%, acc.: 48.44%] [Generator loss: 0.8726%]\n",
            "854 [Discriminator loss: 0.6913%, acc.: 47.27%] [Generator loss: 0.8672%]\n",
            "855 [Discriminator loss: 0.6888%, acc.: 47.27%] [Generator loss: 0.8647%]\n",
            "856 [Discriminator loss: 0.7065%, acc.: 42.97%] [Generator loss: 0.8475%]\n",
            "857 [Discriminator loss: 0.6949%, acc.: 44.53%] [Generator loss: 0.8546%]\n",
            "858 [Discriminator loss: 0.6860%, acc.: 48.83%] [Generator loss: 0.8562%]\n",
            "859 [Discriminator loss: 0.6940%, acc.: 45.70%] [Generator loss: 0.8567%]\n",
            "860 [Discriminator loss: 0.6913%, acc.: 43.36%] [Generator loss: 0.8624%]\n",
            "861 [Discriminator loss: 0.6873%, acc.: 41.80%] [Generator loss: 0.8688%]\n",
            "862 [Discriminator loss: 0.7108%, acc.: 33.20%] [Generator loss: 0.8525%]\n",
            "863 [Discriminator loss: 0.6918%, acc.: 40.62%] [Generator loss: 0.8530%]\n",
            "864 [Discriminator loss: 0.6777%, acc.: 41.80%] [Generator loss: 0.8639%]\n",
            "865 [Discriminator loss: 0.6833%, acc.: 44.14%] [Generator loss: 0.8654%]\n",
            "866 [Discriminator loss: 0.6975%, acc.: 42.58%] [Generator loss: 0.8573%]\n",
            "867 [Discriminator loss: 0.6910%, acc.: 42.58%] [Generator loss: 0.8540%]\n",
            "868 [Discriminator loss: 0.6811%, acc.: 44.53%] [Generator loss: 0.8617%]\n",
            "869 [Discriminator loss: 0.6920%, acc.: 41.80%] [Generator loss: 0.8546%]\n",
            "870 [Discriminator loss: 0.6817%, acc.: 41.02%] [Generator loss: 0.8610%]\n",
            "871 [Discriminator loss: 0.6877%, acc.: 38.28%] [Generator loss: 0.8537%]\n",
            "872 [Discriminator loss: 0.6825%, acc.: 41.41%] [Generator loss: 0.8643%]\n",
            "873 [Discriminator loss: 0.6964%, acc.: 39.84%] [Generator loss: 0.8501%]\n",
            "874 [Discriminator loss: 0.6771%, acc.: 42.58%] [Generator loss: 0.8607%]\n",
            "875 [Discriminator loss: 0.6852%, acc.: 41.41%] [Generator loss: 0.8674%]\n",
            "876 [Discriminator loss: 0.6882%, acc.: 39.45%] [Generator loss: 0.8558%]\n",
            "877 [Discriminator loss: 0.6886%, acc.: 38.67%] [Generator loss: 0.8619%]\n",
            "878 [Discriminator loss: 0.6746%, acc.: 43.36%] [Generator loss: 0.8668%]\n",
            "879 [Discriminator loss: 0.6806%, acc.: 42.58%] [Generator loss: 0.8600%]\n",
            "880 [Discriminator loss: 0.6867%, acc.: 41.41%] [Generator loss: 0.8530%]\n",
            "881 [Discriminator loss: 0.6739%, acc.: 41.80%] [Generator loss: 0.8700%]\n",
            "882 [Discriminator loss: 0.6979%, acc.: 39.45%] [Generator loss: 0.8493%]\n",
            "883 [Discriminator loss: 0.6884%, acc.: 42.19%] [Generator loss: 0.8437%]\n",
            "884 [Discriminator loss: 0.6807%, acc.: 46.09%] [Generator loss: 0.8451%]\n",
            "885 [Discriminator loss: 0.6948%, acc.: 42.19%] [Generator loss: 0.8518%]\n",
            "886 [Discriminator loss: 0.6899%, acc.: 43.36%] [Generator loss: 0.8461%]\n",
            "887 [Discriminator loss: 0.6886%, acc.: 44.14%] [Generator loss: 0.8503%]\n",
            "888 [Discriminator loss: 0.6866%, acc.: 41.41%] [Generator loss: 0.8556%]\n",
            "889 [Discriminator loss: 0.7004%, acc.: 38.28%] [Generator loss: 0.8419%]\n",
            "890 [Discriminator loss: 0.6960%, acc.: 40.62%] [Generator loss: 0.8330%]\n",
            "891 [Discriminator loss: 0.6903%, acc.: 44.53%] [Generator loss: 0.8378%]\n",
            "892 [Discriminator loss: 0.6977%, acc.: 40.23%] [Generator loss: 0.8379%]\n",
            "893 [Discriminator loss: 0.6912%, acc.: 42.58%] [Generator loss: 0.8521%]\n",
            "894 [Discriminator loss: 0.7005%, acc.: 37.50%] [Generator loss: 0.8381%]\n",
            "895 [Discriminator loss: 0.6826%, acc.: 42.19%] [Generator loss: 0.8461%]\n",
            "896 [Discriminator loss: 0.7024%, acc.: 39.06%] [Generator loss: 0.8348%]\n",
            "897 [Discriminator loss: 0.7011%, acc.: 42.97%] [Generator loss: 0.8342%]\n",
            "898 [Discriminator loss: 0.7122%, acc.: 39.06%] [Generator loss: 0.8341%]\n",
            "899 [Discriminator loss: 0.7126%, acc.: 39.06%] [Generator loss: 0.8276%]\n",
            "900 [Discriminator loss: 0.6944%, acc.: 41.02%] [Generator loss: 0.8349%]\n",
            "901 [Discriminator loss: 0.7049%, acc.: 40.62%] [Generator loss: 0.8396%]\n",
            "902 [Discriminator loss: 0.6853%, acc.: 46.88%] [Generator loss: 0.8490%]\n",
            "903 [Discriminator loss: 0.7177%, acc.: 40.23%] [Generator loss: 0.8323%]\n",
            "904 [Discriminator loss: 0.7168%, acc.: 37.50%] [Generator loss: 0.8252%]\n",
            "905 [Discriminator loss: 0.7136%, acc.: 39.06%] [Generator loss: 0.8315%]\n",
            "906 [Discriminator loss: 0.6959%, acc.: 39.45%] [Generator loss: 0.8353%]\n",
            "907 [Discriminator loss: 0.7100%, acc.: 37.50%] [Generator loss: 0.8364%]\n",
            "908 [Discriminator loss: 0.7096%, acc.: 36.72%] [Generator loss: 0.8364%]\n",
            "909 [Discriminator loss: 0.7048%, acc.: 40.23%] [Generator loss: 0.8356%]\n",
            "910 [Discriminator loss: 0.7202%, acc.: 39.45%] [Generator loss: 0.8405%]\n",
            "911 [Discriminator loss: 0.6938%, acc.: 40.23%] [Generator loss: 0.8424%]\n",
            "912 [Discriminator loss: 0.7110%, acc.: 36.33%] [Generator loss: 0.8308%]\n",
            "913 [Discriminator loss: 0.7094%, acc.: 36.72%] [Generator loss: 0.8274%]\n",
            "914 [Discriminator loss: 0.7050%, acc.: 41.80%] [Generator loss: 0.8278%]\n",
            "915 [Discriminator loss: 0.6934%, acc.: 48.05%] [Generator loss: 0.8358%]\n",
            "916 [Discriminator loss: 0.7009%, acc.: 43.36%] [Generator loss: 0.8435%]\n",
            "917 [Discriminator loss: 0.6930%, acc.: 46.88%] [Generator loss: 0.8439%]\n",
            "918 [Discriminator loss: 0.6990%, acc.: 43.36%] [Generator loss: 0.8468%]\n",
            "919 [Discriminator loss: 0.6998%, acc.: 37.11%] [Generator loss: 0.8427%]\n",
            "920 [Discriminator loss: 0.6860%, acc.: 40.62%] [Generator loss: 0.8509%]\n",
            "921 [Discriminator loss: 0.7031%, acc.: 41.02%] [Generator loss: 0.8352%]\n",
            "922 [Discriminator loss: 0.6947%, acc.: 41.02%] [Generator loss: 0.8435%]\n",
            "923 [Discriminator loss: 0.7058%, acc.: 38.28%] [Generator loss: 0.8409%]\n",
            "924 [Discriminator loss: 0.7020%, acc.: 38.67%] [Generator loss: 0.8436%]\n",
            "925 [Discriminator loss: 0.6907%, acc.: 41.02%] [Generator loss: 0.8475%]\n",
            "926 [Discriminator loss: 0.6890%, acc.: 40.23%] [Generator loss: 0.8518%]\n",
            "927 [Discriminator loss: 0.7005%, acc.: 39.45%] [Generator loss: 0.8463%]\n",
            "928 [Discriminator loss: 0.6962%, acc.: 39.84%] [Generator loss: 0.8422%]\n",
            "929 [Discriminator loss: 0.6920%, acc.: 39.84%] [Generator loss: 0.8540%]\n",
            "930 [Discriminator loss: 0.6949%, acc.: 39.06%] [Generator loss: 0.8477%]\n",
            "931 [Discriminator loss: 0.6978%, acc.: 38.67%] [Generator loss: 0.8403%]\n",
            "932 [Discriminator loss: 0.6966%, acc.: 35.55%] [Generator loss: 0.8415%]\n",
            "933 [Discriminator loss: 0.6827%, acc.: 40.23%] [Generator loss: 0.8492%]\n",
            "934 [Discriminator loss: 0.7013%, acc.: 37.89%] [Generator loss: 0.8408%]\n",
            "935 [Discriminator loss: 0.6903%, acc.: 39.06%] [Generator loss: 0.8344%]\n",
            "936 [Discriminator loss: 0.6846%, acc.: 44.14%] [Generator loss: 0.8421%]\n",
            "937 [Discriminator loss: 0.6929%, acc.: 40.62%] [Generator loss: 0.8418%]\n",
            "938 [Discriminator loss: 0.6903%, acc.: 42.58%] [Generator loss: 0.8412%]\n",
            "939 [Discriminator loss: 0.6994%, acc.: 39.84%] [Generator loss: 0.8370%]\n",
            "940 [Discriminator loss: 0.6929%, acc.: 44.92%] [Generator loss: 0.8432%]\n",
            "941 [Discriminator loss: 0.6875%, acc.: 43.75%] [Generator loss: 0.8472%]\n",
            "942 [Discriminator loss: 0.6781%, acc.: 41.41%] [Generator loss: 0.8520%]\n",
            "943 [Discriminator loss: 0.6804%, acc.: 40.23%] [Generator loss: 0.8460%]\n",
            "944 [Discriminator loss: 0.6826%, acc.: 40.23%] [Generator loss: 0.8436%]\n",
            "945 [Discriminator loss: 0.6699%, acc.: 43.75%] [Generator loss: 0.8485%]\n",
            "946 [Discriminator loss: 0.6766%, acc.: 44.53%] [Generator loss: 0.8565%]\n",
            "947 [Discriminator loss: 0.6864%, acc.: 41.80%] [Generator loss: 0.8468%]\n",
            "948 [Discriminator loss: 0.6864%, acc.: 40.23%] [Generator loss: 0.8468%]\n",
            "949 [Discriminator loss: 0.6907%, acc.: 42.58%] [Generator loss: 0.8399%]\n",
            "950 [Discriminator loss: 0.6800%, acc.: 45.70%] [Generator loss: 0.8488%]\n",
            "951 [Discriminator loss: 0.6924%, acc.: 41.41%] [Generator loss: 0.8398%]\n",
            "952 [Discriminator loss: 0.6966%, acc.: 44.92%] [Generator loss: 0.8385%]\n",
            "953 [Discriminator loss: 0.6970%, acc.: 44.53%] [Generator loss: 0.8349%]\n",
            "954 [Discriminator loss: 0.6989%, acc.: 41.02%] [Generator loss: 0.8401%]\n",
            "955 [Discriminator loss: 0.6961%, acc.: 39.45%] [Generator loss: 0.8404%]\n",
            "956 [Discriminator loss: 0.6952%, acc.: 41.80%] [Generator loss: 0.8409%]\n",
            "957 [Discriminator loss: 0.7030%, acc.: 37.50%] [Generator loss: 0.8398%]\n",
            "958 [Discriminator loss: 0.6779%, acc.: 40.62%] [Generator loss: 0.8517%]\n",
            "959 [Discriminator loss: 0.7060%, acc.: 35.94%] [Generator loss: 0.8409%]\n",
            "960 [Discriminator loss: 0.6931%, acc.: 35.94%] [Generator loss: 0.8472%]\n",
            "961 [Discriminator loss: 0.6995%, acc.: 38.28%] [Generator loss: 0.8435%]\n",
            "962 [Discriminator loss: 0.7128%, acc.: 36.72%] [Generator loss: 0.8244%]\n",
            "963 [Discriminator loss: 0.7055%, acc.: 39.06%] [Generator loss: 0.8361%]\n",
            "964 [Discriminator loss: 0.7017%, acc.: 37.11%] [Generator loss: 0.8324%]\n",
            "965 [Discriminator loss: 0.7085%, acc.: 36.33%] [Generator loss: 0.8272%]\n",
            "966 [Discriminator loss: 0.7071%, acc.: 35.55%] [Generator loss: 0.8326%]\n",
            "967 [Discriminator loss: 0.7009%, acc.: 37.89%] [Generator loss: 0.8252%]\n",
            "968 [Discriminator loss: 0.7190%, acc.: 35.16%] [Generator loss: 0.8228%]\n",
            "969 [Discriminator loss: 0.7130%, acc.: 33.59%] [Generator loss: 0.8209%]\n",
            "970 [Discriminator loss: 0.7001%, acc.: 38.67%] [Generator loss: 0.8371%]\n",
            "971 [Discriminator loss: 0.7152%, acc.: 34.77%] [Generator loss: 0.8231%]\n",
            "972 [Discriminator loss: 0.7053%, acc.: 36.33%] [Generator loss: 0.8375%]\n",
            "973 [Discriminator loss: 0.7059%, acc.: 33.59%] [Generator loss: 0.8407%]\n",
            "974 [Discriminator loss: 0.7168%, acc.: 39.06%] [Generator loss: 0.8323%]\n",
            "975 [Discriminator loss: 0.7293%, acc.: 30.86%] [Generator loss: 0.8234%]\n",
            "976 [Discriminator loss: 0.7147%, acc.: 34.77%] [Generator loss: 0.8260%]\n",
            "977 [Discriminator loss: 0.7157%, acc.: 39.06%] [Generator loss: 0.8237%]\n",
            "978 [Discriminator loss: 0.7079%, acc.: 39.45%] [Generator loss: 0.8261%]\n",
            "979 [Discriminator loss: 0.7056%, acc.: 44.92%] [Generator loss: 0.8276%]\n",
            "980 [Discriminator loss: 0.7105%, acc.: 50.00%] [Generator loss: 0.8273%]\n",
            "981 [Discriminator loss: 0.7159%, acc.: 47.66%] [Generator loss: 0.8214%]\n",
            "982 [Discriminator loss: 0.7247%, acc.: 45.31%] [Generator loss: 0.8284%]\n",
            "983 [Discriminator loss: 0.7176%, acc.: 38.67%] [Generator loss: 0.8310%]\n",
            "984 [Discriminator loss: 0.7197%, acc.: 35.16%] [Generator loss: 0.8212%]\n",
            "985 [Discriminator loss: 0.6998%, acc.: 39.06%] [Generator loss: 0.8268%]\n",
            "986 [Discriminator loss: 0.7072%, acc.: 38.28%] [Generator loss: 0.8301%]\n",
            "987 [Discriminator loss: 0.7131%, acc.: 39.45%] [Generator loss: 0.8223%]\n",
            "988 [Discriminator loss: 0.7021%, acc.: 39.06%] [Generator loss: 0.8269%]\n",
            "989 [Discriminator loss: 0.7128%, acc.: 40.23%] [Generator loss: 0.8331%]\n",
            "990 [Discriminator loss: 0.7072%, acc.: 42.58%] [Generator loss: 0.8357%]\n",
            "991 [Discriminator loss: 0.7329%, acc.: 35.16%] [Generator loss: 0.8156%]\n",
            "992 [Discriminator loss: 0.7186%, acc.: 37.89%] [Generator loss: 0.8176%]\n",
            "993 [Discriminator loss: 0.7093%, acc.: 38.28%] [Generator loss: 0.8304%]\n",
            "994 [Discriminator loss: 0.7040%, acc.: 37.11%] [Generator loss: 0.8334%]\n",
            "995 [Discriminator loss: 0.7124%, acc.: 34.38%] [Generator loss: 0.8218%]\n",
            "996 [Discriminator loss: 0.7078%, acc.: 36.72%] [Generator loss: 0.8154%]\n",
            "997 [Discriminator loss: 0.7032%, acc.: 41.80%] [Generator loss: 0.8194%]\n",
            "998 [Discriminator loss: 0.7195%, acc.: 38.28%] [Generator loss: 0.8203%]\n",
            "999 [Discriminator loss: 0.7100%, acc.: 39.45%] [Generator loss: 0.8233%]\n",
            "1000 [Discriminator loss: 0.7071%, acc.: 40.62%] [Generator loss: 0.8202%]\n",
            "1001 [Discriminator loss: 0.7064%, acc.: 39.84%] [Generator loss: 0.8338%]\n",
            "1002 [Discriminator loss: 0.7112%, acc.: 37.50%] [Generator loss: 0.8209%]\n",
            "1003 [Discriminator loss: 0.7062%, acc.: 39.84%] [Generator loss: 0.8230%]\n",
            "1004 [Discriminator loss: 0.7031%, acc.: 41.41%] [Generator loss: 0.8274%]\n",
            "1005 [Discriminator loss: 0.7055%, acc.: 39.84%] [Generator loss: 0.8252%]\n",
            "1006 [Discriminator loss: 0.7008%, acc.: 43.36%] [Generator loss: 0.8248%]\n",
            "1007 [Discriminator loss: 0.7073%, acc.: 42.97%] [Generator loss: 0.8222%]\n",
            "1008 [Discriminator loss: 0.7103%, acc.: 44.53%] [Generator loss: 0.8207%]\n",
            "1009 [Discriminator loss: 0.7268%, acc.: 39.06%] [Generator loss: 0.8246%]\n",
            "1010 [Discriminator loss: 0.7194%, acc.: 35.16%] [Generator loss: 0.8164%]\n",
            "1011 [Discriminator loss: 0.7220%, acc.: 36.72%] [Generator loss: 0.8159%]\n",
            "1012 [Discriminator loss: 0.7275%, acc.: 33.59%] [Generator loss: 0.8064%]\n",
            "1013 [Discriminator loss: 0.7255%, acc.: 35.16%] [Generator loss: 0.8023%]\n",
            "1014 [Discriminator loss: 0.7284%, acc.: 36.33%] [Generator loss: 0.8027%]\n",
            "1015 [Discriminator loss: 0.7154%, acc.: 35.55%] [Generator loss: 0.8072%]\n",
            "1016 [Discriminator loss: 0.7156%, acc.: 37.89%] [Generator loss: 0.8010%]\n",
            "1017 [Discriminator loss: 0.7251%, acc.: 34.38%] [Generator loss: 0.8100%]\n",
            "1018 [Discriminator loss: 0.7312%, acc.: 34.38%] [Generator loss: 0.7978%]\n",
            "1019 [Discriminator loss: 0.7298%, acc.: 33.59%] [Generator loss: 0.7900%]\n",
            "1020 [Discriminator loss: 0.7269%, acc.: 37.89%] [Generator loss: 0.7886%]\n",
            "1021 [Discriminator loss: 0.7364%, acc.: 36.33%] [Generator loss: 0.7859%]\n",
            "1022 [Discriminator loss: 0.7320%, acc.: 35.94%] [Generator loss: 0.7833%]\n",
            "1023 [Discriminator loss: 0.7386%, acc.: 38.28%] [Generator loss: 0.7958%]\n",
            "1024 [Discriminator loss: 0.7314%, acc.: 37.50%] [Generator loss: 0.7919%]\n",
            "1025 [Discriminator loss: 0.7258%, acc.: 38.67%] [Generator loss: 0.7841%]\n",
            "1026 [Discriminator loss: 0.7256%, acc.: 35.55%] [Generator loss: 0.7851%]\n",
            "1027 [Discriminator loss: 0.7324%, acc.: 32.03%] [Generator loss: 0.7908%]\n",
            "1028 [Discriminator loss: 0.7317%, acc.: 35.55%] [Generator loss: 0.7857%]\n",
            "1029 [Discriminator loss: 0.7370%, acc.: 33.20%] [Generator loss: 0.7815%]\n",
            "1030 [Discriminator loss: 0.7422%, acc.: 32.03%] [Generator loss: 0.7810%]\n",
            "1031 [Discriminator loss: 0.7253%, acc.: 36.33%] [Generator loss: 0.7849%]\n",
            "1032 [Discriminator loss: 0.7397%, acc.: 30.47%] [Generator loss: 0.7802%]\n",
            "1033 [Discriminator loss: 0.7410%, acc.: 31.25%] [Generator loss: 0.7782%]\n",
            "1034 [Discriminator loss: 0.7405%, acc.: 36.33%] [Generator loss: 0.7802%]\n",
            "1035 [Discriminator loss: 0.7387%, acc.: 35.55%] [Generator loss: 0.7815%]\n",
            "1036 [Discriminator loss: 0.7360%, acc.: 32.42%] [Generator loss: 0.7838%]\n",
            "1037 [Discriminator loss: 0.7366%, acc.: 31.64%] [Generator loss: 0.7853%]\n",
            "1038 [Discriminator loss: 0.7402%, acc.: 32.42%] [Generator loss: 0.7895%]\n",
            "1039 [Discriminator loss: 0.7282%, acc.: 35.55%] [Generator loss: 0.7910%]\n",
            "1040 [Discriminator loss: 0.7289%, acc.: 34.77%] [Generator loss: 0.7926%]\n",
            "1041 [Discriminator loss: 0.7373%, acc.: 34.38%] [Generator loss: 0.7881%]\n",
            "1042 [Discriminator loss: 0.7345%, acc.: 32.42%] [Generator loss: 0.7913%]\n",
            "1043 [Discriminator loss: 0.7231%, acc.: 36.33%] [Generator loss: 0.7936%]\n",
            "1044 [Discriminator loss: 0.7273%, acc.: 36.33%] [Generator loss: 0.7892%]\n",
            "1045 [Discriminator loss: 0.7283%, acc.: 35.16%] [Generator loss: 0.7899%]\n",
            "1046 [Discriminator loss: 0.7329%, acc.: 35.94%] [Generator loss: 0.7824%]\n",
            "1047 [Discriminator loss: 0.7131%, acc.: 40.23%] [Generator loss: 0.7964%]\n",
            "1048 [Discriminator loss: 0.7255%, acc.: 33.59%] [Generator loss: 0.7860%]\n",
            "1049 [Discriminator loss: 0.7129%, acc.: 38.28%] [Generator loss: 0.7923%]\n",
            "1050 [Discriminator loss: 0.7228%, acc.: 41.02%] [Generator loss: 0.7955%]\n",
            "1051 [Discriminator loss: 0.7217%, acc.: 37.50%] [Generator loss: 0.8012%]\n",
            "1052 [Discriminator loss: 0.7273%, acc.: 35.94%] [Generator loss: 0.7998%]\n",
            "1053 [Discriminator loss: 0.7233%, acc.: 35.16%] [Generator loss: 0.7947%]\n",
            "1054 [Discriminator loss: 0.7075%, acc.: 38.67%] [Generator loss: 0.7954%]\n",
            "1055 [Discriminator loss: 0.7163%, acc.: 34.77%] [Generator loss: 0.7934%]\n",
            "1056 [Discriminator loss: 0.7123%, acc.: 37.50%] [Generator loss: 0.7951%]\n",
            "1057 [Discriminator loss: 0.7159%, acc.: 37.89%] [Generator loss: 0.7886%]\n",
            "1058 [Discriminator loss: 0.7060%, acc.: 42.97%] [Generator loss: 0.8006%]\n",
            "1059 [Discriminator loss: 0.7132%, acc.: 44.14%] [Generator loss: 0.7996%]\n",
            "1060 [Discriminator loss: 0.7106%, acc.: 35.94%] [Generator loss: 0.8036%]\n",
            "1061 [Discriminator loss: 0.7141%, acc.: 35.16%] [Generator loss: 0.8023%]\n",
            "1062 [Discriminator loss: 0.7266%, acc.: 32.81%] [Generator loss: 0.7935%]\n",
            "1063 [Discriminator loss: 0.7237%, acc.: 36.72%] [Generator loss: 0.7899%]\n",
            "1064 [Discriminator loss: 0.7103%, acc.: 40.62%] [Generator loss: 0.8010%]\n",
            "1065 [Discriminator loss: 0.7176%, acc.: 35.16%] [Generator loss: 0.7985%]\n",
            "1066 [Discriminator loss: 0.7145%, acc.: 37.89%] [Generator loss: 0.7949%]\n",
            "1067 [Discriminator loss: 0.7121%, acc.: 35.55%] [Generator loss: 0.7991%]\n",
            "1068 [Discriminator loss: 0.7158%, acc.: 37.89%] [Generator loss: 0.7980%]\n",
            "1069 [Discriminator loss: 0.7171%, acc.: 34.77%] [Generator loss: 0.7862%]\n",
            "1070 [Discriminator loss: 0.7142%, acc.: 38.67%] [Generator loss: 0.7938%]\n",
            "1071 [Discriminator loss: 0.7191%, acc.: 34.77%] [Generator loss: 0.7946%]\n",
            "1072 [Discriminator loss: 0.7174%, acc.: 39.45%] [Generator loss: 0.7884%]\n",
            "1073 [Discriminator loss: 0.7140%, acc.: 38.67%] [Generator loss: 0.7941%]\n",
            "1074 [Discriminator loss: 0.7248%, acc.: 37.89%] [Generator loss: 0.7849%]\n",
            "1075 [Discriminator loss: 0.7149%, acc.: 39.06%] [Generator loss: 0.7886%]\n",
            "1076 [Discriminator loss: 0.7070%, acc.: 41.80%] [Generator loss: 0.7925%]\n",
            "1077 [Discriminator loss: 0.7319%, acc.: 33.59%] [Generator loss: 0.7929%]\n",
            "1078 [Discriminator loss: 0.7239%, acc.: 36.33%] [Generator loss: 0.7885%]\n",
            "1079 [Discriminator loss: 0.7173%, acc.: 37.89%] [Generator loss: 0.7879%]\n",
            "1080 [Discriminator loss: 0.7250%, acc.: 37.50%] [Generator loss: 0.7885%]\n",
            "1081 [Discriminator loss: 0.7221%, acc.: 40.62%] [Generator loss: 0.7873%]\n",
            "1082 [Discriminator loss: 0.7239%, acc.: 38.28%] [Generator loss: 0.7817%]\n",
            "1083 [Discriminator loss: 0.7189%, acc.: 39.06%] [Generator loss: 0.7825%]\n",
            "1084 [Discriminator loss: 0.7130%, acc.: 42.19%] [Generator loss: 0.7865%]\n",
            "1085 [Discriminator loss: 0.7149%, acc.: 46.09%] [Generator loss: 0.7909%]\n",
            "1086 [Discriminator loss: 0.7164%, acc.: 43.36%] [Generator loss: 0.7958%]\n",
            "1087 [Discriminator loss: 0.7183%, acc.: 37.11%] [Generator loss: 0.7931%]\n",
            "1088 [Discriminator loss: 0.7252%, acc.: 35.94%] [Generator loss: 0.7857%]\n",
            "1089 [Discriminator loss: 0.7150%, acc.: 40.62%] [Generator loss: 0.7870%]\n",
            "1090 [Discriminator loss: 0.7194%, acc.: 38.28%] [Generator loss: 0.7854%]\n",
            "1091 [Discriminator loss: 0.7128%, acc.: 37.89%] [Generator loss: 0.7871%]\n",
            "1092 [Discriminator loss: 0.7287%, acc.: 37.11%] [Generator loss: 0.7812%]\n",
            "1093 [Discriminator loss: 0.7249%, acc.: 35.94%] [Generator loss: 0.7783%]\n",
            "1094 [Discriminator loss: 0.7249%, acc.: 37.11%] [Generator loss: 0.7836%]\n",
            "1095 [Discriminator loss: 0.7221%, acc.: 36.72%] [Generator loss: 0.7875%]\n",
            "1096 [Discriminator loss: 0.7227%, acc.: 37.11%] [Generator loss: 0.7908%]\n",
            "1097 [Discriminator loss: 0.7329%, acc.: 34.77%] [Generator loss: 0.7758%]\n",
            "1098 [Discriminator loss: 0.7203%, acc.: 40.62%] [Generator loss: 0.7804%]\n",
            "1099 [Discriminator loss: 0.7189%, acc.: 41.02%] [Generator loss: 0.7823%]\n",
            "1100 [Discriminator loss: 0.7300%, acc.: 38.28%] [Generator loss: 0.7817%]\n",
            "1101 [Discriminator loss: 0.7294%, acc.: 35.94%] [Generator loss: 0.7808%]\n",
            "1102 [Discriminator loss: 0.7202%, acc.: 37.89%] [Generator loss: 0.7801%]\n",
            "1103 [Discriminator loss: 0.7406%, acc.: 35.55%] [Generator loss: 0.7795%]\n",
            "1104 [Discriminator loss: 0.7318%, acc.: 35.16%] [Generator loss: 0.7780%]\n",
            "1105 [Discriminator loss: 0.7260%, acc.: 34.38%] [Generator loss: 0.7812%]\n",
            "1106 [Discriminator loss: 0.7278%, acc.: 36.72%] [Generator loss: 0.7809%]\n",
            "1107 [Discriminator loss: 0.7214%, acc.: 35.55%] [Generator loss: 0.7850%]\n",
            "1108 [Discriminator loss: 0.7234%, acc.: 39.45%] [Generator loss: 0.7838%]\n",
            "1109 [Discriminator loss: 0.7107%, acc.: 40.23%] [Generator loss: 0.7822%]\n",
            "1110 [Discriminator loss: 0.7259%, acc.: 34.77%] [Generator loss: 0.7846%]\n",
            "1111 [Discriminator loss: 0.7142%, acc.: 38.67%] [Generator loss: 0.7930%]\n",
            "1112 [Discriminator loss: 0.7133%, acc.: 37.11%] [Generator loss: 0.7942%]\n",
            "1113 [Discriminator loss: 0.7224%, acc.: 33.59%] [Generator loss: 0.7921%]\n",
            "1114 [Discriminator loss: 0.7214%, acc.: 34.77%] [Generator loss: 0.7995%]\n",
            "1115 [Discriminator loss: 0.7118%, acc.: 35.94%] [Generator loss: 0.8085%]\n",
            "1116 [Discriminator loss: 0.7159%, acc.: 33.59%] [Generator loss: 0.8021%]\n",
            "1117 [Discriminator loss: 0.7123%, acc.: 39.84%] [Generator loss: 0.7960%]\n",
            "1118 [Discriminator loss: 0.7125%, acc.: 38.67%] [Generator loss: 0.8035%]\n",
            "1119 [Discriminator loss: 0.7210%, acc.: 33.59%] [Generator loss: 0.7979%]\n",
            "1120 [Discriminator loss: 0.7176%, acc.: 36.72%] [Generator loss: 0.7981%]\n",
            "1121 [Discriminator loss: 0.7137%, acc.: 37.50%] [Generator loss: 0.7970%]\n",
            "1122 [Discriminator loss: 0.7169%, acc.: 34.38%] [Generator loss: 0.7930%]\n",
            "1123 [Discriminator loss: 0.7061%, acc.: 40.62%] [Generator loss: 0.8010%]\n",
            "1124 [Discriminator loss: 0.7184%, acc.: 34.38%] [Generator loss: 0.7940%]\n",
            "1125 [Discriminator loss: 0.7154%, acc.: 35.55%] [Generator loss: 0.7981%]\n",
            "1126 [Discriminator loss: 0.7060%, acc.: 38.67%] [Generator loss: 0.8028%]\n",
            "1127 [Discriminator loss: 0.7200%, acc.: 33.59%] [Generator loss: 0.7954%]\n",
            "1128 [Discriminator loss: 0.7147%, acc.: 37.50%] [Generator loss: 0.7918%]\n",
            "1129 [Discriminator loss: 0.7073%, acc.: 38.67%] [Generator loss: 0.8004%]\n",
            "1130 [Discriminator loss: 0.7112%, acc.: 37.50%] [Generator loss: 0.7989%]\n",
            "1131 [Discriminator loss: 0.7087%, acc.: 37.11%] [Generator loss: 0.7994%]\n",
            "1132 [Discriminator loss: 0.7171%, acc.: 38.28%] [Generator loss: 0.7891%]\n",
            "1133 [Discriminator loss: 0.7047%, acc.: 43.36%] [Generator loss: 0.7890%]\n",
            "1134 [Discriminator loss: 0.7110%, acc.: 37.89%] [Generator loss: 0.7940%]\n",
            "1135 [Discriminator loss: 0.7117%, acc.: 35.94%] [Generator loss: 0.8013%]\n",
            "1136 [Discriminator loss: 0.7121%, acc.: 39.45%] [Generator loss: 0.7918%]\n",
            "1137 [Discriminator loss: 0.7117%, acc.: 39.06%] [Generator loss: 0.7879%]\n",
            "1138 [Discriminator loss: 0.7073%, acc.: 40.23%] [Generator loss: 0.7911%]\n",
            "1139 [Discriminator loss: 0.7109%, acc.: 37.89%] [Generator loss: 0.7984%]\n",
            "1140 [Discriminator loss: 0.6952%, acc.: 41.80%] [Generator loss: 0.8077%]\n",
            "1141 [Discriminator loss: 0.6965%, acc.: 39.84%] [Generator loss: 0.8155%]\n",
            "1142 [Discriminator loss: 0.7111%, acc.: 36.33%] [Generator loss: 0.8003%]\n",
            "1143 [Discriminator loss: 0.7122%, acc.: 35.55%] [Generator loss: 0.7927%]\n",
            "1144 [Discriminator loss: 0.7154%, acc.: 34.38%] [Generator loss: 0.7941%]\n",
            "1145 [Discriminator loss: 0.7023%, acc.: 37.50%] [Generator loss: 0.8026%]\n",
            "1146 [Discriminator loss: 0.7164%, acc.: 33.20%] [Generator loss: 0.8037%]\n",
            "1147 [Discriminator loss: 0.7064%, acc.: 35.55%] [Generator loss: 0.8036%]\n",
            "1148 [Discriminator loss: 0.7140%, acc.: 32.03%] [Generator loss: 0.7967%]\n",
            "1149 [Discriminator loss: 0.7021%, acc.: 38.67%] [Generator loss: 0.8029%]\n",
            "1150 [Discriminator loss: 0.7116%, acc.: 36.33%] [Generator loss: 0.7999%]\n",
            "1151 [Discriminator loss: 0.7089%, acc.: 37.89%] [Generator loss: 0.8032%]\n",
            "1152 [Discriminator loss: 0.7222%, acc.: 31.25%] [Generator loss: 0.7949%]\n",
            "1153 [Discriminator loss: 0.7157%, acc.: 33.98%] [Generator loss: 0.7960%]\n",
            "1154 [Discriminator loss: 0.7139%, acc.: 34.38%] [Generator loss: 0.7985%]\n",
            "1155 [Discriminator loss: 0.7087%, acc.: 34.38%] [Generator loss: 0.7932%]\n",
            "1156 [Discriminator loss: 0.7175%, acc.: 33.20%] [Generator loss: 0.7939%]\n",
            "1157 [Discriminator loss: 0.7099%, acc.: 36.33%] [Generator loss: 0.7978%]\n",
            "1158 [Discriminator loss: 0.7257%, acc.: 29.30%] [Generator loss: 0.7872%]\n",
            "1159 [Discriminator loss: 0.7046%, acc.: 37.89%] [Generator loss: 0.7946%]\n",
            "1160 [Discriminator loss: 0.7166%, acc.: 33.59%] [Generator loss: 0.7967%]\n",
            "1161 [Discriminator loss: 0.7277%, acc.: 29.69%] [Generator loss: 0.7828%]\n",
            "1162 [Discriminator loss: 0.7140%, acc.: 35.16%] [Generator loss: 0.7836%]\n",
            "1163 [Discriminator loss: 0.7109%, acc.: 33.98%] [Generator loss: 0.7890%]\n",
            "1164 [Discriminator loss: 0.7134%, acc.: 35.16%] [Generator loss: 0.7880%]\n",
            "1165 [Discriminator loss: 0.7198%, acc.: 33.59%] [Generator loss: 0.7903%]\n",
            "1166 [Discriminator loss: 0.7178%, acc.: 37.89%] [Generator loss: 0.7843%]\n",
            "1167 [Discriminator loss: 0.7146%, acc.: 37.50%] [Generator loss: 0.7882%]\n",
            "1168 [Discriminator loss: 0.7227%, acc.: 32.03%] [Generator loss: 0.7836%]\n",
            "1169 [Discriminator loss: 0.7101%, acc.: 38.28%] [Generator loss: 0.7928%]\n",
            "1170 [Discriminator loss: 0.7223%, acc.: 31.25%] [Generator loss: 0.7872%]\n",
            "1171 [Discriminator loss: 0.7095%, acc.: 38.28%] [Generator loss: 0.7860%]\n",
            "1172 [Discriminator loss: 0.7118%, acc.: 36.33%] [Generator loss: 0.7886%]\n",
            "1173 [Discriminator loss: 0.7180%, acc.: 34.38%] [Generator loss: 0.7818%]\n",
            "1174 [Discriminator loss: 0.7182%, acc.: 35.55%] [Generator loss: 0.7833%]\n",
            "1175 [Discriminator loss: 0.7155%, acc.: 33.59%] [Generator loss: 0.7861%]\n",
            "1176 [Discriminator loss: 0.7098%, acc.: 36.72%] [Generator loss: 0.7879%]\n",
            "1177 [Discriminator loss: 0.7124%, acc.: 35.55%] [Generator loss: 0.7875%]\n",
            "1178 [Discriminator loss: 0.7168%, acc.: 32.81%] [Generator loss: 0.7812%]\n",
            "1179 [Discriminator loss: 0.7238%, acc.: 34.38%] [Generator loss: 0.7827%]\n",
            "1180 [Discriminator loss: 0.7200%, acc.: 33.59%] [Generator loss: 0.7844%]\n",
            "1181 [Discriminator loss: 0.7080%, acc.: 35.16%] [Generator loss: 0.8012%]\n",
            "1182 [Discriminator loss: 0.7229%, acc.: 33.98%] [Generator loss: 0.7870%]\n",
            "1183 [Discriminator loss: 0.7182%, acc.: 35.94%] [Generator loss: 0.7842%]\n",
            "1184 [Discriminator loss: 0.7167%, acc.: 35.94%] [Generator loss: 0.7894%]\n",
            "1185 [Discriminator loss: 0.7193%, acc.: 35.55%] [Generator loss: 0.7912%]\n",
            "1186 [Discriminator loss: 0.7153%, acc.: 35.16%] [Generator loss: 0.7900%]\n",
            "1187 [Discriminator loss: 0.7125%, acc.: 34.38%] [Generator loss: 0.7918%]\n",
            "1188 [Discriminator loss: 0.7179%, acc.: 36.72%] [Generator loss: 0.7921%]\n",
            "1189 [Discriminator loss: 0.7201%, acc.: 37.11%] [Generator loss: 0.7854%]\n",
            "1190 [Discriminator loss: 0.7172%, acc.: 36.72%] [Generator loss: 0.7838%]\n",
            "1191 [Discriminator loss: 0.7155%, acc.: 36.72%] [Generator loss: 0.7881%]\n",
            "1192 [Discriminator loss: 0.7169%, acc.: 35.16%] [Generator loss: 0.7938%]\n",
            "1193 [Discriminator loss: 0.7116%, acc.: 35.94%] [Generator loss: 0.8002%]\n",
            "1194 [Discriminator loss: 0.7136%, acc.: 35.55%] [Generator loss: 0.7988%]\n",
            "1195 [Discriminator loss: 0.7175%, acc.: 32.42%] [Generator loss: 0.7937%]\n",
            "1196 [Discriminator loss: 0.7155%, acc.: 35.55%] [Generator loss: 0.7931%]\n",
            "1197 [Discriminator loss: 0.7188%, acc.: 35.94%] [Generator loss: 0.8005%]\n",
            "1198 [Discriminator loss: 0.6990%, acc.: 39.84%] [Generator loss: 0.8067%]\n",
            "1199 [Discriminator loss: 0.7066%, acc.: 35.55%] [Generator loss: 0.8085%]\n",
            "1200 [Discriminator loss: 0.7100%, acc.: 34.38%] [Generator loss: 0.8092%]\n",
            "1201 [Discriminator loss: 0.7123%, acc.: 34.38%] [Generator loss: 0.8024%]\n",
            "1202 [Discriminator loss: 0.7036%, acc.: 34.77%] [Generator loss: 0.8019%]\n",
            "1203 [Discriminator loss: 0.7102%, acc.: 36.33%] [Generator loss: 0.7983%]\n",
            "1204 [Discriminator loss: 0.7216%, acc.: 33.98%] [Generator loss: 0.7962%]\n",
            "1205 [Discriminator loss: 0.7120%, acc.: 35.16%] [Generator loss: 0.8054%]\n",
            "1206 [Discriminator loss: 0.7264%, acc.: 25.78%] [Generator loss: 0.8039%]\n",
            "1207 [Discriminator loss: 0.7064%, acc.: 37.89%] [Generator loss: 0.8068%]\n",
            "1208 [Discriminator loss: 0.7113%, acc.: 37.11%] [Generator loss: 0.8075%]\n",
            "1209 [Discriminator loss: 0.7218%, acc.: 33.59%] [Generator loss: 0.8023%]\n",
            "1210 [Discriminator loss: 0.7038%, acc.: 35.16%] [Generator loss: 0.7999%]\n",
            "1211 [Discriminator loss: 0.7156%, acc.: 34.38%] [Generator loss: 0.7982%]\n",
            "1212 [Discriminator loss: 0.7110%, acc.: 31.25%] [Generator loss: 0.8027%]\n",
            "1213 [Discriminator loss: 0.7099%, acc.: 32.42%] [Generator loss: 0.7963%]\n",
            "1214 [Discriminator loss: 0.7082%, acc.: 35.16%] [Generator loss: 0.7959%]\n",
            "1215 [Discriminator loss: 0.6985%, acc.: 35.16%] [Generator loss: 0.7994%]\n",
            "1216 [Discriminator loss: 0.7074%, acc.: 34.38%] [Generator loss: 0.8030%]\n",
            "1217 [Discriminator loss: 0.7052%, acc.: 37.89%] [Generator loss: 0.8036%]\n",
            "1218 [Discriminator loss: 0.7024%, acc.: 39.84%] [Generator loss: 0.8006%]\n",
            "1219 [Discriminator loss: 0.6995%, acc.: 38.28%] [Generator loss: 0.8008%]\n",
            "1220 [Discriminator loss: 0.7058%, acc.: 31.25%] [Generator loss: 0.8014%]\n",
            "1221 [Discriminator loss: 0.7129%, acc.: 29.69%] [Generator loss: 0.7981%]\n",
            "1222 [Discriminator loss: 0.7075%, acc.: 34.38%] [Generator loss: 0.7895%]\n",
            "1223 [Discriminator loss: 0.6991%, acc.: 37.89%] [Generator loss: 0.7968%]\n",
            "1224 [Discriminator loss: 0.6960%, acc.: 35.94%] [Generator loss: 0.8080%]\n",
            "1225 [Discriminator loss: 0.7117%, acc.: 26.95%] [Generator loss: 0.8026%]\n",
            "1226 [Discriminator loss: 0.7176%, acc.: 28.12%] [Generator loss: 0.7939%]\n",
            "1227 [Discriminator loss: 0.7072%, acc.: 33.20%] [Generator loss: 0.7917%]\n",
            "1228 [Discriminator loss: 0.7126%, acc.: 31.64%] [Generator loss: 0.7886%]\n",
            "1229 [Discriminator loss: 0.6948%, acc.: 35.94%] [Generator loss: 0.7956%]\n",
            "1230 [Discriminator loss: 0.7030%, acc.: 30.47%] [Generator loss: 0.7989%]\n",
            "1231 [Discriminator loss: 0.7004%, acc.: 38.67%] [Generator loss: 0.8029%]\n",
            "1232 [Discriminator loss: 0.6922%, acc.: 39.06%] [Generator loss: 0.8081%]\n",
            "1233 [Discriminator loss: 0.7049%, acc.: 37.89%] [Generator loss: 0.8008%]\n",
            "1234 [Discriminator loss: 0.6991%, acc.: 37.89%] [Generator loss: 0.7981%]\n",
            "1235 [Discriminator loss: 0.7086%, acc.: 42.97%] [Generator loss: 0.8010%]\n",
            "1236 [Discriminator loss: 0.6927%, acc.: 44.92%] [Generator loss: 0.8148%]\n",
            "1237 [Discriminator loss: 0.6929%, acc.: 46.09%] [Generator loss: 0.8216%]\n",
            "1238 [Discriminator loss: 0.7012%, acc.: 37.11%] [Generator loss: 0.8125%]\n",
            "1239 [Discriminator loss: 0.6945%, acc.: 34.38%] [Generator loss: 0.8085%]\n",
            "1240 [Discriminator loss: 0.7018%, acc.: 30.47%] [Generator loss: 0.8125%]\n",
            "1241 [Discriminator loss: 0.6934%, acc.: 35.16%] [Generator loss: 0.8146%]\n",
            "1242 [Discriminator loss: 0.7021%, acc.: 30.08%] [Generator loss: 0.8046%]\n",
            "1243 [Discriminator loss: 0.7103%, acc.: 32.03%] [Generator loss: 0.7996%]\n",
            "1244 [Discriminator loss: 0.6951%, acc.: 37.50%] [Generator loss: 0.8065%]\n",
            "1245 [Discriminator loss: 0.6947%, acc.: 36.33%] [Generator loss: 0.8125%]\n",
            "1246 [Discriminator loss: 0.6946%, acc.: 39.06%] [Generator loss: 0.8111%]\n",
            "1247 [Discriminator loss: 0.6863%, acc.: 46.48%] [Generator loss: 0.8145%]\n",
            "1248 [Discriminator loss: 0.6863%, acc.: 49.22%] [Generator loss: 0.8056%]\n",
            "1249 [Discriminator loss: 0.6881%, acc.: 51.17%] [Generator loss: 0.8024%]\n",
            "1250 [Discriminator loss: 0.6866%, acc.: 54.30%] [Generator loss: 0.8116%]\n",
            "1251 [Discriminator loss: 0.6837%, acc.: 52.34%] [Generator loss: 0.8253%]\n",
            "1252 [Discriminator loss: 0.6760%, acc.: 55.47%] [Generator loss: 0.8264%]\n",
            "1253 [Discriminator loss: 0.6933%, acc.: 46.09%] [Generator loss: 0.8271%]\n",
            "1254 [Discriminator loss: 0.6923%, acc.: 50.00%] [Generator loss: 0.8180%]\n",
            "1255 [Discriminator loss: 0.6889%, acc.: 50.78%] [Generator loss: 0.8151%]\n",
            "1256 [Discriminator loss: 0.6910%, acc.: 48.83%] [Generator loss: 0.8142%]\n",
            "1257 [Discriminator loss: 0.6899%, acc.: 47.66%] [Generator loss: 0.8199%]\n",
            "1258 [Discriminator loss: 0.6872%, acc.: 45.31%] [Generator loss: 0.8270%]\n",
            "1259 [Discriminator loss: 0.6930%, acc.: 33.20%] [Generator loss: 0.8192%]\n",
            "1260 [Discriminator loss: 0.6970%, acc.: 33.20%] [Generator loss: 0.8094%]\n",
            "1261 [Discriminator loss: 0.6928%, acc.: 36.33%] [Generator loss: 0.8111%]\n",
            "1262 [Discriminator loss: 0.6959%, acc.: 33.98%] [Generator loss: 0.8083%]\n",
            "1263 [Discriminator loss: 0.6958%, acc.: 33.20%] [Generator loss: 0.8107%]\n",
            "1264 [Discriminator loss: 0.6847%, acc.: 39.45%] [Generator loss: 0.8152%]\n",
            "1265 [Discriminator loss: 0.6867%, acc.: 36.72%] [Generator loss: 0.8224%]\n",
            "1266 [Discriminator loss: 0.6919%, acc.: 34.38%] [Generator loss: 0.8236%]\n",
            "1267 [Discriminator loss: 0.6968%, acc.: 32.81%] [Generator loss: 0.8075%]\n",
            "1268 [Discriminator loss: 0.6910%, acc.: 35.16%] [Generator loss: 0.8077%]\n",
            "1269 [Discriminator loss: 0.6833%, acc.: 38.67%] [Generator loss: 0.8213%]\n",
            "1270 [Discriminator loss: 0.6981%, acc.: 29.69%] [Generator loss: 0.8131%]\n",
            "1271 [Discriminator loss: 0.6871%, acc.: 36.33%] [Generator loss: 0.8090%]\n",
            "1272 [Discriminator loss: 0.6871%, acc.: 40.23%] [Generator loss: 0.8148%]\n",
            "1273 [Discriminator loss: 0.6968%, acc.: 32.03%] [Generator loss: 0.8088%]\n",
            "1274 [Discriminator loss: 0.6885%, acc.: 36.72%] [Generator loss: 0.8131%]\n",
            "1275 [Discriminator loss: 0.6938%, acc.: 35.16%] [Generator loss: 0.8039%]\n",
            "1276 [Discriminator loss: 0.6878%, acc.: 41.02%] [Generator loss: 0.8086%]\n",
            "1277 [Discriminator loss: 0.6955%, acc.: 36.33%] [Generator loss: 0.8065%]\n",
            "1278 [Discriminator loss: 0.6941%, acc.: 38.67%] [Generator loss: 0.8056%]\n",
            "1279 [Discriminator loss: 0.7016%, acc.: 37.50%] [Generator loss: 0.8051%]\n",
            "1280 [Discriminator loss: 0.6990%, acc.: 33.98%] [Generator loss: 0.8072%]\n",
            "1281 [Discriminator loss: 0.6856%, acc.: 42.19%] [Generator loss: 0.8072%]\n",
            "1282 [Discriminator loss: 0.6979%, acc.: 37.50%] [Generator loss: 0.8051%]\n",
            "1283 [Discriminator loss: 0.6977%, acc.: 38.28%] [Generator loss: 0.8098%]\n",
            "1284 [Discriminator loss: 0.6946%, acc.: 37.50%] [Generator loss: 0.8121%]\n",
            "1285 [Discriminator loss: 0.7009%, acc.: 33.98%] [Generator loss: 0.8111%]\n",
            "1286 [Discriminator loss: 0.6890%, acc.: 39.06%] [Generator loss: 0.8012%]\n",
            "1287 [Discriminator loss: 0.6883%, acc.: 42.58%] [Generator loss: 0.8149%]\n",
            "1288 [Discriminator loss: 0.6949%, acc.: 37.50%] [Generator loss: 0.8089%]\n",
            "1289 [Discriminator loss: 0.6968%, acc.: 39.45%] [Generator loss: 0.8105%]\n",
            "1290 [Discriminator loss: 0.6880%, acc.: 44.92%] [Generator loss: 0.8085%]\n",
            "1291 [Discriminator loss: 0.6866%, acc.: 41.80%] [Generator loss: 0.8080%]\n",
            "1292 [Discriminator loss: 0.6901%, acc.: 42.58%] [Generator loss: 0.8118%]\n",
            "1293 [Discriminator loss: 0.6858%, acc.: 40.23%] [Generator loss: 0.8124%]\n",
            "1294 [Discriminator loss: 0.6914%, acc.: 42.97%] [Generator loss: 0.8125%]\n",
            "1295 [Discriminator loss: 0.6842%, acc.: 47.27%] [Generator loss: 0.8149%]\n",
            "1296 [Discriminator loss: 0.6825%, acc.: 51.56%] [Generator loss: 0.8235%]\n",
            "1297 [Discriminator loss: 0.7030%, acc.: 44.92%] [Generator loss: 0.8173%]\n",
            "1298 [Discriminator loss: 0.6850%, acc.: 34.38%] [Generator loss: 0.8182%]\n",
            "1299 [Discriminator loss: 0.6931%, acc.: 35.94%] [Generator loss: 0.8173%]\n",
            "1300 [Discriminator loss: 0.6865%, acc.: 36.72%] [Generator loss: 0.8167%]\n",
            "1301 [Discriminator loss: 0.6860%, acc.: 36.72%] [Generator loss: 0.8221%]\n",
            "1302 [Discriminator loss: 0.6724%, acc.: 37.89%] [Generator loss: 0.8320%]\n",
            "1303 [Discriminator loss: 0.6811%, acc.: 43.75%] [Generator loss: 0.8346%]\n",
            "1304 [Discriminator loss: 0.6893%, acc.: 45.70%] [Generator loss: 0.8274%]\n",
            "1305 [Discriminator loss: 0.6860%, acc.: 46.88%] [Generator loss: 0.8351%]\n",
            "1306 [Discriminator loss: 0.6873%, acc.: 43.75%] [Generator loss: 0.8222%]\n",
            "1307 [Discriminator loss: 0.6843%, acc.: 42.19%] [Generator loss: 0.8197%]\n",
            "1308 [Discriminator loss: 0.6742%, acc.: 46.09%] [Generator loss: 0.8260%]\n",
            "1309 [Discriminator loss: 0.7021%, acc.: 34.77%] [Generator loss: 0.8185%]\n",
            "1310 [Discriminator loss: 0.6773%, acc.: 39.84%] [Generator loss: 0.8261%]\n",
            "1311 [Discriminator loss: 0.6786%, acc.: 42.58%] [Generator loss: 0.8325%]\n",
            "1312 [Discriminator loss: 0.7011%, acc.: 35.55%] [Generator loss: 0.8419%]\n",
            "1313 [Discriminator loss: 0.6846%, acc.: 44.53%] [Generator loss: 0.8315%]\n",
            "1314 [Discriminator loss: 0.6781%, acc.: 54.69%] [Generator loss: 0.8318%]\n",
            "1315 [Discriminator loss: 0.6708%, acc.: 57.42%] [Generator loss: 0.8522%]\n",
            "1316 [Discriminator loss: 0.6740%, acc.: 51.56%] [Generator loss: 0.8460%]\n",
            "1317 [Discriminator loss: 0.6819%, acc.: 48.05%] [Generator loss: 0.8333%]\n",
            "1318 [Discriminator loss: 0.6574%, acc.: 59.38%] [Generator loss: 0.8398%]\n",
            "1319 [Discriminator loss: 0.6596%, acc.: 60.94%] [Generator loss: 0.8480%]\n",
            "1320 [Discriminator loss: 0.6778%, acc.: 56.64%] [Generator loss: 0.8287%]\n",
            "1321 [Discriminator loss: 0.6750%, acc.: 50.78%] [Generator loss: 0.8353%]\n",
            "1322 [Discriminator loss: 0.6614%, acc.: 58.98%] [Generator loss: 0.8433%]\n",
            "1323 [Discriminator loss: 0.6657%, acc.: 56.25%] [Generator loss: 0.8523%]\n",
            "1324 [Discriminator loss: 0.6530%, acc.: 58.98%] [Generator loss: 0.8501%]\n",
            "1325 [Discriminator loss: 0.6718%, acc.: 57.42%] [Generator loss: 0.8508%]\n",
            "1326 [Discriminator loss: 0.6901%, acc.: 48.05%] [Generator loss: 0.8349%]\n",
            "1327 [Discriminator loss: 0.6710%, acc.: 53.52%] [Generator loss: 0.8437%]\n",
            "1328 [Discriminator loss: 0.6681%, acc.: 57.03%] [Generator loss: 0.8505%]\n",
            "1329 [Discriminator loss: 0.6716%, acc.: 59.77%] [Generator loss: 0.8527%]\n",
            "1330 [Discriminator loss: 0.6814%, acc.: 51.95%] [Generator loss: 0.8409%]\n",
            "1331 [Discriminator loss: 0.6794%, acc.: 51.95%] [Generator loss: 0.8329%]\n",
            "1332 [Discriminator loss: 0.6869%, acc.: 53.91%] [Generator loss: 0.8330%]\n",
            "1333 [Discriminator loss: 0.6749%, acc.: 56.64%] [Generator loss: 0.8297%]\n",
            "1334 [Discriminator loss: 0.6823%, acc.: 54.69%] [Generator loss: 0.8420%]\n",
            "1335 [Discriminator loss: 0.6883%, acc.: 54.30%] [Generator loss: 0.8309%]\n",
            "1336 [Discriminator loss: 0.6753%, acc.: 58.20%] [Generator loss: 0.8384%]\n",
            "1337 [Discriminator loss: 0.6828%, acc.: 53.91%] [Generator loss: 0.8212%]\n",
            "1338 [Discriminator loss: 0.6768%, acc.: 59.77%] [Generator loss: 0.8107%]\n",
            "1339 [Discriminator loss: 0.6758%, acc.: 60.55%] [Generator loss: 0.8334%]\n",
            "1340 [Discriminator loss: 0.6802%, acc.: 56.64%] [Generator loss: 0.8504%]\n",
            "1341 [Discriminator loss: 0.6844%, acc.: 58.98%] [Generator loss: 0.8396%]\n",
            "1342 [Discriminator loss: 0.6755%, acc.: 59.38%] [Generator loss: 0.8479%]\n",
            "1343 [Discriminator loss: 0.6942%, acc.: 55.08%] [Generator loss: 0.8236%]\n",
            "1344 [Discriminator loss: 0.6808%, acc.: 62.89%] [Generator loss: 0.8189%]\n",
            "1345 [Discriminator loss: 0.6839%, acc.: 55.08%] [Generator loss: 0.8376%]\n",
            "1346 [Discriminator loss: 0.6773%, acc.: 58.20%] [Generator loss: 0.8195%]\n",
            "1347 [Discriminator loss: 0.6848%, acc.: 54.30%] [Generator loss: 0.8302%]\n",
            "1348 [Discriminator loss: 0.7083%, acc.: 47.66%] [Generator loss: 0.8151%]\n",
            "1349 [Discriminator loss: 0.6917%, acc.: 52.73%] [Generator loss: 0.8241%]\n",
            "1350 [Discriminator loss: 0.6876%, acc.: 55.08%] [Generator loss: 0.8304%]\n",
            "1351 [Discriminator loss: 0.6987%, acc.: 47.27%] [Generator loss: 0.8212%]\n",
            "1352 [Discriminator loss: 0.6840%, acc.: 53.52%] [Generator loss: 0.8252%]\n",
            "1353 [Discriminator loss: 0.6839%, acc.: 55.47%] [Generator loss: 0.8307%]\n",
            "1354 [Discriminator loss: 0.6928%, acc.: 53.91%] [Generator loss: 0.8318%]\n",
            "1355 [Discriminator loss: 0.6790%, acc.: 61.33%] [Generator loss: 0.8383%]\n",
            "1356 [Discriminator loss: 0.6948%, acc.: 54.69%] [Generator loss: 0.8283%]\n",
            "1357 [Discriminator loss: 0.6770%, acc.: 55.86%] [Generator loss: 0.8217%]\n",
            "1358 [Discriminator loss: 0.6832%, acc.: 55.08%] [Generator loss: 0.8244%]\n",
            "1359 [Discriminator loss: 0.6875%, acc.: 58.98%] [Generator loss: 0.8371%]\n",
            "1360 [Discriminator loss: 0.6820%, acc.: 59.38%] [Generator loss: 0.8371%]\n",
            "1361 [Discriminator loss: 0.6695%, acc.: 62.50%] [Generator loss: 0.8315%]\n",
            "1362 [Discriminator loss: 0.6688%, acc.: 62.11%] [Generator loss: 0.8303%]\n",
            "1363 [Discriminator loss: 0.6602%, acc.: 65.23%] [Generator loss: 0.8419%]\n",
            "1364 [Discriminator loss: 0.6599%, acc.: 66.41%] [Generator loss: 0.8499%]\n",
            "1365 [Discriminator loss: 0.6655%, acc.: 59.77%] [Generator loss: 0.8439%]\n",
            "1366 [Discriminator loss: 0.6600%, acc.: 60.55%] [Generator loss: 0.8516%]\n",
            "1367 [Discriminator loss: 0.6756%, acc.: 57.42%] [Generator loss: 0.8492%]\n",
            "1368 [Discriminator loss: 0.6572%, acc.: 57.81%] [Generator loss: 0.8557%]\n",
            "1369 [Discriminator loss: 0.6755%, acc.: 56.25%] [Generator loss: 0.8513%]\n",
            "1370 [Discriminator loss: 0.6712%, acc.: 54.69%] [Generator loss: 0.8531%]\n",
            "1371 [Discriminator loss: 0.6602%, acc.: 65.23%] [Generator loss: 0.8506%]\n",
            "1372 [Discriminator loss: 0.6598%, acc.: 66.02%] [Generator loss: 0.8477%]\n",
            "1373 [Discriminator loss: 0.6662%, acc.: 63.28%] [Generator loss: 0.8437%]\n",
            "1374 [Discriminator loss: 0.6720%, acc.: 62.11%] [Generator loss: 0.8451%]\n",
            "1375 [Discriminator loss: 0.6801%, acc.: 60.94%] [Generator loss: 0.8496%]\n",
            "1376 [Discriminator loss: 0.6671%, acc.: 63.67%] [Generator loss: 0.8534%]\n",
            "1377 [Discriminator loss: 0.6811%, acc.: 59.38%] [Generator loss: 0.8461%]\n",
            "1378 [Discriminator loss: 0.6725%, acc.: 60.94%] [Generator loss: 0.8634%]\n",
            "1379 [Discriminator loss: 0.6701%, acc.: 61.33%] [Generator loss: 0.8624%]\n",
            "1380 [Discriminator loss: 0.6788%, acc.: 58.59%] [Generator loss: 0.8553%]\n",
            "1381 [Discriminator loss: 0.6634%, acc.: 61.72%] [Generator loss: 0.8533%]\n",
            "1382 [Discriminator loss: 0.6773%, acc.: 57.81%] [Generator loss: 0.8514%]\n",
            "1383 [Discriminator loss: 0.6783%, acc.: 58.98%] [Generator loss: 0.8550%]\n",
            "1384 [Discriminator loss: 0.6755%, acc.: 62.50%] [Generator loss: 0.8520%]\n",
            "1385 [Discriminator loss: 0.6827%, acc.: 58.59%] [Generator loss: 0.8528%]\n",
            "1386 [Discriminator loss: 0.6768%, acc.: 58.20%] [Generator loss: 0.8469%]\n",
            "1387 [Discriminator loss: 0.6823%, acc.: 62.50%] [Generator loss: 0.8529%]\n",
            "1388 [Discriminator loss: 0.6798%, acc.: 62.50%] [Generator loss: 0.8686%]\n",
            "1389 [Discriminator loss: 0.6972%, acc.: 52.73%] [Generator loss: 0.8531%]\n",
            "1390 [Discriminator loss: 0.6950%, acc.: 55.47%] [Generator loss: 0.8503%]\n",
            "1391 [Discriminator loss: 0.6893%, acc.: 54.30%] [Generator loss: 0.8422%]\n",
            "1392 [Discriminator loss: 0.6797%, acc.: 57.42%] [Generator loss: 0.8469%]\n",
            "1393 [Discriminator loss: 0.6936%, acc.: 52.73%] [Generator loss: 0.8406%]\n",
            "1394 [Discriminator loss: 0.6963%, acc.: 52.34%] [Generator loss: 0.8404%]\n",
            "1395 [Discriminator loss: 0.6841%, acc.: 58.20%] [Generator loss: 0.8355%]\n",
            "1396 [Discriminator loss: 0.6995%, acc.: 53.12%] [Generator loss: 0.8500%]\n",
            "1397 [Discriminator loss: 0.6880%, acc.: 54.30%] [Generator loss: 0.8526%]\n",
            "1398 [Discriminator loss: 0.6971%, acc.: 55.08%] [Generator loss: 0.8435%]\n",
            "1399 [Discriminator loss: 0.7068%, acc.: 45.31%] [Generator loss: 0.8382%]\n",
            "1400 [Discriminator loss: 0.6949%, acc.: 54.30%] [Generator loss: 0.8393%]\n",
            "1401 [Discriminator loss: 0.6983%, acc.: 51.56%] [Generator loss: 0.8325%]\n",
            "1402 [Discriminator loss: 0.6853%, acc.: 51.56%] [Generator loss: 0.8401%]\n",
            "1403 [Discriminator loss: 0.6944%, acc.: 47.66%] [Generator loss: 0.8411%]\n",
            "1404 [Discriminator loss: 0.6837%, acc.: 55.08%] [Generator loss: 0.8286%]\n",
            "1405 [Discriminator loss: 0.6971%, acc.: 45.70%] [Generator loss: 0.8222%]\n",
            "1406 [Discriminator loss: 0.6957%, acc.: 48.83%] [Generator loss: 0.8378%]\n",
            "1407 [Discriminator loss: 0.6924%, acc.: 46.48%] [Generator loss: 0.8434%]\n",
            "1408 [Discriminator loss: 0.6802%, acc.: 54.69%] [Generator loss: 0.8390%]\n",
            "1409 [Discriminator loss: 0.6881%, acc.: 46.88%] [Generator loss: 0.8455%]\n",
            "1410 [Discriminator loss: 0.6701%, acc.: 58.59%] [Generator loss: 0.8486%]\n",
            "1411 [Discriminator loss: 0.6833%, acc.: 52.73%] [Generator loss: 0.8519%]\n",
            "1412 [Discriminator loss: 0.6960%, acc.: 48.05%] [Generator loss: 0.8348%]\n",
            "1413 [Discriminator loss: 0.6829%, acc.: 52.34%] [Generator loss: 0.8395%]\n",
            "1414 [Discriminator loss: 0.7032%, acc.: 39.06%] [Generator loss: 0.8408%]\n",
            "1415 [Discriminator loss: 0.6978%, acc.: 41.41%] [Generator loss: 0.8429%]\n",
            "1416 [Discriminator loss: 0.6907%, acc.: 44.53%] [Generator loss: 0.8435%]\n",
            "1417 [Discriminator loss: 0.7014%, acc.: 42.97%] [Generator loss: 0.8289%]\n",
            "1418 [Discriminator loss: 0.6964%, acc.: 42.97%] [Generator loss: 0.8270%]\n",
            "1419 [Discriminator loss: 0.7037%, acc.: 40.23%] [Generator loss: 0.8240%]\n",
            "1420 [Discriminator loss: 0.6861%, acc.: 52.73%] [Generator loss: 0.8474%]\n",
            "1421 [Discriminator loss: 0.6991%, acc.: 41.80%] [Generator loss: 0.8439%]\n",
            "1422 [Discriminator loss: 0.6956%, acc.: 43.36%] [Generator loss: 0.8378%]\n",
            "1423 [Discriminator loss: 0.6937%, acc.: 45.70%] [Generator loss: 0.8421%]\n",
            "1424 [Discriminator loss: 0.6972%, acc.: 46.48%] [Generator loss: 0.8363%]\n",
            "1425 [Discriminator loss: 0.7099%, acc.: 34.77%] [Generator loss: 0.8273%]\n",
            "1426 [Discriminator loss: 0.7001%, acc.: 44.53%] [Generator loss: 0.8278%]\n",
            "1427 [Discriminator loss: 0.7084%, acc.: 38.28%] [Generator loss: 0.8199%]\n",
            "1428 [Discriminator loss: 0.7097%, acc.: 41.41%] [Generator loss: 0.8211%]\n",
            "1429 [Discriminator loss: 0.7061%, acc.: 40.62%] [Generator loss: 0.8203%]\n",
            "1430 [Discriminator loss: 0.7012%, acc.: 45.70%] [Generator loss: 0.8326%]\n",
            "1431 [Discriminator loss: 0.7124%, acc.: 41.41%] [Generator loss: 0.8353%]\n",
            "1432 [Discriminator loss: 0.7016%, acc.: 43.36%] [Generator loss: 0.8375%]\n",
            "1433 [Discriminator loss: 0.7012%, acc.: 39.06%] [Generator loss: 0.8274%]\n",
            "1434 [Discriminator loss: 0.7147%, acc.: 34.77%] [Generator loss: 0.8184%]\n",
            "1435 [Discriminator loss: 0.7100%, acc.: 35.55%] [Generator loss: 0.8127%]\n",
            "1436 [Discriminator loss: 0.7027%, acc.: 39.45%] [Generator loss: 0.8219%]\n",
            "1437 [Discriminator loss: 0.7111%, acc.: 39.45%] [Generator loss: 0.8151%]\n",
            "1438 [Discriminator loss: 0.7073%, acc.: 42.58%] [Generator loss: 0.8223%]\n",
            "1439 [Discriminator loss: 0.7152%, acc.: 37.50%] [Generator loss: 0.8142%]\n",
            "1440 [Discriminator loss: 0.7136%, acc.: 31.64%] [Generator loss: 0.8150%]\n",
            "1441 [Discriminator loss: 0.7017%, acc.: 41.41%] [Generator loss: 0.8123%]\n",
            "1442 [Discriminator loss: 0.7045%, acc.: 42.19%] [Generator loss: 0.8135%]\n",
            "1443 [Discriminator loss: 0.7229%, acc.: 36.72%] [Generator loss: 0.8065%]\n",
            "1444 [Discriminator loss: 0.7143%, acc.: 33.98%] [Generator loss: 0.7976%]\n",
            "1445 [Discriminator loss: 0.7265%, acc.: 30.47%] [Generator loss: 0.7887%]\n",
            "1446 [Discriminator loss: 0.7199%, acc.: 37.50%] [Generator loss: 0.7870%]\n",
            "1447 [Discriminator loss: 0.6967%, acc.: 50.00%] [Generator loss: 0.7984%]\n",
            "1448 [Discriminator loss: 0.7042%, acc.: 52.34%] [Generator loss: 0.8162%]\n",
            "1449 [Discriminator loss: 0.7239%, acc.: 49.22%] [Generator loss: 0.8018%]\n",
            "1450 [Discriminator loss: 0.7031%, acc.: 50.39%] [Generator loss: 0.8112%]\n",
            "1451 [Discriminator loss: 0.7143%, acc.: 34.38%] [Generator loss: 0.8052%]\n",
            "1452 [Discriminator loss: 0.7029%, acc.: 36.33%] [Generator loss: 0.7992%]\n",
            "1453 [Discriminator loss: 0.7025%, acc.: 35.16%] [Generator loss: 0.8116%]\n",
            "1454 [Discriminator loss: 0.6862%, acc.: 38.67%] [Generator loss: 0.8091%]\n",
            "1455 [Discriminator loss: 0.7030%, acc.: 35.16%] [Generator loss: 0.8025%]\n",
            "1456 [Discriminator loss: 0.6821%, acc.: 42.97%] [Generator loss: 0.8114%]\n",
            "1457 [Discriminator loss: 0.6859%, acc.: 43.36%] [Generator loss: 0.8122%]\n",
            "1458 [Discriminator loss: 0.6967%, acc.: 37.89%] [Generator loss: 0.8074%]\n",
            "1459 [Discriminator loss: 0.6774%, acc.: 53.12%] [Generator loss: 0.8073%]\n",
            "1460 [Discriminator loss: 0.6738%, acc.: 58.98%] [Generator loss: 0.8216%]\n",
            "1461 [Discriminator loss: 0.6837%, acc.: 57.03%] [Generator loss: 0.8253%]\n",
            "1462 [Discriminator loss: 0.6836%, acc.: 51.17%] [Generator loss: 0.8258%]\n",
            "1463 [Discriminator loss: 0.6866%, acc.: 42.19%] [Generator loss: 0.8231%]\n",
            "1464 [Discriminator loss: 0.6772%, acc.: 39.06%] [Generator loss: 0.8230%]\n",
            "1465 [Discriminator loss: 0.6782%, acc.: 48.44%] [Generator loss: 0.8230%]\n",
            "1466 [Discriminator loss: 0.6895%, acc.: 36.33%] [Generator loss: 0.8126%]\n",
            "1467 [Discriminator loss: 0.6767%, acc.: 44.14%] [Generator loss: 0.8133%]\n",
            "1468 [Discriminator loss: 0.6792%, acc.: 43.36%] [Generator loss: 0.8134%]\n",
            "1469 [Discriminator loss: 0.6896%, acc.: 42.58%] [Generator loss: 0.8143%]\n",
            "1470 [Discriminator loss: 0.6794%, acc.: 45.31%] [Generator loss: 0.8144%]\n",
            "1471 [Discriminator loss: 0.6891%, acc.: 42.97%] [Generator loss: 0.8140%]\n",
            "1472 [Discriminator loss: 0.6731%, acc.: 53.52%] [Generator loss: 0.8205%]\n",
            "1473 [Discriminator loss: 0.6904%, acc.: 46.48%] [Generator loss: 0.8168%]\n",
            "1474 [Discriminator loss: 0.7015%, acc.: 38.67%] [Generator loss: 0.8098%]\n",
            "1475 [Discriminator loss: 0.6894%, acc.: 37.89%] [Generator loss: 0.8099%]\n",
            "1476 [Discriminator loss: 0.6877%, acc.: 37.11%] [Generator loss: 0.8097%]\n",
            "1477 [Discriminator loss: 0.6991%, acc.: 35.55%] [Generator loss: 0.8034%]\n",
            "1478 [Discriminator loss: 0.6952%, acc.: 37.11%] [Generator loss: 0.8024%]\n",
            "1479 [Discriminator loss: 0.6710%, acc.: 46.09%] [Generator loss: 0.8109%]\n",
            "1480 [Discriminator loss: 0.6890%, acc.: 44.92%] [Generator loss: 0.8143%]\n",
            "1481 [Discriminator loss: 0.6855%, acc.: 41.80%] [Generator loss: 0.8080%]\n",
            "1482 [Discriminator loss: 0.6824%, acc.: 43.75%] [Generator loss: 0.8104%]\n",
            "1483 [Discriminator loss: 0.6858%, acc.: 46.88%] [Generator loss: 0.8143%]\n",
            "1484 [Discriminator loss: 0.6861%, acc.: 50.78%] [Generator loss: 0.8182%]\n",
            "1485 [Discriminator loss: 0.6817%, acc.: 52.73%] [Generator loss: 0.8265%]\n",
            "1486 [Discriminator loss: 0.6855%, acc.: 50.00%] [Generator loss: 0.8199%]\n",
            "1487 [Discriminator loss: 0.6895%, acc.: 42.58%] [Generator loss: 0.8171%]\n",
            "1488 [Discriminator loss: 0.6903%, acc.: 42.97%] [Generator loss: 0.8131%]\n",
            "1489 [Discriminator loss: 0.6861%, acc.: 41.80%] [Generator loss: 0.8117%]\n",
            "1490 [Discriminator loss: 0.6928%, acc.: 41.80%] [Generator loss: 0.8081%]\n",
            "1491 [Discriminator loss: 0.6859%, acc.: 51.17%] [Generator loss: 0.8166%]\n",
            "1492 [Discriminator loss: 0.6775%, acc.: 53.12%] [Generator loss: 0.8201%]\n",
            "1493 [Discriminator loss: 0.6754%, acc.: 52.34%] [Generator loss: 0.8256%]\n",
            "1494 [Discriminator loss: 0.6772%, acc.: 48.83%] [Generator loss: 0.8205%]\n",
            "1495 [Discriminator loss: 0.6789%, acc.: 53.12%] [Generator loss: 0.8108%]\n",
            "1496 [Discriminator loss: 0.6925%, acc.: 52.34%] [Generator loss: 0.8124%]\n",
            "1497 [Discriminator loss: 0.6777%, acc.: 56.64%] [Generator loss: 0.8075%]\n",
            "1498 [Discriminator loss: 0.6748%, acc.: 56.25%] [Generator loss: 0.8156%]\n",
            "1499 [Discriminator loss: 0.6879%, acc.: 55.47%] [Generator loss: 0.8141%]\n",
            "1500 [Discriminator loss: 0.6971%, acc.: 55.08%] [Generator loss: 0.8245%]\n",
            "1501 [Discriminator loss: 0.6659%, acc.: 59.77%] [Generator loss: 0.8334%]\n",
            "1502 [Discriminator loss: 0.6728%, acc.: 62.89%] [Generator loss: 0.8324%]\n",
            "1503 [Discriminator loss: 0.6716%, acc.: 67.19%] [Generator loss: 0.8235%]\n",
            "1504 [Discriminator loss: 0.6677%, acc.: 63.67%] [Generator loss: 0.8334%]\n",
            "1505 [Discriminator loss: 0.6833%, acc.: 58.98%] [Generator loss: 0.8215%]\n",
            "1506 [Discriminator loss: 0.6733%, acc.: 64.45%] [Generator loss: 0.8383%]\n",
            "1507 [Discriminator loss: 0.6620%, acc.: 66.02%] [Generator loss: 0.8456%]\n",
            "1508 [Discriminator loss: 0.6719%, acc.: 60.94%] [Generator loss: 0.8263%]\n",
            "1509 [Discriminator loss: 0.6676%, acc.: 61.72%] [Generator loss: 0.8349%]\n",
            "1510 [Discriminator loss: 0.6692%, acc.: 64.45%] [Generator loss: 0.8439%]\n",
            "1511 [Discriminator loss: 0.6768%, acc.: 56.64%] [Generator loss: 0.8461%]\n",
            "1512 [Discriminator loss: 0.6863%, acc.: 55.86%] [Generator loss: 0.8496%]\n",
            "1513 [Discriminator loss: 0.6713%, acc.: 61.33%] [Generator loss: 0.8504%]\n",
            "1514 [Discriminator loss: 0.6816%, acc.: 53.91%] [Generator loss: 0.8555%]\n",
            "1515 [Discriminator loss: 0.6898%, acc.: 49.61%] [Generator loss: 0.8506%]\n",
            "1516 [Discriminator loss: 0.6781%, acc.: 54.30%] [Generator loss: 0.8338%]\n",
            "1517 [Discriminator loss: 0.6689%, acc.: 60.16%] [Generator loss: 0.8411%]\n",
            "1518 [Discriminator loss: 0.6722%, acc.: 56.25%] [Generator loss: 0.8467%]\n",
            "1519 [Discriminator loss: 0.6859%, acc.: 55.47%] [Generator loss: 0.8397%]\n",
            "1520 [Discriminator loss: 0.6876%, acc.: 58.59%] [Generator loss: 0.8313%]\n",
            "1521 [Discriminator loss: 0.6774%, acc.: 54.69%] [Generator loss: 0.8459%]\n",
            "1522 [Discriminator loss: 0.6891%, acc.: 53.52%] [Generator loss: 0.8376%]\n",
            "1523 [Discriminator loss: 0.6713%, acc.: 56.25%] [Generator loss: 0.8435%]\n",
            "1524 [Discriminator loss: 0.6851%, acc.: 57.03%] [Generator loss: 0.8421%]\n",
            "1525 [Discriminator loss: 0.7048%, acc.: 44.92%] [Generator loss: 0.8258%]\n",
            "1526 [Discriminator loss: 0.6875%, acc.: 50.39%] [Generator loss: 0.8408%]\n",
            "1527 [Discriminator loss: 0.6837%, acc.: 48.44%] [Generator loss: 0.8453%]\n",
            "1528 [Discriminator loss: 0.6865%, acc.: 50.78%] [Generator loss: 0.8346%]\n",
            "1529 [Discriminator loss: 0.6859%, acc.: 50.00%] [Generator loss: 0.8380%]\n",
            "1530 [Discriminator loss: 0.6961%, acc.: 47.66%] [Generator loss: 0.8413%]\n",
            "1531 [Discriminator loss: 0.6939%, acc.: 46.88%] [Generator loss: 0.8351%]\n",
            "1532 [Discriminator loss: 0.6884%, acc.: 45.31%] [Generator loss: 0.8265%]\n",
            "1533 [Discriminator loss: 0.6993%, acc.: 42.58%] [Generator loss: 0.8243%]\n",
            "1534 [Discriminator loss: 0.7016%, acc.: 37.50%] [Generator loss: 0.8175%]\n",
            "1535 [Discriminator loss: 0.6893%, acc.: 48.83%] [Generator loss: 0.8186%]\n",
            "1536 [Discriminator loss: 0.6921%, acc.: 48.44%] [Generator loss: 0.8226%]\n",
            "1537 [Discriminator loss: 0.6887%, acc.: 53.12%] [Generator loss: 0.8179%]\n",
            "1538 [Discriminator loss: 0.6750%, acc.: 51.95%] [Generator loss: 0.8215%]\n",
            "1539 [Discriminator loss: 0.6856%, acc.: 50.00%] [Generator loss: 0.8220%]\n",
            "1540 [Discriminator loss: 0.6846%, acc.: 46.48%] [Generator loss: 0.8115%]\n",
            "1541 [Discriminator loss: 0.6975%, acc.: 45.70%] [Generator loss: 0.8030%]\n",
            "1542 [Discriminator loss: 0.6730%, acc.: 51.17%] [Generator loss: 0.8180%]\n",
            "1543 [Discriminator loss: 0.7102%, acc.: 41.41%] [Generator loss: 0.8094%]\n",
            "1544 [Discriminator loss: 0.6836%, acc.: 52.73%] [Generator loss: 0.8195%]\n",
            "1545 [Discriminator loss: 0.6862%, acc.: 48.44%] [Generator loss: 0.8209%]\n",
            "1546 [Discriminator loss: 0.6917%, acc.: 49.61%] [Generator loss: 0.8132%]\n",
            "1547 [Discriminator loss: 0.6807%, acc.: 54.30%] [Generator loss: 0.8103%]\n",
            "1548 [Discriminator loss: 0.6761%, acc.: 52.73%] [Generator loss: 0.8099%]\n",
            "1549 [Discriminator loss: 0.6816%, acc.: 53.91%] [Generator loss: 0.8127%]\n",
            "1550 [Discriminator loss: 0.6922%, acc.: 52.34%] [Generator loss: 0.8064%]\n",
            "1551 [Discriminator loss: 0.6877%, acc.: 51.56%] [Generator loss: 0.8083%]\n",
            "1552 [Discriminator loss: 0.6895%, acc.: 55.86%] [Generator loss: 0.8090%]\n",
            "1553 [Discriminator loss: 0.6882%, acc.: 51.56%] [Generator loss: 0.8107%]\n",
            "1554 [Discriminator loss: 0.6849%, acc.: 58.59%] [Generator loss: 0.8063%]\n",
            "1555 [Discriminator loss: 0.7101%, acc.: 51.95%] [Generator loss: 0.8072%]\n",
            "1556 [Discriminator loss: 0.6835%, acc.: 56.64%] [Generator loss: 0.8131%]\n",
            "1557 [Discriminator loss: 0.7067%, acc.: 46.09%] [Generator loss: 0.8055%]\n",
            "1558 [Discriminator loss: 0.6909%, acc.: 48.83%] [Generator loss: 0.8161%]\n",
            "1559 [Discriminator loss: 0.6884%, acc.: 52.34%] [Generator loss: 0.8147%]\n",
            "1560 [Discriminator loss: 0.6807%, acc.: 50.39%] [Generator loss: 0.8121%]\n",
            "1561 [Discriminator loss: 0.6875%, acc.: 50.39%] [Generator loss: 0.8171%]\n",
            "1562 [Discriminator loss: 0.6831%, acc.: 52.34%] [Generator loss: 0.8089%]\n",
            "1563 [Discriminator loss: 0.6880%, acc.: 50.39%] [Generator loss: 0.7925%]\n",
            "1564 [Discriminator loss: 0.6869%, acc.: 55.86%] [Generator loss: 0.8109%]\n",
            "1565 [Discriminator loss: 0.6850%, acc.: 53.91%] [Generator loss: 0.8106%]\n",
            "1566 [Discriminator loss: 0.6800%, acc.: 58.20%] [Generator loss: 0.8138%]\n",
            "1567 [Discriminator loss: 0.6813%, acc.: 56.64%] [Generator loss: 0.8072%]\n",
            "1568 [Discriminator loss: 0.6904%, acc.: 46.88%] [Generator loss: 0.8220%]\n",
            "1569 [Discriminator loss: 0.6853%, acc.: 51.17%] [Generator loss: 0.8204%]\n",
            "1570 [Discriminator loss: 0.6756%, acc.: 59.38%] [Generator loss: 0.8291%]\n",
            "1571 [Discriminator loss: 0.6965%, acc.: 48.83%] [Generator loss: 0.8139%]\n",
            "1572 [Discriminator loss: 0.6780%, acc.: 56.64%] [Generator loss: 0.8078%]\n",
            "1573 [Discriminator loss: 0.6819%, acc.: 51.17%] [Generator loss: 0.8122%]\n",
            "1574 [Discriminator loss: 0.6758%, acc.: 59.38%] [Generator loss: 0.8059%]\n",
            "1575 [Discriminator loss: 0.6663%, acc.: 65.62%] [Generator loss: 0.8183%]\n",
            "1576 [Discriminator loss: 0.6792%, acc.: 59.77%] [Generator loss: 0.8230%]\n",
            "1577 [Discriminator loss: 0.6828%, acc.: 56.64%] [Generator loss: 0.8282%]\n",
            "1578 [Discriminator loss: 0.6754%, acc.: 58.20%] [Generator loss: 0.8264%]\n",
            "1579 [Discriminator loss: 0.6821%, acc.: 58.98%] [Generator loss: 0.8202%]\n",
            "1580 [Discriminator loss: 0.6833%, acc.: 55.47%] [Generator loss: 0.8179%]\n",
            "1581 [Discriminator loss: 0.6844%, acc.: 57.03%] [Generator loss: 0.8201%]\n",
            "1582 [Discriminator loss: 0.6960%, acc.: 53.12%] [Generator loss: 0.8227%]\n",
            "1583 [Discriminator loss: 0.6884%, acc.: 54.30%] [Generator loss: 0.8187%]\n",
            "1584 [Discriminator loss: 0.6899%, acc.: 52.73%] [Generator loss: 0.8048%]\n",
            "1585 [Discriminator loss: 0.6839%, acc.: 51.17%] [Generator loss: 0.7967%]\n",
            "1586 [Discriminator loss: 0.6953%, acc.: 53.12%] [Generator loss: 0.8016%]\n",
            "1587 [Discriminator loss: 0.6827%, acc.: 57.42%] [Generator loss: 0.7987%]\n",
            "1588 [Discriminator loss: 0.6912%, acc.: 51.56%] [Generator loss: 0.7958%]\n",
            "1589 [Discriminator loss: 0.6910%, acc.: 57.03%] [Generator loss: 0.7903%]\n",
            "1590 [Discriminator loss: 0.6925%, acc.: 53.52%] [Generator loss: 0.7771%]\n",
            "1591 [Discriminator loss: 0.7018%, acc.: 52.73%] [Generator loss: 0.7787%]\n",
            "1592 [Discriminator loss: 0.6924%, acc.: 51.95%] [Generator loss: 0.7882%]\n",
            "1593 [Discriminator loss: 0.6979%, acc.: 51.56%] [Generator loss: 0.7860%]\n",
            "1594 [Discriminator loss: 0.7065%, acc.: 48.44%] [Generator loss: 0.7962%]\n",
            "1595 [Discriminator loss: 0.6942%, acc.: 55.08%] [Generator loss: 0.7874%]\n",
            "1596 [Discriminator loss: 0.6904%, acc.: 55.47%] [Generator loss: 0.7931%]\n",
            "1597 [Discriminator loss: 0.7045%, acc.: 49.22%] [Generator loss: 0.7863%]\n",
            "1598 [Discriminator loss: 0.7064%, acc.: 47.66%] [Generator loss: 0.7867%]\n",
            "1599 [Discriminator loss: 0.6966%, acc.: 51.95%] [Generator loss: 0.7890%]\n",
            "1600 [Discriminator loss: 0.6955%, acc.: 50.78%] [Generator loss: 0.7913%]\n",
            "1601 [Discriminator loss: 0.6913%, acc.: 52.34%] [Generator loss: 0.8122%]\n",
            "1602 [Discriminator loss: 0.6939%, acc.: 53.12%] [Generator loss: 0.7919%]\n",
            "1603 [Discriminator loss: 0.7082%, acc.: 48.44%] [Generator loss: 0.7886%]\n",
            "1604 [Discriminator loss: 0.6965%, acc.: 52.73%] [Generator loss: 0.7967%]\n",
            "1605 [Discriminator loss: 0.7198%, acc.: 42.19%] [Generator loss: 0.7893%]\n",
            "1606 [Discriminator loss: 0.7050%, acc.: 47.27%] [Generator loss: 0.7858%]\n",
            "1607 [Discriminator loss: 0.7029%, acc.: 51.17%] [Generator loss: 0.7957%]\n",
            "1608 [Discriminator loss: 0.6989%, acc.: 51.17%] [Generator loss: 0.7932%]\n",
            "1609 [Discriminator loss: 0.7033%, acc.: 48.05%] [Generator loss: 0.7848%]\n",
            "1610 [Discriminator loss: 0.6810%, acc.: 58.98%] [Generator loss: 0.7897%]\n",
            "1611 [Discriminator loss: 0.6864%, acc.: 55.08%] [Generator loss: 0.8024%]\n",
            "1612 [Discriminator loss: 0.6997%, acc.: 52.34%] [Generator loss: 0.7958%]\n",
            "1613 [Discriminator loss: 0.6889%, acc.: 55.47%] [Generator loss: 0.7904%]\n",
            "1614 [Discriminator loss: 0.6841%, acc.: 51.95%] [Generator loss: 0.8083%]\n",
            "1615 [Discriminator loss: 0.6976%, acc.: 50.78%] [Generator loss: 0.7986%]\n",
            "1616 [Discriminator loss: 0.6970%, acc.: 49.61%] [Generator loss: 0.7936%]\n",
            "1617 [Discriminator loss: 0.6891%, acc.: 50.00%] [Generator loss: 0.7981%]\n",
            "1618 [Discriminator loss: 0.6879%, acc.: 51.17%] [Generator loss: 0.7885%]\n",
            "1619 [Discriminator loss: 0.6947%, acc.: 44.53%] [Generator loss: 0.7910%]\n",
            "1620 [Discriminator loss: 0.6919%, acc.: 40.62%] [Generator loss: 0.7938%]\n",
            "1621 [Discriminator loss: 0.6893%, acc.: 46.48%] [Generator loss: 0.8024%]\n",
            "1622 [Discriminator loss: 0.6834%, acc.: 52.34%] [Generator loss: 0.8035%]\n",
            "1623 [Discriminator loss: 0.6884%, acc.: 53.91%] [Generator loss: 0.8099%]\n",
            "1624 [Discriminator loss: 0.6852%, acc.: 50.39%] [Generator loss: 0.8175%]\n",
            "1625 [Discriminator loss: 0.6839%, acc.: 54.30%] [Generator loss: 0.8136%]\n",
            "1626 [Discriminator loss: 0.7017%, acc.: 46.09%] [Generator loss: 0.8031%]\n",
            "1627 [Discriminator loss: 0.6875%, acc.: 46.88%] [Generator loss: 0.7892%]\n",
            "1628 [Discriminator loss: 0.6775%, acc.: 51.17%] [Generator loss: 0.7942%]\n",
            "1629 [Discriminator loss: 0.6752%, acc.: 53.12%] [Generator loss: 0.7920%]\n",
            "1630 [Discriminator loss: 0.6795%, acc.: 53.91%] [Generator loss: 0.8057%]\n",
            "1631 [Discriminator loss: 0.6783%, acc.: 57.81%] [Generator loss: 0.8103%]\n",
            "1632 [Discriminator loss: 0.6840%, acc.: 55.08%] [Generator loss: 0.8129%]\n",
            "1633 [Discriminator loss: 0.6981%, acc.: 52.34%] [Generator loss: 0.8189%]\n",
            "1634 [Discriminator loss: 0.6882%, acc.: 54.69%] [Generator loss: 0.7958%]\n",
            "1635 [Discriminator loss: 0.6787%, acc.: 53.52%] [Generator loss: 0.8092%]\n",
            "1636 [Discriminator loss: 0.6872%, acc.: 53.52%] [Generator loss: 0.8036%]\n",
            "1637 [Discriminator loss: 0.6759%, acc.: 58.98%] [Generator loss: 0.8132%]\n",
            "1638 [Discriminator loss: 0.6800%, acc.: 53.12%] [Generator loss: 0.8192%]\n",
            "1639 [Discriminator loss: 0.6963%, acc.: 46.09%] [Generator loss: 0.8145%]\n",
            "1640 [Discriminator loss: 0.6809%, acc.: 51.17%] [Generator loss: 0.8110%]\n",
            "1641 [Discriminator loss: 0.6803%, acc.: 55.08%] [Generator loss: 0.8144%]\n",
            "1642 [Discriminator loss: 0.6753%, acc.: 52.73%] [Generator loss: 0.8234%]\n",
            "1643 [Discriminator loss: 0.6938%, acc.: 46.88%] [Generator loss: 0.8203%]\n",
            "1644 [Discriminator loss: 0.6804%, acc.: 52.34%] [Generator loss: 0.8104%]\n",
            "1645 [Discriminator loss: 0.6814%, acc.: 45.70%] [Generator loss: 0.8183%]\n",
            "1646 [Discriminator loss: 0.6861%, acc.: 48.05%] [Generator loss: 0.8142%]\n",
            "1647 [Discriminator loss: 0.6815%, acc.: 45.31%] [Generator loss: 0.8123%]\n",
            "1648 [Discriminator loss: 0.6929%, acc.: 40.23%] [Generator loss: 0.8113%]\n",
            "1649 [Discriminator loss: 0.6776%, acc.: 45.31%] [Generator loss: 0.8206%]\n",
            "1650 [Discriminator loss: 0.6755%, acc.: 48.05%] [Generator loss: 0.8223%]\n",
            "1651 [Discriminator loss: 0.6749%, acc.: 46.88%] [Generator loss: 0.8273%]\n",
            "1652 [Discriminator loss: 0.6887%, acc.: 41.80%] [Generator loss: 0.8179%]\n",
            "1653 [Discriminator loss: 0.6760%, acc.: 46.88%] [Generator loss: 0.8114%]\n",
            "1654 [Discriminator loss: 0.6741%, acc.: 46.09%] [Generator loss: 0.8140%]\n",
            "1655 [Discriminator loss: 0.6835%, acc.: 44.92%] [Generator loss: 0.8193%]\n",
            "1656 [Discriminator loss: 0.6998%, acc.: 40.23%] [Generator loss: 0.8093%]\n",
            "1657 [Discriminator loss: 0.6658%, acc.: 55.08%] [Generator loss: 0.8121%]\n",
            "1658 [Discriminator loss: 0.6798%, acc.: 52.73%] [Generator loss: 0.8205%]\n",
            "1659 [Discriminator loss: 0.6701%, acc.: 56.25%] [Generator loss: 0.8247%]\n",
            "1660 [Discriminator loss: 0.6797%, acc.: 47.66%] [Generator loss: 0.8265%]\n",
            "1661 [Discriminator loss: 0.6875%, acc.: 44.14%] [Generator loss: 0.8123%]\n",
            "1662 [Discriminator loss: 0.6678%, acc.: 50.00%] [Generator loss: 0.8129%]\n",
            "1663 [Discriminator loss: 0.6747%, acc.: 50.78%] [Generator loss: 0.8136%]\n",
            "1664 [Discriminator loss: 0.6680%, acc.: 54.30%] [Generator loss: 0.8210%]\n",
            "1665 [Discriminator loss: 0.6646%, acc.: 54.30%] [Generator loss: 0.8281%]\n",
            "1666 [Discriminator loss: 0.6683%, acc.: 49.61%] [Generator loss: 0.8286%]\n",
            "1667 [Discriminator loss: 0.6750%, acc.: 50.78%] [Generator loss: 0.8208%]\n",
            "1668 [Discriminator loss: 0.6634%, acc.: 52.73%] [Generator loss: 0.8229%]\n",
            "1669 [Discriminator loss: 0.6671%, acc.: 56.25%] [Generator loss: 0.8282%]\n",
            "1670 [Discriminator loss: 0.6682%, acc.: 51.95%] [Generator loss: 0.8359%]\n",
            "1671 [Discriminator loss: 0.6797%, acc.: 51.95%] [Generator loss: 0.8225%]\n",
            "1672 [Discriminator loss: 0.6625%, acc.: 59.77%] [Generator loss: 0.8240%]\n",
            "1673 [Discriminator loss: 0.6610%, acc.: 61.72%] [Generator loss: 0.8263%]\n",
            "1674 [Discriminator loss: 0.6640%, acc.: 61.33%] [Generator loss: 0.8325%]\n",
            "1675 [Discriminator loss: 0.6710%, acc.: 60.94%] [Generator loss: 0.8265%]\n",
            "1676 [Discriminator loss: 0.6751%, acc.: 53.52%] [Generator loss: 0.8211%]\n",
            "1677 [Discriminator loss: 0.6812%, acc.: 53.91%] [Generator loss: 0.8177%]\n",
            "1678 [Discriminator loss: 0.6651%, acc.: 56.64%] [Generator loss: 0.8262%]\n",
            "1679 [Discriminator loss: 0.6554%, acc.: 63.67%] [Generator loss: 0.8316%]\n",
            "1680 [Discriminator loss: 0.6744%, acc.: 53.91%] [Generator loss: 0.8250%]\n",
            "1681 [Discriminator loss: 0.6565%, acc.: 63.28%] [Generator loss: 0.8248%]\n",
            "1682 [Discriminator loss: 0.6540%, acc.: 61.72%] [Generator loss: 0.8385%]\n",
            "1683 [Discriminator loss: 0.6696%, acc.: 58.59%] [Generator loss: 0.8398%]\n",
            "1684 [Discriminator loss: 0.6673%, acc.: 64.84%] [Generator loss: 0.8352%]\n",
            "1685 [Discriminator loss: 0.6675%, acc.: 60.16%] [Generator loss: 0.8198%]\n",
            "1686 [Discriminator loss: 0.6441%, acc.: 67.97%] [Generator loss: 0.8352%]\n",
            "1687 [Discriminator loss: 0.6718%, acc.: 60.94%] [Generator loss: 0.8418%]\n",
            "1688 [Discriminator loss: 0.6730%, acc.: 55.86%] [Generator loss: 0.8385%]\n",
            "1689 [Discriminator loss: 0.6617%, acc.: 63.28%] [Generator loss: 0.8470%]\n",
            "1690 [Discriminator loss: 0.6722%, acc.: 61.72%] [Generator loss: 0.8395%]\n",
            "1691 [Discriminator loss: 0.6726%, acc.: 53.52%] [Generator loss: 0.8325%]\n",
            "1692 [Discriminator loss: 0.6610%, acc.: 62.89%] [Generator loss: 0.8439%]\n",
            "1693 [Discriminator loss: 0.6685%, acc.: 58.59%] [Generator loss: 0.8318%]\n",
            "1694 [Discriminator loss: 0.6575%, acc.: 60.16%] [Generator loss: 0.8411%]\n",
            "1695 [Discriminator loss: 0.6602%, acc.: 63.67%] [Generator loss: 0.8369%]\n",
            "1696 [Discriminator loss: 0.6681%, acc.: 61.33%] [Generator loss: 0.8447%]\n",
            "1697 [Discriminator loss: 0.6604%, acc.: 61.33%] [Generator loss: 0.8510%]\n",
            "1698 [Discriminator loss: 0.6734%, acc.: 58.20%] [Generator loss: 0.8373%]\n",
            "1699 [Discriminator loss: 0.6570%, acc.: 58.59%] [Generator loss: 0.8449%]\n",
            "1700 [Discriminator loss: 0.6744%, acc.: 60.94%] [Generator loss: 0.8239%]\n",
            "1701 [Discriminator loss: 0.6645%, acc.: 58.20%] [Generator loss: 0.8309%]\n",
            "1702 [Discriminator loss: 0.6853%, acc.: 55.47%] [Generator loss: 0.8255%]\n",
            "1703 [Discriminator loss: 0.6687%, acc.: 55.86%] [Generator loss: 0.8295%]\n",
            "1704 [Discriminator loss: 0.6643%, acc.: 58.20%] [Generator loss: 0.8261%]\n",
            "1705 [Discriminator loss: 0.6826%, acc.: 57.03%] [Generator loss: 0.8293%]\n",
            "1706 [Discriminator loss: 0.6697%, acc.: 55.08%] [Generator loss: 0.8160%]\n",
            "1707 [Discriminator loss: 0.6588%, acc.: 62.11%] [Generator loss: 0.8442%]\n",
            "1708 [Discriminator loss: 0.6810%, acc.: 55.86%] [Generator loss: 0.8363%]\n",
            "1709 [Discriminator loss: 0.6658%, acc.: 61.72%] [Generator loss: 0.8392%]\n",
            "1710 [Discriminator loss: 0.6650%, acc.: 61.72%] [Generator loss: 0.8433%]\n",
            "1711 [Discriminator loss: 0.6796%, acc.: 53.52%] [Generator loss: 0.8317%]\n",
            "1712 [Discriminator loss: 0.6847%, acc.: 56.25%] [Generator loss: 0.8215%]\n",
            "1713 [Discriminator loss: 0.6855%, acc.: 53.52%] [Generator loss: 0.8193%]\n",
            "1714 [Discriminator loss: 0.6674%, acc.: 57.03%] [Generator loss: 0.8413%]\n",
            "1715 [Discriminator loss: 0.6669%, acc.: 60.55%] [Generator loss: 0.8393%]\n",
            "1716 [Discriminator loss: 0.6792%, acc.: 55.08%] [Generator loss: 0.8232%]\n",
            "1717 [Discriminator loss: 0.6989%, acc.: 45.70%] [Generator loss: 0.8282%]\n",
            "1718 [Discriminator loss: 0.6983%, acc.: 51.17%] [Generator loss: 0.8165%]\n",
            "1719 [Discriminator loss: 0.6973%, acc.: 47.27%] [Generator loss: 0.8121%]\n",
            "1720 [Discriminator loss: 0.6684%, acc.: 55.47%] [Generator loss: 0.8281%]\n",
            "1721 [Discriminator loss: 0.6782%, acc.: 53.91%] [Generator loss: 0.8327%]\n",
            "1722 [Discriminator loss: 0.6958%, acc.: 53.12%] [Generator loss: 0.8063%]\n",
            "1723 [Discriminator loss: 0.6863%, acc.: 48.83%] [Generator loss: 0.8007%]\n",
            "1724 [Discriminator loss: 0.6972%, acc.: 50.39%] [Generator loss: 0.8031%]\n",
            "1725 [Discriminator loss: 0.7027%, acc.: 50.39%] [Generator loss: 0.8099%]\n",
            "1726 [Discriminator loss: 0.6815%, acc.: 55.86%] [Generator loss: 0.8263%]\n",
            "1727 [Discriminator loss: 0.6778%, acc.: 55.08%] [Generator loss: 0.8157%]\n",
            "1728 [Discriminator loss: 0.6833%, acc.: 54.69%] [Generator loss: 0.8244%]\n",
            "1729 [Discriminator loss: 0.6992%, acc.: 49.22%] [Generator loss: 0.8138%]\n",
            "1730 [Discriminator loss: 0.6883%, acc.: 54.30%] [Generator loss: 0.8194%]\n",
            "1731 [Discriminator loss: 0.6873%, acc.: 54.30%] [Generator loss: 0.8158%]\n",
            "1732 [Discriminator loss: 0.6884%, acc.: 52.73%] [Generator loss: 0.8301%]\n",
            "1733 [Discriminator loss: 0.6792%, acc.: 50.78%] [Generator loss: 0.8287%]\n",
            "1734 [Discriminator loss: 0.6841%, acc.: 52.34%] [Generator loss: 0.8094%]\n",
            "1735 [Discriminator loss: 0.6876%, acc.: 55.47%] [Generator loss: 0.8042%]\n",
            "1736 [Discriminator loss: 0.7081%, acc.: 47.27%] [Generator loss: 0.8105%]\n",
            "1737 [Discriminator loss: 0.6966%, acc.: 51.95%] [Generator loss: 0.8169%]\n",
            "1738 [Discriminator loss: 0.6790%, acc.: 57.03%] [Generator loss: 0.8085%]\n",
            "1739 [Discriminator loss: 0.7148%, acc.: 47.27%] [Generator loss: 0.8015%]\n",
            "1740 [Discriminator loss: 0.6958%, acc.: 51.95%] [Generator loss: 0.8076%]\n",
            "1741 [Discriminator loss: 0.6879%, acc.: 53.12%] [Generator loss: 0.8013%]\n",
            "1742 [Discriminator loss: 0.6765%, acc.: 57.42%] [Generator loss: 0.8050%]\n",
            "1743 [Discriminator loss: 0.6775%, acc.: 56.25%] [Generator loss: 0.8116%]\n",
            "1744 [Discriminator loss: 0.6971%, acc.: 52.34%] [Generator loss: 0.8141%]\n",
            "1745 [Discriminator loss: 0.6944%, acc.: 52.34%] [Generator loss: 0.8111%]\n",
            "1746 [Discriminator loss: 0.6802%, acc.: 55.47%] [Generator loss: 0.8128%]\n",
            "1747 [Discriminator loss: 0.6862%, acc.: 53.91%] [Generator loss: 0.8190%]\n",
            "1748 [Discriminator loss: 0.6817%, acc.: 54.30%] [Generator loss: 0.8077%]\n",
            "1749 [Discriminator loss: 0.6917%, acc.: 51.56%] [Generator loss: 0.8075%]\n",
            "1750 [Discriminator loss: 0.6723%, acc.: 57.81%] [Generator loss: 0.8164%]\n",
            "1751 [Discriminator loss: 0.6957%, acc.: 51.56%] [Generator loss: 0.8025%]\n",
            "1752 [Discriminator loss: 0.6920%, acc.: 55.08%] [Generator loss: 0.8174%]\n",
            "1753 [Discriminator loss: 0.6859%, acc.: 52.73%] [Generator loss: 0.8225%]\n",
            "1754 [Discriminator loss: 0.6672%, acc.: 57.81%] [Generator loss: 0.8398%]\n",
            "1755 [Discriminator loss: 0.6844%, acc.: 54.69%] [Generator loss: 0.8266%]\n",
            "1756 [Discriminator loss: 0.6733%, acc.: 59.77%] [Generator loss: 0.8249%]\n",
            "1757 [Discriminator loss: 0.6909%, acc.: 49.22%] [Generator loss: 0.8178%]\n",
            "1758 [Discriminator loss: 0.6747%, acc.: 58.20%] [Generator loss: 0.8331%]\n",
            "1759 [Discriminator loss: 0.6756%, acc.: 56.64%] [Generator loss: 0.8236%]\n",
            "1760 [Discriminator loss: 0.6825%, acc.: 55.86%] [Generator loss: 0.8240%]\n",
            "1761 [Discriminator loss: 0.6813%, acc.: 57.81%] [Generator loss: 0.8149%]\n",
            "1762 [Discriminator loss: 0.6731%, acc.: 59.38%] [Generator loss: 0.8298%]\n",
            "1763 [Discriminator loss: 0.6791%, acc.: 58.20%] [Generator loss: 0.8269%]\n",
            "1764 [Discriminator loss: 0.6757%, acc.: 56.25%] [Generator loss: 0.8229%]\n",
            "1765 [Discriminator loss: 0.6686%, acc.: 63.28%] [Generator loss: 0.8200%]\n",
            "1766 [Discriminator loss: 0.6746%, acc.: 59.77%] [Generator loss: 0.8165%]\n",
            "1767 [Discriminator loss: 0.6852%, acc.: 52.34%] [Generator loss: 0.8198%]\n",
            "1768 [Discriminator loss: 0.6812%, acc.: 58.20%] [Generator loss: 0.8304%]\n",
            "1769 [Discriminator loss: 0.6742%, acc.: 55.86%] [Generator loss: 0.8347%]\n",
            "1770 [Discriminator loss: 0.6870%, acc.: 52.34%] [Generator loss: 0.8279%]\n",
            "1771 [Discriminator loss: 0.6698%, acc.: 60.55%] [Generator loss: 0.8308%]\n",
            "1772 [Discriminator loss: 0.6776%, acc.: 58.20%] [Generator loss: 0.8399%]\n",
            "1773 [Discriminator loss: 0.6919%, acc.: 52.73%] [Generator loss: 0.8223%]\n",
            "1774 [Discriminator loss: 0.6691%, acc.: 62.89%] [Generator loss: 0.8405%]\n",
            "1775 [Discriminator loss: 0.6708%, acc.: 58.98%] [Generator loss: 0.8323%]\n",
            "1776 [Discriminator loss: 0.6845%, acc.: 51.95%] [Generator loss: 0.8259%]\n",
            "1777 [Discriminator loss: 0.6885%, acc.: 51.95%] [Generator loss: 0.8315%]\n",
            "1778 [Discriminator loss: 0.6727%, acc.: 58.98%] [Generator loss: 0.8178%]\n",
            "1779 [Discriminator loss: 0.6756%, acc.: 58.59%] [Generator loss: 0.8278%]\n",
            "1780 [Discriminator loss: 0.6710%, acc.: 59.77%] [Generator loss: 0.8104%]\n",
            "1781 [Discriminator loss: 0.6757%, acc.: 57.42%] [Generator loss: 0.8230%]\n",
            "1782 [Discriminator loss: 0.6750%, acc.: 59.38%] [Generator loss: 0.8166%]\n",
            "1783 [Discriminator loss: 0.6760%, acc.: 58.20%] [Generator loss: 0.8116%]\n",
            "1784 [Discriminator loss: 0.6645%, acc.: 64.84%] [Generator loss: 0.8239%]\n",
            "1785 [Discriminator loss: 0.6641%, acc.: 62.50%] [Generator loss: 0.8119%]\n",
            "1786 [Discriminator loss: 0.6682%, acc.: 61.33%] [Generator loss: 0.8142%]\n",
            "1787 [Discriminator loss: 0.6744%, acc.: 62.50%] [Generator loss: 0.8208%]\n",
            "1788 [Discriminator loss: 0.6667%, acc.: 57.81%] [Generator loss: 0.8166%]\n",
            "1789 [Discriminator loss: 0.6633%, acc.: 62.89%] [Generator loss: 0.8319%]\n",
            "1790 [Discriminator loss: 0.6713%, acc.: 58.20%] [Generator loss: 0.8208%]\n",
            "1791 [Discriminator loss: 0.6644%, acc.: 61.72%] [Generator loss: 0.8140%]\n",
            "1792 [Discriminator loss: 0.6835%, acc.: 56.64%] [Generator loss: 0.8192%]\n",
            "1793 [Discriminator loss: 0.6777%, acc.: 57.42%] [Generator loss: 0.8382%]\n",
            "1794 [Discriminator loss: 0.6958%, acc.: 50.39%] [Generator loss: 0.8218%]\n",
            "1795 [Discriminator loss: 0.6690%, acc.: 59.77%] [Generator loss: 0.8321%]\n",
            "1796 [Discriminator loss: 0.6704%, acc.: 59.38%] [Generator loss: 0.8318%]\n",
            "1797 [Discriminator loss: 0.6708%, acc.: 62.11%] [Generator loss: 0.8301%]\n",
            "1798 [Discriminator loss: 0.6615%, acc.: 60.16%] [Generator loss: 0.8264%]\n",
            "1799 [Discriminator loss: 0.6629%, acc.: 60.94%] [Generator loss: 0.8169%]\n",
            "1800 [Discriminator loss: 0.6769%, acc.: 60.55%] [Generator loss: 0.8285%]\n",
            "1801 [Discriminator loss: 0.6653%, acc.: 62.11%] [Generator loss: 0.8273%]\n",
            "1802 [Discriminator loss: 0.6692%, acc.: 57.81%] [Generator loss: 0.8352%]\n",
            "1803 [Discriminator loss: 0.6814%, acc.: 54.69%] [Generator loss: 0.8404%]\n",
            "1804 [Discriminator loss: 0.6837%, acc.: 50.00%] [Generator loss: 0.8319%]\n",
            "1805 [Discriminator loss: 0.6702%, acc.: 61.33%] [Generator loss: 0.8347%]\n",
            "1806 [Discriminator loss: 0.6552%, acc.: 64.84%] [Generator loss: 0.8399%]\n",
            "1807 [Discriminator loss: 0.6659%, acc.: 63.67%] [Generator loss: 0.8457%]\n",
            "1808 [Discriminator loss: 0.6619%, acc.: 64.84%] [Generator loss: 0.8313%]\n",
            "1809 [Discriminator loss: 0.6566%, acc.: 66.80%] [Generator loss: 0.8327%]\n",
            "1810 [Discriminator loss: 0.6703%, acc.: 66.02%] [Generator loss: 0.8472%]\n",
            "1811 [Discriminator loss: 0.6612%, acc.: 63.28%] [Generator loss: 0.8434%]\n",
            "1812 [Discriminator loss: 0.6810%, acc.: 55.08%] [Generator loss: 0.8403%]\n",
            "1813 [Discriminator loss: 0.6600%, acc.: 60.94%] [Generator loss: 0.8406%]\n",
            "1814 [Discriminator loss: 0.6676%, acc.: 56.25%] [Generator loss: 0.8355%]\n",
            "1815 [Discriminator loss: 0.6607%, acc.: 60.55%] [Generator loss: 0.8307%]\n",
            "1816 [Discriminator loss: 0.6384%, acc.: 65.62%] [Generator loss: 0.8430%]\n",
            "1817 [Discriminator loss: 0.6738%, acc.: 52.73%] [Generator loss: 0.8275%]\n",
            "1818 [Discriminator loss: 0.6581%, acc.: 65.23%] [Generator loss: 0.8425%]\n",
            "1819 [Discriminator loss: 0.6671%, acc.: 57.03%] [Generator loss: 0.8526%]\n",
            "1820 [Discriminator loss: 0.6606%, acc.: 64.06%] [Generator loss: 0.8481%]\n",
            "1821 [Discriminator loss: 0.6699%, acc.: 63.28%] [Generator loss: 0.8345%]\n",
            "1822 [Discriminator loss: 0.6594%, acc.: 66.80%] [Generator loss: 0.8370%]\n",
            "1823 [Discriminator loss: 0.6684%, acc.: 60.94%] [Generator loss: 0.8568%]\n",
            "1824 [Discriminator loss: 0.6414%, acc.: 67.58%] [Generator loss: 0.8495%]\n",
            "1825 [Discriminator loss: 0.6480%, acc.: 67.19%] [Generator loss: 0.8489%]\n",
            "1826 [Discriminator loss: 0.6632%, acc.: 62.11%] [Generator loss: 0.8383%]\n",
            "1827 [Discriminator loss: 0.6623%, acc.: 62.89%] [Generator loss: 0.8369%]\n",
            "1828 [Discriminator loss: 0.6429%, acc.: 69.53%] [Generator loss: 0.8367%]\n",
            "1829 [Discriminator loss: 0.6504%, acc.: 67.19%] [Generator loss: 0.8467%]\n",
            "1830 [Discriminator loss: 0.6507%, acc.: 64.45%] [Generator loss: 0.8584%]\n",
            "1831 [Discriminator loss: 0.6711%, acc.: 61.33%] [Generator loss: 0.8464%]\n",
            "1832 [Discriminator loss: 0.6682%, acc.: 60.16%] [Generator loss: 0.8460%]\n",
            "1833 [Discriminator loss: 0.6549%, acc.: 60.94%] [Generator loss: 0.8482%]\n",
            "1834 [Discriminator loss: 0.6546%, acc.: 62.89%] [Generator loss: 0.8700%]\n",
            "1835 [Discriminator loss: 0.6688%, acc.: 57.03%] [Generator loss: 0.8628%]\n",
            "1836 [Discriminator loss: 0.6602%, acc.: 59.38%] [Generator loss: 0.8759%]\n",
            "1837 [Discriminator loss: 0.6528%, acc.: 66.80%] [Generator loss: 0.8636%]\n",
            "1838 [Discriminator loss: 0.6611%, acc.: 66.41%] [Generator loss: 0.8560%]\n",
            "1839 [Discriminator loss: 0.6454%, acc.: 64.45%] [Generator loss: 0.8522%]\n",
            "1840 [Discriminator loss: 0.6445%, acc.: 67.58%] [Generator loss: 0.8695%]\n",
            "1841 [Discriminator loss: 0.6492%, acc.: 70.31%] [Generator loss: 0.8670%]\n",
            "1842 [Discriminator loss: 0.6560%, acc.: 62.11%] [Generator loss: 0.8723%]\n",
            "1843 [Discriminator loss: 0.6384%, acc.: 71.48%] [Generator loss: 0.8849%]\n",
            "1844 [Discriminator loss: 0.6500%, acc.: 68.75%] [Generator loss: 0.8717%]\n",
            "1845 [Discriminator loss: 0.6537%, acc.: 68.36%] [Generator loss: 0.8782%]\n",
            "1846 [Discriminator loss: 0.6544%, acc.: 62.11%] [Generator loss: 0.8654%]\n",
            "1847 [Discriminator loss: 0.6573%, acc.: 63.67%] [Generator loss: 0.8596%]\n",
            "1848 [Discriminator loss: 0.6635%, acc.: 58.59%] [Generator loss: 0.8569%]\n",
            "1849 [Discriminator loss: 0.6307%, acc.: 70.70%] [Generator loss: 0.8695%]\n",
            "1850 [Discriminator loss: 0.6488%, acc.: 64.45%] [Generator loss: 0.8690%]\n",
            "1851 [Discriminator loss: 0.6467%, acc.: 64.06%] [Generator loss: 0.8620%]\n",
            "1852 [Discriminator loss: 0.6420%, acc.: 64.45%] [Generator loss: 0.8516%]\n",
            "1853 [Discriminator loss: 0.6607%, acc.: 61.33%] [Generator loss: 0.8501%]\n",
            "1854 [Discriminator loss: 0.6643%, acc.: 56.25%] [Generator loss: 0.8613%]\n",
            "1855 [Discriminator loss: 0.6468%, acc.: 62.89%] [Generator loss: 0.8519%]\n",
            "1856 [Discriminator loss: 0.6709%, acc.: 57.81%] [Generator loss: 0.8499%]\n",
            "1857 [Discriminator loss: 0.6541%, acc.: 62.11%] [Generator loss: 0.8773%]\n",
            "1858 [Discriminator loss: 0.6574%, acc.: 58.59%] [Generator loss: 0.8674%]\n",
            "1859 [Discriminator loss: 0.6489%, acc.: 61.33%] [Generator loss: 0.8578%]\n",
            "1860 [Discriminator loss: 0.6671%, acc.: 57.42%] [Generator loss: 0.8550%]\n",
            "1861 [Discriminator loss: 0.6549%, acc.: 60.55%] [Generator loss: 0.8669%]\n",
            "1862 [Discriminator loss: 0.6708%, acc.: 57.42%] [Generator loss: 0.8670%]\n",
            "1863 [Discriminator loss: 0.6448%, acc.: 61.72%] [Generator loss: 0.8510%]\n",
            "1864 [Discriminator loss: 0.6889%, acc.: 53.12%] [Generator loss: 0.8458%]\n",
            "1865 [Discriminator loss: 0.6573%, acc.: 62.11%] [Generator loss: 0.8493%]\n",
            "1866 [Discriminator loss: 0.6809%, acc.: 56.25%] [Generator loss: 0.8752%]\n",
            "1867 [Discriminator loss: 0.6374%, acc.: 63.28%] [Generator loss: 0.8540%]\n",
            "1868 [Discriminator loss: 0.6633%, acc.: 55.47%] [Generator loss: 0.8804%]\n",
            "1869 [Discriminator loss: 0.6649%, acc.: 58.59%] [Generator loss: 0.8592%]\n",
            "1870 [Discriminator loss: 0.6520%, acc.: 60.94%] [Generator loss: 0.8514%]\n",
            "1871 [Discriminator loss: 0.6813%, acc.: 52.73%] [Generator loss: 0.8172%]\n",
            "1872 [Discriminator loss: 0.6921%, acc.: 51.56%] [Generator loss: 0.8542%]\n",
            "1873 [Discriminator loss: 0.6502%, acc.: 61.72%] [Generator loss: 0.8729%]\n",
            "1874 [Discriminator loss: 0.6394%, acc.: 66.02%] [Generator loss: 0.8819%]\n",
            "1875 [Discriminator loss: 0.6601%, acc.: 61.72%] [Generator loss: 0.8481%]\n",
            "1876 [Discriminator loss: 0.6574%, acc.: 60.94%] [Generator loss: 0.8450%]\n",
            "1877 [Discriminator loss: 0.6666%, acc.: 64.45%] [Generator loss: 0.8534%]\n",
            "1878 [Discriminator loss: 0.6793%, acc.: 58.20%] [Generator loss: 0.8643%]\n",
            "1879 [Discriminator loss: 0.6723%, acc.: 54.69%] [Generator loss: 0.8777%]\n",
            "1880 [Discriminator loss: 0.6720%, acc.: 58.20%] [Generator loss: 0.8877%]\n",
            "1881 [Discriminator loss: 0.6712%, acc.: 53.91%] [Generator loss: 0.8840%]\n",
            "1882 [Discriminator loss: 0.6765%, acc.: 52.73%] [Generator loss: 0.8709%]\n",
            "1883 [Discriminator loss: 0.6647%, acc.: 51.95%] [Generator loss: 0.8444%]\n",
            "1884 [Discriminator loss: 0.6489%, acc.: 58.59%] [Generator loss: 0.8287%]\n",
            "1885 [Discriminator loss: 0.6765%, acc.: 53.52%] [Generator loss: 0.8417%]\n",
            "1886 [Discriminator loss: 0.6809%, acc.: 51.17%] [Generator loss: 0.8295%]\n",
            "1887 [Discriminator loss: 0.6891%, acc.: 48.83%] [Generator loss: 0.8306%]\n",
            "1888 [Discriminator loss: 0.6824%, acc.: 47.66%] [Generator loss: 0.8361%]\n",
            "1889 [Discriminator loss: 0.6718%, acc.: 56.25%] [Generator loss: 0.8209%]\n",
            "1890 [Discriminator loss: 0.6785%, acc.: 49.61%] [Generator loss: 0.8410%]\n",
            "1891 [Discriminator loss: 0.6691%, acc.: 55.08%] [Generator loss: 0.8491%]\n",
            "1892 [Discriminator loss: 0.6841%, acc.: 47.66%] [Generator loss: 0.8437%]\n",
            "1893 [Discriminator loss: 0.6704%, acc.: 52.73%] [Generator loss: 0.8545%]\n",
            "1894 [Discriminator loss: 0.6614%, acc.: 59.77%] [Generator loss: 0.8491%]\n",
            "1895 [Discriminator loss: 0.6642%, acc.: 61.33%] [Generator loss: 0.8430%]\n",
            "1896 [Discriminator loss: 0.6846%, acc.: 56.25%] [Generator loss: 0.8349%]\n",
            "1897 [Discriminator loss: 0.6709%, acc.: 57.42%] [Generator loss: 0.8340%]\n",
            "1898 [Discriminator loss: 0.6631%, acc.: 60.16%] [Generator loss: 0.8476%]\n",
            "1899 [Discriminator loss: 0.6575%, acc.: 61.33%] [Generator loss: 0.8441%]\n",
            "1900 [Discriminator loss: 0.6843%, acc.: 53.12%] [Generator loss: 0.8392%]\n",
            "1901 [Discriminator loss: 0.6844%, acc.: 57.81%] [Generator loss: 0.8751%]\n",
            "1902 [Discriminator loss: 0.6640%, acc.: 59.38%] [Generator loss: 0.8570%]\n",
            "1903 [Discriminator loss: 0.6608%, acc.: 62.50%] [Generator loss: 0.8378%]\n",
            "1904 [Discriminator loss: 0.6705%, acc.: 58.98%] [Generator loss: 0.8452%]\n",
            "1905 [Discriminator loss: 0.6556%, acc.: 62.89%] [Generator loss: 0.8559%]\n",
            "1906 [Discriminator loss: 0.6571%, acc.: 62.11%] [Generator loss: 0.8451%]\n",
            "1907 [Discriminator loss: 0.6810%, acc.: 58.20%] [Generator loss: 0.8453%]\n",
            "1908 [Discriminator loss: 0.6559%, acc.: 65.23%] [Generator loss: 0.8464%]\n",
            "1909 [Discriminator loss: 0.6623%, acc.: 60.55%] [Generator loss: 0.8324%]\n",
            "1910 [Discriminator loss: 0.6633%, acc.: 55.47%] [Generator loss: 0.8363%]\n",
            "1911 [Discriminator loss: 0.6855%, acc.: 52.73%] [Generator loss: 0.8385%]\n",
            "1912 [Discriminator loss: 0.6695%, acc.: 57.81%] [Generator loss: 0.8377%]\n",
            "1913 [Discriminator loss: 0.6655%, acc.: 58.59%] [Generator loss: 0.8366%]\n",
            "1914 [Discriminator loss: 0.6887%, acc.: 53.52%] [Generator loss: 0.8213%]\n",
            "1915 [Discriminator loss: 0.6849%, acc.: 55.47%] [Generator loss: 0.8243%]\n",
            "1916 [Discriminator loss: 0.6688%, acc.: 60.55%] [Generator loss: 0.8397%]\n",
            "1917 [Discriminator loss: 0.6664%, acc.: 54.30%] [Generator loss: 0.8473%]\n",
            "1918 [Discriminator loss: 0.6731%, acc.: 59.38%] [Generator loss: 0.8286%]\n",
            "1919 [Discriminator loss: 0.6855%, acc.: 56.25%] [Generator loss: 0.8410%]\n",
            "1920 [Discriminator loss: 0.6680%, acc.: 56.64%] [Generator loss: 0.8285%]\n",
            "1921 [Discriminator loss: 0.6696%, acc.: 56.25%] [Generator loss: 0.8260%]\n",
            "1922 [Discriminator loss: 0.6616%, acc.: 58.98%] [Generator loss: 0.8260%]\n",
            "1923 [Discriminator loss: 0.6806%, acc.: 54.30%] [Generator loss: 0.8340%]\n",
            "1924 [Discriminator loss: 0.6833%, acc.: 53.12%] [Generator loss: 0.8268%]\n",
            "1925 [Discriminator loss: 0.6664%, acc.: 55.86%] [Generator loss: 0.8260%]\n",
            "1926 [Discriminator loss: 0.6469%, acc.: 60.16%] [Generator loss: 0.8417%]\n",
            "1927 [Discriminator loss: 0.6625%, acc.: 55.47%] [Generator loss: 0.8486%]\n",
            "1928 [Discriminator loss: 0.6627%, acc.: 53.91%] [Generator loss: 0.8532%]\n",
            "1929 [Discriminator loss: 0.6584%, acc.: 57.03%] [Generator loss: 0.8673%]\n",
            "1930 [Discriminator loss: 0.6934%, acc.: 48.83%] [Generator loss: 0.8391%]\n",
            "1931 [Discriminator loss: 0.6757%, acc.: 51.17%] [Generator loss: 0.8423%]\n",
            "1932 [Discriminator loss: 0.6731%, acc.: 57.42%] [Generator loss: 0.8210%]\n",
            "1933 [Discriminator loss: 0.6840%, acc.: 48.05%] [Generator loss: 0.8167%]\n",
            "1934 [Discriminator loss: 0.6735%, acc.: 52.34%] [Generator loss: 0.8217%]\n",
            "1935 [Discriminator loss: 0.6708%, acc.: 54.69%] [Generator loss: 0.8277%]\n",
            "1936 [Discriminator loss: 0.6746%, acc.: 51.95%] [Generator loss: 0.8260%]\n",
            "1937 [Discriminator loss: 0.6576%, acc.: 61.33%] [Generator loss: 0.8112%]\n",
            "1938 [Discriminator loss: 0.6783%, acc.: 52.73%] [Generator loss: 0.8050%]\n",
            "1939 [Discriminator loss: 0.6890%, acc.: 53.12%] [Generator loss: 0.8025%]\n",
            "1940 [Discriminator loss: 0.6739%, acc.: 54.69%] [Generator loss: 0.8205%]\n",
            "1941 [Discriminator loss: 0.6724%, acc.: 58.59%] [Generator loss: 0.8088%]\n",
            "1942 [Discriminator loss: 0.6689%, acc.: 58.59%] [Generator loss: 0.8090%]\n",
            "1943 [Discriminator loss: 0.6797%, acc.: 53.12%] [Generator loss: 0.8173%]\n",
            "1944 [Discriminator loss: 0.6771%, acc.: 57.42%] [Generator loss: 0.8128%]\n",
            "1945 [Discriminator loss: 0.6762%, acc.: 55.08%] [Generator loss: 0.8208%]\n",
            "1946 [Discriminator loss: 0.6639%, acc.: 58.98%] [Generator loss: 0.8100%]\n",
            "1947 [Discriminator loss: 0.6738%, acc.: 54.30%] [Generator loss: 0.8184%]\n",
            "1948 [Discriminator loss: 0.6820%, acc.: 55.86%] [Generator loss: 0.8155%]\n",
            "1949 [Discriminator loss: 0.6639%, acc.: 63.28%] [Generator loss: 0.8185%]\n",
            "1950 [Discriminator loss: 0.6574%, acc.: 61.33%] [Generator loss: 0.8053%]\n",
            "1951 [Discriminator loss: 0.6763%, acc.: 55.47%] [Generator loss: 0.8095%]\n",
            "1952 [Discriminator loss: 0.6954%, acc.: 50.00%] [Generator loss: 0.8201%]\n",
            "1953 [Discriminator loss: 0.6527%, acc.: 62.50%] [Generator loss: 0.8215%]\n",
            "1954 [Discriminator loss: 0.6780%, acc.: 56.64%] [Generator loss: 0.8071%]\n",
            "1955 [Discriminator loss: 0.6689%, acc.: 60.16%] [Generator loss: 0.8021%]\n",
            "1956 [Discriminator loss: 0.6789%, acc.: 55.08%] [Generator loss: 0.8129%]\n",
            "1957 [Discriminator loss: 0.6712%, acc.: 58.98%] [Generator loss: 0.8262%]\n",
            "1958 [Discriminator loss: 0.6510%, acc.: 59.77%] [Generator loss: 0.8358%]\n",
            "1959 [Discriminator loss: 0.6629%, acc.: 58.98%] [Generator loss: 0.8342%]\n",
            "1960 [Discriminator loss: 0.6750%, acc.: 57.03%] [Generator loss: 0.8505%]\n",
            "1961 [Discriminator loss: 0.6695%, acc.: 54.69%] [Generator loss: 0.8403%]\n",
            "1962 [Discriminator loss: 0.6745%, acc.: 54.69%] [Generator loss: 0.8281%]\n",
            "1963 [Discriminator loss: 0.6804%, acc.: 53.91%] [Generator loss: 0.8225%]\n",
            "1964 [Discriminator loss: 0.6554%, acc.: 61.72%] [Generator loss: 0.8288%]\n",
            "1965 [Discriminator loss: 0.6887%, acc.: 50.78%] [Generator loss: 0.8202%]\n",
            "1966 [Discriminator loss: 0.6680%, acc.: 58.20%] [Generator loss: 0.8357%]\n",
            "1967 [Discriminator loss: 0.6648%, acc.: 59.77%] [Generator loss: 0.8293%]\n",
            "1968 [Discriminator loss: 0.6626%, acc.: 62.11%] [Generator loss: 0.8179%]\n",
            "1969 [Discriminator loss: 0.6725%, acc.: 59.77%] [Generator loss: 0.8242%]\n",
            "1970 [Discriminator loss: 0.6589%, acc.: 64.45%] [Generator loss: 0.8376%]\n",
            "1971 [Discriminator loss: 0.6735%, acc.: 58.20%] [Generator loss: 0.8375%]\n",
            "1972 [Discriminator loss: 0.6596%, acc.: 60.16%] [Generator loss: 0.8250%]\n",
            "1973 [Discriminator loss: 0.6659%, acc.: 57.42%] [Generator loss: 0.8388%]\n",
            "1974 [Discriminator loss: 0.6634%, acc.: 56.25%] [Generator loss: 0.8506%]\n",
            "1975 [Discriminator loss: 0.6822%, acc.: 50.39%] [Generator loss: 0.8442%]\n",
            "1976 [Discriminator loss: 0.6716%, acc.: 57.81%] [Generator loss: 0.8306%]\n",
            "1977 [Discriminator loss: 0.6692%, acc.: 58.20%] [Generator loss: 0.8171%]\n",
            "1978 [Discriminator loss: 0.6577%, acc.: 61.33%] [Generator loss: 0.8266%]\n",
            "1979 [Discriminator loss: 0.6554%, acc.: 60.94%] [Generator loss: 0.8287%]\n",
            "1980 [Discriminator loss: 0.6597%, acc.: 62.89%] [Generator loss: 0.8475%]\n",
            "1981 [Discriminator loss: 0.6662%, acc.: 58.59%] [Generator loss: 0.8378%]\n",
            "1982 [Discriminator loss: 0.6615%, acc.: 64.84%] [Generator loss: 0.8188%]\n",
            "1983 [Discriminator loss: 0.6569%, acc.: 61.33%] [Generator loss: 0.8255%]\n",
            "1984 [Discriminator loss: 0.6615%, acc.: 60.94%] [Generator loss: 0.8224%]\n",
            "1985 [Discriminator loss: 0.6551%, acc.: 66.41%] [Generator loss: 0.8244%]\n",
            "1986 [Discriminator loss: 0.6580%, acc.: 62.89%] [Generator loss: 0.8302%]\n",
            "1987 [Discriminator loss: 0.6567%, acc.: 61.33%] [Generator loss: 0.8321%]\n",
            "1988 [Discriminator loss: 0.6534%, acc.: 66.02%] [Generator loss: 0.8461%]\n",
            "1989 [Discriminator loss: 0.6521%, acc.: 62.89%] [Generator loss: 0.8517%]\n",
            "1990 [Discriminator loss: 0.6572%, acc.: 58.98%] [Generator loss: 0.8395%]\n",
            "1991 [Discriminator loss: 0.6733%, acc.: 55.47%] [Generator loss: 0.8227%]\n",
            "1992 [Discriminator loss: 0.6556%, acc.: 60.55%] [Generator loss: 0.8381%]\n",
            "1993 [Discriminator loss: 0.6667%, acc.: 55.08%] [Generator loss: 0.8282%]\n",
            "1994 [Discriminator loss: 0.6685%, acc.: 60.16%] [Generator loss: 0.8257%]\n",
            "1995 [Discriminator loss: 0.6744%, acc.: 55.47%] [Generator loss: 0.8333%]\n",
            "1996 [Discriminator loss: 0.6617%, acc.: 59.38%] [Generator loss: 0.8431%]\n",
            "1997 [Discriminator loss: 0.6713%, acc.: 54.69%] [Generator loss: 0.8148%]\n",
            "1998 [Discriminator loss: 0.6637%, acc.: 57.42%] [Generator loss: 0.8250%]\n",
            "1999 [Discriminator loss: 0.6744%, acc.: 55.86%] [Generator loss: 0.8194%]\n",
            "2000 [Discriminator loss: 0.6577%, acc.: 60.16%] [Generator loss: 0.8192%]\n",
            "2001 [Discriminator loss: 0.6649%, acc.: 60.16%] [Generator loss: 0.8151%]\n",
            "2002 [Discriminator loss: 0.6732%, acc.: 51.95%] [Generator loss: 0.8349%]\n",
            "2003 [Discriminator loss: 0.6619%, acc.: 59.38%] [Generator loss: 0.8214%]\n",
            "2004 [Discriminator loss: 0.6667%, acc.: 61.72%] [Generator loss: 0.8339%]\n",
            "2005 [Discriminator loss: 0.6570%, acc.: 60.55%] [Generator loss: 0.8240%]\n",
            "2006 [Discriminator loss: 0.6668%, acc.: 57.03%] [Generator loss: 0.8290%]\n",
            "2007 [Discriminator loss: 0.6735%, acc.: 53.91%] [Generator loss: 0.8396%]\n",
            "2008 [Discriminator loss: 0.6764%, acc.: 55.86%] [Generator loss: 0.8291%]\n",
            "2009 [Discriminator loss: 0.6656%, acc.: 57.42%] [Generator loss: 0.8090%]\n",
            "2010 [Discriminator loss: 0.6820%, acc.: 55.47%] [Generator loss: 0.7910%]\n",
            "2011 [Discriminator loss: 0.6823%, acc.: 54.69%] [Generator loss: 0.8103%]\n",
            "2012 [Discriminator loss: 0.6528%, acc.: 61.33%] [Generator loss: 0.8253%]\n",
            "2013 [Discriminator loss: 0.6643%, acc.: 56.64%] [Generator loss: 0.8113%]\n",
            "2014 [Discriminator loss: 0.6554%, acc.: 59.38%] [Generator loss: 0.8211%]\n",
            "2015 [Discriminator loss: 0.6756%, acc.: 55.86%] [Generator loss: 0.8045%]\n",
            "2016 [Discriminator loss: 0.6757%, acc.: 56.25%] [Generator loss: 0.8132%]\n",
            "2017 [Discriminator loss: 0.6847%, acc.: 52.34%] [Generator loss: 0.8050%]\n",
            "2018 [Discriminator loss: 0.6674%, acc.: 56.64%] [Generator loss: 0.7973%]\n",
            "2019 [Discriminator loss: 0.6854%, acc.: 46.48%] [Generator loss: 0.8140%]\n",
            "2020 [Discriminator loss: 0.6815%, acc.: 50.39%] [Generator loss: 0.8078%]\n",
            "2021 [Discriminator loss: 0.6649%, acc.: 51.95%] [Generator loss: 0.8175%]\n",
            "2022 [Discriminator loss: 0.6589%, acc.: 55.08%] [Generator loss: 0.8280%]\n",
            "2023 [Discriminator loss: 0.6640%, acc.: 55.08%] [Generator loss: 0.8393%]\n",
            "2024 [Discriminator loss: 0.6580%, acc.: 60.16%] [Generator loss: 0.8220%]\n",
            "2025 [Discriminator loss: 0.6729%, acc.: 51.17%] [Generator loss: 0.8312%]\n",
            "2026 [Discriminator loss: 0.6712%, acc.: 55.86%] [Generator loss: 0.8118%]\n",
            "2027 [Discriminator loss: 0.6575%, acc.: 55.08%] [Generator loss: 0.8219%]\n",
            "2028 [Discriminator loss: 0.6694%, acc.: 56.64%] [Generator loss: 0.8275%]\n",
            "2029 [Discriminator loss: 0.6615%, acc.: 63.67%] [Generator loss: 0.8393%]\n",
            "2030 [Discriminator loss: 0.6778%, acc.: 54.30%] [Generator loss: 0.8289%]\n",
            "2031 [Discriminator loss: 0.6712%, acc.: 55.86%] [Generator loss: 0.8339%]\n",
            "2032 [Discriminator loss: 0.6706%, acc.: 60.16%] [Generator loss: 0.8417%]\n",
            "2033 [Discriminator loss: 0.6447%, acc.: 60.55%] [Generator loss: 0.8580%]\n",
            "2034 [Discriminator loss: 0.6607%, acc.: 57.42%] [Generator loss: 0.8548%]\n",
            "2035 [Discriminator loss: 0.6882%, acc.: 55.47%] [Generator loss: 0.8544%]\n",
            "2036 [Discriminator loss: 0.6592%, acc.: 63.28%] [Generator loss: 0.8409%]\n",
            "2037 [Discriminator loss: 0.6647%, acc.: 61.33%] [Generator loss: 0.8437%]\n",
            "2038 [Discriminator loss: 0.6758%, acc.: 59.38%] [Generator loss: 0.8264%]\n",
            "2039 [Discriminator loss: 0.6690%, acc.: 62.50%] [Generator loss: 0.8176%]\n",
            "2040 [Discriminator loss: 0.6668%, acc.: 58.20%] [Generator loss: 0.8399%]\n",
            "2041 [Discriminator loss: 0.6731%, acc.: 58.20%] [Generator loss: 0.8455%]\n",
            "2042 [Discriminator loss: 0.6436%, acc.: 63.67%] [Generator loss: 0.8453%]\n",
            "2043 [Discriminator loss: 0.6628%, acc.: 56.25%] [Generator loss: 0.8156%]\n",
            "2044 [Discriminator loss: 0.6508%, acc.: 60.16%] [Generator loss: 0.8418%]\n",
            "2045 [Discriminator loss: 0.6567%, acc.: 59.38%] [Generator loss: 0.8558%]\n",
            "2046 [Discriminator loss: 0.6573%, acc.: 57.42%] [Generator loss: 0.8475%]\n",
            "2047 [Discriminator loss: 0.6628%, acc.: 60.16%] [Generator loss: 0.8429%]\n",
            "2048 [Discriminator loss: 0.6513%, acc.: 64.45%] [Generator loss: 0.8572%]\n",
            "2049 [Discriminator loss: 0.6557%, acc.: 59.38%] [Generator loss: 0.8501%]\n",
            "2050 [Discriminator loss: 0.6685%, acc.: 53.91%] [Generator loss: 0.8480%]\n",
            "2051 [Discriminator loss: 0.6452%, acc.: 59.38%] [Generator loss: 0.8302%]\n",
            "2052 [Discriminator loss: 0.6585%, acc.: 60.94%] [Generator loss: 0.8608%]\n",
            "2053 [Discriminator loss: 0.6533%, acc.: 60.94%] [Generator loss: 0.8571%]\n",
            "2054 [Discriminator loss: 0.6472%, acc.: 62.50%] [Generator loss: 0.8720%]\n",
            "2055 [Discriminator loss: 0.6570%, acc.: 61.33%] [Generator loss: 0.8638%]\n",
            "2056 [Discriminator loss: 0.6681%, acc.: 54.30%] [Generator loss: 0.8578%]\n",
            "2057 [Discriminator loss: 0.6629%, acc.: 58.98%] [Generator loss: 0.8681%]\n",
            "2058 [Discriminator loss: 0.6498%, acc.: 58.59%] [Generator loss: 0.8605%]\n",
            "2059 [Discriminator loss: 0.6506%, acc.: 60.16%] [Generator loss: 0.8795%]\n",
            "2060 [Discriminator loss: 0.6568%, acc.: 58.98%] [Generator loss: 0.8737%]\n",
            "2061 [Discriminator loss: 0.6825%, acc.: 50.78%] [Generator loss: 0.8762%]\n",
            "2062 [Discriminator loss: 0.6587%, acc.: 58.20%] [Generator loss: 0.8545%]\n",
            "2063 [Discriminator loss: 0.6581%, acc.: 58.59%] [Generator loss: 0.8547%]\n",
            "2064 [Discriminator loss: 0.6501%, acc.: 57.42%] [Generator loss: 0.8768%]\n",
            "2065 [Discriminator loss: 0.6522%, acc.: 58.59%] [Generator loss: 0.8856%]\n",
            "2066 [Discriminator loss: 0.6463%, acc.: 60.55%] [Generator loss: 0.8833%]\n",
            "2067 [Discriminator loss: 0.6670%, acc.: 60.55%] [Generator loss: 0.8767%]\n",
            "2068 [Discriminator loss: 0.6359%, acc.: 64.45%] [Generator loss: 0.8832%]\n",
            "2069 [Discriminator loss: 0.6764%, acc.: 50.78%] [Generator loss: 0.8875%]\n",
            "2070 [Discriminator loss: 0.6525%, acc.: 58.59%] [Generator loss: 0.9018%]\n",
            "2071 [Discriminator loss: 0.6604%, acc.: 58.98%] [Generator loss: 0.8837%]\n",
            "2072 [Discriminator loss: 0.6861%, acc.: 56.64%] [Generator loss: 0.9036%]\n",
            "2073 [Discriminator loss: 0.6738%, acc.: 56.64%] [Generator loss: 0.8664%]\n",
            "2074 [Discriminator loss: 0.6666%, acc.: 57.81%] [Generator loss: 0.8759%]\n",
            "2075 [Discriminator loss: 0.6425%, acc.: 66.02%] [Generator loss: 0.8724%]\n",
            "2076 [Discriminator loss: 0.6767%, acc.: 55.86%] [Generator loss: 0.8729%]\n",
            "2077 [Discriminator loss: 0.6921%, acc.: 52.73%] [Generator loss: 0.8546%]\n",
            "2078 [Discriminator loss: 0.6427%, acc.: 63.28%] [Generator loss: 0.8787%]\n",
            "2079 [Discriminator loss: 0.6494%, acc.: 64.45%] [Generator loss: 0.8705%]\n",
            "2080 [Discriminator loss: 0.6842%, acc.: 54.69%] [Generator loss: 0.8500%]\n",
            "2081 [Discriminator loss: 0.6607%, acc.: 60.55%] [Generator loss: 0.8426%]\n",
            "2082 [Discriminator loss: 0.6691%, acc.: 56.64%] [Generator loss: 0.8479%]\n",
            "2083 [Discriminator loss: 0.6736%, acc.: 59.38%] [Generator loss: 0.8470%]\n",
            "2084 [Discriminator loss: 0.6892%, acc.: 55.08%] [Generator loss: 0.8448%]\n",
            "2085 [Discriminator loss: 0.7026%, acc.: 44.92%] [Generator loss: 0.8682%]\n",
            "2086 [Discriminator loss: 0.6619%, acc.: 60.16%] [Generator loss: 0.8685%]\n",
            "2087 [Discriminator loss: 0.6754%, acc.: 55.86%] [Generator loss: 0.8621%]\n",
            "2088 [Discriminator loss: 0.6710%, acc.: 53.91%] [Generator loss: 0.8844%]\n",
            "2089 [Discriminator loss: 0.6861%, acc.: 53.91%] [Generator loss: 0.8790%]\n",
            "2090 [Discriminator loss: 0.6767%, acc.: 52.73%] [Generator loss: 0.8594%]\n",
            "2091 [Discriminator loss: 0.6591%, acc.: 60.94%] [Generator loss: 0.8637%]\n",
            "2092 [Discriminator loss: 0.6776%, acc.: 53.52%] [Generator loss: 0.8369%]\n",
            "2093 [Discriminator loss: 0.6779%, acc.: 53.91%] [Generator loss: 0.8414%]\n",
            "2094 [Discriminator loss: 0.6741%, acc.: 55.47%] [Generator loss: 0.8344%]\n",
            "2095 [Discriminator loss: 0.6767%, acc.: 53.52%] [Generator loss: 0.8501%]\n",
            "2096 [Discriminator loss: 0.6581%, acc.: 58.20%] [Generator loss: 0.8643%]\n",
            "2097 [Discriminator loss: 0.6747%, acc.: 54.30%] [Generator loss: 0.8524%]\n",
            "2098 [Discriminator loss: 0.6783%, acc.: 55.47%] [Generator loss: 0.8350%]\n",
            "2099 [Discriminator loss: 0.6680%, acc.: 55.47%] [Generator loss: 0.8525%]\n",
            "2100 [Discriminator loss: 0.6489%, acc.: 64.45%] [Generator loss: 0.8497%]\n",
            "2101 [Discriminator loss: 0.6636%, acc.: 58.98%] [Generator loss: 0.8608%]\n",
            "2102 [Discriminator loss: 0.6908%, acc.: 51.17%] [Generator loss: 0.8343%]\n",
            "2103 [Discriminator loss: 0.6476%, acc.: 60.55%] [Generator loss: 0.8601%]\n",
            "2104 [Discriminator loss: 0.6713%, acc.: 58.59%] [Generator loss: 0.8453%]\n",
            "2105 [Discriminator loss: 0.6646%, acc.: 57.42%] [Generator loss: 0.8687%]\n",
            "2106 [Discriminator loss: 0.6567%, acc.: 59.77%] [Generator loss: 0.8837%]\n",
            "2107 [Discriminator loss: 0.6742%, acc.: 60.16%] [Generator loss: 0.8526%]\n",
            "2108 [Discriminator loss: 0.6717%, acc.: 61.33%] [Generator loss: 0.8612%]\n",
            "2109 [Discriminator loss: 0.6579%, acc.: 62.50%] [Generator loss: 0.8571%]\n",
            "2110 [Discriminator loss: 0.6536%, acc.: 60.55%] [Generator loss: 0.8723%]\n",
            "2111 [Discriminator loss: 0.6578%, acc.: 56.25%] [Generator loss: 0.8958%]\n",
            "2112 [Discriminator loss: 0.6660%, acc.: 60.16%] [Generator loss: 0.8834%]\n",
            "2113 [Discriminator loss: 0.6471%, acc.: 66.41%] [Generator loss: 0.8597%]\n",
            "2114 [Discriminator loss: 0.6660%, acc.: 58.98%] [Generator loss: 0.8671%]\n",
            "2115 [Discriminator loss: 0.6685%, acc.: 57.03%] [Generator loss: 0.8789%]\n",
            "2116 [Discriminator loss: 0.6342%, acc.: 68.36%] [Generator loss: 0.8806%]\n",
            "2117 [Discriminator loss: 0.6503%, acc.: 66.02%] [Generator loss: 0.8832%]\n",
            "2118 [Discriminator loss: 0.6608%, acc.: 57.81%] [Generator loss: 0.8917%]\n",
            "2119 [Discriminator loss: 0.6480%, acc.: 63.28%] [Generator loss: 0.8995%]\n",
            "2120 [Discriminator loss: 0.6558%, acc.: 62.11%] [Generator loss: 0.8772%]\n",
            "2121 [Discriminator loss: 0.6665%, acc.: 59.77%] [Generator loss: 0.8825%]\n",
            "2122 [Discriminator loss: 0.6342%, acc.: 66.41%] [Generator loss: 0.8870%]\n",
            "2123 [Discriminator loss: 0.6678%, acc.: 57.03%] [Generator loss: 0.8573%]\n",
            "2124 [Discriminator loss: 0.6598%, acc.: 60.16%] [Generator loss: 0.8749%]\n",
            "2125 [Discriminator loss: 0.6476%, acc.: 65.23%] [Generator loss: 0.8836%]\n",
            "2126 [Discriminator loss: 0.6605%, acc.: 58.20%] [Generator loss: 0.8974%]\n",
            "2127 [Discriminator loss: 0.6449%, acc.: 63.67%] [Generator loss: 0.9111%]\n",
            "2128 [Discriminator loss: 0.6500%, acc.: 66.41%] [Generator loss: 0.8785%]\n",
            "2129 [Discriminator loss: 0.6540%, acc.: 60.55%] [Generator loss: 0.8896%]\n",
            "2130 [Discriminator loss: 0.6459%, acc.: 62.50%] [Generator loss: 0.8525%]\n",
            "2131 [Discriminator loss: 0.6334%, acc.: 69.92%] [Generator loss: 0.8370%]\n",
            "2132 [Discriminator loss: 0.6497%, acc.: 60.94%] [Generator loss: 0.8591%]\n",
            "2133 [Discriminator loss: 0.6408%, acc.: 62.50%] [Generator loss: 0.8777%]\n",
            "2134 [Discriminator loss: 0.6509%, acc.: 61.72%] [Generator loss: 0.8772%]\n",
            "2135 [Discriminator loss: 0.6690%, acc.: 57.03%] [Generator loss: 0.8703%]\n",
            "2136 [Discriminator loss: 0.6563%, acc.: 58.20%] [Generator loss: 0.8810%]\n",
            "2137 [Discriminator loss: 0.6491%, acc.: 57.81%] [Generator loss: 0.8635%]\n",
            "2138 [Discriminator loss: 0.6406%, acc.: 61.72%] [Generator loss: 0.8694%]\n",
            "2139 [Discriminator loss: 0.6508%, acc.: 63.28%] [Generator loss: 0.8521%]\n",
            "2140 [Discriminator loss: 0.6651%, acc.: 59.38%] [Generator loss: 0.8523%]\n",
            "2141 [Discriminator loss: 0.6500%, acc.: 60.16%] [Generator loss: 0.8779%]\n",
            "2142 [Discriminator loss: 0.6505%, acc.: 62.50%] [Generator loss: 0.8750%]\n",
            "2143 [Discriminator loss: 0.6462%, acc.: 64.06%] [Generator loss: 0.8546%]\n",
            "2144 [Discriminator loss: 0.6411%, acc.: 62.89%] [Generator loss: 0.8711%]\n",
            "2145 [Discriminator loss: 0.6660%, acc.: 57.81%] [Generator loss: 0.8802%]\n",
            "2146 [Discriminator loss: 0.6573%, acc.: 62.11%] [Generator loss: 0.8922%]\n",
            "2147 [Discriminator loss: 0.6535%, acc.: 63.28%] [Generator loss: 0.9038%]\n",
            "2148 [Discriminator loss: 0.6599%, acc.: 61.72%] [Generator loss: 0.8640%]\n",
            "2149 [Discriminator loss: 0.6689%, acc.: 59.38%] [Generator loss: 0.8650%]\n",
            "2150 [Discriminator loss: 0.6634%, acc.: 60.55%] [Generator loss: 0.8378%]\n",
            "2151 [Discriminator loss: 0.6579%, acc.: 62.11%] [Generator loss: 0.8852%]\n",
            "2152 [Discriminator loss: 0.6460%, acc.: 66.41%] [Generator loss: 0.8905%]\n",
            "2153 [Discriminator loss: 0.6532%, acc.: 62.89%] [Generator loss: 0.8720%]\n",
            "2154 [Discriminator loss: 0.6509%, acc.: 62.50%] [Generator loss: 0.8570%]\n",
            "2155 [Discriminator loss: 0.6654%, acc.: 61.33%] [Generator loss: 0.8493%]\n",
            "2156 [Discriminator loss: 0.6595%, acc.: 55.86%] [Generator loss: 0.8541%]\n",
            "2157 [Discriminator loss: 0.6908%, acc.: 51.56%] [Generator loss: 0.8667%]\n",
            "2158 [Discriminator loss: 0.6541%, acc.: 63.28%] [Generator loss: 0.8954%]\n",
            "2159 [Discriminator loss: 0.6708%, acc.: 54.69%] [Generator loss: 0.8652%]\n",
            "2160 [Discriminator loss: 0.6649%, acc.: 57.42%] [Generator loss: 0.8659%]\n",
            "2161 [Discriminator loss: 0.6447%, acc.: 60.94%] [Generator loss: 0.8719%]\n",
            "2162 [Discriminator loss: 0.6673%, acc.: 55.47%] [Generator loss: 0.9028%]\n",
            "2163 [Discriminator loss: 0.6844%, acc.: 49.22%] [Generator loss: 0.8791%]\n",
            "2164 [Discriminator loss: 0.6674%, acc.: 54.69%] [Generator loss: 0.8532%]\n",
            "2165 [Discriminator loss: 0.6822%, acc.: 52.73%] [Generator loss: 0.8565%]\n",
            "2166 [Discriminator loss: 0.6620%, acc.: 58.20%] [Generator loss: 0.8735%]\n",
            "2167 [Discriminator loss: 0.6661%, acc.: 57.81%] [Generator loss: 0.8827%]\n",
            "2168 [Discriminator loss: 0.6688%, acc.: 57.42%] [Generator loss: 0.8617%]\n",
            "2169 [Discriminator loss: 0.6516%, acc.: 62.50%] [Generator loss: 0.8553%]\n",
            "2170 [Discriminator loss: 0.6572%, acc.: 60.94%] [Generator loss: 0.8911%]\n",
            "2171 [Discriminator loss: 0.6696%, acc.: 61.33%] [Generator loss: 0.8861%]\n",
            "2172 [Discriminator loss: 0.6430%, acc.: 64.45%] [Generator loss: 0.8911%]\n",
            "2173 [Discriminator loss: 0.6540%, acc.: 63.67%] [Generator loss: 0.8732%]\n",
            "2174 [Discriminator loss: 0.6584%, acc.: 58.59%] [Generator loss: 0.8881%]\n",
            "2175 [Discriminator loss: 0.6579%, acc.: 57.03%] [Generator loss: 0.8831%]\n",
            "2176 [Discriminator loss: 0.6659%, acc.: 59.38%] [Generator loss: 0.8840%]\n",
            "2177 [Discriminator loss: 0.6460%, acc.: 58.98%] [Generator loss: 0.9174%]\n",
            "2178 [Discriminator loss: 0.6591%, acc.: 60.16%] [Generator loss: 0.9136%]\n",
            "2179 [Discriminator loss: 0.6595%, acc.: 59.77%] [Generator loss: 0.8975%]\n",
            "2180 [Discriminator loss: 0.6564%, acc.: 58.98%] [Generator loss: 0.8901%]\n",
            "2181 [Discriminator loss: 0.6680%, acc.: 58.20%] [Generator loss: 0.8850%]\n",
            "2182 [Discriminator loss: 0.6442%, acc.: 67.97%] [Generator loss: 0.8845%]\n",
            "2183 [Discriminator loss: 0.6518%, acc.: 58.98%] [Generator loss: 0.8641%]\n",
            "2184 [Discriminator loss: 0.6521%, acc.: 59.38%] [Generator loss: 0.8625%]\n",
            "2185 [Discriminator loss: 0.6409%, acc.: 57.03%] [Generator loss: 0.8935%]\n",
            "2186 [Discriminator loss: 0.6327%, acc.: 64.84%] [Generator loss: 0.9174%]\n",
            "2187 [Discriminator loss: 0.6528%, acc.: 59.38%] [Generator loss: 0.9196%]\n",
            "2188 [Discriminator loss: 0.6424%, acc.: 60.94%] [Generator loss: 0.9093%]\n",
            "2189 [Discriminator loss: 0.6352%, acc.: 64.06%] [Generator loss: 0.8920%]\n",
            "2190 [Discriminator loss: 0.6676%, acc.: 55.08%] [Generator loss: 0.8921%]\n",
            "2191 [Discriminator loss: 0.6426%, acc.: 58.98%] [Generator loss: 0.9140%]\n",
            "2192 [Discriminator loss: 0.6495%, acc.: 56.64%] [Generator loss: 0.9112%]\n",
            "2193 [Discriminator loss: 0.6607%, acc.: 57.81%] [Generator loss: 0.9153%]\n",
            "2194 [Discriminator loss: 0.6304%, acc.: 64.45%] [Generator loss: 0.9006%]\n",
            "2195 [Discriminator loss: 0.6474%, acc.: 64.06%] [Generator loss: 0.8912%]\n",
            "2196 [Discriminator loss: 0.6637%, acc.: 58.98%] [Generator loss: 0.8815%]\n",
            "2197 [Discriminator loss: 0.6528%, acc.: 58.98%] [Generator loss: 0.9097%]\n",
            "2198 [Discriminator loss: 0.6386%, acc.: 64.06%] [Generator loss: 0.8724%]\n",
            "2199 [Discriminator loss: 0.6336%, acc.: 62.50%] [Generator loss: 0.8853%]\n",
            "2200 [Discriminator loss: 0.6330%, acc.: 60.16%] [Generator loss: 0.8956%]\n",
            "2201 [Discriminator loss: 0.6430%, acc.: 58.98%] [Generator loss: 0.9059%]\n",
            "2202 [Discriminator loss: 0.6477%, acc.: 57.81%] [Generator loss: 0.8853%]\n",
            "2203 [Discriminator loss: 0.6435%, acc.: 59.77%] [Generator loss: 0.8958%]\n",
            "2204 [Discriminator loss: 0.6446%, acc.: 60.16%] [Generator loss: 0.9114%]\n",
            "2205 [Discriminator loss: 0.6513%, acc.: 58.98%] [Generator loss: 0.9138%]\n",
            "2206 [Discriminator loss: 0.6462%, acc.: 61.33%] [Generator loss: 0.8833%]\n",
            "2207 [Discriminator loss: 0.6461%, acc.: 60.16%] [Generator loss: 0.8859%]\n",
            "2208 [Discriminator loss: 0.6513%, acc.: 62.11%] [Generator loss: 0.9117%]\n",
            "2209 [Discriminator loss: 0.6445%, acc.: 60.55%] [Generator loss: 0.8935%]\n",
            "2210 [Discriminator loss: 0.6729%, acc.: 54.30%] [Generator loss: 0.9046%]\n",
            "2211 [Discriminator loss: 0.6479%, acc.: 61.33%] [Generator loss: 0.9093%]\n",
            "2212 [Discriminator loss: 0.6434%, acc.: 63.67%] [Generator loss: 0.8972%]\n",
            "2213 [Discriminator loss: 0.6553%, acc.: 59.38%] [Generator loss: 0.9058%]\n",
            "2214 [Discriminator loss: 0.6576%, acc.: 63.67%] [Generator loss: 0.8928%]\n",
            "2215 [Discriminator loss: 0.6710%, acc.: 57.81%] [Generator loss: 0.8640%]\n",
            "2216 [Discriminator loss: 0.6486%, acc.: 58.59%] [Generator loss: 0.8738%]\n",
            "2217 [Discriminator loss: 0.6449%, acc.: 66.02%] [Generator loss: 0.8877%]\n",
            "2218 [Discriminator loss: 0.6749%, acc.: 58.59%] [Generator loss: 0.8742%]\n",
            "2219 [Discriminator loss: 0.6547%, acc.: 61.33%] [Generator loss: 0.8649%]\n",
            "2220 [Discriminator loss: 0.6450%, acc.: 64.06%] [Generator loss: 0.8592%]\n",
            "2221 [Discriminator loss: 0.6686%, acc.: 58.20%] [Generator loss: 0.8433%]\n",
            "2222 [Discriminator loss: 0.6497%, acc.: 62.89%] [Generator loss: 0.8472%]\n",
            "2223 [Discriminator loss: 0.6431%, acc.: 64.84%] [Generator loss: 0.8732%]\n",
            "2224 [Discriminator loss: 0.6650%, acc.: 60.16%] [Generator loss: 0.8563%]\n",
            "2225 [Discriminator loss: 0.6607%, acc.: 58.59%] [Generator loss: 0.8647%]\n",
            "2226 [Discriminator loss: 0.6498%, acc.: 64.84%] [Generator loss: 0.8597%]\n",
            "2227 [Discriminator loss: 0.6437%, acc.: 64.84%] [Generator loss: 0.8820%]\n",
            "2228 [Discriminator loss: 0.6882%, acc.: 57.03%] [Generator loss: 0.8470%]\n",
            "2229 [Discriminator loss: 0.6508%, acc.: 61.33%] [Generator loss: 0.8742%]\n",
            "2230 [Discriminator loss: 0.6563%, acc.: 58.20%] [Generator loss: 0.8692%]\n",
            "2231 [Discriminator loss: 0.6475%, acc.: 61.33%] [Generator loss: 0.8755%]\n",
            "2232 [Discriminator loss: 0.6378%, acc.: 63.67%] [Generator loss: 0.8644%]\n",
            "2233 [Discriminator loss: 0.6513%, acc.: 65.23%] [Generator loss: 0.8443%]\n",
            "2234 [Discriminator loss: 0.6696%, acc.: 56.64%] [Generator loss: 0.8385%]\n",
            "2235 [Discriminator loss: 0.6590%, acc.: 60.55%] [Generator loss: 0.8575%]\n",
            "2236 [Discriminator loss: 0.6659%, acc.: 57.42%] [Generator loss: 0.8382%]\n",
            "2237 [Discriminator loss: 0.6307%, acc.: 66.02%] [Generator loss: 0.8732%]\n",
            "2238 [Discriminator loss: 0.6716%, acc.: 53.91%] [Generator loss: 0.8426%]\n",
            "2239 [Discriminator loss: 0.6648%, acc.: 55.47%] [Generator loss: 0.8465%]\n",
            "2240 [Discriminator loss: 0.6549%, acc.: 59.77%] [Generator loss: 0.8411%]\n",
            "2241 [Discriminator loss: 0.6382%, acc.: 62.89%] [Generator loss: 0.8644%]\n",
            "2242 [Discriminator loss: 0.6718%, acc.: 52.73%] [Generator loss: 0.8431%]\n",
            "2243 [Discriminator loss: 0.6607%, acc.: 59.38%] [Generator loss: 0.8781%]\n",
            "2244 [Discriminator loss: 0.6619%, acc.: 58.59%] [Generator loss: 0.8420%]\n",
            "2245 [Discriminator loss: 0.6573%, acc.: 60.55%] [Generator loss: 0.8401%]\n",
            "2246 [Discriminator loss: 0.6453%, acc.: 62.89%] [Generator loss: 0.8624%]\n",
            "2247 [Discriminator loss: 0.6587%, acc.: 55.86%] [Generator loss: 0.8717%]\n",
            "2248 [Discriminator loss: 0.6560%, acc.: 56.25%] [Generator loss: 0.8639%]\n",
            "2249 [Discriminator loss: 0.6432%, acc.: 57.42%] [Generator loss: 0.8655%]\n",
            "2250 [Discriminator loss: 0.6458%, acc.: 60.94%] [Generator loss: 0.8468%]\n",
            "2251 [Discriminator loss: 0.6814%, acc.: 48.44%] [Generator loss: 0.8478%]\n",
            "2252 [Discriminator loss: 0.6615%, acc.: 58.98%] [Generator loss: 0.8544%]\n",
            "2253 [Discriminator loss: 0.6517%, acc.: 56.64%] [Generator loss: 0.8492%]\n",
            "2254 [Discriminator loss: 0.6503%, acc.: 56.25%] [Generator loss: 0.8609%]\n",
            "2255 [Discriminator loss: 0.6393%, acc.: 62.89%] [Generator loss: 0.8515%]\n",
            "2256 [Discriminator loss: 0.6315%, acc.: 61.33%] [Generator loss: 0.8557%]\n",
            "2257 [Discriminator loss: 0.6526%, acc.: 60.16%] [Generator loss: 0.8488%]\n",
            "2258 [Discriminator loss: 0.6557%, acc.: 59.77%] [Generator loss: 0.8521%]\n",
            "2259 [Discriminator loss: 0.6525%, acc.: 59.77%] [Generator loss: 0.8564%]\n",
            "2260 [Discriminator loss: 0.6589%, acc.: 58.59%] [Generator loss: 0.8592%]\n",
            "2261 [Discriminator loss: 0.6514%, acc.: 58.59%] [Generator loss: 0.8536%]\n",
            "2262 [Discriminator loss: 0.6442%, acc.: 60.16%] [Generator loss: 0.8425%]\n",
            "2263 [Discriminator loss: 0.6430%, acc.: 61.72%] [Generator loss: 0.8624%]\n",
            "2264 [Discriminator loss: 0.6490%, acc.: 57.42%] [Generator loss: 0.8780%]\n",
            "2265 [Discriminator loss: 0.6397%, acc.: 62.11%] [Generator loss: 0.8663%]\n",
            "2266 [Discriminator loss: 0.6381%, acc.: 62.11%] [Generator loss: 0.8666%]\n",
            "2267 [Discriminator loss: 0.6456%, acc.: 62.50%] [Generator loss: 0.8610%]\n",
            "2268 [Discriminator loss: 0.6286%, acc.: 67.19%] [Generator loss: 0.8756%]\n",
            "2269 [Discriminator loss: 0.6370%, acc.: 64.45%] [Generator loss: 0.8792%]\n",
            "2270 [Discriminator loss: 0.6447%, acc.: 62.11%] [Generator loss: 0.8841%]\n",
            "2271 [Discriminator loss: 0.6536%, acc.: 59.38%] [Generator loss: 0.8854%]\n",
            "2272 [Discriminator loss: 0.6365%, acc.: 64.06%] [Generator loss: 0.8722%]\n",
            "2273 [Discriminator loss: 0.6385%, acc.: 61.72%] [Generator loss: 0.8995%]\n",
            "2274 [Discriminator loss: 0.6464%, acc.: 63.28%] [Generator loss: 0.8836%]\n",
            "2275 [Discriminator loss: 0.6397%, acc.: 62.11%] [Generator loss: 0.8749%]\n",
            "2276 [Discriminator loss: 0.6418%, acc.: 64.84%] [Generator loss: 0.8881%]\n",
            "2277 [Discriminator loss: 0.6464%, acc.: 62.11%] [Generator loss: 0.8798%]\n",
            "2278 [Discriminator loss: 0.6413%, acc.: 62.89%] [Generator loss: 0.8603%]\n",
            "2279 [Discriminator loss: 0.6340%, acc.: 66.41%] [Generator loss: 0.8761%]\n",
            "2280 [Discriminator loss: 0.6390%, acc.: 63.28%] [Generator loss: 0.8895%]\n",
            "2281 [Discriminator loss: 0.6398%, acc.: 64.45%] [Generator loss: 0.8557%]\n",
            "2282 [Discriminator loss: 0.6186%, acc.: 67.97%] [Generator loss: 0.8475%]\n",
            "2283 [Discriminator loss: 0.6455%, acc.: 63.28%] [Generator loss: 0.8555%]\n",
            "2284 [Discriminator loss: 0.6507%, acc.: 59.77%] [Generator loss: 0.8637%]\n",
            "2285 [Discriminator loss: 0.6509%, acc.: 60.16%] [Generator loss: 0.8694%]\n",
            "2286 [Discriminator loss: 0.6525%, acc.: 63.28%] [Generator loss: 0.8650%]\n",
            "2287 [Discriminator loss: 0.6509%, acc.: 57.03%] [Generator loss: 0.8665%]\n",
            "2288 [Discriminator loss: 0.6396%, acc.: 67.19%] [Generator loss: 0.8770%]\n",
            "2289 [Discriminator loss: 0.6369%, acc.: 66.41%] [Generator loss: 0.8807%]\n",
            "2290 [Discriminator loss: 0.6335%, acc.: 68.36%] [Generator loss: 0.8859%]\n",
            "2291 [Discriminator loss: 0.6538%, acc.: 64.06%] [Generator loss: 0.8854%]\n",
            "2292 [Discriminator loss: 0.6637%, acc.: 59.77%] [Generator loss: 0.8843%]\n",
            "2293 [Discriminator loss: 0.6530%, acc.: 64.45%] [Generator loss: 0.8668%]\n",
            "2294 [Discriminator loss: 0.6465%, acc.: 66.02%] [Generator loss: 0.8508%]\n",
            "2295 [Discriminator loss: 0.6421%, acc.: 66.80%] [Generator loss: 0.8784%]\n",
            "2296 [Discriminator loss: 0.6476%, acc.: 66.02%] [Generator loss: 0.8738%]\n",
            "2297 [Discriminator loss: 0.6515%, acc.: 62.50%] [Generator loss: 0.8586%]\n",
            "2298 [Discriminator loss: 0.6575%, acc.: 60.16%] [Generator loss: 0.8454%]\n",
            "2299 [Discriminator loss: 0.6456%, acc.: 60.16%] [Generator loss: 0.8884%]\n",
            "2300 [Discriminator loss: 0.6601%, acc.: 55.86%] [Generator loss: 0.8736%]\n",
            "2301 [Discriminator loss: 0.6790%, acc.: 54.30%] [Generator loss: 0.8725%]\n",
            "2302 [Discriminator loss: 0.6787%, acc.: 53.91%] [Generator loss: 0.8446%]\n",
            "2303 [Discriminator loss: 0.6538%, acc.: 57.42%] [Generator loss: 0.8547%]\n",
            "2304 [Discriminator loss: 0.6498%, acc.: 61.33%] [Generator loss: 0.8521%]\n",
            "2305 [Discriminator loss: 0.6579%, acc.: 55.47%] [Generator loss: 0.8475%]\n",
            "2306 [Discriminator loss: 0.6575%, acc.: 57.42%] [Generator loss: 0.8707%]\n",
            "2307 [Discriminator loss: 0.6556%, acc.: 60.94%] [Generator loss: 0.8585%]\n",
            "2308 [Discriminator loss: 0.6405%, acc.: 62.11%] [Generator loss: 0.8732%]\n",
            "2309 [Discriminator loss: 0.6673%, acc.: 57.03%] [Generator loss: 0.8654%]\n",
            "2310 [Discriminator loss: 0.6714%, acc.: 58.59%] [Generator loss: 0.8478%]\n",
            "2311 [Discriminator loss: 0.6678%, acc.: 55.86%] [Generator loss: 0.8554%]\n",
            "2312 [Discriminator loss: 0.6637%, acc.: 55.86%] [Generator loss: 0.8582%]\n",
            "2313 [Discriminator loss: 0.6160%, acc.: 69.92%] [Generator loss: 0.8860%]\n",
            "2314 [Discriminator loss: 0.6422%, acc.: 64.45%] [Generator loss: 0.9034%]\n",
            "2315 [Discriminator loss: 0.6340%, acc.: 65.62%] [Generator loss: 0.8994%]\n",
            "2316 [Discriminator loss: 0.6493%, acc.: 62.11%] [Generator loss: 0.8794%]\n",
            "2317 [Discriminator loss: 0.6345%, acc.: 63.67%] [Generator loss: 0.8562%]\n",
            "2318 [Discriminator loss: 0.6415%, acc.: 60.55%] [Generator loss: 0.8753%]\n",
            "2319 [Discriminator loss: 0.6424%, acc.: 58.20%] [Generator loss: 0.8621%]\n",
            "2320 [Discriminator loss: 0.6557%, acc.: 57.42%] [Generator loss: 0.8958%]\n",
            "2321 [Discriminator loss: 0.6117%, acc.: 67.19%] [Generator loss: 0.8891%]\n",
            "2322 [Discriminator loss: 0.6203%, acc.: 67.19%] [Generator loss: 0.8941%]\n",
            "2323 [Discriminator loss: 0.6404%, acc.: 57.42%] [Generator loss: 0.8669%]\n",
            "2324 [Discriminator loss: 0.6302%, acc.: 61.72%] [Generator loss: 0.8944%]\n",
            "2325 [Discriminator loss: 0.6487%, acc.: 59.38%] [Generator loss: 0.8917%]\n",
            "2326 [Discriminator loss: 0.6349%, acc.: 64.45%] [Generator loss: 0.8790%]\n",
            "2327 [Discriminator loss: 0.6348%, acc.: 60.94%] [Generator loss: 0.8896%]\n",
            "2328 [Discriminator loss: 0.6269%, acc.: 65.62%] [Generator loss: 0.8840%]\n",
            "2329 [Discriminator loss: 0.6386%, acc.: 61.33%] [Generator loss: 0.8904%]\n",
            "2330 [Discriminator loss: 0.6250%, acc.: 63.67%] [Generator loss: 0.8834%]\n",
            "2331 [Discriminator loss: 0.6330%, acc.: 62.11%] [Generator loss: 0.8852%]\n",
            "2332 [Discriminator loss: 0.6142%, acc.: 66.80%] [Generator loss: 0.8988%]\n",
            "2333 [Discriminator loss: 0.6410%, acc.: 63.67%] [Generator loss: 0.9175%]\n",
            "2334 [Discriminator loss: 0.6472%, acc.: 60.94%] [Generator loss: 0.9297%]\n",
            "2335 [Discriminator loss: 0.6298%, acc.: 63.28%] [Generator loss: 0.9165%]\n",
            "2336 [Discriminator loss: 0.6222%, acc.: 68.36%] [Generator loss: 0.9050%]\n",
            "2337 [Discriminator loss: 0.6326%, acc.: 64.84%] [Generator loss: 0.8991%]\n",
            "2338 [Discriminator loss: 0.6442%, acc.: 58.20%] [Generator loss: 0.8939%]\n",
            "2339 [Discriminator loss: 0.6204%, acc.: 61.72%] [Generator loss: 0.9141%]\n",
            "2340 [Discriminator loss: 0.6349%, acc.: 60.16%] [Generator loss: 0.9244%]\n",
            "2341 [Discriminator loss: 0.6326%, acc.: 60.94%] [Generator loss: 0.9212%]\n",
            "2342 [Discriminator loss: 0.6247%, acc.: 64.06%] [Generator loss: 0.8832%]\n",
            "2343 [Discriminator loss: 0.6477%, acc.: 58.59%] [Generator loss: 0.8940%]\n",
            "2344 [Discriminator loss: 0.6309%, acc.: 60.16%] [Generator loss: 0.9106%]\n",
            "2345 [Discriminator loss: 0.6422%, acc.: 63.28%] [Generator loss: 0.9054%]\n",
            "2346 [Discriminator loss: 0.6399%, acc.: 59.38%] [Generator loss: 0.9059%]\n",
            "2347 [Discriminator loss: 0.6756%, acc.: 53.52%] [Generator loss: 0.9017%]\n",
            "2348 [Discriminator loss: 0.6556%, acc.: 61.72%] [Generator loss: 0.8917%]\n",
            "2349 [Discriminator loss: 0.6543%, acc.: 58.20%] [Generator loss: 0.8692%]\n",
            "2350 [Discriminator loss: 0.6669%, acc.: 58.59%] [Generator loss: 0.8785%]\n",
            "2351 [Discriminator loss: 0.6761%, acc.: 53.91%] [Generator loss: 0.8669%]\n",
            "2352 [Discriminator loss: 0.6662%, acc.: 57.03%] [Generator loss: 0.8770%]\n",
            "2353 [Discriminator loss: 0.6767%, acc.: 54.30%] [Generator loss: 0.8551%]\n",
            "2354 [Discriminator loss: 0.6651%, acc.: 54.30%] [Generator loss: 0.8618%]\n",
            "2355 [Discriminator loss: 0.6783%, acc.: 52.34%] [Generator loss: 0.8658%]\n",
            "2356 [Discriminator loss: 0.6626%, acc.: 56.25%] [Generator loss: 0.8750%]\n",
            "2357 [Discriminator loss: 0.6897%, acc.: 52.73%] [Generator loss: 0.8523%]\n",
            "2358 [Discriminator loss: 0.6861%, acc.: 55.47%] [Generator loss: 0.8632%]\n",
            "2359 [Discriminator loss: 0.6760%, acc.: 55.86%] [Generator loss: 0.8545%]\n",
            "2360 [Discriminator loss: 0.6904%, acc.: 52.73%] [Generator loss: 0.8683%]\n",
            "2361 [Discriminator loss: 0.6711%, acc.: 55.86%] [Generator loss: 0.8498%]\n",
            "2362 [Discriminator loss: 0.6775%, acc.: 54.30%] [Generator loss: 0.8574%]\n",
            "2363 [Discriminator loss: 0.6942%, acc.: 48.44%] [Generator loss: 0.8464%]\n",
            "2364 [Discriminator loss: 0.6880%, acc.: 50.39%] [Generator loss: 0.8591%]\n",
            "2365 [Discriminator loss: 0.6988%, acc.: 48.83%] [Generator loss: 0.8668%]\n",
            "2366 [Discriminator loss: 0.6974%, acc.: 43.75%] [Generator loss: 0.8687%]\n",
            "2367 [Discriminator loss: 0.6807%, acc.: 51.17%] [Generator loss: 0.8756%]\n",
            "2368 [Discriminator loss: 0.6796%, acc.: 53.52%] [Generator loss: 0.8400%]\n",
            "2369 [Discriminator loss: 0.6962%, acc.: 50.00%] [Generator loss: 0.8342%]\n",
            "2370 [Discriminator loss: 0.6778%, acc.: 55.86%] [Generator loss: 0.8573%]\n",
            "2371 [Discriminator loss: 0.6870%, acc.: 55.08%] [Generator loss: 0.8556%]\n",
            "2372 [Discriminator loss: 0.6707%, acc.: 58.59%] [Generator loss: 0.8793%]\n",
            "2373 [Discriminator loss: 0.6878%, acc.: 51.17%] [Generator loss: 0.8841%]\n",
            "2374 [Discriminator loss: 0.6915%, acc.: 51.56%] [Generator loss: 0.9023%]\n",
            "2375 [Discriminator loss: 0.6692%, acc.: 55.47%] [Generator loss: 0.8632%]\n",
            "2376 [Discriminator loss: 0.6875%, acc.: 52.34%] [Generator loss: 0.8490%]\n",
            "2377 [Discriminator loss: 0.6840%, acc.: 53.91%] [Generator loss: 0.8554%]\n",
            "2378 [Discriminator loss: 0.6957%, acc.: 47.66%] [Generator loss: 0.8501%]\n",
            "2379 [Discriminator loss: 0.6763%, acc.: 59.38%] [Generator loss: 0.8605%]\n",
            "2380 [Discriminator loss: 0.6705%, acc.: 55.86%] [Generator loss: 0.8791%]\n",
            "2381 [Discriminator loss: 0.7016%, acc.: 49.61%] [Generator loss: 0.9013%]\n",
            "2382 [Discriminator loss: 0.6625%, acc.: 58.98%] [Generator loss: 0.9276%]\n",
            "2383 [Discriminator loss: 0.6749%, acc.: 59.38%] [Generator loss: 0.8917%]\n",
            "2384 [Discriminator loss: 0.6609%, acc.: 56.25%] [Generator loss: 0.8718%]\n",
            "2385 [Discriminator loss: 0.6738%, acc.: 55.86%] [Generator loss: 0.8605%]\n",
            "2386 [Discriminator loss: 0.6667%, acc.: 60.16%] [Generator loss: 0.8588%]\n",
            "2387 [Discriminator loss: 0.6476%, acc.: 63.67%] [Generator loss: 0.8707%]\n",
            "2388 [Discriminator loss: 0.6701%, acc.: 55.86%] [Generator loss: 0.8700%]\n",
            "2389 [Discriminator loss: 0.6491%, acc.: 67.58%] [Generator loss: 0.8708%]\n",
            "2390 [Discriminator loss: 0.6574%, acc.: 61.72%] [Generator loss: 0.8545%]\n",
            "2391 [Discriminator loss: 0.6531%, acc.: 62.89%] [Generator loss: 0.8425%]\n",
            "2392 [Discriminator loss: 0.6812%, acc.: 57.42%] [Generator loss: 0.8297%]\n",
            "2393 [Discriminator loss: 0.6496%, acc.: 61.33%] [Generator loss: 0.8446%]\n",
            "2394 [Discriminator loss: 0.6378%, acc.: 64.45%] [Generator loss: 0.8670%]\n",
            "2395 [Discriminator loss: 0.6458%, acc.: 66.02%] [Generator loss: 0.8575%]\n",
            "2396 [Discriminator loss: 0.6591%, acc.: 61.72%] [Generator loss: 0.8656%]\n",
            "2397 [Discriminator loss: 0.6659%, acc.: 57.03%] [Generator loss: 0.8543%]\n",
            "2398 [Discriminator loss: 0.6590%, acc.: 59.77%] [Generator loss: 0.8424%]\n",
            "2399 [Discriminator loss: 0.6682%, acc.: 51.56%] [Generator loss: 0.8469%]\n",
            "2400 [Discriminator loss: 0.6264%, acc.: 63.67%] [Generator loss: 0.8772%]\n",
            "2401 [Discriminator loss: 0.6581%, acc.: 56.64%] [Generator loss: 0.8835%]\n",
            "2402 [Discriminator loss: 0.6492%, acc.: 59.77%] [Generator loss: 0.8939%]\n",
            "2403 [Discriminator loss: 0.6404%, acc.: 64.84%] [Generator loss: 0.8877%]\n",
            "2404 [Discriminator loss: 0.6512%, acc.: 64.45%] [Generator loss: 0.8585%]\n",
            "2405 [Discriminator loss: 0.6505%, acc.: 57.42%] [Generator loss: 0.8726%]\n",
            "2406 [Discriminator loss: 0.6373%, acc.: 63.28%] [Generator loss: 0.8751%]\n",
            "2407 [Discriminator loss: 0.6413%, acc.: 63.67%] [Generator loss: 0.8689%]\n",
            "2408 [Discriminator loss: 0.6393%, acc.: 62.50%] [Generator loss: 0.8752%]\n",
            "2409 [Discriminator loss: 0.6455%, acc.: 61.33%] [Generator loss: 0.8872%]\n",
            "2410 [Discriminator loss: 0.6471%, acc.: 62.89%] [Generator loss: 0.8821%]\n",
            "2411 [Discriminator loss: 0.6631%, acc.: 57.42%] [Generator loss: 0.8898%]\n",
            "2412 [Discriminator loss: 0.6240%, acc.: 69.14%] [Generator loss: 0.8706%]\n",
            "2413 [Discriminator loss: 0.6295%, acc.: 67.19%] [Generator loss: 0.8851%]\n",
            "2414 [Discriminator loss: 0.6514%, acc.: 64.45%] [Generator loss: 0.8894%]\n",
            "2415 [Discriminator loss: 0.6394%, acc.: 65.23%] [Generator loss: 0.8786%]\n",
            "2416 [Discriminator loss: 0.6433%, acc.: 64.45%] [Generator loss: 0.8790%]\n",
            "2417 [Discriminator loss: 0.6280%, acc.: 64.84%] [Generator loss: 0.8815%]\n",
            "2418 [Discriminator loss: 0.6506%, acc.: 59.77%] [Generator loss: 0.8931%]\n",
            "2419 [Discriminator loss: 0.6516%, acc.: 60.16%] [Generator loss: 0.8798%]\n",
            "2420 [Discriminator loss: 0.6412%, acc.: 59.38%] [Generator loss: 0.8663%]\n",
            "2421 [Discriminator loss: 0.6550%, acc.: 58.59%] [Generator loss: 0.8465%]\n",
            "2422 [Discriminator loss: 0.6513%, acc.: 58.20%] [Generator loss: 0.8605%]\n",
            "2423 [Discriminator loss: 0.6571%, acc.: 61.72%] [Generator loss: 0.8878%]\n",
            "2424 [Discriminator loss: 0.6544%, acc.: 64.84%] [Generator loss: 0.8603%]\n",
            "2425 [Discriminator loss: 0.6756%, acc.: 55.08%] [Generator loss: 0.8422%]\n",
            "2426 [Discriminator loss: 0.6532%, acc.: 60.16%] [Generator loss: 0.8503%]\n",
            "2427 [Discriminator loss: 0.6453%, acc.: 69.14%] [Generator loss: 0.8513%]\n",
            "2428 [Discriminator loss: 0.6303%, acc.: 69.92%] [Generator loss: 0.8691%]\n",
            "2429 [Discriminator loss: 0.6663%, acc.: 57.81%] [Generator loss: 0.8872%]\n",
            "2430 [Discriminator loss: 0.6481%, acc.: 62.50%] [Generator loss: 0.8653%]\n",
            "2431 [Discriminator loss: 0.6444%, acc.: 63.28%] [Generator loss: 0.8737%]\n",
            "2432 [Discriminator loss: 0.6486%, acc.: 64.06%] [Generator loss: 0.8606%]\n",
            "2433 [Discriminator loss: 0.6505%, acc.: 59.77%] [Generator loss: 0.8658%]\n",
            "2434 [Discriminator loss: 0.6584%, acc.: 55.47%] [Generator loss: 0.8610%]\n",
            "2435 [Discriminator loss: 0.6484%, acc.: 58.20%] [Generator loss: 0.8588%]\n",
            "2436 [Discriminator loss: 0.6493%, acc.: 61.72%] [Generator loss: 0.8496%]\n",
            "2437 [Discriminator loss: 0.6313%, acc.: 64.84%] [Generator loss: 0.8835%]\n",
            "2438 [Discriminator loss: 0.6541%, acc.: 60.16%] [Generator loss: 0.8635%]\n",
            "2439 [Discriminator loss: 0.6532%, acc.: 60.94%] [Generator loss: 0.8769%]\n",
            "2440 [Discriminator loss: 0.6572%, acc.: 58.59%] [Generator loss: 0.8876%]\n",
            "2441 [Discriminator loss: 0.6451%, acc.: 63.67%] [Generator loss: 0.8674%]\n",
            "2442 [Discriminator loss: 0.6391%, acc.: 63.67%] [Generator loss: 0.8877%]\n",
            "2443 [Discriminator loss: 0.6413%, acc.: 61.72%] [Generator loss: 0.8861%]\n",
            "2444 [Discriminator loss: 0.6494%, acc.: 60.55%] [Generator loss: 0.8770%]\n",
            "2445 [Discriminator loss: 0.6539%, acc.: 63.28%] [Generator loss: 0.9087%]\n",
            "2446 [Discriminator loss: 0.6344%, acc.: 65.62%] [Generator loss: 0.8917%]\n",
            "2447 [Discriminator loss: 0.6403%, acc.: 64.84%] [Generator loss: 0.8873%]\n",
            "2448 [Discriminator loss: 0.6384%, acc.: 66.41%] [Generator loss: 0.8922%]\n",
            "2449 [Discriminator loss: 0.6337%, acc.: 70.31%] [Generator loss: 0.8830%]\n",
            "2450 [Discriminator loss: 0.6318%, acc.: 69.92%] [Generator loss: 0.9109%]\n",
            "2451 [Discriminator loss: 0.6186%, acc.: 70.31%] [Generator loss: 0.9059%]\n",
            "2452 [Discriminator loss: 0.6371%, acc.: 72.27%] [Generator loss: 0.8737%]\n",
            "2453 [Discriminator loss: 0.6302%, acc.: 65.23%] [Generator loss: 0.8808%]\n",
            "2454 [Discriminator loss: 0.6108%, acc.: 69.92%] [Generator loss: 0.8783%]\n",
            "2455 [Discriminator loss: 0.6319%, acc.: 67.58%] [Generator loss: 0.9064%]\n",
            "2456 [Discriminator loss: 0.6375%, acc.: 62.50%] [Generator loss: 0.8812%]\n",
            "2457 [Discriminator loss: 0.6348%, acc.: 66.41%] [Generator loss: 0.8680%]\n",
            "2458 [Discriminator loss: 0.6443%, acc.: 60.94%] [Generator loss: 0.8824%]\n",
            "2459 [Discriminator loss: 0.6369%, acc.: 66.41%] [Generator loss: 0.8772%]\n",
            "2460 [Discriminator loss: 0.6496%, acc.: 62.50%] [Generator loss: 0.8846%]\n",
            "2461 [Discriminator loss: 0.6339%, acc.: 61.33%] [Generator loss: 0.8796%]\n",
            "2462 [Discriminator loss: 0.6551%, acc.: 59.77%] [Generator loss: 0.8653%]\n",
            "2463 [Discriminator loss: 0.6759%, acc.: 53.12%] [Generator loss: 0.8679%]\n",
            "2464 [Discriminator loss: 0.6513%, acc.: 60.55%] [Generator loss: 0.8833%]\n",
            "2465 [Discriminator loss: 0.6736%, acc.: 55.47%] [Generator loss: 0.8563%]\n",
            "2466 [Discriminator loss: 0.6647%, acc.: 59.38%] [Generator loss: 0.8759%]\n",
            "2467 [Discriminator loss: 0.6481%, acc.: 62.11%] [Generator loss: 0.8797%]\n",
            "2468 [Discriminator loss: 0.6465%, acc.: 65.62%] [Generator loss: 0.8885%]\n",
            "2469 [Discriminator loss: 0.6471%, acc.: 64.06%] [Generator loss: 0.8701%]\n",
            "2470 [Discriminator loss: 0.6729%, acc.: 54.69%] [Generator loss: 0.8612%]\n",
            "2471 [Discriminator loss: 0.6825%, acc.: 54.30%] [Generator loss: 0.8556%]\n",
            "2472 [Discriminator loss: 0.6578%, acc.: 56.64%] [Generator loss: 0.8670%]\n",
            "2473 [Discriminator loss: 0.6701%, acc.: 57.03%] [Generator loss: 0.8769%]\n",
            "2474 [Discriminator loss: 0.6517%, acc.: 62.89%] [Generator loss: 0.8934%]\n",
            "2475 [Discriminator loss: 0.6717%, acc.: 59.38%] [Generator loss: 0.8923%]\n",
            "2476 [Discriminator loss: 0.6637%, acc.: 58.20%] [Generator loss: 0.8984%]\n",
            "2477 [Discriminator loss: 0.6857%, acc.: 53.91%] [Generator loss: 0.8743%]\n",
            "2478 [Discriminator loss: 0.6722%, acc.: 60.16%] [Generator loss: 0.8874%]\n",
            "2479 [Discriminator loss: 0.6415%, acc.: 67.19%] [Generator loss: 0.8947%]\n",
            "2480 [Discriminator loss: 0.6810%, acc.: 52.34%] [Generator loss: 0.8709%]\n",
            "2481 [Discriminator loss: 0.6685%, acc.: 57.03%] [Generator loss: 0.8540%]\n",
            "2482 [Discriminator loss: 0.6789%, acc.: 52.34%] [Generator loss: 0.8600%]\n",
            "2483 [Discriminator loss: 0.6745%, acc.: 55.86%] [Generator loss: 0.8773%]\n",
            "2484 [Discriminator loss: 0.6571%, acc.: 61.33%] [Generator loss: 0.8662%]\n",
            "2485 [Discriminator loss: 0.6565%, acc.: 62.11%] [Generator loss: 0.8533%]\n",
            "2486 [Discriminator loss: 0.6632%, acc.: 60.94%] [Generator loss: 0.8692%]\n",
            "2487 [Discriminator loss: 0.6746%, acc.: 54.30%] [Generator loss: 0.8773%]\n",
            "2488 [Discriminator loss: 0.6641%, acc.: 61.33%] [Generator loss: 0.8728%]\n",
            "2489 [Discriminator loss: 0.6587%, acc.: 59.77%] [Generator loss: 0.8672%]\n",
            "2490 [Discriminator loss: 0.6465%, acc.: 60.16%] [Generator loss: 0.8745%]\n",
            "2491 [Discriminator loss: 0.6720%, acc.: 57.03%] [Generator loss: 0.8707%]\n",
            "2492 [Discriminator loss: 0.6700%, acc.: 56.64%] [Generator loss: 0.8570%]\n",
            "2493 [Discriminator loss: 0.6614%, acc.: 56.64%] [Generator loss: 0.8748%]\n",
            "2494 [Discriminator loss: 0.6671%, acc.: 58.20%] [Generator loss: 0.8552%]\n",
            "2495 [Discriminator loss: 0.6536%, acc.: 62.11%] [Generator loss: 0.8614%]\n",
            "2496 [Discriminator loss: 0.6784%, acc.: 53.91%] [Generator loss: 0.8661%]\n",
            "2497 [Discriminator loss: 0.6612%, acc.: 57.42%] [Generator loss: 0.8530%]\n",
            "2498 [Discriminator loss: 0.6778%, acc.: 53.12%] [Generator loss: 0.8494%]\n",
            "2499 [Discriminator loss: 0.6511%, acc.: 60.55%] [Generator loss: 0.8798%]\n",
            "2500 [Discriminator loss: 0.6444%, acc.: 63.28%] [Generator loss: 0.8940%]\n",
            "2501 [Discriminator loss: 0.6549%, acc.: 60.94%] [Generator loss: 0.8793%]\n",
            "2502 [Discriminator loss: 0.6518%, acc.: 66.80%] [Generator loss: 0.8705%]\n",
            "2503 [Discriminator loss: 0.6576%, acc.: 66.80%] [Generator loss: 0.8667%]\n",
            "2504 [Discriminator loss: 0.6663%, acc.: 56.64%] [Generator loss: 0.8733%]\n",
            "2505 [Discriminator loss: 0.6532%, acc.: 60.16%] [Generator loss: 0.8853%]\n",
            "2506 [Discriminator loss: 0.6745%, acc.: 57.03%] [Generator loss: 0.8848%]\n",
            "2507 [Discriminator loss: 0.6402%, acc.: 67.97%] [Generator loss: 0.8739%]\n",
            "2508 [Discriminator loss: 0.6771%, acc.: 53.12%] [Generator loss: 0.8693%]\n",
            "2509 [Discriminator loss: 0.6553%, acc.: 61.72%] [Generator loss: 0.8638%]\n",
            "2510 [Discriminator loss: 0.6838%, acc.: 54.30%] [Generator loss: 0.8453%]\n",
            "2511 [Discriminator loss: 0.6697%, acc.: 60.55%] [Generator loss: 0.8622%]\n",
            "2512 [Discriminator loss: 0.6551%, acc.: 62.50%] [Generator loss: 0.8671%]\n",
            "2513 [Discriminator loss: 0.6624%, acc.: 60.16%] [Generator loss: 0.8712%]\n",
            "2514 [Discriminator loss: 0.6685%, acc.: 54.69%] [Generator loss: 0.8724%]\n",
            "2515 [Discriminator loss: 0.6725%, acc.: 57.03%] [Generator loss: 0.8517%]\n",
            "2516 [Discriminator loss: 0.6871%, acc.: 50.78%] [Generator loss: 0.8498%]\n",
            "2517 [Discriminator loss: 0.6708%, acc.: 59.38%] [Generator loss: 0.8305%]\n",
            "2518 [Discriminator loss: 0.6779%, acc.: 51.95%] [Generator loss: 0.8365%]\n",
            "2519 [Discriminator loss: 0.6496%, acc.: 58.59%] [Generator loss: 0.8660%]\n",
            "2520 [Discriminator loss: 0.6810%, acc.: 50.00%] [Generator loss: 0.8258%]\n",
            "2521 [Discriminator loss: 0.6714%, acc.: 54.69%] [Generator loss: 0.8506%]\n",
            "2522 [Discriminator loss: 0.6828%, acc.: 50.39%] [Generator loss: 0.8424%]\n",
            "2523 [Discriminator loss: 0.6834%, acc.: 51.95%] [Generator loss: 0.8246%]\n",
            "2524 [Discriminator loss: 0.6800%, acc.: 58.59%] [Generator loss: 0.8322%]\n",
            "2525 [Discriminator loss: 0.6851%, acc.: 53.12%] [Generator loss: 0.8237%]\n",
            "2526 [Discriminator loss: 0.6656%, acc.: 55.86%] [Generator loss: 0.8240%]\n",
            "2527 [Discriminator loss: 0.6813%, acc.: 53.12%] [Generator loss: 0.8353%]\n",
            "2528 [Discriminator loss: 0.6830%, acc.: 56.25%] [Generator loss: 0.8642%]\n",
            "2529 [Discriminator loss: 0.6685%, acc.: 60.16%] [Generator loss: 0.8707%]\n",
            "2530 [Discriminator loss: 0.6571%, acc.: 58.98%] [Generator loss: 0.8860%]\n",
            "2531 [Discriminator loss: 0.6444%, acc.: 65.62%] [Generator loss: 0.8898%]\n",
            "2532 [Discriminator loss: 0.6570%, acc.: 59.77%] [Generator loss: 0.8797%]\n",
            "2533 [Discriminator loss: 0.6851%, acc.: 57.03%] [Generator loss: 0.8487%]\n",
            "2534 [Discriminator loss: 0.6582%, acc.: 59.38%] [Generator loss: 0.8467%]\n",
            "2535 [Discriminator loss: 0.6491%, acc.: 60.16%] [Generator loss: 0.8673%]\n",
            "2536 [Discriminator loss: 0.6764%, acc.: 58.20%] [Generator loss: 0.8481%]\n",
            "2537 [Discriminator loss: 0.6594%, acc.: 62.89%] [Generator loss: 0.8517%]\n",
            "2538 [Discriminator loss: 0.6779%, acc.: 55.08%] [Generator loss: 0.8362%]\n",
            "2539 [Discriminator loss: 0.6618%, acc.: 60.55%] [Generator loss: 0.8526%]\n",
            "2540 [Discriminator loss: 0.6760%, acc.: 58.20%] [Generator loss: 0.8474%]\n",
            "2541 [Discriminator loss: 0.6559%, acc.: 57.81%] [Generator loss: 0.8348%]\n",
            "2542 [Discriminator loss: 0.6490%, acc.: 57.42%] [Generator loss: 0.8687%]\n",
            "2543 [Discriminator loss: 0.6480%, acc.: 62.50%] [Generator loss: 0.8818%]\n",
            "2544 [Discriminator loss: 0.6387%, acc.: 66.80%] [Generator loss: 0.8766%]\n",
            "2545 [Discriminator loss: 0.6342%, acc.: 65.62%] [Generator loss: 0.8717%]\n",
            "2546 [Discriminator loss: 0.6557%, acc.: 60.94%] [Generator loss: 0.8542%]\n",
            "2547 [Discriminator loss: 0.6446%, acc.: 61.72%] [Generator loss: 0.8517%]\n",
            "2548 [Discriminator loss: 0.6616%, acc.: 58.59%] [Generator loss: 0.8460%]\n",
            "2549 [Discriminator loss: 0.6590%, acc.: 57.42%] [Generator loss: 0.8630%]\n",
            "2550 [Discriminator loss: 0.6415%, acc.: 62.50%] [Generator loss: 0.8719%]\n",
            "2551 [Discriminator loss: 0.6469%, acc.: 62.50%] [Generator loss: 0.8792%]\n",
            "2552 [Discriminator loss: 0.6456%, acc.: 66.41%] [Generator loss: 0.8739%]\n",
            "2553 [Discriminator loss: 0.6516%, acc.: 58.98%] [Generator loss: 0.8572%]\n",
            "2554 [Discriminator loss: 0.6403%, acc.: 62.89%] [Generator loss: 0.8570%]\n",
            "2555 [Discriminator loss: 0.6481%, acc.: 62.11%] [Generator loss: 0.8766%]\n",
            "2556 [Discriminator loss: 0.6370%, acc.: 65.23%] [Generator loss: 0.8846%]\n",
            "2557 [Discriminator loss: 0.6490%, acc.: 56.64%] [Generator loss: 0.8732%]\n",
            "2558 [Discriminator loss: 0.6647%, acc.: 58.98%] [Generator loss: 0.8720%]\n",
            "2559 [Discriminator loss: 0.6643%, acc.: 57.42%] [Generator loss: 0.8619%]\n",
            "2560 [Discriminator loss: 0.6408%, acc.: 60.55%] [Generator loss: 0.8540%]\n",
            "2561 [Discriminator loss: 0.6578%, acc.: 61.72%] [Generator loss: 0.8704%]\n",
            "2562 [Discriminator loss: 0.6699%, acc.: 55.08%] [Generator loss: 0.8447%]\n",
            "2563 [Discriminator loss: 0.6567%, acc.: 58.59%] [Generator loss: 0.8579%]\n",
            "2564 [Discriminator loss: 0.6716%, acc.: 56.64%] [Generator loss: 0.8499%]\n",
            "2565 [Discriminator loss: 0.6561%, acc.: 58.98%] [Generator loss: 0.8296%]\n",
            "2566 [Discriminator loss: 0.6458%, acc.: 60.16%] [Generator loss: 0.8510%]\n",
            "2567 [Discriminator loss: 0.6645%, acc.: 55.86%] [Generator loss: 0.8581%]\n",
            "2568 [Discriminator loss: 0.6531%, acc.: 57.81%] [Generator loss: 0.8713%]\n",
            "2569 [Discriminator loss: 0.6577%, acc.: 56.25%] [Generator loss: 0.8524%]\n",
            "2570 [Discriminator loss: 0.6688%, acc.: 57.03%] [Generator loss: 0.8523%]\n",
            "2571 [Discriminator loss: 0.6627%, acc.: 55.86%] [Generator loss: 0.8502%]\n",
            "2572 [Discriminator loss: 0.6859%, acc.: 56.25%] [Generator loss: 0.8267%]\n",
            "2573 [Discriminator loss: 0.6704%, acc.: 56.25%] [Generator loss: 0.8333%]\n",
            "2574 [Discriminator loss: 0.6477%, acc.: 61.72%] [Generator loss: 0.8354%]\n",
            "2575 [Discriminator loss: 0.6659%, acc.: 52.34%] [Generator loss: 0.8309%]\n",
            "2576 [Discriminator loss: 0.6682%, acc.: 53.91%] [Generator loss: 0.8347%]\n",
            "2577 [Discriminator loss: 0.6770%, acc.: 49.61%] [Generator loss: 0.8397%]\n",
            "2578 [Discriminator loss: 0.6556%, acc.: 57.42%] [Generator loss: 0.8559%]\n",
            "2579 [Discriminator loss: 0.6718%, acc.: 56.64%] [Generator loss: 0.8345%]\n",
            "2580 [Discriminator loss: 0.6410%, acc.: 62.89%] [Generator loss: 0.8301%]\n",
            "2581 [Discriminator loss: 0.6648%, acc.: 59.77%] [Generator loss: 0.8387%]\n",
            "2582 [Discriminator loss: 0.6413%, acc.: 64.84%] [Generator loss: 0.8485%]\n",
            "2583 [Discriminator loss: 0.6499%, acc.: 62.50%] [Generator loss: 0.8462%]\n",
            "2584 [Discriminator loss: 0.6580%, acc.: 55.86%] [Generator loss: 0.8403%]\n",
            "2585 [Discriminator loss: 0.6601%, acc.: 56.64%] [Generator loss: 0.8417%]\n",
            "2586 [Discriminator loss: 0.6457%, acc.: 62.11%] [Generator loss: 0.8529%]\n",
            "2587 [Discriminator loss: 0.6489%, acc.: 62.11%] [Generator loss: 0.8565%]\n",
            "2588 [Discriminator loss: 0.6447%, acc.: 65.62%] [Generator loss: 0.8788%]\n",
            "2589 [Discriminator loss: 0.6536%, acc.: 62.89%] [Generator loss: 0.8770%]\n",
            "2590 [Discriminator loss: 0.6465%, acc.: 64.84%] [Generator loss: 0.8651%]\n",
            "2591 [Discriminator loss: 0.6566%, acc.: 58.98%] [Generator loss: 0.8587%]\n",
            "2592 [Discriminator loss: 0.6418%, acc.: 62.11%] [Generator loss: 0.8612%]\n",
            "2593 [Discriminator loss: 0.6580%, acc.: 58.20%] [Generator loss: 0.8592%]\n",
            "2594 [Discriminator loss: 0.6408%, acc.: 67.58%] [Generator loss: 0.8627%]\n",
            "2595 [Discriminator loss: 0.6548%, acc.: 61.72%] [Generator loss: 0.8606%]\n",
            "2596 [Discriminator loss: 0.6401%, acc.: 64.45%] [Generator loss: 0.8700%]\n",
            "2597 [Discriminator loss: 0.6298%, acc.: 66.80%] [Generator loss: 0.8858%]\n",
            "2598 [Discriminator loss: 0.6499%, acc.: 64.84%] [Generator loss: 0.8787%]\n",
            "2599 [Discriminator loss: 0.6253%, acc.: 66.02%] [Generator loss: 0.8822%]\n",
            "2600 [Discriminator loss: 0.6267%, acc.: 66.02%] [Generator loss: 0.8809%]\n",
            "2601 [Discriminator loss: 0.6419%, acc.: 64.84%] [Generator loss: 0.8933%]\n",
            "2602 [Discriminator loss: 0.6443%, acc.: 63.28%] [Generator loss: 0.8689%]\n",
            "2603 [Discriminator loss: 0.6570%, acc.: 59.77%] [Generator loss: 0.8546%]\n",
            "2604 [Discriminator loss: 0.6458%, acc.: 62.50%] [Generator loss: 0.8755%]\n",
            "2605 [Discriminator loss: 0.6461%, acc.: 62.50%] [Generator loss: 0.8612%]\n",
            "2606 [Discriminator loss: 0.6421%, acc.: 64.84%] [Generator loss: 0.8603%]\n",
            "2607 [Discriminator loss: 0.6267%, acc.: 71.09%] [Generator loss: 0.8843%]\n",
            "2608 [Discriminator loss: 0.6348%, acc.: 66.80%] [Generator loss: 0.8582%]\n",
            "2609 [Discriminator loss: 0.6172%, acc.: 72.27%] [Generator loss: 0.8744%]\n",
            "2610 [Discriminator loss: 0.6608%, acc.: 62.89%] [Generator loss: 0.8742%]\n",
            "2611 [Discriminator loss: 0.6416%, acc.: 67.97%] [Generator loss: 0.8791%]\n",
            "2612 [Discriminator loss: 0.6424%, acc.: 64.06%] [Generator loss: 0.8717%]\n",
            "2613 [Discriminator loss: 0.6491%, acc.: 65.23%] [Generator loss: 0.8818%]\n",
            "2614 [Discriminator loss: 0.6611%, acc.: 58.59%] [Generator loss: 0.8709%]\n",
            "2615 [Discriminator loss: 0.6455%, acc.: 65.62%] [Generator loss: 0.8525%]\n",
            "2616 [Discriminator loss: 0.6501%, acc.: 59.77%] [Generator loss: 0.8730%]\n",
            "2617 [Discriminator loss: 0.6395%, acc.: 65.23%] [Generator loss: 0.8913%]\n",
            "2618 [Discriminator loss: 0.6526%, acc.: 62.50%] [Generator loss: 0.8697%]\n",
            "2619 [Discriminator loss: 0.6437%, acc.: 61.72%] [Generator loss: 0.8611%]\n",
            "2620 [Discriminator loss: 0.6389%, acc.: 64.84%] [Generator loss: 0.8596%]\n",
            "2621 [Discriminator loss: 0.6425%, acc.: 63.28%] [Generator loss: 0.8757%]\n",
            "2622 [Discriminator loss: 0.6071%, acc.: 74.61%] [Generator loss: 0.9082%]\n",
            "2623 [Discriminator loss: 0.6344%, acc.: 69.92%] [Generator loss: 0.8734%]\n",
            "2624 [Discriminator loss: 0.6426%, acc.: 69.14%] [Generator loss: 0.8820%]\n",
            "2625 [Discriminator loss: 0.6298%, acc.: 67.58%] [Generator loss: 0.8735%]\n",
            "2626 [Discriminator loss: 0.6499%, acc.: 61.33%] [Generator loss: 0.8549%]\n",
            "2627 [Discriminator loss: 0.6301%, acc.: 67.97%] [Generator loss: 0.8871%]\n",
            "2628 [Discriminator loss: 0.6581%, acc.: 59.77%] [Generator loss: 0.8849%]\n",
            "2629 [Discriminator loss: 0.6403%, acc.: 65.62%] [Generator loss: 0.8675%]\n",
            "2630 [Discriminator loss: 0.6411%, acc.: 62.89%] [Generator loss: 0.8676%]\n",
            "2631 [Discriminator loss: 0.6463%, acc.: 63.67%] [Generator loss: 0.8656%]\n",
            "2632 [Discriminator loss: 0.6487%, acc.: 62.89%] [Generator loss: 0.8567%]\n",
            "2633 [Discriminator loss: 0.6245%, acc.: 66.02%] [Generator loss: 0.8747%]\n",
            "2634 [Discriminator loss: 0.6484%, acc.: 64.84%] [Generator loss: 0.8756%]\n",
            "2635 [Discriminator loss: 0.6307%, acc.: 65.62%] [Generator loss: 0.8631%]\n",
            "2636 [Discriminator loss: 0.6398%, acc.: 66.02%] [Generator loss: 0.8734%]\n",
            "2637 [Discriminator loss: 0.6375%, acc.: 66.41%] [Generator loss: 0.9049%]\n",
            "2638 [Discriminator loss: 0.6312%, acc.: 67.97%] [Generator loss: 0.9001%]\n",
            "2639 [Discriminator loss: 0.6515%, acc.: 62.89%] [Generator loss: 0.8650%]\n",
            "2640 [Discriminator loss: 0.6318%, acc.: 66.41%] [Generator loss: 0.8713%]\n",
            "2641 [Discriminator loss: 0.6442%, acc.: 62.50%] [Generator loss: 0.8822%]\n",
            "2642 [Discriminator loss: 0.6394%, acc.: 67.58%] [Generator loss: 0.8591%]\n",
            "2643 [Discriminator loss: 0.6287%, acc.: 62.89%] [Generator loss: 0.8674%]\n",
            "2644 [Discriminator loss: 0.6410%, acc.: 66.80%] [Generator loss: 0.8591%]\n",
            "2645 [Discriminator loss: 0.6440%, acc.: 64.84%] [Generator loss: 0.8791%]\n",
            "2646 [Discriminator loss: 0.6422%, acc.: 62.50%] [Generator loss: 0.8747%]\n",
            "2647 [Discriminator loss: 0.6507%, acc.: 62.89%] [Generator loss: 0.8723%]\n",
            "2648 [Discriminator loss: 0.6439%, acc.: 64.84%] [Generator loss: 0.8416%]\n",
            "2649 [Discriminator loss: 0.6479%, acc.: 60.94%] [Generator loss: 0.8634%]\n",
            "2650 [Discriminator loss: 0.6298%, acc.: 66.41%] [Generator loss: 0.8521%]\n",
            "2651 [Discriminator loss: 0.6487%, acc.: 61.72%] [Generator loss: 0.8720%]\n",
            "2652 [Discriminator loss: 0.6149%, acc.: 70.70%] [Generator loss: 0.8721%]\n",
            "2653 [Discriminator loss: 0.6452%, acc.: 64.45%] [Generator loss: 0.8550%]\n",
            "2654 [Discriminator loss: 0.6373%, acc.: 63.67%] [Generator loss: 0.8504%]\n",
            "2655 [Discriminator loss: 0.6418%, acc.: 62.50%] [Generator loss: 0.8830%]\n",
            "2656 [Discriminator loss: 0.6572%, acc.: 57.03%] [Generator loss: 0.8685%]\n",
            "2657 [Discriminator loss: 0.6592%, acc.: 56.25%] [Generator loss: 0.8769%]\n",
            "2658 [Discriminator loss: 0.6427%, acc.: 58.20%] [Generator loss: 0.8748%]\n",
            "2659 [Discriminator loss: 0.6407%, acc.: 58.59%] [Generator loss: 0.8683%]\n",
            "2660 [Discriminator loss: 0.6348%, acc.: 62.11%] [Generator loss: 0.8698%]\n",
            "2661 [Discriminator loss: 0.6376%, acc.: 64.06%] [Generator loss: 0.8258%]\n",
            "2662 [Discriminator loss: 0.6312%, acc.: 62.50%] [Generator loss: 0.8561%]\n",
            "2663 [Discriminator loss: 0.6548%, acc.: 57.03%] [Generator loss: 0.8541%]\n",
            "2664 [Discriminator loss: 0.6617%, acc.: 58.98%] [Generator loss: 0.8414%]\n",
            "2665 [Discriminator loss: 0.6318%, acc.: 62.50%] [Generator loss: 0.8431%]\n",
            "2666 [Discriminator loss: 0.6381%, acc.: 62.11%] [Generator loss: 0.8521%]\n",
            "2667 [Discriminator loss: 0.6505%, acc.: 58.98%] [Generator loss: 0.8758%]\n",
            "2668 [Discriminator loss: 0.6661%, acc.: 56.64%] [Generator loss: 0.8572%]\n",
            "2669 [Discriminator loss: 0.6496%, acc.: 57.42%] [Generator loss: 0.8746%]\n",
            "2670 [Discriminator loss: 0.6429%, acc.: 58.59%] [Generator loss: 0.8673%]\n",
            "2671 [Discriminator loss: 0.6402%, acc.: 56.25%] [Generator loss: 0.8712%]\n",
            "2672 [Discriminator loss: 0.6502%, acc.: 54.69%] [Generator loss: 0.8655%]\n",
            "2673 [Discriminator loss: 0.6656%, acc.: 55.08%] [Generator loss: 0.8709%]\n",
            "2674 [Discriminator loss: 0.6355%, acc.: 59.77%] [Generator loss: 0.8551%]\n",
            "2675 [Discriminator loss: 0.6532%, acc.: 55.47%] [Generator loss: 0.8491%]\n",
            "2676 [Discriminator loss: 0.6584%, acc.: 55.08%] [Generator loss: 0.8454%]\n",
            "2677 [Discriminator loss: 0.6533%, acc.: 56.25%] [Generator loss: 0.8665%]\n",
            "2678 [Discriminator loss: 0.6755%, acc.: 50.39%] [Generator loss: 0.8540%]\n",
            "2679 [Discriminator loss: 0.6792%, acc.: 51.17%] [Generator loss: 0.8742%]\n",
            "2680 [Discriminator loss: 0.6421%, acc.: 58.59%] [Generator loss: 0.9008%]\n",
            "2681 [Discriminator loss: 0.6521%, acc.: 56.25%] [Generator loss: 0.8980%]\n",
            "2682 [Discriminator loss: 0.6544%, acc.: 58.59%] [Generator loss: 0.9107%]\n",
            "2683 [Discriminator loss: 0.6495%, acc.: 59.77%] [Generator loss: 0.8971%]\n",
            "2684 [Discriminator loss: 0.6668%, acc.: 47.66%] [Generator loss: 0.9030%]\n",
            "2685 [Discriminator loss: 0.6650%, acc.: 50.78%] [Generator loss: 0.8973%]\n",
            "2686 [Discriminator loss: 0.6581%, acc.: 53.52%] [Generator loss: 0.8943%]\n",
            "2687 [Discriminator loss: 0.6494%, acc.: 56.25%] [Generator loss: 0.8868%]\n",
            "2688 [Discriminator loss: 0.6367%, acc.: 57.03%] [Generator loss: 0.8979%]\n",
            "2689 [Discriminator loss: 0.6423%, acc.: 60.55%] [Generator loss: 0.9326%]\n",
            "2690 [Discriminator loss: 0.6504%, acc.: 60.55%] [Generator loss: 0.9437%]\n",
            "2691 [Discriminator loss: 0.6374%, acc.: 59.77%] [Generator loss: 0.9061%]\n",
            "2692 [Discriminator loss: 0.6457%, acc.: 60.16%] [Generator loss: 0.9040%]\n",
            "2693 [Discriminator loss: 0.6517%, acc.: 59.38%] [Generator loss: 0.9410%]\n",
            "2694 [Discriminator loss: 0.6495%, acc.: 61.33%] [Generator loss: 0.9390%]\n",
            "2695 [Discriminator loss: 0.6028%, acc.: 69.92%] [Generator loss: 0.9366%]\n",
            "2696 [Discriminator loss: 0.6143%, acc.: 67.19%] [Generator loss: 0.9031%]\n",
            "2697 [Discriminator loss: 0.6237%, acc.: 62.11%] [Generator loss: 0.9418%]\n",
            "2698 [Discriminator loss: 0.6178%, acc.: 66.41%] [Generator loss: 0.9387%]\n",
            "2699 [Discriminator loss: 0.6280%, acc.: 65.62%] [Generator loss: 0.9367%]\n",
            "2700 [Discriminator loss: 0.6273%, acc.: 64.45%] [Generator loss: 0.9509%]\n",
            "2701 [Discriminator loss: 0.6443%, acc.: 63.28%] [Generator loss: 0.9577%]\n",
            "2702 [Discriminator loss: 0.6406%, acc.: 60.55%] [Generator loss: 0.9349%]\n",
            "2703 [Discriminator loss: 0.6293%, acc.: 64.45%] [Generator loss: 0.9341%]\n",
            "2704 [Discriminator loss: 0.6446%, acc.: 61.72%] [Generator loss: 0.9097%]\n",
            "2705 [Discriminator loss: 0.6376%, acc.: 60.55%] [Generator loss: 0.8677%]\n",
            "2706 [Discriminator loss: 0.6109%, acc.: 66.41%] [Generator loss: 0.8838%]\n",
            "2707 [Discriminator loss: 0.6390%, acc.: 57.42%] [Generator loss: 0.9198%]\n",
            "2708 [Discriminator loss: 0.6317%, acc.: 60.94%] [Generator loss: 0.8892%]\n",
            "2709 [Discriminator loss: 0.6223%, acc.: 59.77%] [Generator loss: 0.9100%]\n",
            "2710 [Discriminator loss: 0.6445%, acc.: 59.77%] [Generator loss: 0.8855%]\n",
            "2711 [Discriminator loss: 0.6528%, acc.: 61.33%] [Generator loss: 0.8742%]\n",
            "2712 [Discriminator loss: 0.6482%, acc.: 58.98%] [Generator loss: 0.8305%]\n",
            "2713 [Discriminator loss: 0.6535%, acc.: 55.08%] [Generator loss: 0.8596%]\n",
            "2714 [Discriminator loss: 0.6380%, acc.: 58.98%] [Generator loss: 0.8609%]\n",
            "2715 [Discriminator loss: 0.6552%, acc.: 56.25%] [Generator loss: 0.8409%]\n",
            "2716 [Discriminator loss: 0.6386%, acc.: 62.11%] [Generator loss: 0.8566%]\n",
            "2717 [Discriminator loss: 0.6143%, acc.: 62.89%] [Generator loss: 0.8703%]\n",
            "2718 [Discriminator loss: 0.6302%, acc.: 60.55%] [Generator loss: 0.8723%]\n",
            "2719 [Discriminator loss: 0.6399%, acc.: 59.38%] [Generator loss: 0.8742%]\n",
            "2720 [Discriminator loss: 0.6396%, acc.: 59.77%] [Generator loss: 0.8866%]\n",
            "2721 [Discriminator loss: 0.6068%, acc.: 67.58%] [Generator loss: 0.8995%]\n",
            "2722 [Discriminator loss: 0.6232%, acc.: 63.28%] [Generator loss: 0.8977%]\n",
            "2723 [Discriminator loss: 0.6216%, acc.: 67.19%] [Generator loss: 0.8772%]\n",
            "2724 [Discriminator loss: 0.6469%, acc.: 58.98%] [Generator loss: 0.8635%]\n",
            "2725 [Discriminator loss: 0.6262%, acc.: 62.11%] [Generator loss: 0.8691%]\n",
            "2726 [Discriminator loss: 0.6215%, acc.: 60.55%] [Generator loss: 0.8793%]\n",
            "2727 [Discriminator loss: 0.6266%, acc.: 61.33%] [Generator loss: 0.8778%]\n",
            "2728 [Discriminator loss: 0.6169%, acc.: 66.02%] [Generator loss: 0.8748%]\n",
            "2729 [Discriminator loss: 0.6323%, acc.: 56.64%] [Generator loss: 0.8799%]\n",
            "2730 [Discriminator loss: 0.6328%, acc.: 62.89%] [Generator loss: 0.8999%]\n",
            "2731 [Discriminator loss: 0.6133%, acc.: 64.84%] [Generator loss: 0.9014%]\n",
            "2732 [Discriminator loss: 0.6181%, acc.: 64.84%] [Generator loss: 0.9157%]\n",
            "2733 [Discriminator loss: 0.6212%, acc.: 66.80%] [Generator loss: 0.9005%]\n",
            "2734 [Discriminator loss: 0.6107%, acc.: 63.28%] [Generator loss: 0.8940%]\n",
            "2735 [Discriminator loss: 0.6195%, acc.: 61.33%] [Generator loss: 0.9263%]\n",
            "2736 [Discriminator loss: 0.6414%, acc.: 57.81%] [Generator loss: 0.9557%]\n",
            "2737 [Discriminator loss: 0.5959%, acc.: 68.36%] [Generator loss: 0.9376%]\n",
            "2738 [Discriminator loss: 0.6475%, acc.: 53.12%] [Generator loss: 0.9086%]\n",
            "2739 [Discriminator loss: 0.6549%, acc.: 57.81%] [Generator loss: 0.9213%]\n",
            "2740 [Discriminator loss: 0.6435%, acc.: 55.86%] [Generator loss: 0.9143%]\n",
            "2741 [Discriminator loss: 0.6475%, acc.: 58.59%] [Generator loss: 0.9265%]\n",
            "2742 [Discriminator loss: 0.6601%, acc.: 54.69%] [Generator loss: 0.8895%]\n",
            "2743 [Discriminator loss: 0.6377%, acc.: 57.42%] [Generator loss: 0.8967%]\n",
            "2744 [Discriminator loss: 0.6468%, acc.: 57.81%] [Generator loss: 0.8748%]\n",
            "2745 [Discriminator loss: 0.6244%, acc.: 61.72%] [Generator loss: 0.8856%]\n",
            "2746 [Discriminator loss: 0.6425%, acc.: 57.03%] [Generator loss: 0.8899%]\n",
            "2747 [Discriminator loss: 0.6464%, acc.: 61.33%] [Generator loss: 0.8749%]\n",
            "2748 [Discriminator loss: 0.6532%, acc.: 56.25%] [Generator loss: 0.8811%]\n",
            "2749 [Discriminator loss: 0.6573%, acc.: 54.30%] [Generator loss: 0.8807%]\n",
            "2750 [Discriminator loss: 0.6647%, acc.: 56.64%] [Generator loss: 0.8739%]\n",
            "2751 [Discriminator loss: 0.6748%, acc.: 50.78%] [Generator loss: 0.8700%]\n",
            "2752 [Discriminator loss: 0.6547%, acc.: 54.30%] [Generator loss: 0.8676%]\n",
            "2753 [Discriminator loss: 0.6743%, acc.: 53.91%] [Generator loss: 0.8688%]\n",
            "2754 [Discriminator loss: 0.6410%, acc.: 60.55%] [Generator loss: 0.8779%]\n",
            "2755 [Discriminator loss: 0.6814%, acc.: 50.00%] [Generator loss: 0.8831%]\n",
            "2756 [Discriminator loss: 0.6868%, acc.: 47.66%] [Generator loss: 0.8767%]\n",
            "2757 [Discriminator loss: 0.6639%, acc.: 54.69%] [Generator loss: 0.8717%]\n",
            "2758 [Discriminator loss: 0.6698%, acc.: 55.47%] [Generator loss: 0.8628%]\n",
            "2759 [Discriminator loss: 0.6690%, acc.: 54.30%] [Generator loss: 0.8689%]\n",
            "2760 [Discriminator loss: 0.6762%, acc.: 51.56%] [Generator loss: 0.8368%]\n",
            "2761 [Discriminator loss: 0.6682%, acc.: 53.91%] [Generator loss: 0.8444%]\n",
            "2762 [Discriminator loss: 0.6883%, acc.: 50.39%] [Generator loss: 0.8536%]\n",
            "2763 [Discriminator loss: 0.6764%, acc.: 51.95%] [Generator loss: 0.8771%]\n",
            "2764 [Discriminator loss: 0.6824%, acc.: 50.00%] [Generator loss: 0.8935%]\n",
            "2765 [Discriminator loss: 0.6893%, acc.: 52.34%] [Generator loss: 0.8619%]\n",
            "2766 [Discriminator loss: 0.6699%, acc.: 58.20%] [Generator loss: 0.8543%]\n",
            "2767 [Discriminator loss: 0.6889%, acc.: 51.56%] [Generator loss: 0.8748%]\n",
            "2768 [Discriminator loss: 0.6766%, acc.: 52.73%] [Generator loss: 0.8389%]\n",
            "2769 [Discriminator loss: 0.6899%, acc.: 49.61%] [Generator loss: 0.8585%]\n",
            "2770 [Discriminator loss: 0.6776%, acc.: 52.34%] [Generator loss: 0.8849%]\n",
            "2771 [Discriminator loss: 0.6707%, acc.: 60.94%] [Generator loss: 0.8801%]\n",
            "2772 [Discriminator loss: 0.6836%, acc.: 55.08%] [Generator loss: 0.8469%]\n",
            "2773 [Discriminator loss: 0.6525%, acc.: 59.77%] [Generator loss: 0.8434%]\n",
            "2774 [Discriminator loss: 0.6634%, acc.: 62.50%] [Generator loss: 0.8573%]\n",
            "2775 [Discriminator loss: 0.6723%, acc.: 57.81%] [Generator loss: 0.8560%]\n",
            "2776 [Discriminator loss: 0.6719%, acc.: 59.38%] [Generator loss: 0.8594%]\n",
            "2777 [Discriminator loss: 0.6576%, acc.: 64.45%] [Generator loss: 0.8607%]\n",
            "2778 [Discriminator loss: 0.6806%, acc.: 57.42%] [Generator loss: 0.8735%]\n",
            "2779 [Discriminator loss: 0.6618%, acc.: 59.38%] [Generator loss: 0.8793%]\n",
            "2780 [Discriminator loss: 0.6758%, acc.: 55.47%] [Generator loss: 0.8797%]\n",
            "2781 [Discriminator loss: 0.6507%, acc.: 61.72%] [Generator loss: 0.8673%]\n",
            "2782 [Discriminator loss: 0.6708%, acc.: 56.64%] [Generator loss: 0.8500%]\n",
            "2783 [Discriminator loss: 0.6538%, acc.: 59.38%] [Generator loss: 0.8648%]\n",
            "2784 [Discriminator loss: 0.6642%, acc.: 59.77%] [Generator loss: 0.8709%]\n",
            "2785 [Discriminator loss: 0.6597%, acc.: 58.98%] [Generator loss: 0.8555%]\n",
            "2786 [Discriminator loss: 0.6662%, acc.: 59.77%] [Generator loss: 0.8722%]\n",
            "2787 [Discriminator loss: 0.6476%, acc.: 65.62%] [Generator loss: 0.8751%]\n",
            "2788 [Discriminator loss: 0.6598%, acc.: 60.55%] [Generator loss: 0.8621%]\n",
            "2789 [Discriminator loss: 0.6465%, acc.: 60.94%] [Generator loss: 0.8767%]\n",
            "2790 [Discriminator loss: 0.6237%, acc.: 69.92%] [Generator loss: 0.8979%]\n",
            "2791 [Discriminator loss: 0.6478%, acc.: 63.67%] [Generator loss: 0.8762%]\n",
            "2792 [Discriminator loss: 0.6356%, acc.: 65.62%] [Generator loss: 0.8890%]\n",
            "2793 [Discriminator loss: 0.6360%, acc.: 67.19%] [Generator loss: 0.9020%]\n",
            "2794 [Discriminator loss: 0.6512%, acc.: 64.06%] [Generator loss: 0.8804%]\n",
            "2795 [Discriminator loss: 0.6577%, acc.: 60.94%] [Generator loss: 0.8544%]\n",
            "2796 [Discriminator loss: 0.6509%, acc.: 60.16%] [Generator loss: 0.8563%]\n",
            "2797 [Discriminator loss: 0.6441%, acc.: 57.81%] [Generator loss: 0.8505%]\n",
            "2798 [Discriminator loss: 0.6391%, acc.: 62.89%] [Generator loss: 0.8661%]\n",
            "2799 [Discriminator loss: 0.6429%, acc.: 60.55%] [Generator loss: 0.8706%]\n",
            "2800 [Discriminator loss: 0.6277%, acc.: 66.02%] [Generator loss: 0.8839%]\n",
            "2801 [Discriminator loss: 0.6439%, acc.: 65.23%] [Generator loss: 0.8616%]\n",
            "2802 [Discriminator loss: 0.6516%, acc.: 65.62%] [Generator loss: 0.8597%]\n",
            "2803 [Discriminator loss: 0.6353%, acc.: 62.89%] [Generator loss: 0.8734%]\n",
            "2804 [Discriminator loss: 0.6417%, acc.: 62.50%] [Generator loss: 0.8581%]\n",
            "2805 [Discriminator loss: 0.6480%, acc.: 62.50%] [Generator loss: 0.8692%]\n",
            "2806 [Discriminator loss: 0.6406%, acc.: 65.62%] [Generator loss: 0.8818%]\n",
            "2807 [Discriminator loss: 0.6398%, acc.: 65.62%] [Generator loss: 0.8688%]\n",
            "2808 [Discriminator loss: 0.6423%, acc.: 65.62%] [Generator loss: 0.8700%]\n",
            "2809 [Discriminator loss: 0.6325%, acc.: 64.45%] [Generator loss: 0.8833%]\n",
            "2810 [Discriminator loss: 0.6248%, acc.: 64.45%] [Generator loss: 0.8686%]\n",
            "2811 [Discriminator loss: 0.6281%, acc.: 64.06%] [Generator loss: 0.8706%]\n",
            "2812 [Discriminator loss: 0.6602%, acc.: 56.25%] [Generator loss: 0.8628%]\n",
            "2813 [Discriminator loss: 0.6320%, acc.: 66.02%] [Generator loss: 0.8633%]\n",
            "2814 [Discriminator loss: 0.6223%, acc.: 67.19%] [Generator loss: 0.8703%]\n",
            "2815 [Discriminator loss: 0.6222%, acc.: 68.36%] [Generator loss: 0.8867%]\n",
            "2816 [Discriminator loss: 0.6070%, acc.: 70.70%] [Generator loss: 0.9206%]\n",
            "2817 [Discriminator loss: 0.6159%, acc.: 67.97%] [Generator loss: 0.9109%]\n",
            "2818 [Discriminator loss: 0.6484%, acc.: 63.67%] [Generator loss: 0.8763%]\n",
            "2819 [Discriminator loss: 0.6117%, acc.: 71.09%] [Generator loss: 0.8965%]\n",
            "2820 [Discriminator loss: 0.6311%, acc.: 66.80%] [Generator loss: 0.9043%]\n",
            "2821 [Discriminator loss: 0.6045%, acc.: 73.05%] [Generator loss: 0.9009%]\n",
            "2822 [Discriminator loss: 0.6256%, acc.: 66.41%] [Generator loss: 0.9190%]\n",
            "2823 [Discriminator loss: 0.6160%, acc.: 69.53%] [Generator loss: 0.9224%]\n",
            "2824 [Discriminator loss: 0.6156%, acc.: 68.75%] [Generator loss: 0.9183%]\n",
            "2825 [Discriminator loss: 0.6451%, acc.: 62.89%] [Generator loss: 0.8930%]\n",
            "2826 [Discriminator loss: 0.6103%, acc.: 67.97%] [Generator loss: 0.9107%]\n",
            "2827 [Discriminator loss: 0.5984%, acc.: 71.48%] [Generator loss: 0.9303%]\n",
            "2828 [Discriminator loss: 0.6095%, acc.: 69.14%] [Generator loss: 0.9330%]\n",
            "2829 [Discriminator loss: 0.6055%, acc.: 71.88%] [Generator loss: 0.9102%]\n",
            "2830 [Discriminator loss: 0.6225%, acc.: 62.50%] [Generator loss: 0.8964%]\n",
            "2831 [Discriminator loss: 0.5909%, acc.: 70.31%] [Generator loss: 0.8919%]\n",
            "2832 [Discriminator loss: 0.6164%, acc.: 66.02%] [Generator loss: 0.8914%]\n",
            "2833 [Discriminator loss: 0.6381%, acc.: 63.28%] [Generator loss: 0.8764%]\n",
            "2834 [Discriminator loss: 0.6415%, acc.: 61.72%] [Generator loss: 0.8879%]\n",
            "2835 [Discriminator loss: 0.6249%, acc.: 66.80%] [Generator loss: 0.9184%]\n",
            "2836 [Discriminator loss: 0.6217%, acc.: 68.75%] [Generator loss: 0.8835%]\n",
            "2837 [Discriminator loss: 0.6138%, acc.: 69.92%] [Generator loss: 0.8913%]\n",
            "2838 [Discriminator loss: 0.6317%, acc.: 64.06%] [Generator loss: 0.8901%]\n",
            "2839 [Discriminator loss: 0.6310%, acc.: 62.89%] [Generator loss: 0.9054%]\n",
            "2840 [Discriminator loss: 0.6273%, acc.: 65.62%] [Generator loss: 0.8921%]\n",
            "2841 [Discriminator loss: 0.6350%, acc.: 60.94%] [Generator loss: 0.9107%]\n",
            "2842 [Discriminator loss: 0.6380%, acc.: 64.45%] [Generator loss: 0.8862%]\n",
            "2843 [Discriminator loss: 0.6568%, acc.: 57.81%] [Generator loss: 0.9025%]\n",
            "2844 [Discriminator loss: 0.6358%, acc.: 64.06%] [Generator loss: 0.9016%]\n",
            "2845 [Discriminator loss: 0.6285%, acc.: 67.97%] [Generator loss: 0.9234%]\n",
            "2846 [Discriminator loss: 0.6227%, acc.: 65.62%] [Generator loss: 0.9292%]\n",
            "2847 [Discriminator loss: 0.6329%, acc.: 66.80%] [Generator loss: 0.8990%]\n",
            "2848 [Discriminator loss: 0.6246%, acc.: 64.84%] [Generator loss: 0.9052%]\n",
            "2849 [Discriminator loss: 0.6445%, acc.: 64.45%] [Generator loss: 0.8924%]\n",
            "2850 [Discriminator loss: 0.6302%, acc.: 62.50%] [Generator loss: 0.8864%]\n",
            "2851 [Discriminator loss: 0.6488%, acc.: 63.67%] [Generator loss: 0.8799%]\n",
            "2852 [Discriminator loss: 0.6416%, acc.: 58.98%] [Generator loss: 0.8775%]\n",
            "2853 [Discriminator loss: 0.6510%, acc.: 57.81%] [Generator loss: 0.9025%]\n",
            "2854 [Discriminator loss: 0.6311%, acc.: 64.45%] [Generator loss: 0.9319%]\n",
            "2855 [Discriminator loss: 0.6540%, acc.: 58.98%] [Generator loss: 0.9241%]\n",
            "2856 [Discriminator loss: 0.6508%, acc.: 60.16%] [Generator loss: 0.8971%]\n",
            "2857 [Discriminator loss: 0.6488%, acc.: 64.45%] [Generator loss: 0.9069%]\n",
            "2858 [Discriminator loss: 0.6250%, acc.: 64.45%] [Generator loss: 0.9131%]\n",
            "2859 [Discriminator loss: 0.6316%, acc.: 67.19%] [Generator loss: 0.9145%]\n",
            "2860 [Discriminator loss: 0.6247%, acc.: 66.41%] [Generator loss: 0.9321%]\n",
            "2861 [Discriminator loss: 0.6323%, acc.: 62.50%] [Generator loss: 0.9490%]\n",
            "2862 [Discriminator loss: 0.6217%, acc.: 64.84%] [Generator loss: 0.9315%]\n",
            "2863 [Discriminator loss: 0.6137%, acc.: 64.84%] [Generator loss: 0.9221%]\n",
            "2864 [Discriminator loss: 0.6055%, acc.: 70.31%] [Generator loss: 0.9056%]\n",
            "2865 [Discriminator loss: 0.5965%, acc.: 72.66%] [Generator loss: 0.8791%]\n",
            "2866 [Discriminator loss: 0.6205%, acc.: 64.06%] [Generator loss: 0.9075%]\n",
            "2867 [Discriminator loss: 0.6160%, acc.: 68.75%] [Generator loss: 0.9245%]\n",
            "2868 [Discriminator loss: 0.6054%, acc.: 69.53%] [Generator loss: 0.9515%]\n",
            "2869 [Discriminator loss: 0.6253%, acc.: 65.23%] [Generator loss: 0.9595%]\n",
            "2870 [Discriminator loss: 0.6280%, acc.: 66.41%] [Generator loss: 0.9320%]\n",
            "2871 [Discriminator loss: 0.5892%, acc.: 75.39%] [Generator loss: 0.9230%]\n",
            "2872 [Discriminator loss: 0.5856%, acc.: 70.31%] [Generator loss: 0.9552%]\n",
            "2873 [Discriminator loss: 0.6245%, acc.: 65.23%] [Generator loss: 0.9423%]\n",
            "2874 [Discriminator loss: 0.5919%, acc.: 70.31%] [Generator loss: 0.9424%]\n",
            "2875 [Discriminator loss: 0.5946%, acc.: 69.53%] [Generator loss: 0.9675%]\n",
            "2876 [Discriminator loss: 0.6100%, acc.: 66.41%] [Generator loss: 0.9492%]\n",
            "2877 [Discriminator loss: 0.5695%, acc.: 75.00%] [Generator loss: 0.9534%]\n",
            "2878 [Discriminator loss: 0.5743%, acc.: 73.44%] [Generator loss: 0.9603%]\n",
            "2879 [Discriminator loss: 0.6043%, acc.: 72.27%] [Generator loss: 0.9482%]\n",
            "2880 [Discriminator loss: 0.5808%, acc.: 72.27%] [Generator loss: 0.9638%]\n",
            "2881 [Discriminator loss: 0.5943%, acc.: 71.88%] [Generator loss: 0.9696%]\n",
            "2882 [Discriminator loss: 0.6015%, acc.: 65.23%] [Generator loss: 0.9524%]\n",
            "2883 [Discriminator loss: 0.6190%, acc.: 67.19%] [Generator loss: 0.9519%]\n",
            "2884 [Discriminator loss: 0.5953%, acc.: 66.41%] [Generator loss: 0.9239%]\n",
            "2885 [Discriminator loss: 0.6171%, acc.: 63.28%] [Generator loss: 0.9459%]\n",
            "2886 [Discriminator loss: 0.5996%, acc.: 68.75%] [Generator loss: 0.9737%]\n",
            "2887 [Discriminator loss: 0.6202%, acc.: 65.23%] [Generator loss: 0.9777%]\n",
            "2888 [Discriminator loss: 0.6349%, acc.: 62.50%] [Generator loss: 0.9559%]\n",
            "2889 [Discriminator loss: 0.6010%, acc.: 71.09%] [Generator loss: 0.9449%]\n",
            "2890 [Discriminator loss: 0.6327%, acc.: 62.89%] [Generator loss: 0.9332%]\n",
            "2891 [Discriminator loss: 0.6282%, acc.: 66.02%] [Generator loss: 0.9298%]\n",
            "2892 [Discriminator loss: 0.6416%, acc.: 62.50%] [Generator loss: 0.9149%]\n",
            "2893 [Discriminator loss: 0.6081%, acc.: 69.14%] [Generator loss: 0.9167%]\n",
            "2894 [Discriminator loss: 0.6485%, acc.: 59.38%] [Generator loss: 0.9056%]\n",
            "2895 [Discriminator loss: 0.6167%, acc.: 65.62%] [Generator loss: 0.9075%]\n",
            "2896 [Discriminator loss: 0.6200%, acc.: 66.41%] [Generator loss: 0.9214%]\n",
            "2897 [Discriminator loss: 0.6419%, acc.: 63.28%] [Generator loss: 0.9270%]\n",
            "2898 [Discriminator loss: 0.6382%, acc.: 61.72%] [Generator loss: 0.9091%]\n",
            "2899 [Discriminator loss: 0.6294%, acc.: 67.97%] [Generator loss: 0.9031%]\n",
            "2900 [Discriminator loss: 0.6287%, acc.: 66.02%] [Generator loss: 0.8962%]\n",
            "2901 [Discriminator loss: 0.6373%, acc.: 61.72%] [Generator loss: 0.8969%]\n",
            "2902 [Discriminator loss: 0.6315%, acc.: 64.84%] [Generator loss: 0.9045%]\n",
            "2903 [Discriminator loss: 0.6306%, acc.: 63.67%] [Generator loss: 0.8823%]\n",
            "2904 [Discriminator loss: 0.6350%, acc.: 62.89%] [Generator loss: 0.8936%]\n",
            "2905 [Discriminator loss: 0.6467%, acc.: 62.50%] [Generator loss: 0.8827%]\n",
            "2906 [Discriminator loss: 0.6516%, acc.: 60.16%] [Generator loss: 0.9115%]\n",
            "2907 [Discriminator loss: 0.6232%, acc.: 67.97%] [Generator loss: 0.9156%]\n",
            "2908 [Discriminator loss: 0.6503%, acc.: 62.50%] [Generator loss: 0.8763%]\n",
            "2909 [Discriminator loss: 0.6639%, acc.: 54.69%] [Generator loss: 0.8765%]\n",
            "2910 [Discriminator loss: 0.6421%, acc.: 62.11%] [Generator loss: 0.8724%]\n",
            "2911 [Discriminator loss: 0.6575%, acc.: 61.33%] [Generator loss: 0.8658%]\n",
            "2912 [Discriminator loss: 0.6839%, acc.: 52.34%] [Generator loss: 0.8653%]\n",
            "2913 [Discriminator loss: 0.6526%, acc.: 58.20%] [Generator loss: 0.8952%]\n",
            "2914 [Discriminator loss: 0.6812%, acc.: 53.52%] [Generator loss: 0.8676%]\n",
            "2915 [Discriminator loss: 0.6740%, acc.: 56.64%] [Generator loss: 0.8743%]\n",
            "2916 [Discriminator loss: 0.6808%, acc.: 53.52%] [Generator loss: 0.8865%]\n",
            "2917 [Discriminator loss: 0.7100%, acc.: 46.88%] [Generator loss: 0.8922%]\n",
            "2918 [Discriminator loss: 0.6798%, acc.: 54.69%] [Generator loss: 0.8716%]\n",
            "2919 [Discriminator loss: 0.6561%, acc.: 58.98%] [Generator loss: 0.8832%]\n",
            "2920 [Discriminator loss: 0.7100%, acc.: 50.00%] [Generator loss: 0.8365%]\n",
            "2921 [Discriminator loss: 0.6901%, acc.: 51.17%] [Generator loss: 0.8910%]\n",
            "2922 [Discriminator loss: 0.6849%, acc.: 52.73%] [Generator loss: 0.8918%]\n",
            "2923 [Discriminator loss: 0.6869%, acc.: 50.78%] [Generator loss: 0.8739%]\n",
            "2924 [Discriminator loss: 0.6568%, acc.: 57.81%] [Generator loss: 0.8774%]\n",
            "2925 [Discriminator loss: 0.6677%, acc.: 57.03%] [Generator loss: 0.8719%]\n",
            "2926 [Discriminator loss: 0.6275%, acc.: 69.53%] [Generator loss: 0.8951%]\n",
            "2927 [Discriminator loss: 0.6754%, acc.: 60.55%] [Generator loss: 0.8933%]\n",
            "2928 [Discriminator loss: 0.6628%, acc.: 62.11%] [Generator loss: 0.8951%]\n",
            "2929 [Discriminator loss: 0.6456%, acc.: 65.23%] [Generator loss: 0.8978%]\n",
            "2930 [Discriminator loss: 0.6949%, acc.: 50.00%] [Generator loss: 0.8804%]\n",
            "2931 [Discriminator loss: 0.6808%, acc.: 51.56%] [Generator loss: 0.8734%]\n",
            "2932 [Discriminator loss: 0.6750%, acc.: 53.52%] [Generator loss: 0.8709%]\n",
            "2933 [Discriminator loss: 0.6734%, acc.: 56.64%] [Generator loss: 0.9074%]\n",
            "2934 [Discriminator loss: 0.6664%, acc.: 56.25%] [Generator loss: 0.8698%]\n",
            "2935 [Discriminator loss: 0.6725%, acc.: 55.47%] [Generator loss: 0.8904%]\n",
            "2936 [Discriminator loss: 0.6752%, acc.: 51.56%] [Generator loss: 0.9176%]\n",
            "2937 [Discriminator loss: 0.6719%, acc.: 59.77%] [Generator loss: 0.8707%]\n",
            "2938 [Discriminator loss: 0.6727%, acc.: 53.12%] [Generator loss: 0.8547%]\n",
            "2939 [Discriminator loss: 0.6534%, acc.: 60.16%] [Generator loss: 0.8545%]\n",
            "2940 [Discriminator loss: 0.6545%, acc.: 61.33%] [Generator loss: 0.8995%]\n",
            "2941 [Discriminator loss: 0.6647%, acc.: 60.16%] [Generator loss: 0.8937%]\n",
            "2942 [Discriminator loss: 0.6599%, acc.: 61.72%] [Generator loss: 0.9038%]\n",
            "2943 [Discriminator loss: 0.6486%, acc.: 62.11%] [Generator loss: 0.8735%]\n",
            "2944 [Discriminator loss: 0.6528%, acc.: 63.67%] [Generator loss: 0.8763%]\n",
            "2945 [Discriminator loss: 0.6299%, acc.: 64.84%] [Generator loss: 0.8829%]\n",
            "2946 [Discriminator loss: 0.6392%, acc.: 66.41%] [Generator loss: 0.8929%]\n",
            "2947 [Discriminator loss: 0.6484%, acc.: 63.67%] [Generator loss: 0.8970%]\n",
            "2948 [Discriminator loss: 0.6325%, acc.: 64.84%] [Generator loss: 0.8784%]\n",
            "2949 [Discriminator loss: 0.6348%, acc.: 64.84%] [Generator loss: 0.8570%]\n",
            "2950 [Discriminator loss: 0.6454%, acc.: 62.11%] [Generator loss: 0.8879%]\n",
            "2951 [Discriminator loss: 0.6253%, acc.: 67.97%] [Generator loss: 0.8727%]\n",
            "2952 [Discriminator loss: 0.6341%, acc.: 64.84%] [Generator loss: 0.8999%]\n",
            "2953 [Discriminator loss: 0.6481%, acc.: 60.94%] [Generator loss: 0.9301%]\n",
            "2954 [Discriminator loss: 0.6230%, acc.: 70.70%] [Generator loss: 0.9203%]\n",
            "2955 [Discriminator loss: 0.6486%, acc.: 64.45%] [Generator loss: 0.8950%]\n",
            "2956 [Discriminator loss: 0.6487%, acc.: 65.62%] [Generator loss: 0.8501%]\n",
            "2957 [Discriminator loss: 0.6631%, acc.: 58.98%] [Generator loss: 0.8601%]\n",
            "2958 [Discriminator loss: 0.6321%, acc.: 67.19%] [Generator loss: 0.8781%]\n",
            "2959 [Discriminator loss: 0.6791%, acc.: 48.83%] [Generator loss: 0.8504%]\n",
            "2960 [Discriminator loss: 0.6565%, acc.: 53.91%] [Generator loss: 0.8565%]\n",
            "2961 [Discriminator loss: 0.6321%, acc.: 62.11%] [Generator loss: 0.8859%]\n",
            "2962 [Discriminator loss: 0.6417%, acc.: 61.72%] [Generator loss: 0.8934%]\n",
            "2963 [Discriminator loss: 0.6449%, acc.: 58.20%] [Generator loss: 0.8638%]\n",
            "2964 [Discriminator loss: 0.6387%, acc.: 65.23%] [Generator loss: 0.8826%]\n",
            "2965 [Discriminator loss: 0.6430%, acc.: 61.33%] [Generator loss: 0.8811%]\n",
            "2966 [Discriminator loss: 0.6470%, acc.: 61.72%] [Generator loss: 0.8969%]\n",
            "2967 [Discriminator loss: 0.6696%, acc.: 51.95%] [Generator loss: 0.9033%]\n",
            "2968 [Discriminator loss: 0.6238%, acc.: 65.23%] [Generator loss: 0.9149%]\n",
            "2969 [Discriminator loss: 0.6424%, acc.: 63.28%] [Generator loss: 0.8946%]\n",
            "2970 [Discriminator loss: 0.6368%, acc.: 61.33%] [Generator loss: 0.8750%]\n",
            "2971 [Discriminator loss: 0.6477%, acc.: 59.38%] [Generator loss: 0.8917%]\n",
            "2972 [Discriminator loss: 0.6661%, acc.: 53.91%] [Generator loss: 0.8853%]\n",
            "2973 [Discriminator loss: 0.6395%, acc.: 60.94%] [Generator loss: 0.9075%]\n",
            "2974 [Discriminator loss: 0.6686%, acc.: 57.42%] [Generator loss: 0.8785%]\n",
            "2975 [Discriminator loss: 0.6558%, acc.: 58.59%] [Generator loss: 0.8703%]\n",
            "2976 [Discriminator loss: 0.6548%, acc.: 56.64%] [Generator loss: 0.8603%]\n",
            "2977 [Discriminator loss: 0.6544%, acc.: 57.03%] [Generator loss: 0.8589%]\n",
            "2978 [Discriminator loss: 0.6516%, acc.: 51.95%] [Generator loss: 0.8690%]\n",
            "2979 [Discriminator loss: 0.6285%, acc.: 60.94%] [Generator loss: 0.8874%]\n",
            "2980 [Discriminator loss: 0.6642%, acc.: 58.59%] [Generator loss: 0.8914%]\n",
            "2981 [Discriminator loss: 0.6423%, acc.: 62.11%] [Generator loss: 0.8915%]\n",
            "2982 [Discriminator loss: 0.6295%, acc.: 63.28%] [Generator loss: 0.8812%]\n",
            "2983 [Discriminator loss: 0.6568%, acc.: 53.12%] [Generator loss: 0.9065%]\n",
            "2984 [Discriminator loss: 0.6735%, acc.: 54.69%] [Generator loss: 0.8903%]\n",
            "2985 [Discriminator loss: 0.6505%, acc.: 52.34%] [Generator loss: 0.8802%]\n",
            "2986 [Discriminator loss: 0.6679%, acc.: 54.30%] [Generator loss: 0.8782%]\n",
            "2987 [Discriminator loss: 0.6371%, acc.: 60.16%] [Generator loss: 0.8838%]\n",
            "2988 [Discriminator loss: 0.6524%, acc.: 55.47%] [Generator loss: 0.9111%]\n",
            "2989 [Discriminator loss: 0.6416%, acc.: 60.16%] [Generator loss: 0.8855%]\n",
            "2990 [Discriminator loss: 0.6710%, acc.: 50.78%] [Generator loss: 0.8905%]\n",
            "2991 [Discriminator loss: 0.6721%, acc.: 52.73%] [Generator loss: 0.8892%]\n",
            "2992 [Discriminator loss: 0.6589%, acc.: 54.30%] [Generator loss: 0.8908%]\n",
            "2993 [Discriminator loss: 0.6495%, acc.: 54.30%] [Generator loss: 0.8953%]\n",
            "2994 [Discriminator loss: 0.6335%, acc.: 56.64%] [Generator loss: 0.8934%]\n",
            "2995 [Discriminator loss: 0.6207%, acc.: 64.06%] [Generator loss: 0.9172%]\n",
            "2996 [Discriminator loss: 0.6748%, acc.: 53.91%] [Generator loss: 0.8709%]\n",
            "2997 [Discriminator loss: 0.6631%, acc.: 51.56%] [Generator loss: 0.8712%]\n",
            "2998 [Discriminator loss: 0.6664%, acc.: 52.73%] [Generator loss: 0.8649%]\n",
            "2999 [Discriminator loss: 0.6468%, acc.: 57.42%] [Generator loss: 0.8719%]\n",
            "3000 [Discriminator loss: 0.6400%, acc.: 63.28%] [Generator loss: 0.9075%]\n",
            "3001 [Discriminator loss: 0.6640%, acc.: 55.08%] [Generator loss: 0.8979%]\n",
            "3002 [Discriminator loss: 0.6452%, acc.: 57.81%] [Generator loss: 0.9090%]\n",
            "3003 [Discriminator loss: 0.6521%, acc.: 54.69%] [Generator loss: 0.8909%]\n",
            "3004 [Discriminator loss: 0.6615%, acc.: 57.03%] [Generator loss: 0.8953%]\n",
            "3005 [Discriminator loss: 0.6137%, acc.: 65.62%] [Generator loss: 0.8981%]\n",
            "3006 [Discriminator loss: 0.6436%, acc.: 61.72%] [Generator loss: 0.8853%]\n",
            "3007 [Discriminator loss: 0.6499%, acc.: 59.77%] [Generator loss: 0.9027%]\n",
            "3008 [Discriminator loss: 0.6294%, acc.: 63.67%] [Generator loss: 0.9065%]\n",
            "3009 [Discriminator loss: 0.6211%, acc.: 64.84%] [Generator loss: 0.9177%]\n",
            "3010 [Discriminator loss: 0.6798%, acc.: 51.17%] [Generator loss: 0.9104%]\n",
            "3011 [Discriminator loss: 0.6521%, acc.: 59.77%] [Generator loss: 0.9152%]\n",
            "3012 [Discriminator loss: 0.6536%, acc.: 59.77%] [Generator loss: 0.8935%]\n",
            "3013 [Discriminator loss: 0.6623%, acc.: 57.42%] [Generator loss: 0.8878%]\n",
            "3014 [Discriminator loss: 0.6629%, acc.: 58.20%] [Generator loss: 0.8904%]\n",
            "3015 [Discriminator loss: 0.6582%, acc.: 58.98%] [Generator loss: 0.8723%]\n",
            "3016 [Discriminator loss: 0.6636%, acc.: 54.30%] [Generator loss: 0.8687%]\n",
            "3017 [Discriminator loss: 0.6482%, acc.: 60.55%] [Generator loss: 0.8699%]\n",
            "3018 [Discriminator loss: 0.6505%, acc.: 60.94%] [Generator loss: 0.8683%]\n",
            "3019 [Discriminator loss: 0.6541%, acc.: 59.77%] [Generator loss: 0.8342%]\n",
            "3020 [Discriminator loss: 0.6531%, acc.: 62.50%] [Generator loss: 0.8551%]\n",
            "3021 [Discriminator loss: 0.6644%, acc.: 57.42%] [Generator loss: 0.8478%]\n",
            "3022 [Discriminator loss: 0.6554%, acc.: 57.81%] [Generator loss: 0.8763%]\n",
            "3023 [Discriminator loss: 0.6631%, acc.: 62.89%] [Generator loss: 0.8836%]\n",
            "3024 [Discriminator loss: 0.6662%, acc.: 60.94%] [Generator loss: 0.8676%]\n",
            "3025 [Discriminator loss: 0.6876%, acc.: 53.52%] [Generator loss: 0.8568%]\n",
            "3026 [Discriminator loss: 0.6756%, acc.: 55.08%] [Generator loss: 0.8442%]\n",
            "3027 [Discriminator loss: 0.6812%, acc.: 57.03%] [Generator loss: 0.8646%]\n",
            "3028 [Discriminator loss: 0.6822%, acc.: 53.52%] [Generator loss: 0.8311%]\n",
            "3029 [Discriminator loss: 0.6765%, acc.: 53.91%] [Generator loss: 0.8321%]\n",
            "3030 [Discriminator loss: 0.6874%, acc.: 55.47%] [Generator loss: 0.8360%]\n",
            "3031 [Discriminator loss: 0.6846%, acc.: 52.73%] [Generator loss: 0.8382%]\n",
            "3032 [Discriminator loss: 0.6650%, acc.: 55.08%] [Generator loss: 0.8857%]\n",
            "3033 [Discriminator loss: 0.6833%, acc.: 55.47%] [Generator loss: 0.8295%]\n",
            "3034 [Discriminator loss: 0.6845%, acc.: 53.12%] [Generator loss: 0.8381%]\n",
            "3035 [Discriminator loss: 0.6680%, acc.: 56.64%] [Generator loss: 0.8329%]\n",
            "3036 [Discriminator loss: 0.6789%, acc.: 50.78%] [Generator loss: 0.8597%]\n",
            "3037 [Discriminator loss: 0.6649%, acc.: 57.42%] [Generator loss: 0.8577%]\n",
            "3038 [Discriminator loss: 0.6598%, acc.: 57.03%] [Generator loss: 0.8930%]\n",
            "3039 [Discriminator loss: 0.6795%, acc.: 56.25%] [Generator loss: 0.8776%]\n",
            "3040 [Discriminator loss: 0.6520%, acc.: 60.94%] [Generator loss: 0.8611%]\n",
            "3041 [Discriminator loss: 0.6468%, acc.: 62.50%] [Generator loss: 0.8654%]\n",
            "3042 [Discriminator loss: 0.6737%, acc.: 60.16%] [Generator loss: 0.8565%]\n",
            "3043 [Discriminator loss: 0.6597%, acc.: 60.16%] [Generator loss: 0.8659%]\n",
            "3044 [Discriminator loss: 0.6571%, acc.: 62.89%] [Generator loss: 0.8846%]\n",
            "3045 [Discriminator loss: 0.6679%, acc.: 60.94%] [Generator loss: 0.8665%]\n",
            "3046 [Discriminator loss: 0.6626%, acc.: 59.38%] [Generator loss: 0.8767%]\n",
            "3047 [Discriminator loss: 0.6499%, acc.: 60.94%] [Generator loss: 0.8516%]\n",
            "3048 [Discriminator loss: 0.6489%, acc.: 60.94%] [Generator loss: 0.8713%]\n",
            "3049 [Discriminator loss: 0.6789%, acc.: 54.69%] [Generator loss: 0.8726%]\n",
            "3050 [Discriminator loss: 0.6466%, acc.: 60.16%] [Generator loss: 0.8689%]\n",
            "3051 [Discriminator loss: 0.6680%, acc.: 56.64%] [Generator loss: 0.8520%]\n",
            "3052 [Discriminator loss: 0.6425%, acc.: 61.33%] [Generator loss: 0.8718%]\n",
            "3053 [Discriminator loss: 0.6284%, acc.: 67.58%] [Generator loss: 0.8723%]\n",
            "3054 [Discriminator loss: 0.6406%, acc.: 62.11%] [Generator loss: 0.8551%]\n",
            "3055 [Discriminator loss: 0.6949%, acc.: 49.22%] [Generator loss: 0.8616%]\n",
            "3056 [Discriminator loss: 0.6453%, acc.: 61.33%] [Generator loss: 0.8660%]\n",
            "3057 [Discriminator loss: 0.6644%, acc.: 60.94%] [Generator loss: 0.8597%]\n",
            "3058 [Discriminator loss: 0.6693%, acc.: 55.47%] [Generator loss: 0.8571%]\n",
            "3059 [Discriminator loss: 0.6739%, acc.: 54.69%] [Generator loss: 0.8637%]\n",
            "3060 [Discriminator loss: 0.6569%, acc.: 57.42%] [Generator loss: 0.8658%]\n",
            "3061 [Discriminator loss: 0.6506%, acc.: 61.33%] [Generator loss: 0.8512%]\n",
            "3062 [Discriminator loss: 0.6587%, acc.: 58.59%] [Generator loss: 0.8566%]\n",
            "3063 [Discriminator loss: 0.6370%, acc.: 64.84%] [Generator loss: 0.8301%]\n",
            "3064 [Discriminator loss: 0.6552%, acc.: 58.98%] [Generator loss: 0.8524%]\n",
            "3065 [Discriminator loss: 0.6583%, acc.: 59.77%] [Generator loss: 0.8509%]\n",
            "3066 [Discriminator loss: 0.6700%, acc.: 56.64%] [Generator loss: 0.8454%]\n",
            "3067 [Discriminator loss: 0.6599%, acc.: 56.25%] [Generator loss: 0.8156%]\n",
            "3068 [Discriminator loss: 0.6472%, acc.: 61.72%] [Generator loss: 0.8625%]\n",
            "3069 [Discriminator loss: 0.6779%, acc.: 51.95%] [Generator loss: 0.8520%]\n",
            "3070 [Discriminator loss: 0.6654%, acc.: 57.03%] [Generator loss: 0.8333%]\n",
            "3071 [Discriminator loss: 0.6669%, acc.: 57.81%] [Generator loss: 0.8549%]\n",
            "3072 [Discriminator loss: 0.6441%, acc.: 63.67%] [Generator loss: 0.8761%]\n",
            "3073 [Discriminator loss: 0.6461%, acc.: 58.98%] [Generator loss: 0.8971%]\n",
            "3074 [Discriminator loss: 0.6571%, acc.: 57.42%] [Generator loss: 0.8793%]\n",
            "3075 [Discriminator loss: 0.6569%, acc.: 61.72%] [Generator loss: 0.8686%]\n",
            "3076 [Discriminator loss: 0.6774%, acc.: 58.98%] [Generator loss: 0.8738%]\n",
            "3077 [Discriminator loss: 0.6481%, acc.: 59.38%] [Generator loss: 0.8583%]\n",
            "3078 [Discriminator loss: 0.6359%, acc.: 63.67%] [Generator loss: 0.8720%]\n",
            "3079 [Discriminator loss: 0.6425%, acc.: 62.50%] [Generator loss: 0.8836%]\n",
            "3080 [Discriminator loss: 0.6249%, acc.: 67.58%] [Generator loss: 0.8941%]\n",
            "3081 [Discriminator loss: 0.6489%, acc.: 58.20%] [Generator loss: 0.8728%]\n",
            "3082 [Discriminator loss: 0.6571%, acc.: 59.77%] [Generator loss: 0.8631%]\n",
            "3083 [Discriminator loss: 0.6487%, acc.: 60.55%] [Generator loss: 0.8572%]\n",
            "3084 [Discriminator loss: 0.6437%, acc.: 60.16%] [Generator loss: 0.8477%]\n",
            "3085 [Discriminator loss: 0.6639%, acc.: 51.17%] [Generator loss: 0.8755%]\n",
            "3086 [Discriminator loss: 0.6433%, acc.: 65.23%] [Generator loss: 0.8742%]\n",
            "3087 [Discriminator loss: 0.6351%, acc.: 62.11%] [Generator loss: 0.8685%]\n",
            "3088 [Discriminator loss: 0.6532%, acc.: 56.25%] [Generator loss: 0.8615%]\n",
            "3089 [Discriminator loss: 0.6558%, acc.: 59.38%] [Generator loss: 0.8636%]\n",
            "3090 [Discriminator loss: 0.6627%, acc.: 55.47%] [Generator loss: 0.8477%]\n",
            "3091 [Discriminator loss: 0.6570%, acc.: 54.69%] [Generator loss: 0.8461%]\n",
            "3092 [Discriminator loss: 0.6457%, acc.: 64.45%] [Generator loss: 0.8484%]\n",
            "3093 [Discriminator loss: 0.6525%, acc.: 61.33%] [Generator loss: 0.8683%]\n",
            "3094 [Discriminator loss: 0.6598%, acc.: 60.55%] [Generator loss: 0.8999%]\n",
            "3095 [Discriminator loss: 0.6434%, acc.: 64.06%] [Generator loss: 0.8771%]\n",
            "3096 [Discriminator loss: 0.6430%, acc.: 64.06%] [Generator loss: 0.8910%]\n",
            "3097 [Discriminator loss: 0.6422%, acc.: 67.19%] [Generator loss: 0.9032%]\n",
            "3098 [Discriminator loss: 0.6521%, acc.: 63.28%] [Generator loss: 0.8824%]\n",
            "3099 [Discriminator loss: 0.6369%, acc.: 64.06%] [Generator loss: 0.9253%]\n",
            "3100 [Discriminator loss: 0.6804%, acc.: 60.16%] [Generator loss: 0.9047%]\n",
            "3101 [Discriminator loss: 0.6383%, acc.: 67.58%] [Generator loss: 0.9008%]\n",
            "3102 [Discriminator loss: 0.6546%, acc.: 61.72%] [Generator loss: 0.8830%]\n",
            "3103 [Discriminator loss: 0.6358%, acc.: 62.11%] [Generator loss: 0.8745%]\n",
            "3104 [Discriminator loss: 0.6541%, acc.: 61.33%] [Generator loss: 0.8359%]\n",
            "3105 [Discriminator loss: 0.6525%, acc.: 59.38%] [Generator loss: 0.8533%]\n",
            "3106 [Discriminator loss: 0.6464%, acc.: 60.55%] [Generator loss: 0.8764%]\n",
            "3107 [Discriminator loss: 0.6325%, acc.: 64.06%] [Generator loss: 0.8874%]\n",
            "3108 [Discriminator loss: 0.6625%, acc.: 60.16%] [Generator loss: 0.8739%]\n",
            "3109 [Discriminator loss: 0.6669%, acc.: 58.59%] [Generator loss: 0.8616%]\n",
            "3110 [Discriminator loss: 0.6606%, acc.: 60.55%] [Generator loss: 0.8803%]\n",
            "3111 [Discriminator loss: 0.6700%, acc.: 56.64%] [Generator loss: 0.8737%]\n",
            "3112 [Discriminator loss: 0.6648%, acc.: 57.81%] [Generator loss: 0.8690%]\n",
            "3113 [Discriminator loss: 0.6825%, acc.: 55.86%] [Generator loss: 0.8670%]\n",
            "3114 [Discriminator loss: 0.6583%, acc.: 59.77%] [Generator loss: 0.8840%]\n",
            "3115 [Discriminator loss: 0.6690%, acc.: 59.38%] [Generator loss: 0.8694%]\n",
            "3116 [Discriminator loss: 0.6503%, acc.: 60.55%] [Generator loss: 0.8775%]\n",
            "3117 [Discriminator loss: 0.6560%, acc.: 58.98%] [Generator loss: 0.8742%]\n",
            "3118 [Discriminator loss: 0.6496%, acc.: 62.11%] [Generator loss: 0.8638%]\n",
            "3119 [Discriminator loss: 0.6665%, acc.: 52.34%] [Generator loss: 0.8613%]\n",
            "3120 [Discriminator loss: 0.6583%, acc.: 60.94%] [Generator loss: 0.8592%]\n",
            "3121 [Discriminator loss: 0.6662%, acc.: 60.16%] [Generator loss: 0.8609%]\n",
            "3122 [Discriminator loss: 0.6560%, acc.: 59.38%] [Generator loss: 0.8573%]\n",
            "3123 [Discriminator loss: 0.6471%, acc.: 64.45%] [Generator loss: 0.8828%]\n",
            "3124 [Discriminator loss: 0.6603%, acc.: 59.77%] [Generator loss: 0.9000%]\n",
            "3125 [Discriminator loss: 0.6426%, acc.: 60.55%] [Generator loss: 0.8809%]\n",
            "3126 [Discriminator loss: 0.6510%, acc.: 59.77%] [Generator loss: 0.8756%]\n",
            "3127 [Discriminator loss: 0.6607%, acc.: 54.30%] [Generator loss: 0.8753%]\n",
            "3128 [Discriminator loss: 0.6499%, acc.: 61.33%] [Generator loss: 0.8680%]\n",
            "3129 [Discriminator loss: 0.6569%, acc.: 57.42%] [Generator loss: 0.8662%]\n",
            "3130 [Discriminator loss: 0.6509%, acc.: 59.77%] [Generator loss: 0.8567%]\n",
            "3131 [Discriminator loss: 0.6589%, acc.: 61.72%] [Generator loss: 0.8477%]\n",
            "3132 [Discriminator loss: 0.6385%, acc.: 59.77%] [Generator loss: 0.8506%]\n",
            "3133 [Discriminator loss: 0.6629%, acc.: 56.64%] [Generator loss: 0.8559%]\n",
            "3134 [Discriminator loss: 0.6587%, acc.: 60.55%] [Generator loss: 0.8632%]\n",
            "3135 [Discriminator loss: 0.6469%, acc.: 62.50%] [Generator loss: 0.8766%]\n",
            "3136 [Discriminator loss: 0.6640%, acc.: 57.81%] [Generator loss: 0.8766%]\n",
            "3137 [Discriminator loss: 0.6522%, acc.: 62.11%] [Generator loss: 0.8977%]\n",
            "3138 [Discriminator loss: 0.6709%, acc.: 57.42%] [Generator loss: 0.8584%]\n",
            "3139 [Discriminator loss: 0.6415%, acc.: 61.33%] [Generator loss: 0.8720%]\n",
            "3140 [Discriminator loss: 0.6387%, acc.: 65.62%] [Generator loss: 0.8759%]\n",
            "3141 [Discriminator loss: 0.6363%, acc.: 66.02%] [Generator loss: 0.8916%]\n",
            "3142 [Discriminator loss: 0.6366%, acc.: 67.97%] [Generator loss: 0.8857%]\n",
            "3143 [Discriminator loss: 0.6484%, acc.: 63.67%] [Generator loss: 0.8717%]\n",
            "3144 [Discriminator loss: 0.6290%, acc.: 66.80%] [Generator loss: 0.8467%]\n",
            "3145 [Discriminator loss: 0.6458%, acc.: 62.50%] [Generator loss: 0.8594%]\n",
            "3146 [Discriminator loss: 0.6494%, acc.: 62.89%] [Generator loss: 0.8828%]\n",
            "3147 [Discriminator loss: 0.6623%, acc.: 60.94%] [Generator loss: 0.8767%]\n",
            "3148 [Discriminator loss: 0.6528%, acc.: 59.38%] [Generator loss: 0.8525%]\n",
            "3149 [Discriminator loss: 0.6451%, acc.: 59.77%] [Generator loss: 0.8919%]\n",
            "3150 [Discriminator loss: 0.6596%, acc.: 58.59%] [Generator loss: 0.8827%]\n",
            "3151 [Discriminator loss: 0.6425%, acc.: 64.84%] [Generator loss: 0.8643%]\n",
            "3152 [Discriminator loss: 0.6767%, acc.: 55.86%] [Generator loss: 0.8446%]\n",
            "3153 [Discriminator loss: 0.6504%, acc.: 61.33%] [Generator loss: 0.8365%]\n",
            "3154 [Discriminator loss: 0.6633%, acc.: 52.73%] [Generator loss: 0.8490%]\n",
            "3155 [Discriminator loss: 0.6489%, acc.: 62.11%] [Generator loss: 0.8353%]\n",
            "3156 [Discriminator loss: 0.6601%, acc.: 56.25%] [Generator loss: 0.8661%]\n",
            "3157 [Discriminator loss: 0.6647%, acc.: 55.86%] [Generator loss: 0.8384%]\n",
            "3158 [Discriminator loss: 0.6495%, acc.: 62.11%] [Generator loss: 0.8562%]\n",
            "3159 [Discriminator loss: 0.6720%, acc.: 55.86%] [Generator loss: 0.8566%]\n",
            "3160 [Discriminator loss: 0.6514%, acc.: 57.81%] [Generator loss: 0.8524%]\n",
            "3161 [Discriminator loss: 0.6515%, acc.: 58.59%] [Generator loss: 0.8622%]\n",
            "3162 [Discriminator loss: 0.6497%, acc.: 64.84%] [Generator loss: 0.8701%]\n",
            "3163 [Discriminator loss: 0.6497%, acc.: 61.33%] [Generator loss: 0.8795%]\n",
            "3164 [Discriminator loss: 0.6504%, acc.: 60.16%] [Generator loss: 0.8717%]\n",
            "3165 [Discriminator loss: 0.6495%, acc.: 58.59%] [Generator loss: 0.8832%]\n",
            "3166 [Discriminator loss: 0.6443%, acc.: 63.28%] [Generator loss: 0.8764%]\n",
            "3167 [Discriminator loss: 0.6543%, acc.: 54.69%] [Generator loss: 0.8563%]\n",
            "3168 [Discriminator loss: 0.6525%, acc.: 56.64%] [Generator loss: 0.8626%]\n",
            "3169 [Discriminator loss: 0.6490%, acc.: 62.11%] [Generator loss: 0.8506%]\n",
            "3170 [Discriminator loss: 0.6441%, acc.: 58.59%] [Generator loss: 0.8771%]\n",
            "3171 [Discriminator loss: 0.6622%, acc.: 57.81%] [Generator loss: 0.8596%]\n",
            "3172 [Discriminator loss: 0.6505%, acc.: 59.38%] [Generator loss: 0.8669%]\n",
            "3173 [Discriminator loss: 0.6096%, acc.: 71.48%] [Generator loss: 0.8796%]\n",
            "3174 [Discriminator loss: 0.6441%, acc.: 66.41%] [Generator loss: 0.8791%]\n",
            "3175 [Discriminator loss: 0.6095%, acc.: 72.66%] [Generator loss: 0.9062%]\n",
            "3176 [Discriminator loss: 0.6515%, acc.: 63.67%] [Generator loss: 0.8955%]\n",
            "3177 [Discriminator loss: 0.6408%, acc.: 64.45%] [Generator loss: 0.8999%]\n",
            "3178 [Discriminator loss: 0.6471%, acc.: 60.55%] [Generator loss: 0.8782%]\n",
            "3179 [Discriminator loss: 0.6602%, acc.: 58.59%] [Generator loss: 0.8729%]\n",
            "3180 [Discriminator loss: 0.6347%, acc.: 60.55%] [Generator loss: 0.8854%]\n",
            "3181 [Discriminator loss: 0.6197%, acc.: 66.41%] [Generator loss: 0.9208%]\n",
            "3182 [Discriminator loss: 0.6241%, acc.: 68.36%] [Generator loss: 0.9126%]\n",
            "3183 [Discriminator loss: 0.6395%, acc.: 61.72%] [Generator loss: 0.8846%]\n",
            "3184 [Discriminator loss: 0.6714%, acc.: 50.39%] [Generator loss: 0.8819%]\n",
            "3185 [Discriminator loss: 0.6549%, acc.: 54.69%] [Generator loss: 0.8866%]\n",
            "3186 [Discriminator loss: 0.6371%, acc.: 62.11%] [Generator loss: 0.8757%]\n",
            "3187 [Discriminator loss: 0.6467%, acc.: 55.86%] [Generator loss: 0.8846%]\n",
            "3188 [Discriminator loss: 0.6409%, acc.: 62.89%] [Generator loss: 0.9092%]\n",
            "3189 [Discriminator loss: 0.6484%, acc.: 60.94%] [Generator loss: 0.9077%]\n",
            "3190 [Discriminator loss: 0.6550%, acc.: 60.16%] [Generator loss: 0.8798%]\n",
            "3191 [Discriminator loss: 0.6706%, acc.: 57.42%] [Generator loss: 0.8689%]\n",
            "3192 [Discriminator loss: 0.6434%, acc.: 55.47%] [Generator loss: 0.8637%]\n",
            "3193 [Discriminator loss: 0.6428%, acc.: 58.59%] [Generator loss: 0.8571%]\n",
            "3194 [Discriminator loss: 0.6305%, acc.: 61.33%] [Generator loss: 0.8714%]\n",
            "3195 [Discriminator loss: 0.6689%, acc.: 54.30%] [Generator loss: 0.8787%]\n",
            "3196 [Discriminator loss: 0.6734%, acc.: 53.91%] [Generator loss: 0.8754%]\n",
            "3197 [Discriminator loss: 0.6463%, acc.: 61.72%] [Generator loss: 0.8534%]\n",
            "3198 [Discriminator loss: 0.6403%, acc.: 57.03%] [Generator loss: 0.8663%]\n",
            "3199 [Discriminator loss: 0.6465%, acc.: 59.77%] [Generator loss: 0.8838%]\n",
            "3200 [Discriminator loss: 0.6630%, acc.: 55.08%] [Generator loss: 0.8567%]\n",
            "3201 [Discriminator loss: 0.6244%, acc.: 60.55%] [Generator loss: 0.8876%]\n",
            "3202 [Discriminator loss: 0.6418%, acc.: 58.59%] [Generator loss: 0.8726%]\n",
            "3203 [Discriminator loss: 0.6359%, acc.: 58.20%] [Generator loss: 0.8931%]\n",
            "3204 [Discriminator loss: 0.6556%, acc.: 58.59%] [Generator loss: 0.8547%]\n",
            "3205 [Discriminator loss: 0.6433%, acc.: 59.77%] [Generator loss: 0.8496%]\n",
            "3206 [Discriminator loss: 0.6533%, acc.: 50.39%] [Generator loss: 0.8356%]\n",
            "3207 [Discriminator loss: 0.6386%, acc.: 58.20%] [Generator loss: 0.8562%]\n",
            "3208 [Discriminator loss: 0.6287%, acc.: 59.77%] [Generator loss: 0.8828%]\n",
            "3209 [Discriminator loss: 0.6288%, acc.: 61.72%] [Generator loss: 0.9152%]\n",
            "3210 [Discriminator loss: 0.6268%, acc.: 61.33%] [Generator loss: 0.9234%]\n",
            "3211 [Discriminator loss: 0.6360%, acc.: 59.38%] [Generator loss: 0.8865%]\n",
            "3212 [Discriminator loss: 0.6310%, acc.: 62.50%] [Generator loss: 0.8819%]\n",
            "3213 [Discriminator loss: 0.6421%, acc.: 59.77%] [Generator loss: 0.8771%]\n",
            "3214 [Discriminator loss: 0.6361%, acc.: 59.38%] [Generator loss: 0.8845%]\n",
            "3215 [Discriminator loss: 0.6265%, acc.: 63.67%] [Generator loss: 0.9088%]\n",
            "3216 [Discriminator loss: 0.6408%, acc.: 62.50%] [Generator loss: 0.8965%]\n",
            "3217 [Discriminator loss: 0.6888%, acc.: 48.44%] [Generator loss: 0.8838%]\n",
            "3218 [Discriminator loss: 0.6795%, acc.: 53.12%] [Generator loss: 0.9118%]\n",
            "3219 [Discriminator loss: 0.6519%, acc.: 58.20%] [Generator loss: 0.9046%]\n",
            "3220 [Discriminator loss: 0.6559%, acc.: 57.81%] [Generator loss: 0.8698%]\n",
            "3221 [Discriminator loss: 0.6751%, acc.: 55.08%] [Generator loss: 0.8862%]\n",
            "3222 [Discriminator loss: 0.6579%, acc.: 55.47%] [Generator loss: 0.8609%]\n",
            "3223 [Discriminator loss: 0.6723%, acc.: 55.08%] [Generator loss: 0.8644%]\n",
            "3224 [Discriminator loss: 0.6716%, acc.: 57.03%] [Generator loss: 0.8782%]\n",
            "3225 [Discriminator loss: 0.6528%, acc.: 58.98%] [Generator loss: 0.9446%]\n",
            "3226 [Discriminator loss: 0.6829%, acc.: 56.25%] [Generator loss: 0.9145%]\n",
            "3227 [Discriminator loss: 0.6423%, acc.: 62.89%] [Generator loss: 0.8984%]\n",
            "3228 [Discriminator loss: 0.6857%, acc.: 54.69%] [Generator loss: 0.9179%]\n",
            "3229 [Discriminator loss: 0.6545%, acc.: 59.77%] [Generator loss: 0.9126%]\n",
            "3230 [Discriminator loss: 0.6746%, acc.: 53.52%] [Generator loss: 0.9107%]\n",
            "3231 [Discriminator loss: 0.6671%, acc.: 55.86%] [Generator loss: 0.8620%]\n",
            "3232 [Discriminator loss: 0.6657%, acc.: 58.20%] [Generator loss: 0.8854%]\n",
            "3233 [Discriminator loss: 0.6533%, acc.: 60.16%] [Generator loss: 0.9143%]\n",
            "3234 [Discriminator loss: 0.6903%, acc.: 51.56%] [Generator loss: 0.8922%]\n",
            "3235 [Discriminator loss: 0.6479%, acc.: 57.81%] [Generator loss: 0.8954%]\n",
            "3236 [Discriminator loss: 0.6830%, acc.: 48.83%] [Generator loss: 0.8859%]\n",
            "3237 [Discriminator loss: 0.6747%, acc.: 52.34%] [Generator loss: 0.8851%]\n",
            "3238 [Discriminator loss: 0.6830%, acc.: 50.78%] [Generator loss: 0.8627%]\n",
            "3239 [Discriminator loss: 0.6677%, acc.: 55.47%] [Generator loss: 0.8568%]\n",
            "3240 [Discriminator loss: 0.6652%, acc.: 57.81%] [Generator loss: 0.8868%]\n",
            "3241 [Discriminator loss: 0.6666%, acc.: 56.25%] [Generator loss: 0.8688%]\n",
            "3242 [Discriminator loss: 0.6844%, acc.: 50.78%] [Generator loss: 0.8335%]\n",
            "3243 [Discriminator loss: 0.6529%, acc.: 58.59%] [Generator loss: 0.8337%]\n",
            "3244 [Discriminator loss: 0.6791%, acc.: 53.52%] [Generator loss: 0.8452%]\n",
            "3245 [Discriminator loss: 0.6832%, acc.: 50.00%] [Generator loss: 0.8392%]\n",
            "3246 [Discriminator loss: 0.6876%, acc.: 53.91%] [Generator loss: 0.8581%]\n",
            "3247 [Discriminator loss: 0.6810%, acc.: 51.17%] [Generator loss: 0.8448%]\n",
            "3248 [Discriminator loss: 0.6675%, acc.: 57.03%] [Generator loss: 0.8501%]\n",
            "3249 [Discriminator loss: 0.6736%, acc.: 53.91%] [Generator loss: 0.8605%]\n",
            "3250 [Discriminator loss: 0.6612%, acc.: 58.20%] [Generator loss: 0.8500%]\n",
            "3251 [Discriminator loss: 0.6672%, acc.: 54.30%] [Generator loss: 0.8759%]\n",
            "3252 [Discriminator loss: 0.6505%, acc.: 61.33%] [Generator loss: 0.8800%]\n",
            "3253 [Discriminator loss: 0.6514%, acc.: 60.55%] [Generator loss: 0.8739%]\n",
            "3254 [Discriminator loss: 0.6552%, acc.: 58.20%] [Generator loss: 0.8567%]\n",
            "3255 [Discriminator loss: 0.6522%, acc.: 58.98%] [Generator loss: 0.8512%]\n",
            "3256 [Discriminator loss: 0.6678%, acc.: 58.59%] [Generator loss: 0.8429%]\n",
            "3257 [Discriminator loss: 0.6410%, acc.: 62.50%] [Generator loss: 0.8361%]\n",
            "3258 [Discriminator loss: 0.6741%, acc.: 52.73%] [Generator loss: 0.8383%]\n",
            "3259 [Discriminator loss: 0.6496%, acc.: 65.23%] [Generator loss: 0.8283%]\n",
            "3260 [Discriminator loss: 0.6603%, acc.: 60.55%] [Generator loss: 0.8654%]\n",
            "3261 [Discriminator loss: 0.6659%, acc.: 57.81%] [Generator loss: 0.8590%]\n",
            "3262 [Discriminator loss: 0.6486%, acc.: 63.28%] [Generator loss: 0.8579%]\n",
            "3263 [Discriminator loss: 0.6554%, acc.: 64.06%] [Generator loss: 0.8575%]\n",
            "3264 [Discriminator loss: 0.6477%, acc.: 63.28%] [Generator loss: 0.8440%]\n",
            "3265 [Discriminator loss: 0.6543%, acc.: 62.50%] [Generator loss: 0.8338%]\n",
            "3266 [Discriminator loss: 0.6451%, acc.: 67.97%] [Generator loss: 0.8633%]\n",
            "3267 [Discriminator loss: 0.6410%, acc.: 64.84%] [Generator loss: 0.8749%]\n",
            "3268 [Discriminator loss: 0.6486%, acc.: 65.23%] [Generator loss: 0.8756%]\n",
            "3269 [Discriminator loss: 0.6568%, acc.: 61.72%] [Generator loss: 0.8711%]\n",
            "3270 [Discriminator loss: 0.6452%, acc.: 64.06%] [Generator loss: 0.8670%]\n",
            "3271 [Discriminator loss: 0.6532%, acc.: 63.28%] [Generator loss: 0.8498%]\n",
            "3272 [Discriminator loss: 0.6163%, acc.: 72.27%] [Generator loss: 0.8683%]\n",
            "3273 [Discriminator loss: 0.6545%, acc.: 62.50%] [Generator loss: 0.8660%]\n",
            "3274 [Discriminator loss: 0.6511%, acc.: 66.80%] [Generator loss: 0.8675%]\n",
            "3275 [Discriminator loss: 0.6355%, acc.: 69.92%] [Generator loss: 0.8642%]\n",
            "3276 [Discriminator loss: 0.6385%, acc.: 68.75%] [Generator loss: 0.8608%]\n",
            "3277 [Discriminator loss: 0.6577%, acc.: 62.11%] [Generator loss: 0.8647%]\n",
            "3278 [Discriminator loss: 0.6149%, acc.: 68.75%] [Generator loss: 0.8705%]\n",
            "3279 [Discriminator loss: 0.6246%, acc.: 68.36%] [Generator loss: 0.8655%]\n",
            "3280 [Discriminator loss: 0.6404%, acc.: 67.19%] [Generator loss: 0.8780%]\n",
            "3281 [Discriminator loss: 0.6249%, acc.: 67.58%] [Generator loss: 0.8813%]\n",
            "3282 [Discriminator loss: 0.6345%, acc.: 64.06%] [Generator loss: 0.8907%]\n",
            "3283 [Discriminator loss: 0.6368%, acc.: 68.36%] [Generator loss: 0.8763%]\n",
            "3284 [Discriminator loss: 0.6108%, acc.: 75.78%] [Generator loss: 0.9080%]\n",
            "3285 [Discriminator loss: 0.6349%, acc.: 71.88%] [Generator loss: 0.8752%]\n",
            "3286 [Discriminator loss: 0.6376%, acc.: 65.62%] [Generator loss: 0.8836%]\n",
            "3287 [Discriminator loss: 0.6257%, acc.: 71.09%] [Generator loss: 0.8705%]\n",
            "3288 [Discriminator loss: 0.6396%, acc.: 67.19%] [Generator loss: 0.8778%]\n",
            "3289 [Discriminator loss: 0.6276%, acc.: 67.58%] [Generator loss: 0.8859%]\n",
            "3290 [Discriminator loss: 0.6370%, acc.: 66.41%] [Generator loss: 0.8945%]\n",
            "3291 [Discriminator loss: 0.6322%, acc.: 67.58%] [Generator loss: 0.8939%]\n",
            "3292 [Discriminator loss: 0.6048%, acc.: 73.83%] [Generator loss: 0.8802%]\n",
            "3293 [Discriminator loss: 0.6294%, acc.: 68.75%] [Generator loss: 0.8691%]\n",
            "3294 [Discriminator loss: 0.6143%, acc.: 73.44%] [Generator loss: 0.8694%]\n",
            "3295 [Discriminator loss: 0.6256%, acc.: 68.36%] [Generator loss: 0.8741%]\n",
            "3296 [Discriminator loss: 0.6101%, acc.: 75.00%] [Generator loss: 0.8970%]\n",
            "3297 [Discriminator loss: 0.6215%, acc.: 69.92%] [Generator loss: 0.8943%]\n",
            "3298 [Discriminator loss: 0.6062%, acc.: 75.00%] [Generator loss: 0.8974%]\n",
            "3299 [Discriminator loss: 0.6140%, acc.: 70.31%] [Generator loss: 0.9179%]\n",
            "3300 [Discriminator loss: 0.6429%, acc.: 66.41%] [Generator loss: 0.8914%]\n",
            "3301 [Discriminator loss: 0.6264%, acc.: 65.23%] [Generator loss: 0.8854%]\n",
            "3302 [Discriminator loss: 0.6238%, acc.: 68.36%] [Generator loss: 0.9036%]\n",
            "3303 [Discriminator loss: 0.6219%, acc.: 67.58%] [Generator loss: 0.9118%]\n",
            "3304 [Discriminator loss: 0.6264%, acc.: 71.48%] [Generator loss: 0.9197%]\n",
            "3305 [Discriminator loss: 0.6224%, acc.: 69.14%] [Generator loss: 0.8836%]\n",
            "3306 [Discriminator loss: 0.6411%, acc.: 67.97%] [Generator loss: 0.8809%]\n",
            "3307 [Discriminator loss: 0.6103%, acc.: 73.44%] [Generator loss: 0.8952%]\n",
            "3308 [Discriminator loss: 0.6364%, acc.: 65.62%] [Generator loss: 0.8803%]\n",
            "3309 [Discriminator loss: 0.6296%, acc.: 68.75%] [Generator loss: 0.8767%]\n",
            "3310 [Discriminator loss: 0.6270%, acc.: 67.19%] [Generator loss: 0.8596%]\n",
            "3311 [Discriminator loss: 0.6226%, acc.: 70.70%] [Generator loss: 0.8655%]\n",
            "3312 [Discriminator loss: 0.6634%, acc.: 62.11%] [Generator loss: 0.8736%]\n",
            "3313 [Discriminator loss: 0.6366%, acc.: 67.58%] [Generator loss: 0.8753%]\n",
            "3314 [Discriminator loss: 0.6534%, acc.: 60.94%] [Generator loss: 0.8707%]\n",
            "3315 [Discriminator loss: 0.6421%, acc.: 66.80%] [Generator loss: 0.8709%]\n",
            "3316 [Discriminator loss: 0.6329%, acc.: 67.97%] [Generator loss: 0.8801%]\n",
            "3317 [Discriminator loss: 0.6448%, acc.: 66.41%] [Generator loss: 0.8620%]\n",
            "3318 [Discriminator loss: 0.6634%, acc.: 57.42%] [Generator loss: 0.8452%]\n",
            "3319 [Discriminator loss: 0.6322%, acc.: 69.14%] [Generator loss: 0.8556%]\n",
            "3320 [Discriminator loss: 0.6624%, acc.: 60.16%] [Generator loss: 0.8243%]\n",
            "3321 [Discriminator loss: 0.6490%, acc.: 60.94%] [Generator loss: 0.8551%]\n",
            "3322 [Discriminator loss: 0.6535%, acc.: 61.33%] [Generator loss: 0.8614%]\n",
            "3323 [Discriminator loss: 0.6532%, acc.: 59.77%] [Generator loss: 0.8475%]\n",
            "3324 [Discriminator loss: 0.6427%, acc.: 66.80%] [Generator loss: 0.8638%]\n",
            "3325 [Discriminator loss: 0.6604%, acc.: 56.64%] [Generator loss: 0.8497%]\n",
            "3326 [Discriminator loss: 0.6603%, acc.: 58.59%] [Generator loss: 0.8345%]\n",
            "3327 [Discriminator loss: 0.6504%, acc.: 59.38%] [Generator loss: 0.8499%]\n",
            "3328 [Discriminator loss: 0.6413%, acc.: 63.28%] [Generator loss: 0.8476%]\n",
            "3329 [Discriminator loss: 0.6522%, acc.: 61.72%] [Generator loss: 0.8564%]\n",
            "3330 [Discriminator loss: 0.6530%, acc.: 62.11%] [Generator loss: 0.8504%]\n",
            "3331 [Discriminator loss: 0.6426%, acc.: 60.16%] [Generator loss: 0.8552%]\n",
            "3332 [Discriminator loss: 0.6465%, acc.: 63.67%] [Generator loss: 0.8635%]\n",
            "3333 [Discriminator loss: 0.6526%, acc.: 61.72%] [Generator loss: 0.8497%]\n",
            "3334 [Discriminator loss: 0.6508%, acc.: 62.50%] [Generator loss: 0.8500%]\n",
            "3335 [Discriminator loss: 0.6632%, acc.: 60.16%] [Generator loss: 0.8398%]\n",
            "3336 [Discriminator loss: 0.6462%, acc.: 65.62%] [Generator loss: 0.8492%]\n",
            "3337 [Discriminator loss: 0.6562%, acc.: 59.77%] [Generator loss: 0.8607%]\n",
            "3338 [Discriminator loss: 0.6492%, acc.: 61.72%] [Generator loss: 0.8619%]\n",
            "3339 [Discriminator loss: 0.6571%, acc.: 57.81%] [Generator loss: 0.8612%]\n",
            "3340 [Discriminator loss: 0.6696%, acc.: 52.34%] [Generator loss: 0.8505%]\n",
            "3341 [Discriminator loss: 0.6523%, acc.: 59.77%] [Generator loss: 0.8546%]\n",
            "3342 [Discriminator loss: 0.6634%, acc.: 57.42%] [Generator loss: 0.8719%]\n",
            "3343 [Discriminator loss: 0.6732%, acc.: 54.69%] [Generator loss: 0.8708%]\n",
            "3344 [Discriminator loss: 0.6511%, acc.: 58.98%] [Generator loss: 0.8621%]\n",
            "3345 [Discriminator loss: 0.6646%, acc.: 59.38%] [Generator loss: 0.8870%]\n",
            "3346 [Discriminator loss: 0.6765%, acc.: 58.59%] [Generator loss: 0.8348%]\n",
            "3347 [Discriminator loss: 0.6632%, acc.: 53.52%] [Generator loss: 0.8474%]\n",
            "3348 [Discriminator loss: 0.6520%, acc.: 60.94%] [Generator loss: 0.8614%]\n",
            "3349 [Discriminator loss: 0.6535%, acc.: 62.11%] [Generator loss: 0.8631%]\n",
            "3350 [Discriminator loss: 0.6547%, acc.: 58.20%] [Generator loss: 0.8765%]\n",
            "3351 [Discriminator loss: 0.6414%, acc.: 60.94%] [Generator loss: 0.8608%]\n",
            "3352 [Discriminator loss: 0.6332%, acc.: 64.45%] [Generator loss: 0.9009%]\n",
            "3353 [Discriminator loss: 0.6705%, acc.: 56.64%] [Generator loss: 0.8769%]\n",
            "3354 [Discriminator loss: 0.6679%, acc.: 55.86%] [Generator loss: 0.8689%]\n",
            "3355 [Discriminator loss: 0.6599%, acc.: 59.38%] [Generator loss: 0.8631%]\n",
            "3356 [Discriminator loss: 0.6560%, acc.: 59.77%] [Generator loss: 0.8477%]\n",
            "3357 [Discriminator loss: 0.6382%, acc.: 66.02%] [Generator loss: 0.8765%]\n",
            "3358 [Discriminator loss: 0.6588%, acc.: 57.42%] [Generator loss: 0.8957%]\n",
            "3359 [Discriminator loss: 0.6514%, acc.: 63.67%] [Generator loss: 0.8753%]\n",
            "3360 [Discriminator loss: 0.6759%, acc.: 55.08%] [Generator loss: 0.8827%]\n",
            "3361 [Discriminator loss: 0.6641%, acc.: 57.03%] [Generator loss: 0.8538%]\n",
            "3362 [Discriminator loss: 0.6512%, acc.: 60.16%] [Generator loss: 0.8358%]\n",
            "3363 [Discriminator loss: 0.6525%, acc.: 57.03%] [Generator loss: 0.8243%]\n",
            "3364 [Discriminator loss: 0.6760%, acc.: 52.73%] [Generator loss: 0.8546%]\n",
            "3365 [Discriminator loss: 0.6512%, acc.: 57.42%] [Generator loss: 0.8438%]\n",
            "3366 [Discriminator loss: 0.6768%, acc.: 49.61%] [Generator loss: 0.8266%]\n",
            "3367 [Discriminator loss: 0.6519%, acc.: 56.64%] [Generator loss: 0.8492%]\n",
            "3368 [Discriminator loss: 0.6766%, acc.: 54.30%] [Generator loss: 0.8728%]\n",
            "3369 [Discriminator loss: 0.6631%, acc.: 57.81%] [Generator loss: 0.8613%]\n",
            "3370 [Discriminator loss: 0.6606%, acc.: 58.98%] [Generator loss: 0.8686%]\n",
            "3371 [Discriminator loss: 0.6498%, acc.: 60.94%] [Generator loss: 0.8558%]\n",
            "3372 [Discriminator loss: 0.6746%, acc.: 57.03%] [Generator loss: 0.8821%]\n",
            "3373 [Discriminator loss: 0.6541%, acc.: 59.38%] [Generator loss: 0.8502%]\n",
            "3374 [Discriminator loss: 0.6579%, acc.: 58.98%] [Generator loss: 0.8758%]\n",
            "3375 [Discriminator loss: 0.6661%, acc.: 59.77%] [Generator loss: 0.8449%]\n",
            "3376 [Discriminator loss: 0.6685%, acc.: 58.20%] [Generator loss: 0.8555%]\n",
            "3377 [Discriminator loss: 0.6804%, acc.: 55.08%] [Generator loss: 0.8505%]\n",
            "3378 [Discriminator loss: 0.6572%, acc.: 61.72%] [Generator loss: 0.8428%]\n",
            "3379 [Discriminator loss: 0.6601%, acc.: 57.03%] [Generator loss: 0.8837%]\n",
            "3380 [Discriminator loss: 0.6455%, acc.: 61.72%] [Generator loss: 0.8850%]\n",
            "3381 [Discriminator loss: 0.6655%, acc.: 60.55%] [Generator loss: 0.8744%]\n",
            "3382 [Discriminator loss: 0.6748%, acc.: 56.64%] [Generator loss: 0.8538%]\n",
            "3383 [Discriminator loss: 0.6495%, acc.: 61.72%] [Generator loss: 0.8831%]\n",
            "3384 [Discriminator loss: 0.6815%, acc.: 55.47%] [Generator loss: 0.8866%]\n",
            "3385 [Discriminator loss: 0.6662%, acc.: 55.08%] [Generator loss: 0.8607%]\n",
            "3386 [Discriminator loss: 0.6634%, acc.: 58.20%] [Generator loss: 0.8350%]\n",
            "3387 [Discriminator loss: 0.6496%, acc.: 59.77%] [Generator loss: 0.8758%]\n",
            "3388 [Discriminator loss: 0.6886%, acc.: 51.56%] [Generator loss: 0.8683%]\n",
            "3389 [Discriminator loss: 0.6617%, acc.: 55.08%] [Generator loss: 0.8611%]\n",
            "3390 [Discriminator loss: 0.6590%, acc.: 59.77%] [Generator loss: 0.8795%]\n",
            "3391 [Discriminator loss: 0.6632%, acc.: 57.42%] [Generator loss: 0.8882%]\n",
            "3392 [Discriminator loss: 0.6615%, acc.: 62.50%] [Generator loss: 0.8810%]\n",
            "3393 [Discriminator loss: 0.6557%, acc.: 60.55%] [Generator loss: 0.8768%]\n",
            "3394 [Discriminator loss: 0.6826%, acc.: 57.42%] [Generator loss: 0.8657%]\n",
            "3395 [Discriminator loss: 0.6678%, acc.: 59.38%] [Generator loss: 0.8704%]\n",
            "3396 [Discriminator loss: 0.6780%, acc.: 58.59%] [Generator loss: 0.8663%]\n",
            "3397 [Discriminator loss: 0.6530%, acc.: 62.50%] [Generator loss: 0.8870%]\n",
            "3398 [Discriminator loss: 0.6531%, acc.: 62.11%] [Generator loss: 0.8762%]\n",
            "3399 [Discriminator loss: 0.6628%, acc.: 61.72%] [Generator loss: 0.8867%]\n",
            "3400 [Discriminator loss: 0.6518%, acc.: 62.50%] [Generator loss: 0.8704%]\n",
            "3401 [Discriminator loss: 0.6621%, acc.: 60.55%] [Generator loss: 0.8859%]\n",
            "3402 [Discriminator loss: 0.6590%, acc.: 58.20%] [Generator loss: 0.8610%]\n",
            "3403 [Discriminator loss: 0.6653%, acc.: 55.08%] [Generator loss: 0.8785%]\n",
            "3404 [Discriminator loss: 0.6351%, acc.: 59.77%] [Generator loss: 0.9015%]\n",
            "3405 [Discriminator loss: 0.6630%, acc.: 60.55%] [Generator loss: 0.8814%]\n",
            "3406 [Discriminator loss: 0.6908%, acc.: 56.25%] [Generator loss: 0.8442%]\n",
            "3407 [Discriminator loss: 0.6600%, acc.: 56.25%] [Generator loss: 0.8620%]\n",
            "3408 [Discriminator loss: 0.6364%, acc.: 64.84%] [Generator loss: 0.8633%]\n",
            "3409 [Discriminator loss: 0.6340%, acc.: 63.28%] [Generator loss: 0.8890%]\n",
            "3410 [Discriminator loss: 0.6336%, acc.: 66.02%] [Generator loss: 0.9078%]\n",
            "3411 [Discriminator loss: 0.6635%, acc.: 58.59%] [Generator loss: 0.8995%]\n",
            "3412 [Discriminator loss: 0.6525%, acc.: 63.67%] [Generator loss: 0.8698%]\n",
            "3413 [Discriminator loss: 0.6596%, acc.: 59.77%] [Generator loss: 0.8424%]\n",
            "3414 [Discriminator loss: 0.6315%, acc.: 64.84%] [Generator loss: 0.8793%]\n",
            "3415 [Discriminator loss: 0.6450%, acc.: 61.72%] [Generator loss: 0.8829%]\n",
            "3416 [Discriminator loss: 0.6614%, acc.: 61.33%] [Generator loss: 0.8870%]\n",
            "3417 [Discriminator loss: 0.6433%, acc.: 66.02%] [Generator loss: 0.8879%]\n",
            "3418 [Discriminator loss: 0.6294%, acc.: 67.58%] [Generator loss: 0.8668%]\n",
            "3419 [Discriminator loss: 0.6124%, acc.: 72.66%] [Generator loss: 0.8848%]\n",
            "3420 [Discriminator loss: 0.6520%, acc.: 63.28%] [Generator loss: 0.8558%]\n",
            "3421 [Discriminator loss: 0.6562%, acc.: 58.59%] [Generator loss: 0.8708%]\n",
            "3422 [Discriminator loss: 0.6296%, acc.: 64.45%] [Generator loss: 0.8772%]\n",
            "3423 [Discriminator loss: 0.6342%, acc.: 62.11%] [Generator loss: 0.8907%]\n",
            "3424 [Discriminator loss: 0.6270%, acc.: 67.97%] [Generator loss: 0.8782%]\n",
            "3425 [Discriminator loss: 0.6313%, acc.: 66.41%] [Generator loss: 0.8675%]\n",
            "3426 [Discriminator loss: 0.6493%, acc.: 60.16%] [Generator loss: 0.8741%]\n",
            "3427 [Discriminator loss: 0.6382%, acc.: 61.72%] [Generator loss: 0.8805%]\n",
            "3428 [Discriminator loss: 0.6334%, acc.: 62.89%] [Generator loss: 0.8842%]\n",
            "3429 [Discriminator loss: 0.6232%, acc.: 66.80%] [Generator loss: 0.8835%]\n",
            "3430 [Discriminator loss: 0.6457%, acc.: 60.16%] [Generator loss: 0.8664%]\n",
            "3431 [Discriminator loss: 0.6476%, acc.: 62.50%] [Generator loss: 0.8577%]\n",
            "3432 [Discriminator loss: 0.6526%, acc.: 57.81%] [Generator loss: 0.8550%]\n",
            "3433 [Discriminator loss: 0.6311%, acc.: 62.89%] [Generator loss: 0.8199%]\n",
            "3434 [Discriminator loss: 0.6543%, acc.: 54.69%] [Generator loss: 0.8295%]\n",
            "3435 [Discriminator loss: 0.6168%, acc.: 64.45%] [Generator loss: 0.8673%]\n",
            "3436 [Discriminator loss: 0.6099%, acc.: 67.97%] [Generator loss: 0.8785%]\n",
            "3437 [Discriminator loss: 0.6491%, acc.: 60.55%] [Generator loss: 0.8610%]\n",
            "3438 [Discriminator loss: 0.6401%, acc.: 60.55%] [Generator loss: 0.8874%]\n",
            "3439 [Discriminator loss: 0.6464%, acc.: 63.28%] [Generator loss: 0.8630%]\n",
            "3440 [Discriminator loss: 0.6317%, acc.: 64.06%] [Generator loss: 0.8770%]\n",
            "3441 [Discriminator loss: 0.6478%, acc.: 58.20%] [Generator loss: 0.8562%]\n",
            "3442 [Discriminator loss: 0.6225%, acc.: 62.89%] [Generator loss: 0.8620%]\n",
            "3443 [Discriminator loss: 0.6533%, acc.: 60.94%] [Generator loss: 0.8441%]\n",
            "3444 [Discriminator loss: 0.6391%, acc.: 60.16%] [Generator loss: 0.8458%]\n",
            "3445 [Discriminator loss: 0.6558%, acc.: 57.42%] [Generator loss: 0.8742%]\n",
            "3446 [Discriminator loss: 0.6340%, acc.: 64.84%] [Generator loss: 0.8825%]\n",
            "3447 [Discriminator loss: 0.6239%, acc.: 65.23%] [Generator loss: 0.8887%]\n",
            "3448 [Discriminator loss: 0.6232%, acc.: 63.67%] [Generator loss: 0.8769%]\n",
            "3449 [Discriminator loss: 0.6325%, acc.: 64.45%] [Generator loss: 0.8873%]\n",
            "3450 [Discriminator loss: 0.6527%, acc.: 58.59%] [Generator loss: 0.8884%]\n",
            "3451 [Discriminator loss: 0.6646%, acc.: 53.91%] [Generator loss: 0.8875%]\n",
            "3452 [Discriminator loss: 0.6544%, acc.: 58.59%] [Generator loss: 0.8977%]\n",
            "3453 [Discriminator loss: 0.6525%, acc.: 58.98%] [Generator loss: 0.8811%]\n",
            "3454 [Discriminator loss: 0.6254%, acc.: 64.45%] [Generator loss: 0.8826%]\n",
            "3455 [Discriminator loss: 0.6314%, acc.: 64.06%] [Generator loss: 0.8787%]\n",
            "3456 [Discriminator loss: 0.6478%, acc.: 62.89%] [Generator loss: 0.8578%]\n",
            "3457 [Discriminator loss: 0.6571%, acc.: 58.59%] [Generator loss: 0.8571%]\n",
            "3458 [Discriminator loss: 0.6488%, acc.: 57.42%] [Generator loss: 0.8647%]\n",
            "3459 [Discriminator loss: 0.6409%, acc.: 63.28%] [Generator loss: 0.8688%]\n",
            "3460 [Discriminator loss: 0.6375%, acc.: 62.11%] [Generator loss: 0.8599%]\n",
            "3461 [Discriminator loss: 0.6383%, acc.: 60.55%] [Generator loss: 0.8727%]\n",
            "3462 [Discriminator loss: 0.6475%, acc.: 62.50%] [Generator loss: 0.8681%]\n",
            "3463 [Discriminator loss: 0.6487%, acc.: 56.64%] [Generator loss: 0.8605%]\n",
            "3464 [Discriminator loss: 0.6805%, acc.: 52.73%] [Generator loss: 0.8599%]\n",
            "3465 [Discriminator loss: 0.6635%, acc.: 57.03%] [Generator loss: 0.8423%]\n",
            "3466 [Discriminator loss: 0.6338%, acc.: 58.20%] [Generator loss: 0.8727%]\n",
            "3467 [Discriminator loss: 0.6517%, acc.: 59.38%] [Generator loss: 0.8758%]\n",
            "3468 [Discriminator loss: 0.6715%, acc.: 53.52%] [Generator loss: 0.9051%]\n",
            "3469 [Discriminator loss: 0.6702%, acc.: 54.30%] [Generator loss: 0.8722%]\n",
            "3470 [Discriminator loss: 0.6808%, acc.: 50.39%] [Generator loss: 0.8766%]\n",
            "3471 [Discriminator loss: 0.6669%, acc.: 55.47%] [Generator loss: 0.8973%]\n",
            "3472 [Discriminator loss: 0.6711%, acc.: 51.56%] [Generator loss: 0.8397%]\n",
            "3473 [Discriminator loss: 0.7025%, acc.: 48.05%] [Generator loss: 0.8377%]\n",
            "3474 [Discriminator loss: 0.6822%, acc.: 52.73%] [Generator loss: 0.8577%]\n",
            "3475 [Discriminator loss: 0.6674%, acc.: 55.86%] [Generator loss: 0.8540%]\n",
            "3476 [Discriminator loss: 0.6626%, acc.: 60.55%] [Generator loss: 0.8732%]\n",
            "3477 [Discriminator loss: 0.6757%, acc.: 54.69%] [Generator loss: 0.8629%]\n",
            "3478 [Discriminator loss: 0.6784%, acc.: 55.08%] [Generator loss: 0.8792%]\n",
            "3479 [Discriminator loss: 0.6907%, acc.: 51.95%] [Generator loss: 0.8956%]\n",
            "3480 [Discriminator loss: 0.6625%, acc.: 57.03%] [Generator loss: 0.8851%]\n",
            "3481 [Discriminator loss: 0.6492%, acc.: 59.77%] [Generator loss: 0.8695%]\n",
            "3482 [Discriminator loss: 0.6622%, acc.: 59.77%] [Generator loss: 0.8637%]\n",
            "3483 [Discriminator loss: 0.6581%, acc.: 58.98%] [Generator loss: 0.8653%]\n",
            "3484 [Discriminator loss: 0.6501%, acc.: 62.89%] [Generator loss: 0.8624%]\n",
            "3485 [Discriminator loss: 0.6477%, acc.: 61.72%] [Generator loss: 0.8526%]\n",
            "3486 [Discriminator loss: 0.6644%, acc.: 55.47%] [Generator loss: 0.8778%]\n",
            "3487 [Discriminator loss: 0.6620%, acc.: 57.42%] [Generator loss: 0.8689%]\n",
            "3488 [Discriminator loss: 0.6336%, acc.: 62.89%] [Generator loss: 0.8975%]\n",
            "3489 [Discriminator loss: 0.6485%, acc.: 62.50%] [Generator loss: 0.9003%]\n",
            "3490 [Discriminator loss: 0.6646%, acc.: 62.11%] [Generator loss: 0.8746%]\n",
            "3491 [Discriminator loss: 0.6586%, acc.: 57.42%] [Generator loss: 0.8604%]\n",
            "3492 [Discriminator loss: 0.6629%, acc.: 58.20%] [Generator loss: 0.8798%]\n",
            "3493 [Discriminator loss: 0.6587%, acc.: 60.55%] [Generator loss: 0.8976%]\n",
            "3494 [Discriminator loss: 0.6528%, acc.: 60.55%] [Generator loss: 0.8625%]\n",
            "3495 [Discriminator loss: 0.6490%, acc.: 60.55%] [Generator loss: 0.8884%]\n",
            "3496 [Discriminator loss: 0.6667%, acc.: 58.59%] [Generator loss: 0.8846%]\n",
            "3497 [Discriminator loss: 0.6321%, acc.: 70.31%] [Generator loss: 0.8615%]\n",
            "3498 [Discriminator loss: 0.6447%, acc.: 60.94%] [Generator loss: 0.8557%]\n",
            "3499 [Discriminator loss: 0.6285%, acc.: 69.53%] [Generator loss: 0.8755%]\n",
            "3500 [Discriminator loss: 0.6546%, acc.: 67.58%] [Generator loss: 0.8643%]\n",
            "3501 [Discriminator loss: 0.6318%, acc.: 62.89%] [Generator loss: 0.8531%]\n",
            "3502 [Discriminator loss: 0.6189%, acc.: 70.31%] [Generator loss: 0.9058%]\n",
            "3503 [Discriminator loss: 0.6460%, acc.: 61.72%] [Generator loss: 0.8963%]\n",
            "3504 [Discriminator loss: 0.6127%, acc.: 69.92%] [Generator loss: 0.8985%]\n",
            "3505 [Discriminator loss: 0.6427%, acc.: 59.77%] [Generator loss: 0.9162%]\n",
            "3506 [Discriminator loss: 0.6294%, acc.: 68.36%] [Generator loss: 0.8889%]\n",
            "3507 [Discriminator loss: 0.6564%, acc.: 57.81%] [Generator loss: 0.8727%]\n",
            "3508 [Discriminator loss: 0.6174%, acc.: 64.45%] [Generator loss: 0.8821%]\n",
            "3509 [Discriminator loss: 0.6225%, acc.: 64.84%] [Generator loss: 0.8842%]\n",
            "3510 [Discriminator loss: 0.6504%, acc.: 63.67%] [Generator loss: 0.8772%]\n",
            "3511 [Discriminator loss: 0.6219%, acc.: 67.19%] [Generator loss: 0.9033%]\n",
            "3512 [Discriminator loss: 0.6208%, acc.: 70.70%] [Generator loss: 0.8910%]\n",
            "3513 [Discriminator loss: 0.6571%, acc.: 59.38%] [Generator loss: 0.9096%]\n",
            "3514 [Discriminator loss: 0.6328%, acc.: 65.62%] [Generator loss: 0.8893%]\n",
            "3515 [Discriminator loss: 0.6326%, acc.: 66.02%] [Generator loss: 0.8939%]\n",
            "3516 [Discriminator loss: 0.6361%, acc.: 62.89%] [Generator loss: 0.9360%]\n",
            "3517 [Discriminator loss: 0.6347%, acc.: 67.19%] [Generator loss: 0.9184%]\n",
            "3518 [Discriminator loss: 0.6160%, acc.: 70.31%] [Generator loss: 0.9378%]\n",
            "3519 [Discriminator loss: 0.6281%, acc.: 66.80%] [Generator loss: 0.9240%]\n",
            "3520 [Discriminator loss: 0.6684%, acc.: 57.81%] [Generator loss: 0.9092%]\n",
            "3521 [Discriminator loss: 0.6178%, acc.: 68.75%] [Generator loss: 0.9132%]\n",
            "3522 [Discriminator loss: 0.6216%, acc.: 69.92%] [Generator loss: 0.8994%]\n",
            "3523 [Discriminator loss: 0.6071%, acc.: 73.44%] [Generator loss: 0.9411%]\n",
            "3524 [Discriminator loss: 0.6199%, acc.: 69.92%] [Generator loss: 0.9543%]\n",
            "3525 [Discriminator loss: 0.6364%, acc.: 66.41%] [Generator loss: 0.9406%]\n",
            "3526 [Discriminator loss: 0.6319%, acc.: 65.62%] [Generator loss: 0.9284%]\n",
            "3527 [Discriminator loss: 0.6232%, acc.: 68.75%] [Generator loss: 0.9303%]\n",
            "3528 [Discriminator loss: 0.6212%, acc.: 70.70%] [Generator loss: 0.9319%]\n",
            "3529 [Discriminator loss: 0.6353%, acc.: 64.84%] [Generator loss: 0.9030%]\n",
            "3530 [Discriminator loss: 0.6324%, acc.: 67.19%] [Generator loss: 0.8871%]\n",
            "3531 [Discriminator loss: 0.6455%, acc.: 58.98%] [Generator loss: 0.8982%]\n",
            "3532 [Discriminator loss: 0.6178%, acc.: 71.88%] [Generator loss: 0.9241%]\n",
            "3533 [Discriminator loss: 0.6245%, acc.: 70.70%] [Generator loss: 0.9159%]\n",
            "3534 [Discriminator loss: 0.6281%, acc.: 69.92%] [Generator loss: 0.9056%]\n",
            "3535 [Discriminator loss: 0.6207%, acc.: 64.84%] [Generator loss: 0.9002%]\n",
            "3536 [Discriminator loss: 0.6331%, acc.: 62.89%] [Generator loss: 0.9061%]\n",
            "3537 [Discriminator loss: 0.6017%, acc.: 68.36%] [Generator loss: 0.9259%]\n",
            "3538 [Discriminator loss: 0.6192%, acc.: 65.23%] [Generator loss: 0.9135%]\n",
            "3539 [Discriminator loss: 0.6483%, acc.: 64.06%] [Generator loss: 0.9068%]\n",
            "3540 [Discriminator loss: 0.6108%, acc.: 68.75%] [Generator loss: 0.9320%]\n",
            "3541 [Discriminator loss: 0.6177%, acc.: 69.53%] [Generator loss: 0.9345%]\n",
            "3542 [Discriminator loss: 0.6274%, acc.: 70.70%] [Generator loss: 0.9359%]\n",
            "3543 [Discriminator loss: 0.6417%, acc.: 65.23%] [Generator loss: 0.9142%]\n",
            "3544 [Discriminator loss: 0.6252%, acc.: 67.58%] [Generator loss: 0.9186%]\n",
            "3545 [Discriminator loss: 0.6357%, acc.: 69.53%] [Generator loss: 0.9109%]\n",
            "3546 [Discriminator loss: 0.6210%, acc.: 69.14%] [Generator loss: 0.9004%]\n",
            "3547 [Discriminator loss: 0.6280%, acc.: 68.36%] [Generator loss: 0.9058%]\n",
            "3548 [Discriminator loss: 0.6512%, acc.: 62.50%] [Generator loss: 0.9060%]\n",
            "3549 [Discriminator loss: 0.6043%, acc.: 71.88%] [Generator loss: 0.9137%]\n",
            "3550 [Discriminator loss: 0.6413%, acc.: 61.72%] [Generator loss: 0.8957%]\n",
            "3551 [Discriminator loss: 0.6208%, acc.: 65.62%] [Generator loss: 0.8978%]\n",
            "3552 [Discriminator loss: 0.6585%, acc.: 58.20%] [Generator loss: 0.8816%]\n",
            "3553 [Discriminator loss: 0.6285%, acc.: 63.67%] [Generator loss: 0.9047%]\n",
            "3554 [Discriminator loss: 0.6413%, acc.: 64.06%] [Generator loss: 0.9098%]\n",
            "3555 [Discriminator loss: 0.6523%, acc.: 62.50%] [Generator loss: 0.9039%]\n",
            "3556 [Discriminator loss: 0.6280%, acc.: 62.50%] [Generator loss: 0.9329%]\n",
            "3557 [Discriminator loss: 0.6101%, acc.: 69.53%] [Generator loss: 0.9433%]\n",
            "3558 [Discriminator loss: 0.6421%, acc.: 66.02%] [Generator loss: 0.9376%]\n",
            "3559 [Discriminator loss: 0.6132%, acc.: 67.97%] [Generator loss: 0.9146%]\n",
            "3560 [Discriminator loss: 0.6494%, acc.: 65.62%] [Generator loss: 0.9100%]\n",
            "3561 [Discriminator loss: 0.6359%, acc.: 66.80%] [Generator loss: 0.9047%]\n",
            "3562 [Discriminator loss: 0.6333%, acc.: 66.41%] [Generator loss: 0.9029%]\n",
            "3563 [Discriminator loss: 0.5975%, acc.: 71.48%] [Generator loss: 0.9076%]\n",
            "3564 [Discriminator loss: 0.6310%, acc.: 66.02%] [Generator loss: 0.9247%]\n",
            "3565 [Discriminator loss: 0.6330%, acc.: 63.28%] [Generator loss: 0.9089%]\n",
            "3566 [Discriminator loss: 0.6063%, acc.: 71.48%] [Generator loss: 0.9238%]\n",
            "3567 [Discriminator loss: 0.6395%, acc.: 64.06%] [Generator loss: 0.9007%]\n",
            "3568 [Discriminator loss: 0.6437%, acc.: 64.06%] [Generator loss: 0.9132%]\n",
            "3569 [Discriminator loss: 0.6257%, acc.: 68.36%] [Generator loss: 0.9066%]\n",
            "3570 [Discriminator loss: 0.5958%, acc.: 68.75%] [Generator loss: 0.9264%]\n",
            "3571 [Discriminator loss: 0.6309%, acc.: 64.45%] [Generator loss: 0.9071%]\n",
            "3572 [Discriminator loss: 0.6214%, acc.: 67.58%] [Generator loss: 0.9025%]\n",
            "3573 [Discriminator loss: 0.6161%, acc.: 61.72%] [Generator loss: 0.9276%]\n",
            "3574 [Discriminator loss: 0.6256%, acc.: 67.58%] [Generator loss: 0.9110%]\n",
            "3575 [Discriminator loss: 0.6254%, acc.: 64.84%] [Generator loss: 0.9141%]\n",
            "3576 [Discriminator loss: 0.6378%, acc.: 60.16%] [Generator loss: 0.8980%]\n",
            "3577 [Discriminator loss: 0.6105%, acc.: 61.72%] [Generator loss: 0.9195%]\n",
            "3578 [Discriminator loss: 0.6386%, acc.: 62.11%] [Generator loss: 0.9131%]\n",
            "3579 [Discriminator loss: 0.6289%, acc.: 61.33%] [Generator loss: 0.8914%]\n",
            "3580 [Discriminator loss: 0.6271%, acc.: 65.23%] [Generator loss: 0.8761%]\n",
            "3581 [Discriminator loss: 0.6465%, acc.: 56.25%] [Generator loss: 0.9090%]\n",
            "3582 [Discriminator loss: 0.6473%, acc.: 58.98%] [Generator loss: 0.8925%]\n",
            "3583 [Discriminator loss: 0.6308%, acc.: 63.28%] [Generator loss: 0.8891%]\n",
            "3584 [Discriminator loss: 0.6290%, acc.: 61.72%] [Generator loss: 0.8939%]\n",
            "3585 [Discriminator loss: 0.6588%, acc.: 58.59%] [Generator loss: 0.8664%]\n",
            "3586 [Discriminator loss: 0.6205%, acc.: 65.62%] [Generator loss: 0.8666%]\n",
            "3587 [Discriminator loss: 0.6338%, acc.: 62.50%] [Generator loss: 0.8745%]\n",
            "3588 [Discriminator loss: 0.6476%, acc.: 58.98%] [Generator loss: 0.8598%]\n",
            "3589 [Discriminator loss: 0.6459%, acc.: 58.20%] [Generator loss: 0.8820%]\n",
            "3590 [Discriminator loss: 0.6560%, acc.: 53.52%] [Generator loss: 0.8571%]\n",
            "3591 [Discriminator loss: 0.6561%, acc.: 56.25%] [Generator loss: 0.8608%]\n",
            "3592 [Discriminator loss: 0.6406%, acc.: 58.20%] [Generator loss: 0.8591%]\n",
            "3593 [Discriminator loss: 0.6618%, acc.: 56.64%] [Generator loss: 0.8551%]\n",
            "3594 [Discriminator loss: 0.6475%, acc.: 54.30%] [Generator loss: 0.8744%]\n",
            "3595 [Discriminator loss: 0.6459%, acc.: 54.69%] [Generator loss: 0.8835%]\n",
            "3596 [Discriminator loss: 0.6590%, acc.: 55.86%] [Generator loss: 0.8925%]\n",
            "3597 [Discriminator loss: 0.6544%, acc.: 54.69%] [Generator loss: 0.8977%]\n",
            "3598 [Discriminator loss: 0.6483%, acc.: 57.81%] [Generator loss: 0.8863%]\n",
            "3599 [Discriminator loss: 0.6432%, acc.: 61.72%] [Generator loss: 0.8927%]\n",
            "3600 [Discriminator loss: 0.6594%, acc.: 60.16%] [Generator loss: 0.8749%]\n",
            "3601 [Discriminator loss: 0.6445%, acc.: 58.20%] [Generator loss: 0.8522%]\n",
            "3602 [Discriminator loss: 0.6543%, acc.: 61.33%] [Generator loss: 0.8561%]\n",
            "3603 [Discriminator loss: 0.6579%, acc.: 61.33%] [Generator loss: 0.8735%]\n",
            "3604 [Discriminator loss: 0.6679%, acc.: 62.11%] [Generator loss: 0.8545%]\n",
            "3605 [Discriminator loss: 0.6765%, acc.: 53.52%] [Generator loss: 0.8570%]\n",
            "3606 [Discriminator loss: 0.6532%, acc.: 61.72%] [Generator loss: 0.8608%]\n",
            "3607 [Discriminator loss: 0.6335%, acc.: 65.23%] [Generator loss: 0.8721%]\n",
            "3608 [Discriminator loss: 0.6744%, acc.: 53.91%] [Generator loss: 0.8667%]\n",
            "3609 [Discriminator loss: 0.6819%, acc.: 54.30%] [Generator loss: 0.8425%]\n",
            "3610 [Discriminator loss: 0.6806%, acc.: 54.69%] [Generator loss: 0.8616%]\n",
            "3611 [Discriminator loss: 0.6692%, acc.: 57.03%] [Generator loss: 0.8627%]\n",
            "3612 [Discriminator loss: 0.6744%, acc.: 59.77%] [Generator loss: 0.8571%]\n",
            "3613 [Discriminator loss: 0.6517%, acc.: 60.55%] [Generator loss: 0.8611%]\n",
            "3614 [Discriminator loss: 0.6754%, acc.: 54.69%] [Generator loss: 0.8615%]\n",
            "3615 [Discriminator loss: 0.6998%, acc.: 52.34%] [Generator loss: 0.8479%]\n",
            "3616 [Discriminator loss: 0.7008%, acc.: 49.61%] [Generator loss: 0.8353%]\n",
            "3617 [Discriminator loss: 0.6737%, acc.: 55.47%] [Generator loss: 0.8470%]\n",
            "3618 [Discriminator loss: 0.6827%, acc.: 55.47%] [Generator loss: 0.8732%]\n",
            "3619 [Discriminator loss: 0.6531%, acc.: 64.45%] [Generator loss: 0.8657%]\n",
            "3620 [Discriminator loss: 0.6718%, acc.: 56.64%] [Generator loss: 0.8500%]\n",
            "3621 [Discriminator loss: 0.6765%, acc.: 57.42%] [Generator loss: 0.8854%]\n",
            "3622 [Discriminator loss: 0.6567%, acc.: 59.77%] [Generator loss: 0.8702%]\n",
            "3623 [Discriminator loss: 0.6652%, acc.: 57.42%] [Generator loss: 0.8494%]\n",
            "3624 [Discriminator loss: 0.6901%, acc.: 51.56%] [Generator loss: 0.8290%]\n",
            "3625 [Discriminator loss: 0.6521%, acc.: 57.03%] [Generator loss: 0.8721%]\n",
            "3626 [Discriminator loss: 0.6732%, acc.: 55.86%] [Generator loss: 0.8361%]\n",
            "3627 [Discriminator loss: 0.6456%, acc.: 63.67%] [Generator loss: 0.8404%]\n",
            "3628 [Discriminator loss: 0.6326%, acc.: 62.89%] [Generator loss: 0.8492%]\n",
            "3629 [Discriminator loss: 0.6805%, acc.: 54.30%] [Generator loss: 0.8417%]\n",
            "3630 [Discriminator loss: 0.6679%, acc.: 55.86%] [Generator loss: 0.8691%]\n",
            "3631 [Discriminator loss: 0.6833%, acc.: 52.73%] [Generator loss: 0.8519%]\n",
            "3632 [Discriminator loss: 0.6576%, acc.: 57.03%] [Generator loss: 0.8494%]\n",
            "3633 [Discriminator loss: 0.6215%, acc.: 68.75%] [Generator loss: 0.8781%]\n",
            "3634 [Discriminator loss: 0.6492%, acc.: 65.23%] [Generator loss: 0.8687%]\n",
            "3635 [Discriminator loss: 0.6654%, acc.: 59.38%] [Generator loss: 0.8711%]\n",
            "3636 [Discriminator loss: 0.6589%, acc.: 57.42%] [Generator loss: 0.8630%]\n",
            "3637 [Discriminator loss: 0.6685%, acc.: 58.98%] [Generator loss: 0.8691%]\n",
            "3638 [Discriminator loss: 0.6738%, acc.: 59.38%] [Generator loss: 0.8407%]\n",
            "3639 [Discriminator loss: 0.6718%, acc.: 53.52%] [Generator loss: 0.8529%]\n",
            "3640 [Discriminator loss: 0.6502%, acc.: 65.23%] [Generator loss: 0.8620%]\n",
            "3641 [Discriminator loss: 0.6484%, acc.: 62.50%] [Generator loss: 0.8653%]\n",
            "3642 [Discriminator loss: 0.6687%, acc.: 59.38%] [Generator loss: 0.8682%]\n",
            "3643 [Discriminator loss: 0.6499%, acc.: 60.16%] [Generator loss: 0.8672%]\n",
            "3644 [Discriminator loss: 0.6425%, acc.: 66.02%] [Generator loss: 0.8848%]\n",
            "3645 [Discriminator loss: 0.6624%, acc.: 56.64%] [Generator loss: 0.8740%]\n",
            "3646 [Discriminator loss: 0.6432%, acc.: 64.45%] [Generator loss: 0.8892%]\n",
            "3647 [Discriminator loss: 0.6890%, acc.: 55.86%] [Generator loss: 0.8473%]\n",
            "3648 [Discriminator loss: 0.6582%, acc.: 60.55%] [Generator loss: 0.8504%]\n",
            "3649 [Discriminator loss: 0.6594%, acc.: 56.25%] [Generator loss: 0.8403%]\n",
            "3650 [Discriminator loss: 0.6452%, acc.: 60.16%] [Generator loss: 0.8683%]\n",
            "3651 [Discriminator loss: 0.6577%, acc.: 58.20%] [Generator loss: 0.8560%]\n",
            "3652 [Discriminator loss: 0.6858%, acc.: 52.73%] [Generator loss: 0.8385%]\n",
            "3653 [Discriminator loss: 0.6596%, acc.: 56.64%] [Generator loss: 0.8399%]\n",
            "3654 [Discriminator loss: 0.6547%, acc.: 58.59%] [Generator loss: 0.8627%]\n",
            "3655 [Discriminator loss: 0.6555%, acc.: 63.28%] [Generator loss: 0.8549%]\n",
            "3656 [Discriminator loss: 0.6797%, acc.: 53.52%] [Generator loss: 0.8415%]\n",
            "3657 [Discriminator loss: 0.6814%, acc.: 51.95%] [Generator loss: 0.8052%]\n",
            "3658 [Discriminator loss: 0.6680%, acc.: 56.25%] [Generator loss: 0.8039%]\n",
            "3659 [Discriminator loss: 0.6496%, acc.: 60.55%] [Generator loss: 0.8046%]\n",
            "3660 [Discriminator loss: 0.6722%, acc.: 58.20%] [Generator loss: 0.8354%]\n",
            "3661 [Discriminator loss: 0.6796%, acc.: 54.30%] [Generator loss: 0.8097%]\n",
            "3662 [Discriminator loss: 0.6354%, acc.: 57.81%] [Generator loss: 0.8362%]\n",
            "3663 [Discriminator loss: 0.6670%, acc.: 54.69%] [Generator loss: 0.8401%]\n",
            "3664 [Discriminator loss: 0.6581%, acc.: 55.86%] [Generator loss: 0.8325%]\n",
            "3665 [Discriminator loss: 0.6554%, acc.: 55.47%] [Generator loss: 0.8477%]\n",
            "3666 [Discriminator loss: 0.6529%, acc.: 60.94%] [Generator loss: 0.8447%]\n",
            "3667 [Discriminator loss: 0.6759%, acc.: 52.73%] [Generator loss: 0.8607%]\n",
            "3668 [Discriminator loss: 0.6775%, acc.: 53.12%] [Generator loss: 0.8555%]\n",
            "3669 [Discriminator loss: 0.6625%, acc.: 55.47%] [Generator loss: 0.8593%]\n",
            "3670 [Discriminator loss: 0.6697%, acc.: 53.91%] [Generator loss: 0.8359%]\n",
            "3671 [Discriminator loss: 0.6759%, acc.: 55.47%] [Generator loss: 0.8164%]\n",
            "3672 [Discriminator loss: 0.6832%, acc.: 49.61%] [Generator loss: 0.8420%]\n",
            "3673 [Discriminator loss: 0.6721%, acc.: 55.47%] [Generator loss: 0.8419%]\n",
            "3674 [Discriminator loss: 0.6704%, acc.: 56.64%] [Generator loss: 0.8591%]\n",
            "3675 [Discriminator loss: 0.6649%, acc.: 53.12%] [Generator loss: 0.8441%]\n",
            "3676 [Discriminator loss: 0.6534%, acc.: 51.95%] [Generator loss: 0.8344%]\n",
            "3677 [Discriminator loss: 0.6725%, acc.: 53.12%] [Generator loss: 0.8784%]\n",
            "3678 [Discriminator loss: 0.6831%, acc.: 55.86%] [Generator loss: 0.8575%]\n",
            "3679 [Discriminator loss: 0.6809%, acc.: 56.25%] [Generator loss: 0.8278%]\n",
            "3680 [Discriminator loss: 0.6514%, acc.: 59.77%] [Generator loss: 0.8443%]\n",
            "3681 [Discriminator loss: 0.6610%, acc.: 55.86%] [Generator loss: 0.8664%]\n",
            "3682 [Discriminator loss: 0.6711%, acc.: 57.81%] [Generator loss: 0.8542%]\n",
            "3683 [Discriminator loss: 0.6694%, acc.: 55.08%] [Generator loss: 0.8410%]\n",
            "3684 [Discriminator loss: 0.6686%, acc.: 56.64%] [Generator loss: 0.8516%]\n",
            "3685 [Discriminator loss: 0.6444%, acc.: 57.42%] [Generator loss: 0.8598%]\n",
            "3686 [Discriminator loss: 0.6371%, acc.: 63.67%] [Generator loss: 0.8601%]\n",
            "3687 [Discriminator loss: 0.6522%, acc.: 62.11%] [Generator loss: 0.8611%]\n",
            "3688 [Discriminator loss: 0.6531%, acc.: 64.06%] [Generator loss: 0.8859%]\n",
            "3689 [Discriminator loss: 0.6428%, acc.: 64.84%] [Generator loss: 0.8744%]\n",
            "3690 [Discriminator loss: 0.6571%, acc.: 58.20%] [Generator loss: 0.8769%]\n",
            "3691 [Discriminator loss: 0.6324%, acc.: 67.58%] [Generator loss: 0.8726%]\n",
            "3692 [Discriminator loss: 0.6684%, acc.: 56.25%] [Generator loss: 0.8374%]\n",
            "3693 [Discriminator loss: 0.6695%, acc.: 60.16%] [Generator loss: 0.8423%]\n",
            "3694 [Discriminator loss: 0.6561%, acc.: 59.77%] [Generator loss: 0.8628%]\n",
            "3695 [Discriminator loss: 0.6628%, acc.: 60.16%] [Generator loss: 0.8444%]\n",
            "3696 [Discriminator loss: 0.6765%, acc.: 56.64%] [Generator loss: 0.8711%]\n",
            "3697 [Discriminator loss: 0.6564%, acc.: 62.50%] [Generator loss: 0.8677%]\n",
            "3698 [Discriminator loss: 0.6550%, acc.: 59.38%] [Generator loss: 0.8529%]\n",
            "3699 [Discriminator loss: 0.6424%, acc.: 64.45%] [Generator loss: 0.8739%]\n",
            "3700 [Discriminator loss: 0.6792%, acc.: 54.69%] [Generator loss: 0.8313%]\n",
            "3701 [Discriminator loss: 0.6715%, acc.: 57.81%] [Generator loss: 0.8457%]\n",
            "3702 [Discriminator loss: 0.6485%, acc.: 62.11%] [Generator loss: 0.8512%]\n",
            "3703 [Discriminator loss: 0.6650%, acc.: 59.38%] [Generator loss: 0.8614%]\n",
            "3704 [Discriminator loss: 0.6563%, acc.: 61.72%] [Generator loss: 0.8539%]\n",
            "3705 [Discriminator loss: 0.6403%, acc.: 67.58%] [Generator loss: 0.8703%]\n",
            "3706 [Discriminator loss: 0.6681%, acc.: 60.94%] [Generator loss: 0.8475%]\n",
            "3707 [Discriminator loss: 0.6804%, acc.: 55.08%] [Generator loss: 0.8161%]\n",
            "3708 [Discriminator loss: 0.6662%, acc.: 59.77%] [Generator loss: 0.8278%]\n",
            "3709 [Discriminator loss: 0.6515%, acc.: 59.38%] [Generator loss: 0.8467%]\n",
            "3710 [Discriminator loss: 0.6860%, acc.: 54.69%] [Generator loss: 0.8275%]\n",
            "3711 [Discriminator loss: 0.6762%, acc.: 54.69%] [Generator loss: 0.8304%]\n",
            "3712 [Discriminator loss: 0.6686%, acc.: 57.03%] [Generator loss: 0.8169%]\n",
            "3713 [Discriminator loss: 0.6658%, acc.: 60.16%] [Generator loss: 0.8104%]\n",
            "3714 [Discriminator loss: 0.6906%, acc.: 53.91%] [Generator loss: 0.8342%]\n",
            "3715 [Discriminator loss: 0.6689%, acc.: 55.86%] [Generator loss: 0.8075%]\n",
            "3716 [Discriminator loss: 0.6686%, acc.: 55.47%] [Generator loss: 0.8277%]\n",
            "3717 [Discriminator loss: 0.6668%, acc.: 55.86%] [Generator loss: 0.8260%]\n",
            "3718 [Discriminator loss: 0.6770%, acc.: 55.86%] [Generator loss: 0.8278%]\n",
            "3719 [Discriminator loss: 0.6478%, acc.: 65.62%] [Generator loss: 0.8354%]\n",
            "3720 [Discriminator loss: 0.6885%, acc.: 52.34%] [Generator loss: 0.8184%]\n",
            "3721 [Discriminator loss: 0.6684%, acc.: 60.16%] [Generator loss: 0.8476%]\n",
            "3722 [Discriminator loss: 0.6791%, acc.: 57.03%] [Generator loss: 0.8191%]\n",
            "3723 [Discriminator loss: 0.6717%, acc.: 58.59%] [Generator loss: 0.8233%]\n",
            "3724 [Discriminator loss: 0.6621%, acc.: 59.38%] [Generator loss: 0.8104%]\n",
            "3725 [Discriminator loss: 0.6714%, acc.: 54.69%] [Generator loss: 0.8244%]\n",
            "3726 [Discriminator loss: 0.6624%, acc.: 59.38%] [Generator loss: 0.8196%]\n",
            "3727 [Discriminator loss: 0.6777%, acc.: 52.73%] [Generator loss: 0.8206%]\n",
            "3728 [Discriminator loss: 0.6848%, acc.: 56.25%] [Generator loss: 0.8155%]\n",
            "3729 [Discriminator loss: 0.6635%, acc.: 58.20%] [Generator loss: 0.8216%]\n",
            "3730 [Discriminator loss: 0.6781%, acc.: 57.03%] [Generator loss: 0.8104%]\n",
            "3731 [Discriminator loss: 0.6555%, acc.: 58.59%] [Generator loss: 0.8227%]\n",
            "3732 [Discriminator loss: 0.6640%, acc.: 61.72%] [Generator loss: 0.8271%]\n",
            "3733 [Discriminator loss: 0.6660%, acc.: 60.16%] [Generator loss: 0.8286%]\n",
            "3734 [Discriminator loss: 0.6533%, acc.: 61.33%] [Generator loss: 0.8118%]\n",
            "3735 [Discriminator loss: 0.6689%, acc.: 57.03%] [Generator loss: 0.8219%]\n",
            "3736 [Discriminator loss: 0.6741%, acc.: 56.25%] [Generator loss: 0.8275%]\n",
            "3737 [Discriminator loss: 0.6932%, acc.: 51.56%] [Generator loss: 0.8037%]\n",
            "3738 [Discriminator loss: 0.6770%, acc.: 57.81%] [Generator loss: 0.7974%]\n",
            "3739 [Discriminator loss: 0.6850%, acc.: 51.17%] [Generator loss: 0.8033%]\n",
            "3740 [Discriminator loss: 0.6566%, acc.: 58.20%] [Generator loss: 0.8088%]\n",
            "3741 [Discriminator loss: 0.6615%, acc.: 59.38%] [Generator loss: 0.8026%]\n",
            "3742 [Discriminator loss: 0.6706%, acc.: 60.55%] [Generator loss: 0.7985%]\n",
            "3743 [Discriminator loss: 0.6807%, acc.: 53.52%] [Generator loss: 0.8381%]\n",
            "3744 [Discriminator loss: 0.6649%, acc.: 56.25%] [Generator loss: 0.8341%]\n",
            "3745 [Discriminator loss: 0.6884%, acc.: 50.39%] [Generator loss: 0.8146%]\n",
            "3746 [Discriminator loss: 0.6663%, acc.: 58.98%] [Generator loss: 0.8202%]\n",
            "3747 [Discriminator loss: 0.6695%, acc.: 53.91%] [Generator loss: 0.8021%]\n",
            "3748 [Discriminator loss: 0.6879%, acc.: 50.39%] [Generator loss: 0.8013%]\n",
            "3749 [Discriminator loss: 0.6601%, acc.: 60.16%] [Generator loss: 0.8135%]\n",
            "3750 [Discriminator loss: 0.6783%, acc.: 56.25%] [Generator loss: 0.8149%]\n",
            "3751 [Discriminator loss: 0.6791%, acc.: 58.20%] [Generator loss: 0.8225%]\n",
            "3752 [Discriminator loss: 0.6870%, acc.: 53.12%] [Generator loss: 0.8162%]\n",
            "3753 [Discriminator loss: 0.6668%, acc.: 57.42%] [Generator loss: 0.8213%]\n",
            "3754 [Discriminator loss: 0.6681%, acc.: 59.38%] [Generator loss: 0.8281%]\n",
            "3755 [Discriminator loss: 0.6859%, acc.: 55.47%] [Generator loss: 0.8258%]\n",
            "3756 [Discriminator loss: 0.6815%, acc.: 58.20%] [Generator loss: 0.8153%]\n",
            "3757 [Discriminator loss: 0.6709%, acc.: 59.77%] [Generator loss: 0.8096%]\n",
            "3758 [Discriminator loss: 0.6800%, acc.: 54.69%] [Generator loss: 0.8245%]\n",
            "3759 [Discriminator loss: 0.6716%, acc.: 54.69%] [Generator loss: 0.8435%]\n",
            "3760 [Discriminator loss: 0.6874%, acc.: 52.34%] [Generator loss: 0.8256%]\n",
            "3761 [Discriminator loss: 0.6702%, acc.: 60.55%] [Generator loss: 0.8138%]\n",
            "3762 [Discriminator loss: 0.7027%, acc.: 49.22%] [Generator loss: 0.7916%]\n",
            "3763 [Discriminator loss: 0.6869%, acc.: 53.91%] [Generator loss: 0.8086%]\n",
            "3764 [Discriminator loss: 0.6830%, acc.: 51.95%] [Generator loss: 0.8293%]\n",
            "3765 [Discriminator loss: 0.6730%, acc.: 53.91%] [Generator loss: 0.8126%]\n",
            "3766 [Discriminator loss: 0.6776%, acc.: 58.20%] [Generator loss: 0.8228%]\n",
            "3767 [Discriminator loss: 0.7027%, acc.: 51.95%] [Generator loss: 0.8158%]\n",
            "3768 [Discriminator loss: 0.6768%, acc.: 57.42%] [Generator loss: 0.8202%]\n",
            "3769 [Discriminator loss: 0.6672%, acc.: 58.98%] [Generator loss: 0.8073%]\n",
            "3770 [Discriminator loss: 0.6851%, acc.: 53.12%] [Generator loss: 0.8033%]\n",
            "3771 [Discriminator loss: 0.6822%, acc.: 56.25%] [Generator loss: 0.8190%]\n",
            "3772 [Discriminator loss: 0.6777%, acc.: 55.86%] [Generator loss: 0.8299%]\n",
            "3773 [Discriminator loss: 0.6800%, acc.: 53.52%] [Generator loss: 0.8382%]\n",
            "3774 [Discriminator loss: 0.6806%, acc.: 55.86%] [Generator loss: 0.8115%]\n",
            "3775 [Discriminator loss: 0.6732%, acc.: 58.59%] [Generator loss: 0.8261%]\n",
            "3776 [Discriminator loss: 0.6870%, acc.: 51.95%] [Generator loss: 0.7899%]\n",
            "3777 [Discriminator loss: 0.7016%, acc.: 51.17%] [Generator loss: 0.8003%]\n",
            "3778 [Discriminator loss: 0.6905%, acc.: 49.22%] [Generator loss: 0.8080%]\n",
            "3779 [Discriminator loss: 0.6714%, acc.: 57.42%] [Generator loss: 0.7955%]\n",
            "3780 [Discriminator loss: 0.6787%, acc.: 55.86%] [Generator loss: 0.8311%]\n",
            "3781 [Discriminator loss: 0.6783%, acc.: 55.86%] [Generator loss: 0.8473%]\n",
            "3782 [Discriminator loss: 0.6999%, acc.: 54.69%] [Generator loss: 0.8265%]\n",
            "3783 [Discriminator loss: 0.6716%, acc.: 52.73%] [Generator loss: 0.8495%]\n",
            "3784 [Discriminator loss: 0.6745%, acc.: 55.47%] [Generator loss: 0.8246%]\n",
            "3785 [Discriminator loss: 0.6785%, acc.: 55.86%] [Generator loss: 0.8160%]\n",
            "3786 [Discriminator loss: 0.6632%, acc.: 55.47%] [Generator loss: 0.8542%]\n",
            "3787 [Discriminator loss: 0.6739%, acc.: 54.30%] [Generator loss: 0.8374%]\n",
            "3788 [Discriminator loss: 0.6809%, acc.: 55.86%] [Generator loss: 0.8602%]\n",
            "3789 [Discriminator loss: 0.6749%, acc.: 53.12%] [Generator loss: 0.8281%]\n",
            "3790 [Discriminator loss: 0.6593%, acc.: 60.55%] [Generator loss: 0.8447%]\n",
            "3791 [Discriminator loss: 0.6604%, acc.: 61.72%] [Generator loss: 0.8259%]\n",
            "3792 [Discriminator loss: 0.6820%, acc.: 54.30%] [Generator loss: 0.8135%]\n",
            "3793 [Discriminator loss: 0.6680%, acc.: 57.03%] [Generator loss: 0.8468%]\n",
            "3794 [Discriminator loss: 0.6570%, acc.: 59.38%] [Generator loss: 0.8238%]\n",
            "3795 [Discriminator loss: 0.6878%, acc.: 53.91%] [Generator loss: 0.8115%]\n",
            "3796 [Discriminator loss: 0.6689%, acc.: 55.08%] [Generator loss: 0.8307%]\n",
            "3797 [Discriminator loss: 0.6902%, acc.: 49.61%] [Generator loss: 0.8200%]\n",
            "3798 [Discriminator loss: 0.6777%, acc.: 55.47%] [Generator loss: 0.8046%]\n",
            "3799 [Discriminator loss: 0.6771%, acc.: 54.69%] [Generator loss: 0.8079%]\n",
            "3800 [Discriminator loss: 0.6925%, acc.: 55.47%] [Generator loss: 0.8227%]\n",
            "3801 [Discriminator loss: 0.6697%, acc.: 53.91%] [Generator loss: 0.8276%]\n",
            "3802 [Discriminator loss: 0.6797%, acc.: 53.12%] [Generator loss: 0.8315%]\n",
            "3803 [Discriminator loss: 0.6855%, acc.: 51.17%] [Generator loss: 0.7970%]\n",
            "3804 [Discriminator loss: 0.6813%, acc.: 53.12%] [Generator loss: 0.8064%]\n",
            "3805 [Discriminator loss: 0.6815%, acc.: 55.86%] [Generator loss: 0.8043%]\n",
            "3806 [Discriminator loss: 0.6869%, acc.: 51.17%] [Generator loss: 0.8113%]\n",
            "3807 [Discriminator loss: 0.6933%, acc.: 51.17%] [Generator loss: 0.8104%]\n",
            "3808 [Discriminator loss: 0.6652%, acc.: 58.59%] [Generator loss: 0.8198%]\n",
            "3809 [Discriminator loss: 0.6622%, acc.: 59.77%] [Generator loss: 0.8059%]\n",
            "3810 [Discriminator loss: 0.6841%, acc.: 56.25%] [Generator loss: 0.8004%]\n",
            "3811 [Discriminator loss: 0.6830%, acc.: 54.69%] [Generator loss: 0.8003%]\n",
            "3812 [Discriminator loss: 0.6595%, acc.: 55.47%] [Generator loss: 0.8252%]\n",
            "3813 [Discriminator loss: 0.6704%, acc.: 57.42%] [Generator loss: 0.8203%]\n",
            "3814 [Discriminator loss: 0.6943%, acc.: 54.69%] [Generator loss: 0.8501%]\n",
            "3815 [Discriminator loss: 0.6811%, acc.: 59.77%] [Generator loss: 0.8161%]\n",
            "3816 [Discriminator loss: 0.6806%, acc.: 55.47%] [Generator loss: 0.8032%]\n",
            "3817 [Discriminator loss: 0.6816%, acc.: 55.08%] [Generator loss: 0.8255%]\n",
            "3818 [Discriminator loss: 0.6777%, acc.: 55.47%] [Generator loss: 0.8415%]\n",
            "3819 [Discriminator loss: 0.6691%, acc.: 60.16%] [Generator loss: 0.8299%]\n",
            "3820 [Discriminator loss: 0.6896%, acc.: 48.83%] [Generator loss: 0.8275%]\n",
            "3821 [Discriminator loss: 0.7006%, acc.: 52.73%] [Generator loss: 0.8407%]\n",
            "3822 [Discriminator loss: 0.6735%, acc.: 61.72%] [Generator loss: 0.8471%]\n",
            "3823 [Discriminator loss: 0.6574%, acc.: 58.98%] [Generator loss: 0.8259%]\n",
            "3824 [Discriminator loss: 0.6824%, acc.: 53.12%] [Generator loss: 0.8026%]\n",
            "3825 [Discriminator loss: 0.6796%, acc.: 55.08%] [Generator loss: 0.8142%]\n",
            "3826 [Discriminator loss: 0.6885%, acc.: 51.95%] [Generator loss: 0.8394%]\n",
            "3827 [Discriminator loss: 0.6693%, acc.: 55.08%] [Generator loss: 0.8243%]\n",
            "3828 [Discriminator loss: 0.6849%, acc.: 53.91%] [Generator loss: 0.8399%]\n",
            "3829 [Discriminator loss: 0.6743%, acc.: 53.12%] [Generator loss: 0.8384%]\n",
            "3830 [Discriminator loss: 0.6606%, acc.: 62.50%] [Generator loss: 0.8178%]\n",
            "3831 [Discriminator loss: 0.6805%, acc.: 55.86%] [Generator loss: 0.8332%]\n",
            "3832 [Discriminator loss: 0.6871%, acc.: 56.25%] [Generator loss: 0.8288%]\n",
            "3833 [Discriminator loss: 0.6851%, acc.: 55.47%] [Generator loss: 0.8261%]\n",
            "3834 [Discriminator loss: 0.6975%, acc.: 51.56%] [Generator loss: 0.8348%]\n",
            "3835 [Discriminator loss: 0.6902%, acc.: 55.86%] [Generator loss: 0.8212%]\n",
            "3836 [Discriminator loss: 0.6597%, acc.: 64.84%] [Generator loss: 0.8222%]\n",
            "3837 [Discriminator loss: 0.6712%, acc.: 58.98%] [Generator loss: 0.8296%]\n",
            "3838 [Discriminator loss: 0.6655%, acc.: 63.28%] [Generator loss: 0.8221%]\n",
            "3839 [Discriminator loss: 0.6640%, acc.: 58.20%] [Generator loss: 0.8326%]\n",
            "3840 [Discriminator loss: 0.6329%, acc.: 67.19%] [Generator loss: 0.8222%]\n",
            "3841 [Discriminator loss: 0.6376%, acc.: 64.45%] [Generator loss: 0.8331%]\n",
            "3842 [Discriminator loss: 0.6538%, acc.: 62.89%] [Generator loss: 0.8497%]\n",
            "3843 [Discriminator loss: 0.6582%, acc.: 59.77%] [Generator loss: 0.8468%]\n",
            "3844 [Discriminator loss: 0.6506%, acc.: 65.23%] [Generator loss: 0.8293%]\n",
            "3845 [Discriminator loss: 0.6814%, acc.: 58.20%] [Generator loss: 0.8259%]\n",
            "3846 [Discriminator loss: 0.6549%, acc.: 61.72%] [Generator loss: 0.8446%]\n",
            "3847 [Discriminator loss: 0.6602%, acc.: 64.45%] [Generator loss: 0.8169%]\n",
            "3848 [Discriminator loss: 0.6580%, acc.: 62.11%] [Generator loss: 0.8301%]\n",
            "3849 [Discriminator loss: 0.6512%, acc.: 66.80%] [Generator loss: 0.8475%]\n",
            "3850 [Discriminator loss: 0.6625%, acc.: 63.67%] [Generator loss: 0.8328%]\n",
            "3851 [Discriminator loss: 0.6649%, acc.: 56.25%] [Generator loss: 0.8352%]\n",
            "3852 [Discriminator loss: 0.6443%, acc.: 64.45%] [Generator loss: 0.8203%]\n",
            "3853 [Discriminator loss: 0.6317%, acc.: 67.19%] [Generator loss: 0.8304%]\n",
            "3854 [Discriminator loss: 0.6513%, acc.: 61.72%] [Generator loss: 0.8441%]\n",
            "3855 [Discriminator loss: 0.6524%, acc.: 60.94%] [Generator loss: 0.8341%]\n",
            "3856 [Discriminator loss: 0.6764%, acc.: 57.81%] [Generator loss: 0.8374%]\n",
            "3857 [Discriminator loss: 0.6654%, acc.: 60.55%] [Generator loss: 0.8393%]\n",
            "3858 [Discriminator loss: 0.6432%, acc.: 63.67%] [Generator loss: 0.8645%]\n",
            "3859 [Discriminator loss: 0.6602%, acc.: 59.77%] [Generator loss: 0.8513%]\n",
            "3860 [Discriminator loss: 0.6608%, acc.: 61.33%] [Generator loss: 0.8392%]\n",
            "3861 [Discriminator loss: 0.6494%, acc.: 64.06%] [Generator loss: 0.8424%]\n",
            "3862 [Discriminator loss: 0.6505%, acc.: 58.98%] [Generator loss: 0.8607%]\n",
            "3863 [Discriminator loss: 0.6460%, acc.: 65.62%] [Generator loss: 0.8302%]\n",
            "3864 [Discriminator loss: 0.6505%, acc.: 66.80%] [Generator loss: 0.8484%]\n",
            "3865 [Discriminator loss: 0.6660%, acc.: 62.11%] [Generator loss: 0.8381%]\n",
            "3866 [Discriminator loss: 0.6418%, acc.: 65.62%] [Generator loss: 0.8142%]\n",
            "3867 [Discriminator loss: 0.6640%, acc.: 62.50%] [Generator loss: 0.8212%]\n",
            "3868 [Discriminator loss: 0.6546%, acc.: 60.94%] [Generator loss: 0.8159%]\n",
            "3869 [Discriminator loss: 0.6930%, acc.: 55.47%] [Generator loss: 0.8235%]\n",
            "3870 [Discriminator loss: 0.6376%, acc.: 64.45%] [Generator loss: 0.8086%]\n",
            "3871 [Discriminator loss: 0.6782%, acc.: 60.16%] [Generator loss: 0.8436%]\n",
            "3872 [Discriminator loss: 0.6561%, acc.: 63.28%] [Generator loss: 0.8165%]\n",
            "3873 [Discriminator loss: 0.6552%, acc.: 64.06%] [Generator loss: 0.8335%]\n",
            "3874 [Discriminator loss: 0.6609%, acc.: 57.81%] [Generator loss: 0.8152%]\n",
            "3875 [Discriminator loss: 0.6611%, acc.: 57.03%] [Generator loss: 0.8299%]\n",
            "3876 [Discriminator loss: 0.6686%, acc.: 60.16%] [Generator loss: 0.8379%]\n",
            "3877 [Discriminator loss: 0.6682%, acc.: 56.25%] [Generator loss: 0.8103%]\n",
            "3878 [Discriminator loss: 0.6672%, acc.: 57.81%] [Generator loss: 0.8051%]\n",
            "3879 [Discriminator loss: 0.6777%, acc.: 55.86%] [Generator loss: 0.8228%]\n",
            "3880 [Discriminator loss: 0.6702%, acc.: 55.86%] [Generator loss: 0.8425%]\n",
            "3881 [Discriminator loss: 0.6573%, acc.: 60.16%] [Generator loss: 0.8450%]\n",
            "3882 [Discriminator loss: 0.6548%, acc.: 61.33%] [Generator loss: 0.8412%]\n",
            "3883 [Discriminator loss: 0.6622%, acc.: 61.72%] [Generator loss: 0.8430%]\n",
            "3884 [Discriminator loss: 0.6618%, acc.: 60.55%] [Generator loss: 0.8164%]\n",
            "3885 [Discriminator loss: 0.6972%, acc.: 49.61%] [Generator loss: 0.8158%]\n",
            "3886 [Discriminator loss: 0.6858%, acc.: 52.73%] [Generator loss: 0.8108%]\n",
            "3887 [Discriminator loss: 0.6784%, acc.: 49.61%] [Generator loss: 0.8389%]\n",
            "3888 [Discriminator loss: 0.6910%, acc.: 53.12%] [Generator loss: 0.8113%]\n",
            "3889 [Discriminator loss: 0.6870%, acc.: 51.56%] [Generator loss: 0.8152%]\n",
            "3890 [Discriminator loss: 0.6651%, acc.: 56.64%] [Generator loss: 0.8352%]\n",
            "3891 [Discriminator loss: 0.6947%, acc.: 51.95%] [Generator loss: 0.8295%]\n",
            "3892 [Discriminator loss: 0.6842%, acc.: 55.47%] [Generator loss: 0.8192%]\n",
            "3893 [Discriminator loss: 0.6931%, acc.: 50.00%] [Generator loss: 0.8217%]\n",
            "3894 [Discriminator loss: 0.6934%, acc.: 50.39%] [Generator loss: 0.8153%]\n",
            "3895 [Discriminator loss: 0.6932%, acc.: 52.73%] [Generator loss: 0.8277%]\n",
            "3896 [Discriminator loss: 0.6889%, acc.: 50.39%] [Generator loss: 0.8089%]\n",
            "3897 [Discriminator loss: 0.7022%, acc.: 48.44%] [Generator loss: 0.8063%]\n",
            "3898 [Discriminator loss: 0.6896%, acc.: 47.27%] [Generator loss: 0.8118%]\n",
            "3899 [Discriminator loss: 0.6774%, acc.: 50.00%] [Generator loss: 0.8182%]\n",
            "3900 [Discriminator loss: 0.6818%, acc.: 54.30%] [Generator loss: 0.8170%]\n",
            "3901 [Discriminator loss: 0.6906%, acc.: 49.22%] [Generator loss: 0.8060%]\n",
            "3902 [Discriminator loss: 0.7004%, acc.: 47.27%] [Generator loss: 0.7945%]\n",
            "3903 [Discriminator loss: 0.6738%, acc.: 54.30%] [Generator loss: 0.8234%]\n",
            "3904 [Discriminator loss: 0.6827%, acc.: 53.91%] [Generator loss: 0.8157%]\n",
            "3905 [Discriminator loss: 0.6794%, acc.: 55.86%] [Generator loss: 0.8109%]\n",
            "3906 [Discriminator loss: 0.6759%, acc.: 57.42%] [Generator loss: 0.8239%]\n",
            "3907 [Discriminator loss: 0.6966%, acc.: 52.73%] [Generator loss: 0.8193%]\n",
            "3908 [Discriminator loss: 0.6875%, acc.: 52.34%] [Generator loss: 0.8136%]\n",
            "3909 [Discriminator loss: 0.6609%, acc.: 56.64%] [Generator loss: 0.8282%]\n",
            "3910 [Discriminator loss: 0.6761%, acc.: 54.30%] [Generator loss: 0.8201%]\n",
            "3911 [Discriminator loss: 0.6845%, acc.: 52.34%] [Generator loss: 0.8164%]\n",
            "3912 [Discriminator loss: 0.6918%, acc.: 55.86%] [Generator loss: 0.7895%]\n",
            "3913 [Discriminator loss: 0.6951%, acc.: 48.44%] [Generator loss: 0.7796%]\n",
            "3914 [Discriminator loss: 0.6789%, acc.: 52.73%] [Generator loss: 0.7944%]\n",
            "3915 [Discriminator loss: 0.6729%, acc.: 58.20%] [Generator loss: 0.8009%]\n",
            "3916 [Discriminator loss: 0.6769%, acc.: 53.12%] [Generator loss: 0.8046%]\n",
            "3917 [Discriminator loss: 0.6573%, acc.: 57.81%] [Generator loss: 0.8026%]\n",
            "3918 [Discriminator loss: 0.6735%, acc.: 52.34%] [Generator loss: 0.8173%]\n",
            "3919 [Discriminator loss: 0.6599%, acc.: 60.16%] [Generator loss: 0.8112%]\n",
            "3920 [Discriminator loss: 0.6589%, acc.: 60.16%] [Generator loss: 0.8440%]\n",
            "3921 [Discriminator loss: 0.6834%, acc.: 56.64%] [Generator loss: 0.8173%]\n",
            "3922 [Discriminator loss: 0.6652%, acc.: 63.28%] [Generator loss: 0.8205%]\n",
            "3923 [Discriminator loss: 0.6602%, acc.: 62.89%] [Generator loss: 0.8153%]\n",
            "3924 [Discriminator loss: 0.6675%, acc.: 58.98%] [Generator loss: 0.8435%]\n",
            "3925 [Discriminator loss: 0.6590%, acc.: 61.72%] [Generator loss: 0.8131%]\n",
            "3926 [Discriminator loss: 0.6631%, acc.: 60.94%] [Generator loss: 0.7880%]\n",
            "3927 [Discriminator loss: 0.6643%, acc.: 58.59%] [Generator loss: 0.8187%]\n",
            "3928 [Discriminator loss: 0.6431%, acc.: 66.02%] [Generator loss: 0.8132%]\n",
            "3929 [Discriminator loss: 0.6956%, acc.: 51.95%] [Generator loss: 0.8153%]\n",
            "3930 [Discriminator loss: 0.6593%, acc.: 63.28%] [Generator loss: 0.8046%]\n",
            "3931 [Discriminator loss: 0.6716%, acc.: 57.81%] [Generator loss: 0.8212%]\n",
            "3932 [Discriminator loss: 0.6501%, acc.: 62.89%] [Generator loss: 0.8206%]\n",
            "3933 [Discriminator loss: 0.6625%, acc.: 59.77%] [Generator loss: 0.8327%]\n",
            "3934 [Discriminator loss: 0.6420%, acc.: 64.45%] [Generator loss: 0.8304%]\n",
            "3935 [Discriminator loss: 0.6402%, acc.: 66.80%] [Generator loss: 0.8509%]\n",
            "3936 [Discriminator loss: 0.6590%, acc.: 60.16%] [Generator loss: 0.8332%]\n",
            "3937 [Discriminator loss: 0.6577%, acc.: 58.59%] [Generator loss: 0.8607%]\n",
            "3938 [Discriminator loss: 0.6647%, acc.: 58.98%] [Generator loss: 0.8324%]\n",
            "3939 [Discriminator loss: 0.6778%, acc.: 57.03%] [Generator loss: 0.8265%]\n",
            "3940 [Discriminator loss: 0.6765%, acc.: 55.08%] [Generator loss: 0.8457%]\n",
            "3941 [Discriminator loss: 0.6600%, acc.: 60.16%] [Generator loss: 0.8333%]\n",
            "3942 [Discriminator loss: 0.6794%, acc.: 55.47%] [Generator loss: 0.8347%]\n",
            "3943 [Discriminator loss: 0.6627%, acc.: 60.16%] [Generator loss: 0.8381%]\n",
            "3944 [Discriminator loss: 0.6823%, acc.: 55.47%] [Generator loss: 0.8269%]\n",
            "3945 [Discriminator loss: 0.6642%, acc.: 56.64%] [Generator loss: 0.8153%]\n",
            "3946 [Discriminator loss: 0.6481%, acc.: 61.33%] [Generator loss: 0.8464%]\n",
            "3947 [Discriminator loss: 0.6746%, acc.: 55.86%] [Generator loss: 0.8336%]\n",
            "3948 [Discriminator loss: 0.6761%, acc.: 58.20%] [Generator loss: 0.7981%]\n",
            "3949 [Discriminator loss: 0.6520%, acc.: 61.72%] [Generator loss: 0.8019%]\n",
            "3950 [Discriminator loss: 0.6546%, acc.: 59.38%] [Generator loss: 0.8280%]\n",
            "3951 [Discriminator loss: 0.6738%, acc.: 57.81%] [Generator loss: 0.8162%]\n",
            "3952 [Discriminator loss: 0.6614%, acc.: 58.98%] [Generator loss: 0.8100%]\n",
            "3953 [Discriminator loss: 0.6564%, acc.: 62.50%] [Generator loss: 0.8320%]\n",
            "3954 [Discriminator loss: 0.6831%, acc.: 51.95%] [Generator loss: 0.8174%]\n",
            "3955 [Discriminator loss: 0.6838%, acc.: 52.73%] [Generator loss: 0.8291%]\n",
            "3956 [Discriminator loss: 0.6751%, acc.: 54.69%] [Generator loss: 0.8198%]\n",
            "3957 [Discriminator loss: 0.6621%, acc.: 57.81%] [Generator loss: 0.8208%]\n",
            "3958 [Discriminator loss: 0.6563%, acc.: 59.77%] [Generator loss: 0.8145%]\n",
            "3959 [Discriminator loss: 0.6730%, acc.: 55.08%] [Generator loss: 0.8088%]\n",
            "3960 [Discriminator loss: 0.6783%, acc.: 57.42%] [Generator loss: 0.8165%]\n",
            "3961 [Discriminator loss: 0.6702%, acc.: 54.69%] [Generator loss: 0.8186%]\n",
            "3962 [Discriminator loss: 0.6677%, acc.: 58.98%] [Generator loss: 0.8246%]\n",
            "3963 [Discriminator loss: 0.6591%, acc.: 59.77%] [Generator loss: 0.8348%]\n",
            "3964 [Discriminator loss: 0.6776%, acc.: 55.86%] [Generator loss: 0.8408%]\n",
            "3965 [Discriminator loss: 0.6922%, acc.: 49.61%] [Generator loss: 0.8283%]\n",
            "3966 [Discriminator loss: 0.6830%, acc.: 56.25%] [Generator loss: 0.8185%]\n",
            "3967 [Discriminator loss: 0.6566%, acc.: 59.38%] [Generator loss: 0.8072%]\n",
            "3968 [Discriminator loss: 0.6719%, acc.: 57.42%] [Generator loss: 0.8105%]\n",
            "3969 [Discriminator loss: 0.6987%, acc.: 49.61%] [Generator loss: 0.8205%]\n",
            "3970 [Discriminator loss: 0.6571%, acc.: 58.20%] [Generator loss: 0.8289%]\n",
            "3971 [Discriminator loss: 0.6615%, acc.: 60.55%] [Generator loss: 0.8221%]\n",
            "3972 [Discriminator loss: 0.6645%, acc.: 59.38%] [Generator loss: 0.8383%]\n",
            "3973 [Discriminator loss: 0.6651%, acc.: 60.55%] [Generator loss: 0.8280%]\n",
            "3974 [Discriminator loss: 0.6534%, acc.: 65.62%] [Generator loss: 0.8097%]\n",
            "3975 [Discriminator loss: 0.6588%, acc.: 58.59%] [Generator loss: 0.8351%]\n",
            "3976 [Discriminator loss: 0.6614%, acc.: 57.42%] [Generator loss: 0.8302%]\n",
            "3977 [Discriminator loss: 0.6642%, acc.: 61.33%] [Generator loss: 0.8518%]\n",
            "3978 [Discriminator loss: 0.6642%, acc.: 60.55%] [Generator loss: 0.8337%]\n",
            "3979 [Discriminator loss: 0.6479%, acc.: 61.72%] [Generator loss: 0.8308%]\n",
            "3980 [Discriminator loss: 0.6424%, acc.: 64.84%] [Generator loss: 0.8402%]\n",
            "3981 [Discriminator loss: 0.6554%, acc.: 62.50%] [Generator loss: 0.8443%]\n",
            "3982 [Discriminator loss: 0.6464%, acc.: 64.84%] [Generator loss: 0.8618%]\n",
            "3983 [Discriminator loss: 0.6595%, acc.: 58.59%] [Generator loss: 0.8501%]\n",
            "3984 [Discriminator loss: 0.6599%, acc.: 61.72%] [Generator loss: 0.8390%]\n",
            "3985 [Discriminator loss: 0.6631%, acc.: 55.86%] [Generator loss: 0.8194%]\n",
            "3986 [Discriminator loss: 0.6609%, acc.: 59.38%] [Generator loss: 0.8121%]\n",
            "3987 [Discriminator loss: 0.6671%, acc.: 55.47%] [Generator loss: 0.8320%]\n",
            "3988 [Discriminator loss: 0.6450%, acc.: 63.67%] [Generator loss: 0.8403%]\n",
            "3989 [Discriminator loss: 0.6741%, acc.: 55.08%] [Generator loss: 0.8205%]\n",
            "3990 [Discriminator loss: 0.6322%, acc.: 66.41%] [Generator loss: 0.8410%]\n",
            "3991 [Discriminator loss: 0.6607%, acc.: 60.94%] [Generator loss: 0.8396%]\n",
            "3992 [Discriminator loss: 0.6511%, acc.: 58.59%] [Generator loss: 0.8444%]\n",
            "3993 [Discriminator loss: 0.6573%, acc.: 58.59%] [Generator loss: 0.8409%]\n",
            "3994 [Discriminator loss: 0.6617%, acc.: 59.77%] [Generator loss: 0.8100%]\n",
            "3995 [Discriminator loss: 0.6428%, acc.: 63.67%] [Generator loss: 0.7986%]\n",
            "3996 [Discriminator loss: 0.6644%, acc.: 58.59%] [Generator loss: 0.8016%]\n",
            "3997 [Discriminator loss: 0.6527%, acc.: 58.59%] [Generator loss: 0.8169%]\n",
            "3998 [Discriminator loss: 0.6584%, acc.: 58.20%] [Generator loss: 0.8378%]\n",
            "3999 [Discriminator loss: 0.6557%, acc.: 59.38%] [Generator loss: 0.8484%]\n",
            "4000 [Discriminator loss: 0.6532%, acc.: 59.38%] [Generator loss: 0.8610%]\n",
            "4001 [Discriminator loss: 0.6407%, acc.: 64.06%] [Generator loss: 0.8355%]\n",
            "4002 [Discriminator loss: 0.6552%, acc.: 59.77%] [Generator loss: 0.8530%]\n",
            "4003 [Discriminator loss: 0.6568%, acc.: 60.16%] [Generator loss: 0.8420%]\n",
            "4004 [Discriminator loss: 0.6399%, acc.: 63.28%] [Generator loss: 0.8477%]\n",
            "4005 [Discriminator loss: 0.6632%, acc.: 62.11%] [Generator loss: 0.8585%]\n",
            "4006 [Discriminator loss: 0.6567%, acc.: 61.72%] [Generator loss: 0.8304%]\n",
            "4007 [Discriminator loss: 0.6366%, acc.: 67.19%] [Generator loss: 0.8596%]\n",
            "4008 [Discriminator loss: 0.6828%, acc.: 55.86%] [Generator loss: 0.8355%]\n",
            "4009 [Discriminator loss: 0.6619%, acc.: 59.38%] [Generator loss: 0.8152%]\n",
            "4010 [Discriminator loss: 0.6498%, acc.: 60.55%] [Generator loss: 0.8349%]\n",
            "4011 [Discriminator loss: 0.6491%, acc.: 64.84%] [Generator loss: 0.8469%]\n",
            "4012 [Discriminator loss: 0.6433%, acc.: 62.89%] [Generator loss: 0.8253%]\n",
            "4013 [Discriminator loss: 0.6470%, acc.: 58.20%] [Generator loss: 0.8381%]\n",
            "4014 [Discriminator loss: 0.6319%, acc.: 63.67%] [Generator loss: 0.8264%]\n",
            "4015 [Discriminator loss: 0.6377%, acc.: 62.50%] [Generator loss: 0.8436%]\n",
            "4016 [Discriminator loss: 0.6454%, acc.: 60.94%] [Generator loss: 0.8515%]\n",
            "4017 [Discriminator loss: 0.6510%, acc.: 60.94%] [Generator loss: 0.8285%]\n",
            "4018 [Discriminator loss: 0.6472%, acc.: 60.94%] [Generator loss: 0.8527%]\n",
            "4019 [Discriminator loss: 0.6357%, acc.: 62.89%] [Generator loss: 0.8523%]\n",
            "4020 [Discriminator loss: 0.6456%, acc.: 62.50%] [Generator loss: 0.8336%]\n",
            "4021 [Discriminator loss: 0.6709%, acc.: 57.81%] [Generator loss: 0.8270%]\n",
            "4022 [Discriminator loss: 0.6548%, acc.: 60.16%] [Generator loss: 0.8558%]\n",
            "4023 [Discriminator loss: 0.6341%, acc.: 63.67%] [Generator loss: 0.8742%]\n",
            "4024 [Discriminator loss: 0.6527%, acc.: 63.28%] [Generator loss: 0.8557%]\n",
            "4025 [Discriminator loss: 0.6411%, acc.: 62.89%] [Generator loss: 0.8489%]\n",
            "4026 [Discriminator loss: 0.6593%, acc.: 59.38%] [Generator loss: 0.8199%]\n",
            "4027 [Discriminator loss: 0.6620%, acc.: 55.86%] [Generator loss: 0.8161%]\n",
            "4028 [Discriminator loss: 0.6383%, acc.: 61.72%] [Generator loss: 0.8504%]\n",
            "4029 [Discriminator loss: 0.6404%, acc.: 65.23%] [Generator loss: 0.8401%]\n",
            "4030 [Discriminator loss: 0.6551%, acc.: 61.33%] [Generator loss: 0.8439%]\n",
            "4031 [Discriminator loss: 0.6748%, acc.: 58.59%] [Generator loss: 0.8261%]\n",
            "4032 [Discriminator loss: 0.6571%, acc.: 57.03%] [Generator loss: 0.8431%]\n",
            "4033 [Discriminator loss: 0.6311%, acc.: 64.06%] [Generator loss: 0.8468%]\n",
            "4034 [Discriminator loss: 0.6546%, acc.: 60.16%] [Generator loss: 0.8543%]\n",
            "4035 [Discriminator loss: 0.6415%, acc.: 63.28%] [Generator loss: 0.8555%]\n",
            "4036 [Discriminator loss: 0.6590%, acc.: 61.33%] [Generator loss: 0.8493%]\n",
            "4037 [Discriminator loss: 0.6448%, acc.: 63.28%] [Generator loss: 0.8487%]\n",
            "4038 [Discriminator loss: 0.6670%, acc.: 56.25%] [Generator loss: 0.8062%]\n",
            "4039 [Discriminator loss: 0.6514%, acc.: 55.86%] [Generator loss: 0.8147%]\n",
            "4040 [Discriminator loss: 0.6410%, acc.: 60.16%] [Generator loss: 0.8055%]\n",
            "4041 [Discriminator loss: 0.6712%, acc.: 52.73%] [Generator loss: 0.8372%]\n",
            "4042 [Discriminator loss: 0.6811%, acc.: 52.34%] [Generator loss: 0.8470%]\n",
            "4043 [Discriminator loss: 0.6595%, acc.: 58.98%] [Generator loss: 0.8448%]\n",
            "4044 [Discriminator loss: 0.6555%, acc.: 60.94%] [Generator loss: 0.8262%]\n",
            "4045 [Discriminator loss: 0.6706%, acc.: 59.38%] [Generator loss: 0.8356%]\n",
            "4046 [Discriminator loss: 0.6688%, acc.: 57.03%] [Generator loss: 0.8184%]\n",
            "4047 [Discriminator loss: 0.6239%, acc.: 70.31%] [Generator loss: 0.8158%]\n",
            "4048 [Discriminator loss: 0.6629%, acc.: 61.33%] [Generator loss: 0.8189%]\n",
            "4049 [Discriminator loss: 0.6760%, acc.: 54.69%] [Generator loss: 0.8463%]\n",
            "4050 [Discriminator loss: 0.6542%, acc.: 60.94%] [Generator loss: 0.8473%]\n",
            "4051 [Discriminator loss: 0.6527%, acc.: 61.72%] [Generator loss: 0.8356%]\n",
            "4052 [Discriminator loss: 0.6630%, acc.: 58.59%] [Generator loss: 0.8382%]\n",
            "4053 [Discriminator loss: 0.6652%, acc.: 58.20%] [Generator loss: 0.8373%]\n",
            "4054 [Discriminator loss: 0.6715%, acc.: 56.25%] [Generator loss: 0.8115%]\n",
            "4055 [Discriminator loss: 0.6658%, acc.: 55.86%] [Generator loss: 0.8455%]\n",
            "4056 [Discriminator loss: 0.6713%, acc.: 52.73%] [Generator loss: 0.8302%]\n",
            "4057 [Discriminator loss: 0.6976%, acc.: 49.61%] [Generator loss: 0.8260%]\n",
            "4058 [Discriminator loss: 0.6606%, acc.: 60.16%] [Generator loss: 0.8375%]\n",
            "4059 [Discriminator loss: 0.6632%, acc.: 58.98%] [Generator loss: 0.8423%]\n",
            "4060 [Discriminator loss: 0.6741%, acc.: 58.20%] [Generator loss: 0.8434%]\n",
            "4061 [Discriminator loss: 0.6734%, acc.: 57.42%] [Generator loss: 0.8346%]\n",
            "4062 [Discriminator loss: 0.6739%, acc.: 55.47%] [Generator loss: 0.8207%]\n",
            "4063 [Discriminator loss: 0.6771%, acc.: 52.73%] [Generator loss: 0.8016%]\n",
            "4064 [Discriminator loss: 0.6919%, acc.: 51.56%] [Generator loss: 0.8120%]\n",
            "4065 [Discriminator loss: 0.6717%, acc.: 57.42%] [Generator loss: 0.7832%]\n",
            "4066 [Discriminator loss: 0.6952%, acc.: 51.17%] [Generator loss: 0.8257%]\n",
            "4067 [Discriminator loss: 0.6964%, acc.: 49.61%] [Generator loss: 0.8510%]\n",
            "4068 [Discriminator loss: 0.6785%, acc.: 55.08%] [Generator loss: 0.8406%]\n",
            "4069 [Discriminator loss: 0.6627%, acc.: 61.33%] [Generator loss: 0.8396%]\n",
            "4070 [Discriminator loss: 0.6836%, acc.: 57.42%] [Generator loss: 0.8236%]\n",
            "4071 [Discriminator loss: 0.6679%, acc.: 57.42%] [Generator loss: 0.8216%]\n",
            "4072 [Discriminator loss: 0.6794%, acc.: 51.95%] [Generator loss: 0.8660%]\n",
            "4073 [Discriminator loss: 0.6619%, acc.: 61.33%] [Generator loss: 0.8361%]\n",
            "4074 [Discriminator loss: 0.6892%, acc.: 53.91%] [Generator loss: 0.8426%]\n",
            "4075 [Discriminator loss: 0.6721%, acc.: 57.42%] [Generator loss: 0.8412%]\n",
            "4076 [Discriminator loss: 0.6833%, acc.: 56.25%] [Generator loss: 0.8631%]\n",
            "4077 [Discriminator loss: 0.6785%, acc.: 54.30%] [Generator loss: 0.8442%]\n",
            "4078 [Discriminator loss: 0.6782%, acc.: 56.64%] [Generator loss: 0.8527%]\n",
            "4079 [Discriminator loss: 0.6748%, acc.: 58.98%] [Generator loss: 0.8381%]\n",
            "4080 [Discriminator loss: 0.6686%, acc.: 57.03%] [Generator loss: 0.8282%]\n",
            "4081 [Discriminator loss: 0.6729%, acc.: 60.55%] [Generator loss: 0.8266%]\n",
            "4082 [Discriminator loss: 0.6949%, acc.: 50.39%] [Generator loss: 0.8724%]\n",
            "4083 [Discriminator loss: 0.6567%, acc.: 62.50%] [Generator loss: 0.8383%]\n",
            "4084 [Discriminator loss: 0.6561%, acc.: 64.06%] [Generator loss: 0.8705%]\n",
            "4085 [Discriminator loss: 0.6888%, acc.: 56.25%] [Generator loss: 0.8590%]\n",
            "4086 [Discriminator loss: 0.6806%, acc.: 54.69%] [Generator loss: 0.8257%]\n",
            "4087 [Discriminator loss: 0.6795%, acc.: 55.08%] [Generator loss: 0.8329%]\n",
            "4088 [Discriminator loss: 0.6921%, acc.: 56.25%] [Generator loss: 0.8508%]\n",
            "4089 [Discriminator loss: 0.6909%, acc.: 54.30%] [Generator loss: 0.8305%]\n",
            "4090 [Discriminator loss: 0.7048%, acc.: 48.83%] [Generator loss: 0.8228%]\n",
            "4091 [Discriminator loss: 0.6957%, acc.: 50.78%] [Generator loss: 0.8029%]\n",
            "4092 [Discriminator loss: 0.6814%, acc.: 54.69%] [Generator loss: 0.8293%]\n",
            "4093 [Discriminator loss: 0.7018%, acc.: 50.78%] [Generator loss: 0.8266%]\n",
            "4094 [Discriminator loss: 0.6702%, acc.: 58.20%] [Generator loss: 0.8426%]\n",
            "4095 [Discriminator loss: 0.6830%, acc.: 52.34%] [Generator loss: 0.8230%]\n",
            "4096 [Discriminator loss: 0.6967%, acc.: 55.47%] [Generator loss: 0.8005%]\n",
            "4097 [Discriminator loss: 0.6823%, acc.: 55.86%] [Generator loss: 0.8217%]\n",
            "4098 [Discriminator loss: 0.6807%, acc.: 57.03%] [Generator loss: 0.8278%]\n",
            "4099 [Discriminator loss: 0.6800%, acc.: 53.52%] [Generator loss: 0.8286%]\n",
            "4100 [Discriminator loss: 0.6662%, acc.: 57.81%] [Generator loss: 0.8326%]\n",
            "4101 [Discriminator loss: 0.6818%, acc.: 51.17%] [Generator loss: 0.8577%]\n",
            "4102 [Discriminator loss: 0.6874%, acc.: 55.86%] [Generator loss: 0.8474%]\n",
            "4103 [Discriminator loss: 0.6802%, acc.: 56.25%] [Generator loss: 0.8390%]\n",
            "4104 [Discriminator loss: 0.6942%, acc.: 52.34%] [Generator loss: 0.8261%]\n",
            "4105 [Discriminator loss: 0.6691%, acc.: 57.42%] [Generator loss: 0.8128%]\n",
            "4106 [Discriminator loss: 0.6742%, acc.: 55.86%] [Generator loss: 0.8320%]\n",
            "4107 [Discriminator loss: 0.6972%, acc.: 53.91%] [Generator loss: 0.8479%]\n",
            "4108 [Discriminator loss: 0.6505%, acc.: 65.23%] [Generator loss: 0.8272%]\n",
            "4109 [Discriminator loss: 0.6766%, acc.: 60.16%] [Generator loss: 0.8000%]\n",
            "4110 [Discriminator loss: 0.6576%, acc.: 60.55%] [Generator loss: 0.8417%]\n",
            "4111 [Discriminator loss: 0.6593%, acc.: 60.94%] [Generator loss: 0.8344%]\n",
            "4112 [Discriminator loss: 0.6656%, acc.: 60.55%] [Generator loss: 0.8186%]\n",
            "4113 [Discriminator loss: 0.6797%, acc.: 55.47%] [Generator loss: 0.8129%]\n",
            "4114 [Discriminator loss: 0.6761%, acc.: 57.42%] [Generator loss: 0.8056%]\n",
            "4115 [Discriminator loss: 0.6697%, acc.: 58.20%] [Generator loss: 0.8381%]\n",
            "4116 [Discriminator loss: 0.6784%, acc.: 57.03%] [Generator loss: 0.8314%]\n",
            "4117 [Discriminator loss: 0.6638%, acc.: 60.94%] [Generator loss: 0.8283%]\n",
            "4118 [Discriminator loss: 0.6779%, acc.: 55.86%] [Generator loss: 0.8265%]\n",
            "4119 [Discriminator loss: 0.6778%, acc.: 60.16%] [Generator loss: 0.8248%]\n",
            "4120 [Discriminator loss: 0.6694%, acc.: 58.20%] [Generator loss: 0.8246%]\n",
            "4121 [Discriminator loss: 0.6680%, acc.: 60.94%] [Generator loss: 0.8297%]\n",
            "4122 [Discriminator loss: 0.6915%, acc.: 52.73%] [Generator loss: 0.8196%]\n",
            "4123 [Discriminator loss: 0.6589%, acc.: 64.45%] [Generator loss: 0.8247%]\n",
            "4124 [Discriminator loss: 0.6775%, acc.: 58.59%] [Generator loss: 0.8428%]\n",
            "4125 [Discriminator loss: 0.6763%, acc.: 60.16%] [Generator loss: 0.8180%]\n",
            "4126 [Discriminator loss: 0.6929%, acc.: 54.30%] [Generator loss: 0.8156%]\n",
            "4127 [Discriminator loss: 0.6669%, acc.: 60.55%] [Generator loss: 0.8231%]\n",
            "4128 [Discriminator loss: 0.6882%, acc.: 61.33%] [Generator loss: 0.8151%]\n",
            "4129 [Discriminator loss: 0.6703%, acc.: 60.94%] [Generator loss: 0.8226%]\n",
            "4130 [Discriminator loss: 0.7015%, acc.: 51.17%] [Generator loss: 0.8021%]\n",
            "4131 [Discriminator loss: 0.7017%, acc.: 48.44%] [Generator loss: 0.8422%]\n",
            "4132 [Discriminator loss: 0.7053%, acc.: 51.95%] [Generator loss: 0.8031%]\n",
            "4133 [Discriminator loss: 0.6803%, acc.: 56.25%] [Generator loss: 0.7979%]\n",
            "4134 [Discriminator loss: 0.6901%, acc.: 51.17%] [Generator loss: 0.8207%]\n",
            "4135 [Discriminator loss: 0.6765%, acc.: 56.64%] [Generator loss: 0.7970%]\n",
            "4136 [Discriminator loss: 0.6609%, acc.: 58.98%] [Generator loss: 0.7936%]\n",
            "4137 [Discriminator loss: 0.6617%, acc.: 57.03%] [Generator loss: 0.8146%]\n",
            "4138 [Discriminator loss: 0.6904%, acc.: 51.56%] [Generator loss: 0.8206%]\n",
            "4139 [Discriminator loss: 0.6785%, acc.: 60.55%] [Generator loss: 0.8131%]\n",
            "4140 [Discriminator loss: 0.6760%, acc.: 55.86%] [Generator loss: 0.8143%]\n",
            "4141 [Discriminator loss: 0.6753%, acc.: 54.30%] [Generator loss: 0.8216%]\n",
            "4142 [Discriminator loss: 0.6554%, acc.: 63.28%] [Generator loss: 0.8311%]\n",
            "4143 [Discriminator loss: 0.6776%, acc.: 57.03%] [Generator loss: 0.8220%]\n",
            "4144 [Discriminator loss: 0.6856%, acc.: 55.47%] [Generator loss: 0.8064%]\n",
            "4145 [Discriminator loss: 0.6772%, acc.: 55.86%] [Generator loss: 0.8173%]\n",
            "4146 [Discriminator loss: 0.6869%, acc.: 52.73%] [Generator loss: 0.8160%]\n",
            "4147 [Discriminator loss: 0.6802%, acc.: 57.81%] [Generator loss: 0.7910%]\n",
            "4148 [Discriminator loss: 0.6655%, acc.: 61.72%] [Generator loss: 0.8255%]\n",
            "4149 [Discriminator loss: 0.6675%, acc.: 60.94%] [Generator loss: 0.8372%]\n",
            "4150 [Discriminator loss: 0.6508%, acc.: 64.06%] [Generator loss: 0.8098%]\n",
            "4151 [Discriminator loss: 0.6749%, acc.: 61.33%] [Generator loss: 0.8281%]\n",
            "4152 [Discriminator loss: 0.6763%, acc.: 57.42%] [Generator loss: 0.8088%]\n",
            "4153 [Discriminator loss: 0.6734%, acc.: 58.98%] [Generator loss: 0.8103%]\n",
            "4154 [Discriminator loss: 0.6593%, acc.: 58.59%] [Generator loss: 0.8190%]\n",
            "4155 [Discriminator loss: 0.6839%, acc.: 55.08%] [Generator loss: 0.8101%]\n",
            "4156 [Discriminator loss: 0.6828%, acc.: 55.08%] [Generator loss: 0.8063%]\n",
            "4157 [Discriminator loss: 0.6721%, acc.: 56.64%] [Generator loss: 0.8061%]\n",
            "4158 [Discriminator loss: 0.6466%, acc.: 64.06%] [Generator loss: 0.8033%]\n",
            "4159 [Discriminator loss: 0.6461%, acc.: 65.62%] [Generator loss: 0.8023%]\n",
            "4160 [Discriminator loss: 0.6712%, acc.: 58.59%] [Generator loss: 0.8021%]\n",
            "4161 [Discriminator loss: 0.6803%, acc.: 55.47%] [Generator loss: 0.8352%]\n",
            "4162 [Discriminator loss: 0.6430%, acc.: 64.84%] [Generator loss: 0.8361%]\n",
            "4163 [Discriminator loss: 0.6700%, acc.: 61.72%] [Generator loss: 0.8198%]\n",
            "4164 [Discriminator loss: 0.6712%, acc.: 58.98%] [Generator loss: 0.8146%]\n",
            "4165 [Discriminator loss: 0.6717%, acc.: 56.64%] [Generator loss: 0.7982%]\n",
            "4166 [Discriminator loss: 0.6590%, acc.: 61.33%] [Generator loss: 0.7966%]\n",
            "4167 [Discriminator loss: 0.6537%, acc.: 62.11%] [Generator loss: 0.8004%]\n",
            "4168 [Discriminator loss: 0.6480%, acc.: 67.19%] [Generator loss: 0.8431%]\n",
            "4169 [Discriminator loss: 0.6548%, acc.: 60.55%] [Generator loss: 0.8149%]\n",
            "4170 [Discriminator loss: 0.6360%, acc.: 71.09%] [Generator loss: 0.8211%]\n",
            "4171 [Discriminator loss: 0.6728%, acc.: 60.55%] [Generator loss: 0.8213%]\n",
            "4172 [Discriminator loss: 0.6463%, acc.: 58.98%] [Generator loss: 0.8076%]\n",
            "4173 [Discriminator loss: 0.6506%, acc.: 62.89%] [Generator loss: 0.8109%]\n",
            "4174 [Discriminator loss: 0.6543%, acc.: 62.89%] [Generator loss: 0.8208%]\n",
            "4175 [Discriminator loss: 0.6620%, acc.: 58.98%] [Generator loss: 0.8045%]\n",
            "4176 [Discriminator loss: 0.6627%, acc.: 59.38%] [Generator loss: 0.8181%]\n",
            "4177 [Discriminator loss: 0.6461%, acc.: 63.67%] [Generator loss: 0.8546%]\n",
            "4178 [Discriminator loss: 0.6587%, acc.: 55.08%] [Generator loss: 0.8186%]\n",
            "4179 [Discriminator loss: 0.6560%, acc.: 62.11%] [Generator loss: 0.8258%]\n",
            "4180 [Discriminator loss: 0.6671%, acc.: 60.16%] [Generator loss: 0.8160%]\n",
            "4181 [Discriminator loss: 0.6503%, acc.: 58.98%] [Generator loss: 0.8080%]\n",
            "4182 [Discriminator loss: 0.6632%, acc.: 60.16%] [Generator loss: 0.8318%]\n",
            "4183 [Discriminator loss: 0.6701%, acc.: 55.47%] [Generator loss: 0.7918%]\n",
            "4184 [Discriminator loss: 0.6689%, acc.: 61.72%] [Generator loss: 0.7987%]\n",
            "4185 [Discriminator loss: 0.6491%, acc.: 60.55%] [Generator loss: 0.8058%]\n",
            "4186 [Discriminator loss: 0.6545%, acc.: 60.94%] [Generator loss: 0.8049%]\n",
            "4187 [Discriminator loss: 0.6606%, acc.: 59.38%] [Generator loss: 0.7866%]\n",
            "4188 [Discriminator loss: 0.6620%, acc.: 58.98%] [Generator loss: 0.7869%]\n",
            "4189 [Discriminator loss: 0.6576%, acc.: 59.38%] [Generator loss: 0.8067%]\n",
            "4190 [Discriminator loss: 0.6687%, acc.: 59.38%] [Generator loss: 0.8140%]\n",
            "4191 [Discriminator loss: 0.6644%, acc.: 56.64%] [Generator loss: 0.8158%]\n",
            "4192 [Discriminator loss: 0.6642%, acc.: 57.42%] [Generator loss: 0.8083%]\n",
            "4193 [Discriminator loss: 0.6655%, acc.: 57.42%] [Generator loss: 0.8263%]\n",
            "4194 [Discriminator loss: 0.6423%, acc.: 63.28%] [Generator loss: 0.8157%]\n",
            "4195 [Discriminator loss: 0.6622%, acc.: 59.38%] [Generator loss: 0.8416%]\n",
            "4196 [Discriminator loss: 0.6826%, acc.: 57.81%] [Generator loss: 0.8064%]\n",
            "4197 [Discriminator loss: 0.6579%, acc.: 60.55%] [Generator loss: 0.8286%]\n",
            "4198 [Discriminator loss: 0.6561%, acc.: 60.94%] [Generator loss: 0.8211%]\n",
            "4199 [Discriminator loss: 0.6867%, acc.: 53.12%] [Generator loss: 0.8161%]\n",
            "4200 [Discriminator loss: 0.6786%, acc.: 54.69%] [Generator loss: 0.8135%]\n",
            "4201 [Discriminator loss: 0.6592%, acc.: 56.25%] [Generator loss: 0.8160%]\n",
            "4202 [Discriminator loss: 0.6907%, acc.: 53.91%] [Generator loss: 0.8123%]\n",
            "4203 [Discriminator loss: 0.6498%, acc.: 59.38%] [Generator loss: 0.8120%]\n",
            "4204 [Discriminator loss: 0.6694%, acc.: 58.98%] [Generator loss: 0.8270%]\n",
            "4205 [Discriminator loss: 0.6674%, acc.: 54.69%] [Generator loss: 0.8140%]\n",
            "4206 [Discriminator loss: 0.6673%, acc.: 57.81%] [Generator loss: 0.8202%]\n",
            "4207 [Discriminator loss: 0.6701%, acc.: 59.38%] [Generator loss: 0.7960%]\n",
            "4208 [Discriminator loss: 0.6490%, acc.: 66.80%] [Generator loss: 0.8232%]\n",
            "4209 [Discriminator loss: 0.6795%, acc.: 52.73%] [Generator loss: 0.8152%]\n",
            "4210 [Discriminator loss: 0.6620%, acc.: 58.59%] [Generator loss: 0.8189%]\n",
            "4211 [Discriminator loss: 0.6705%, acc.: 57.42%] [Generator loss: 0.8373%]\n",
            "4212 [Discriminator loss: 0.6508%, acc.: 60.55%] [Generator loss: 0.8437%]\n",
            "4213 [Discriminator loss: 0.6663%, acc.: 57.81%] [Generator loss: 0.8371%]\n",
            "4214 [Discriminator loss: 0.6774%, acc.: 55.08%] [Generator loss: 0.8174%]\n",
            "4215 [Discriminator loss: 0.6610%, acc.: 61.72%] [Generator loss: 0.8028%]\n",
            "4216 [Discriminator loss: 0.6698%, acc.: 53.91%] [Generator loss: 0.8343%]\n",
            "4217 [Discriminator loss: 0.6891%, acc.: 55.08%] [Generator loss: 0.8393%]\n",
            "4218 [Discriminator loss: 0.6591%, acc.: 59.38%] [Generator loss: 0.8172%]\n",
            "4219 [Discriminator loss: 0.6702%, acc.: 56.64%] [Generator loss: 0.8155%]\n",
            "4220 [Discriminator loss: 0.6955%, acc.: 53.12%] [Generator loss: 0.8140%]\n",
            "4221 [Discriminator loss: 0.6883%, acc.: 55.08%] [Generator loss: 0.8199%]\n",
            "4222 [Discriminator loss: 0.6723%, acc.: 58.59%] [Generator loss: 0.8237%]\n",
            "4223 [Discriminator loss: 0.6748%, acc.: 55.86%] [Generator loss: 0.8253%]\n",
            "4224 [Discriminator loss: 0.6837%, acc.: 51.56%] [Generator loss: 0.8387%]\n",
            "4225 [Discriminator loss: 0.6628%, acc.: 58.98%] [Generator loss: 0.8390%]\n",
            "4226 [Discriminator loss: 0.6787%, acc.: 55.08%] [Generator loss: 0.8226%]\n",
            "4227 [Discriminator loss: 0.6616%, acc.: 60.55%] [Generator loss: 0.8377%]\n",
            "4228 [Discriminator loss: 0.6667%, acc.: 57.81%] [Generator loss: 0.8239%]\n",
            "4229 [Discriminator loss: 0.6596%, acc.: 59.77%] [Generator loss: 0.8171%]\n",
            "4230 [Discriminator loss: 0.6613%, acc.: 55.47%] [Generator loss: 0.8380%]\n",
            "4231 [Discriminator loss: 0.6614%, acc.: 62.89%] [Generator loss: 0.8198%]\n",
            "4232 [Discriminator loss: 0.6618%, acc.: 60.55%] [Generator loss: 0.8360%]\n",
            "4233 [Discriminator loss: 0.6862%, acc.: 55.08%] [Generator loss: 0.7982%]\n",
            "4234 [Discriminator loss: 0.6619%, acc.: 57.81%] [Generator loss: 0.8078%]\n",
            "4235 [Discriminator loss: 0.6471%, acc.: 62.11%] [Generator loss: 0.8422%]\n",
            "4236 [Discriminator loss: 0.6471%, acc.: 60.16%] [Generator loss: 0.8091%]\n",
            "4237 [Discriminator loss: 0.6552%, acc.: 61.33%] [Generator loss: 0.8102%]\n",
            "4238 [Discriminator loss: 0.6762%, acc.: 55.47%] [Generator loss: 0.7856%]\n",
            "4239 [Discriminator loss: 0.6385%, acc.: 64.84%] [Generator loss: 0.8095%]\n",
            "4240 [Discriminator loss: 0.6527%, acc.: 64.06%] [Generator loss: 0.8090%]\n",
            "4241 [Discriminator loss: 0.6638%, acc.: 57.03%] [Generator loss: 0.7937%]\n",
            "4242 [Discriminator loss: 0.6498%, acc.: 62.89%] [Generator loss: 0.7895%]\n",
            "4243 [Discriminator loss: 0.6562%, acc.: 60.94%] [Generator loss: 0.8171%]\n",
            "4244 [Discriminator loss: 0.6588%, acc.: 56.25%] [Generator loss: 0.8127%]\n",
            "4245 [Discriminator loss: 0.6388%, acc.: 69.53%] [Generator loss: 0.8159%]\n",
            "4246 [Discriminator loss: 0.6335%, acc.: 66.02%] [Generator loss: 0.8142%]\n",
            "4247 [Discriminator loss: 0.6634%, acc.: 59.77%] [Generator loss: 0.8080%]\n",
            "4248 [Discriminator loss: 0.6679%, acc.: 53.91%] [Generator loss: 0.8333%]\n",
            "4249 [Discriminator loss: 0.6605%, acc.: 62.11%] [Generator loss: 0.8321%]\n",
            "4250 [Discriminator loss: 0.6558%, acc.: 61.33%] [Generator loss: 0.8410%]\n",
            "4251 [Discriminator loss: 0.6422%, acc.: 64.06%] [Generator loss: 0.8348%]\n",
            "4252 [Discriminator loss: 0.6474%, acc.: 62.89%] [Generator loss: 0.8297%]\n",
            "4253 [Discriminator loss: 0.6471%, acc.: 62.89%] [Generator loss: 0.8181%]\n",
            "4254 [Discriminator loss: 0.6528%, acc.: 62.50%] [Generator loss: 0.8326%]\n",
            "4255 [Discriminator loss: 0.6557%, acc.: 62.11%] [Generator loss: 0.8266%]\n",
            "4256 [Discriminator loss: 0.6419%, acc.: 61.33%] [Generator loss: 0.8307%]\n",
            "4257 [Discriminator loss: 0.6669%, acc.: 60.94%] [Generator loss: 0.8257%]\n",
            "4258 [Discriminator loss: 0.6480%, acc.: 61.72%] [Generator loss: 0.8212%]\n",
            "4259 [Discriminator loss: 0.6633%, acc.: 58.98%] [Generator loss: 0.8258%]\n",
            "4260 [Discriminator loss: 0.6392%, acc.: 68.36%] [Generator loss: 0.8023%]\n",
            "4261 [Discriminator loss: 0.6467%, acc.: 64.06%] [Generator loss: 0.8276%]\n",
            "4262 [Discriminator loss: 0.6443%, acc.: 64.45%] [Generator loss: 0.8367%]\n",
            "4263 [Discriminator loss: 0.6493%, acc.: 64.06%] [Generator loss: 0.8195%]\n",
            "4264 [Discriminator loss: 0.6569%, acc.: 61.72%] [Generator loss: 0.8287%]\n",
            "4265 [Discriminator loss: 0.6484%, acc.: 62.50%] [Generator loss: 0.8260%]\n",
            "4266 [Discriminator loss: 0.6323%, acc.: 69.92%] [Generator loss: 0.8406%]\n",
            "4267 [Discriminator loss: 0.6468%, acc.: 65.23%] [Generator loss: 0.8316%]\n",
            "4268 [Discriminator loss: 0.6402%, acc.: 68.36%] [Generator loss: 0.8212%]\n",
            "4269 [Discriminator loss: 0.6366%, acc.: 66.02%] [Generator loss: 0.8333%]\n",
            "4270 [Discriminator loss: 0.6555%, acc.: 59.38%] [Generator loss: 0.8292%]\n",
            "4271 [Discriminator loss: 0.6412%, acc.: 64.06%] [Generator loss: 0.8383%]\n",
            "4272 [Discriminator loss: 0.6336%, acc.: 70.70%] [Generator loss: 0.8216%]\n",
            "4273 [Discriminator loss: 0.6668%, acc.: 64.45%] [Generator loss: 0.8357%]\n",
            "4274 [Discriminator loss: 0.6340%, acc.: 68.36%] [Generator loss: 0.8184%]\n",
            "4275 [Discriminator loss: 0.6659%, acc.: 62.50%] [Generator loss: 0.8293%]\n",
            "4276 [Discriminator loss: 0.6443%, acc.: 64.45%] [Generator loss: 0.8285%]\n",
            "4277 [Discriminator loss: 0.6560%, acc.: 61.72%] [Generator loss: 0.8227%]\n",
            "4278 [Discriminator loss: 0.6432%, acc.: 65.23%] [Generator loss: 0.8094%]\n",
            "4279 [Discriminator loss: 0.6506%, acc.: 61.72%] [Generator loss: 0.8046%]\n",
            "4280 [Discriminator loss: 0.6440%, acc.: 62.89%] [Generator loss: 0.8062%]\n",
            "4281 [Discriminator loss: 0.6538%, acc.: 62.89%] [Generator loss: 0.8210%]\n",
            "4282 [Discriminator loss: 0.6437%, acc.: 65.62%] [Generator loss: 0.8017%]\n",
            "4283 [Discriminator loss: 0.6561%, acc.: 63.67%] [Generator loss: 0.8188%]\n",
            "4284 [Discriminator loss: 0.6610%, acc.: 56.64%] [Generator loss: 0.8163%]\n",
            "4285 [Discriminator loss: 0.6664%, acc.: 58.59%] [Generator loss: 0.8229%]\n",
            "4286 [Discriminator loss: 0.6563%, acc.: 58.98%] [Generator loss: 0.8291%]\n",
            "4287 [Discriminator loss: 0.6596%, acc.: 60.16%] [Generator loss: 0.8130%]\n",
            "4288 [Discriminator loss: 0.6478%, acc.: 64.06%] [Generator loss: 0.8053%]\n",
            "4289 [Discriminator loss: 0.6652%, acc.: 59.77%] [Generator loss: 0.8228%]\n",
            "4290 [Discriminator loss: 0.6691%, acc.: 58.20%] [Generator loss: 0.8226%]\n",
            "4291 [Discriminator loss: 0.6717%, acc.: 55.47%] [Generator loss: 0.8023%]\n",
            "4292 [Discriminator loss: 0.6423%, acc.: 66.02%] [Generator loss: 0.8330%]\n",
            "4293 [Discriminator loss: 0.6708%, acc.: 60.16%] [Generator loss: 0.8037%]\n",
            "4294 [Discriminator loss: 0.6551%, acc.: 60.94%] [Generator loss: 0.8048%]\n",
            "4295 [Discriminator loss: 0.6549%, acc.: 62.50%] [Generator loss: 0.8061%]\n",
            "4296 [Discriminator loss: 0.6426%, acc.: 62.89%] [Generator loss: 0.8019%]\n",
            "4297 [Discriminator loss: 0.6518%, acc.: 60.55%] [Generator loss: 0.8080%]\n",
            "4298 [Discriminator loss: 0.6617%, acc.: 60.16%] [Generator loss: 0.8216%]\n",
            "4299 [Discriminator loss: 0.6617%, acc.: 59.38%] [Generator loss: 0.8062%]\n",
            "4300 [Discriminator loss: 0.6772%, acc.: 55.86%] [Generator loss: 0.8195%]\n",
            "4301 [Discriminator loss: 0.6424%, acc.: 69.14%] [Generator loss: 0.8404%]\n",
            "4302 [Discriminator loss: 0.6730%, acc.: 58.98%] [Generator loss: 0.8166%]\n",
            "4303 [Discriminator loss: 0.6550%, acc.: 62.11%] [Generator loss: 0.8132%]\n",
            "4304 [Discriminator loss: 0.6439%, acc.: 65.62%] [Generator loss: 0.8220%]\n",
            "4305 [Discriminator loss: 0.6554%, acc.: 61.33%] [Generator loss: 0.8246%]\n",
            "4306 [Discriminator loss: 0.6624%, acc.: 57.03%] [Generator loss: 0.8080%]\n",
            "4307 [Discriminator loss: 0.6531%, acc.: 63.67%] [Generator loss: 0.7979%]\n",
            "4308 [Discriminator loss: 0.6618%, acc.: 61.72%] [Generator loss: 0.7916%]\n",
            "4309 [Discriminator loss: 0.6621%, acc.: 59.38%] [Generator loss: 0.8018%]\n",
            "4310 [Discriminator loss: 0.6530%, acc.: 60.94%] [Generator loss: 0.8265%]\n",
            "4311 [Discriminator loss: 0.6691%, acc.: 58.98%] [Generator loss: 0.8162%]\n",
            "4312 [Discriminator loss: 0.6690%, acc.: 58.59%] [Generator loss: 0.8078%]\n",
            "4313 [Discriminator loss: 0.6618%, acc.: 57.81%] [Generator loss: 0.7993%]\n",
            "4314 [Discriminator loss: 0.6703%, acc.: 60.55%] [Generator loss: 0.8143%]\n",
            "4315 [Discriminator loss: 0.6607%, acc.: 62.89%] [Generator loss: 0.8303%]\n",
            "4316 [Discriminator loss: 0.6664%, acc.: 60.16%] [Generator loss: 0.8118%]\n",
            "4317 [Discriminator loss: 0.6777%, acc.: 56.25%] [Generator loss: 0.8087%]\n",
            "4318 [Discriminator loss: 0.6582%, acc.: 63.28%] [Generator loss: 0.8042%]\n",
            "4319 [Discriminator loss: 0.6649%, acc.: 58.98%] [Generator loss: 0.7966%]\n",
            "4320 [Discriminator loss: 0.6759%, acc.: 56.64%] [Generator loss: 0.8214%]\n",
            "4321 [Discriminator loss: 0.6535%, acc.: 60.55%] [Generator loss: 0.8150%]\n",
            "4322 [Discriminator loss: 0.6629%, acc.: 60.16%] [Generator loss: 0.8328%]\n",
            "4323 [Discriminator loss: 0.6652%, acc.: 60.94%] [Generator loss: 0.8048%]\n",
            "4324 [Discriminator loss: 0.6426%, acc.: 64.06%] [Generator loss: 0.8264%]\n",
            "4325 [Discriminator loss: 0.6806%, acc.: 58.20%] [Generator loss: 0.8222%]\n",
            "4326 [Discriminator loss: 0.6699%, acc.: 57.42%] [Generator loss: 0.8123%]\n",
            "4327 [Discriminator loss: 0.6409%, acc.: 67.19%] [Generator loss: 0.8321%]\n",
            "4328 [Discriminator loss: 0.6775%, acc.: 56.64%] [Generator loss: 0.8045%]\n",
            "4329 [Discriminator loss: 0.6418%, acc.: 68.36%] [Generator loss: 0.8327%]\n",
            "4330 [Discriminator loss: 0.6683%, acc.: 60.16%] [Generator loss: 0.8377%]\n",
            "4331 [Discriminator loss: 0.6633%, acc.: 61.33%] [Generator loss: 0.8257%]\n",
            "4332 [Discriminator loss: 0.6855%, acc.: 53.12%] [Generator loss: 0.8233%]\n",
            "4333 [Discriminator loss: 0.6708%, acc.: 60.55%] [Generator loss: 0.8196%]\n",
            "4334 [Discriminator loss: 0.6425%, acc.: 63.67%] [Generator loss: 0.8120%]\n",
            "4335 [Discriminator loss: 0.6482%, acc.: 62.11%] [Generator loss: 0.8285%]\n",
            "4336 [Discriminator loss: 0.6619%, acc.: 60.16%] [Generator loss: 0.8480%]\n",
            "4337 [Discriminator loss: 0.6514%, acc.: 62.11%] [Generator loss: 0.8422%]\n",
            "4338 [Discriminator loss: 0.6703%, acc.: 55.86%] [Generator loss: 0.8172%]\n",
            "4339 [Discriminator loss: 0.6471%, acc.: 59.77%] [Generator loss: 0.8274%]\n",
            "4340 [Discriminator loss: 0.6429%, acc.: 61.33%] [Generator loss: 0.8115%]\n",
            "4341 [Discriminator loss: 0.6570%, acc.: 63.28%] [Generator loss: 0.8105%]\n",
            "4342 [Discriminator loss: 0.6512%, acc.: 58.20%] [Generator loss: 0.8160%]\n",
            "4343 [Discriminator loss: 0.6454%, acc.: 64.84%] [Generator loss: 0.8114%]\n",
            "4344 [Discriminator loss: 0.6701%, acc.: 55.86%] [Generator loss: 0.8038%]\n",
            "4345 [Discriminator loss: 0.6597%, acc.: 58.98%] [Generator loss: 0.7647%]\n",
            "4346 [Discriminator loss: 0.6609%, acc.: 58.20%] [Generator loss: 0.7811%]\n",
            "4347 [Discriminator loss: 0.6815%, acc.: 52.73%] [Generator loss: 0.7956%]\n",
            "4348 [Discriminator loss: 0.6598%, acc.: 57.03%] [Generator loss: 0.8032%]\n",
            "4349 [Discriminator loss: 0.6667%, acc.: 60.55%] [Generator loss: 0.8193%]\n",
            "4350 [Discriminator loss: 0.6612%, acc.: 58.20%] [Generator loss: 0.8025%]\n",
            "4351 [Discriminator loss: 0.6609%, acc.: 58.59%] [Generator loss: 0.7941%]\n",
            "4352 [Discriminator loss: 0.6346%, acc.: 63.28%] [Generator loss: 0.8129%]\n",
            "4353 [Discriminator loss: 0.6396%, acc.: 62.89%] [Generator loss: 0.8406%]\n",
            "4354 [Discriminator loss: 0.6529%, acc.: 58.59%] [Generator loss: 0.8179%]\n",
            "4355 [Discriminator loss: 0.6458%, acc.: 60.94%] [Generator loss: 0.8102%]\n",
            "4356 [Discriminator loss: 0.6439%, acc.: 62.50%] [Generator loss: 0.8311%]\n",
            "4357 [Discriminator loss: 0.6502%, acc.: 60.16%] [Generator loss: 0.8427%]\n",
            "4358 [Discriminator loss: 0.6596%, acc.: 60.55%] [Generator loss: 0.8312%]\n",
            "4359 [Discriminator loss: 0.6364%, acc.: 64.84%] [Generator loss: 0.8131%]\n",
            "4360 [Discriminator loss: 0.6559%, acc.: 60.94%] [Generator loss: 0.8387%]\n",
            "4361 [Discriminator loss: 0.6420%, acc.: 63.28%] [Generator loss: 0.8168%]\n",
            "4362 [Discriminator loss: 0.6644%, acc.: 57.42%] [Generator loss: 0.8207%]\n",
            "4363 [Discriminator loss: 0.6663%, acc.: 57.03%] [Generator loss: 0.7970%]\n",
            "4364 [Discriminator loss: 0.6587%, acc.: 61.72%] [Generator loss: 0.8225%]\n",
            "4365 [Discriminator loss: 0.6624%, acc.: 60.94%] [Generator loss: 0.8121%]\n",
            "4366 [Discriminator loss: 0.6653%, acc.: 58.98%] [Generator loss: 0.8220%]\n",
            "4367 [Discriminator loss: 0.6536%, acc.: 61.72%] [Generator loss: 0.8386%]\n",
            "4368 [Discriminator loss: 0.6494%, acc.: 62.11%] [Generator loss: 0.8242%]\n",
            "4369 [Discriminator loss: 0.6367%, acc.: 64.84%] [Generator loss: 0.8310%]\n",
            "4370 [Discriminator loss: 0.6468%, acc.: 61.33%] [Generator loss: 0.8277%]\n",
            "4371 [Discriminator loss: 0.6546%, acc.: 60.94%] [Generator loss: 0.8144%]\n",
            "4372 [Discriminator loss: 0.6535%, acc.: 58.98%] [Generator loss: 0.8079%]\n",
            "4373 [Discriminator loss: 0.6434%, acc.: 60.55%] [Generator loss: 0.8130%]\n",
            "4374 [Discriminator loss: 0.6657%, acc.: 56.64%] [Generator loss: 0.8059%]\n",
            "4375 [Discriminator loss: 0.6512%, acc.: 60.16%] [Generator loss: 0.8364%]\n",
            "4376 [Discriminator loss: 0.6705%, acc.: 56.64%] [Generator loss: 0.8397%]\n",
            "4377 [Discriminator loss: 0.6777%, acc.: 50.78%] [Generator loss: 0.7991%]\n",
            "4378 [Discriminator loss: 0.6519%, acc.: 60.55%] [Generator loss: 0.8116%]\n",
            "4379 [Discriminator loss: 0.6669%, acc.: 57.03%] [Generator loss: 0.7831%]\n",
            "4380 [Discriminator loss: 0.6612%, acc.: 56.25%] [Generator loss: 0.7944%]\n",
            "4381 [Discriminator loss: 0.6735%, acc.: 54.30%] [Generator loss: 0.7908%]\n",
            "4382 [Discriminator loss: 0.6747%, acc.: 55.47%] [Generator loss: 0.8420%]\n",
            "4383 [Discriminator loss: 0.6556%, acc.: 60.94%] [Generator loss: 0.8348%]\n",
            "4384 [Discriminator loss: 0.6765%, acc.: 55.08%] [Generator loss: 0.8357%]\n",
            "4385 [Discriminator loss: 0.6600%, acc.: 64.06%] [Generator loss: 0.8259%]\n",
            "4386 [Discriminator loss: 0.6557%, acc.: 60.55%] [Generator loss: 0.8113%]\n",
            "4387 [Discriminator loss: 0.6761%, acc.: 58.20%] [Generator loss: 0.7959%]\n",
            "4388 [Discriminator loss: 0.6672%, acc.: 55.08%] [Generator loss: 0.8087%]\n",
            "4389 [Discriminator loss: 0.6664%, acc.: 55.08%] [Generator loss: 0.8028%]\n",
            "4390 [Discriminator loss: 0.6826%, acc.: 55.86%] [Generator loss: 0.8022%]\n",
            "4391 [Discriminator loss: 0.6660%, acc.: 56.64%] [Generator loss: 0.8499%]\n",
            "4392 [Discriminator loss: 0.6900%, acc.: 49.22%] [Generator loss: 0.8031%]\n",
            "4393 [Discriminator loss: 0.6804%, acc.: 59.77%] [Generator loss: 0.8144%]\n",
            "4394 [Discriminator loss: 0.6474%, acc.: 61.72%] [Generator loss: 0.8131%]\n",
            "4395 [Discriminator loss: 0.6669%, acc.: 57.42%] [Generator loss: 0.8331%]\n",
            "4396 [Discriminator loss: 0.6588%, acc.: 58.98%] [Generator loss: 0.8091%]\n",
            "4397 [Discriminator loss: 0.6473%, acc.: 64.84%] [Generator loss: 0.8110%]\n",
            "4398 [Discriminator loss: 0.6532%, acc.: 55.86%] [Generator loss: 0.8134%]\n",
            "4399 [Discriminator loss: 0.6675%, acc.: 58.98%] [Generator loss: 0.8050%]\n",
            "4400 [Discriminator loss: 0.6580%, acc.: 60.16%] [Generator loss: 0.8251%]\n",
            "4401 [Discriminator loss: 0.6623%, acc.: 58.98%] [Generator loss: 0.8010%]\n",
            "4402 [Discriminator loss: 0.6746%, acc.: 54.30%] [Generator loss: 0.8226%]\n",
            "4403 [Discriminator loss: 0.6588%, acc.: 64.84%] [Generator loss: 0.8431%]\n",
            "4404 [Discriminator loss: 0.6753%, acc.: 54.69%] [Generator loss: 0.8291%]\n",
            "4405 [Discriminator loss: 0.6817%, acc.: 54.30%] [Generator loss: 0.8447%]\n",
            "4406 [Discriminator loss: 0.6484%, acc.: 58.59%] [Generator loss: 0.8203%]\n",
            "4407 [Discriminator loss: 0.6750%, acc.: 51.56%] [Generator loss: 0.8320%]\n",
            "4408 [Discriminator loss: 0.6842%, acc.: 51.95%] [Generator loss: 0.8031%]\n",
            "4409 [Discriminator loss: 0.6686%, acc.: 55.47%] [Generator loss: 0.8179%]\n",
            "4410 [Discriminator loss: 0.6654%, acc.: 54.30%] [Generator loss: 0.8258%]\n",
            "4411 [Discriminator loss: 0.6833%, acc.: 52.34%] [Generator loss: 0.7979%]\n",
            "4412 [Discriminator loss: 0.6809%, acc.: 50.78%] [Generator loss: 0.7900%]\n",
            "4413 [Discriminator loss: 0.6634%, acc.: 51.17%] [Generator loss: 0.7932%]\n",
            "4414 [Discriminator loss: 0.6659%, acc.: 55.86%] [Generator loss: 0.8327%]\n",
            "4415 [Discriminator loss: 0.6526%, acc.: 56.25%] [Generator loss: 0.8172%]\n",
            "4416 [Discriminator loss: 0.6542%, acc.: 57.42%] [Generator loss: 0.8574%]\n",
            "4417 [Discriminator loss: 0.6596%, acc.: 55.86%] [Generator loss: 0.8284%]\n",
            "4418 [Discriminator loss: 0.6607%, acc.: 58.59%] [Generator loss: 0.7984%]\n",
            "4419 [Discriminator loss: 0.6702%, acc.: 52.73%] [Generator loss: 0.7877%]\n",
            "4420 [Discriminator loss: 0.6902%, acc.: 53.12%] [Generator loss: 0.8366%]\n",
            "4421 [Discriminator loss: 0.6828%, acc.: 53.91%] [Generator loss: 0.8132%]\n",
            "4422 [Discriminator loss: 0.6476%, acc.: 58.20%] [Generator loss: 0.8323%]\n",
            "4423 [Discriminator loss: 0.6708%, acc.: 56.25%] [Generator loss: 0.8235%]\n",
            "4424 [Discriminator loss: 0.6833%, acc.: 57.03%] [Generator loss: 0.8547%]\n",
            "4425 [Discriminator loss: 0.6675%, acc.: 57.42%] [Generator loss: 0.8440%]\n",
            "4426 [Discriminator loss: 0.6480%, acc.: 59.38%] [Generator loss: 0.8154%]\n",
            "4427 [Discriminator loss: 0.6778%, acc.: 51.95%] [Generator loss: 0.7929%]\n",
            "4428 [Discriminator loss: 0.6431%, acc.: 63.28%] [Generator loss: 0.8124%]\n",
            "4429 [Discriminator loss: 0.6645%, acc.: 57.03%] [Generator loss: 0.8153%]\n",
            "4430 [Discriminator loss: 0.6660%, acc.: 57.42%] [Generator loss: 0.8048%]\n",
            "4431 [Discriminator loss: 0.6770%, acc.: 54.69%] [Generator loss: 0.7976%]\n",
            "4432 [Discriminator loss: 0.6583%, acc.: 60.16%] [Generator loss: 0.7884%]\n",
            "4433 [Discriminator loss: 0.6840%, acc.: 52.34%] [Generator loss: 0.8165%]\n",
            "4434 [Discriminator loss: 0.6450%, acc.: 58.98%] [Generator loss: 0.8164%]\n",
            "4435 [Discriminator loss: 0.6525%, acc.: 60.16%] [Generator loss: 0.8243%]\n",
            "4436 [Discriminator loss: 0.6693%, acc.: 55.47%] [Generator loss: 0.8538%]\n",
            "4437 [Discriminator loss: 0.6893%, acc.: 50.78%] [Generator loss: 0.8266%]\n",
            "4438 [Discriminator loss: 0.6640%, acc.: 57.03%] [Generator loss: 0.8411%]\n",
            "4439 [Discriminator loss: 0.6694%, acc.: 55.08%] [Generator loss: 0.8169%]\n",
            "4440 [Discriminator loss: 0.6740%, acc.: 55.08%] [Generator loss: 0.7976%]\n",
            "4441 [Discriminator loss: 0.6561%, acc.: 57.42%] [Generator loss: 0.8296%]\n",
            "4442 [Discriminator loss: 0.6530%, acc.: 58.20%] [Generator loss: 0.8220%]\n",
            "4443 [Discriminator loss: 0.6538%, acc.: 57.42%] [Generator loss: 0.8464%]\n",
            "4444 [Discriminator loss: 0.6593%, acc.: 53.91%] [Generator loss: 0.8297%]\n",
            "4445 [Discriminator loss: 0.6627%, acc.: 56.25%] [Generator loss: 0.8192%]\n",
            "4446 [Discriminator loss: 0.6400%, acc.: 63.67%] [Generator loss: 0.8327%]\n",
            "4447 [Discriminator loss: 0.6403%, acc.: 64.84%] [Generator loss: 0.8125%]\n",
            "4448 [Discriminator loss: 0.6613%, acc.: 55.86%] [Generator loss: 0.8122%]\n",
            "4449 [Discriminator loss: 0.6301%, acc.: 60.16%] [Generator loss: 0.8039%]\n",
            "4450 [Discriminator loss: 0.6594%, acc.: 56.64%] [Generator loss: 0.8293%]\n",
            "4451 [Discriminator loss: 0.6553%, acc.: 55.47%] [Generator loss: 0.8325%]\n",
            "4452 [Discriminator loss: 0.6407%, acc.: 60.94%] [Generator loss: 0.8016%]\n",
            "4453 [Discriminator loss: 0.6620%, acc.: 55.47%] [Generator loss: 0.8031%]\n",
            "4454 [Discriminator loss: 0.6470%, acc.: 56.25%] [Generator loss: 0.8217%]\n",
            "4455 [Discriminator loss: 0.6393%, acc.: 64.45%] [Generator loss: 0.8405%]\n",
            "4456 [Discriminator loss: 0.6496%, acc.: 61.72%] [Generator loss: 0.8245%]\n",
            "4457 [Discriminator loss: 0.6618%, acc.: 57.03%] [Generator loss: 0.8328%]\n",
            "4458 [Discriminator loss: 0.6724%, acc.: 54.69%] [Generator loss: 0.8124%]\n",
            "4459 [Discriminator loss: 0.6474%, acc.: 57.81%] [Generator loss: 0.8112%]\n",
            "4460 [Discriminator loss: 0.6527%, acc.: 58.20%] [Generator loss: 0.8193%]\n",
            "4461 [Discriminator loss: 0.6606%, acc.: 57.03%] [Generator loss: 0.8286%]\n",
            "4462 [Discriminator loss: 0.6512%, acc.: 62.50%] [Generator loss: 0.8138%]\n",
            "4463 [Discriminator loss: 0.6424%, acc.: 62.11%] [Generator loss: 0.8041%]\n",
            "4464 [Discriminator loss: 0.6761%, acc.: 57.81%] [Generator loss: 0.8088%]\n",
            "4465 [Discriminator loss: 0.6272%, acc.: 64.84%] [Generator loss: 0.8502%]\n",
            "4466 [Discriminator loss: 0.6375%, acc.: 62.50%] [Generator loss: 0.8510%]\n",
            "4467 [Discriminator loss: 0.6619%, acc.: 54.30%] [Generator loss: 0.8305%]\n",
            "4468 [Discriminator loss: 0.6512%, acc.: 57.42%] [Generator loss: 0.8384%]\n",
            "4469 [Discriminator loss: 0.6706%, acc.: 56.25%] [Generator loss: 0.8236%]\n",
            "4470 [Discriminator loss: 0.6823%, acc.: 53.52%] [Generator loss: 0.8369%]\n",
            "4471 [Discriminator loss: 0.6535%, acc.: 58.98%] [Generator loss: 0.8299%]\n",
            "4472 [Discriminator loss: 0.6538%, acc.: 60.55%] [Generator loss: 0.7993%]\n",
            "4473 [Discriminator loss: 0.6675%, acc.: 55.47%] [Generator loss: 0.8068%]\n",
            "4474 [Discriminator loss: 0.6736%, acc.: 50.00%] [Generator loss: 0.8368%]\n",
            "4475 [Discriminator loss: 0.6699%, acc.: 55.08%] [Generator loss: 0.8337%]\n",
            "4476 [Discriminator loss: 0.6707%, acc.: 57.81%] [Generator loss: 0.8228%]\n",
            "4477 [Discriminator loss: 0.6853%, acc.: 48.44%] [Generator loss: 0.8412%]\n",
            "4478 [Discriminator loss: 0.6911%, acc.: 46.09%] [Generator loss: 0.8427%]\n",
            "4479 [Discriminator loss: 0.6515%, acc.: 62.11%] [Generator loss: 0.8181%]\n",
            "4480 [Discriminator loss: 0.6693%, acc.: 56.25%] [Generator loss: 0.8083%]\n",
            "4481 [Discriminator loss: 0.6511%, acc.: 54.30%] [Generator loss: 0.8375%]\n",
            "4482 [Discriminator loss: 0.6912%, acc.: 49.61%] [Generator loss: 0.8325%]\n",
            "4483 [Discriminator loss: 0.6795%, acc.: 48.83%] [Generator loss: 0.8210%]\n",
            "4484 [Discriminator loss: 0.6759%, acc.: 51.95%] [Generator loss: 0.8326%]\n",
            "4485 [Discriminator loss: 0.6906%, acc.: 50.78%] [Generator loss: 0.8476%]\n",
            "4486 [Discriminator loss: 0.6618%, acc.: 56.64%] [Generator loss: 0.8324%]\n",
            "4487 [Discriminator loss: 0.6783%, acc.: 55.86%] [Generator loss: 0.8159%]\n",
            "4488 [Discriminator loss: 0.6856%, acc.: 50.39%] [Generator loss: 0.8339%]\n",
            "4489 [Discriminator loss: 0.6940%, acc.: 55.47%] [Generator loss: 0.8126%]\n",
            "4490 [Discriminator loss: 0.6626%, acc.: 55.86%] [Generator loss: 0.8245%]\n",
            "4491 [Discriminator loss: 0.6593%, acc.: 58.59%] [Generator loss: 0.8332%]\n",
            "4492 [Discriminator loss: 0.6386%, acc.: 60.16%] [Generator loss: 0.8295%]\n",
            "4493 [Discriminator loss: 0.6593%, acc.: 61.72%] [Generator loss: 0.8435%]\n",
            "4494 [Discriminator loss: 0.6755%, acc.: 54.69%] [Generator loss: 0.8154%]\n",
            "4495 [Discriminator loss: 0.6670%, acc.: 58.20%] [Generator loss: 0.7918%]\n",
            "4496 [Discriminator loss: 0.6542%, acc.: 60.16%] [Generator loss: 0.8071%]\n",
            "4497 [Discriminator loss: 0.6455%, acc.: 60.94%] [Generator loss: 0.8055%]\n",
            "4498 [Discriminator loss: 0.6730%, acc.: 54.30%] [Generator loss: 0.8090%]\n",
            "4499 [Discriminator loss: 0.6922%, acc.: 49.61%] [Generator loss: 0.8054%]\n",
            "4500 [Discriminator loss: 0.6798%, acc.: 52.73%] [Generator loss: 0.7721%]\n",
            "4501 [Discriminator loss: 0.6801%, acc.: 53.52%] [Generator loss: 0.8063%]\n",
            "4502 [Discriminator loss: 0.6769%, acc.: 51.56%] [Generator loss: 0.8379%]\n",
            "4503 [Discriminator loss: 0.6790%, acc.: 55.08%] [Generator loss: 0.8270%]\n",
            "4504 [Discriminator loss: 0.6734%, acc.: 52.34%] [Generator loss: 0.8270%]\n",
            "4505 [Discriminator loss: 0.6661%, acc.: 54.69%] [Generator loss: 0.8401%]\n",
            "4506 [Discriminator loss: 0.6678%, acc.: 58.20%] [Generator loss: 0.8382%]\n",
            "4507 [Discriminator loss: 0.6811%, acc.: 55.47%] [Generator loss: 0.8230%]\n",
            "4508 [Discriminator loss: 0.6685%, acc.: 57.81%] [Generator loss: 0.8111%]\n",
            "4509 [Discriminator loss: 0.6814%, acc.: 54.30%] [Generator loss: 0.8223%]\n",
            "4510 [Discriminator loss: 0.6911%, acc.: 55.47%] [Generator loss: 0.8143%]\n",
            "4511 [Discriminator loss: 0.6660%, acc.: 58.98%] [Generator loss: 0.8044%]\n",
            "4512 [Discriminator loss: 0.6698%, acc.: 58.59%] [Generator loss: 0.8141%]\n",
            "4513 [Discriminator loss: 0.6817%, acc.: 53.91%] [Generator loss: 0.8302%]\n",
            "4514 [Discriminator loss: 0.6570%, acc.: 64.45%] [Generator loss: 0.8465%]\n",
            "4515 [Discriminator loss: 0.6694%, acc.: 59.38%] [Generator loss: 0.8183%]\n",
            "4516 [Discriminator loss: 0.6603%, acc.: 60.94%] [Generator loss: 0.8129%]\n",
            "4517 [Discriminator loss: 0.6668%, acc.: 56.25%] [Generator loss: 0.8362%]\n",
            "4518 [Discriminator loss: 0.6899%, acc.: 52.34%] [Generator loss: 0.8054%]\n",
            "4519 [Discriminator loss: 0.6758%, acc.: 58.20%] [Generator loss: 0.7979%]\n",
            "4520 [Discriminator loss: 0.6819%, acc.: 55.47%] [Generator loss: 0.8229%]\n",
            "4521 [Discriminator loss: 0.6949%, acc.: 53.52%] [Generator loss: 0.8217%]\n",
            "4522 [Discriminator loss: 0.6798%, acc.: 60.94%] [Generator loss: 0.8315%]\n",
            "4523 [Discriminator loss: 0.6750%, acc.: 53.52%] [Generator loss: 0.8013%]\n",
            "4524 [Discriminator loss: 0.6763%, acc.: 54.69%] [Generator loss: 0.8083%]\n",
            "4525 [Discriminator loss: 0.6831%, acc.: 58.59%] [Generator loss: 0.7903%]\n",
            "4526 [Discriminator loss: 0.6630%, acc.: 64.06%] [Generator loss: 0.8316%]\n",
            "4527 [Discriminator loss: 0.6639%, acc.: 62.50%] [Generator loss: 0.8100%]\n",
            "4528 [Discriminator loss: 0.6808%, acc.: 55.08%] [Generator loss: 0.8272%]\n",
            "4529 [Discriminator loss: 0.6869%, acc.: 52.34%] [Generator loss: 0.8150%]\n",
            "4530 [Discriminator loss: 0.6590%, acc.: 61.72%] [Generator loss: 0.8162%]\n",
            "4531 [Discriminator loss: 0.6929%, acc.: 51.95%] [Generator loss: 0.8163%]\n",
            "4532 [Discriminator loss: 0.6893%, acc.: 51.17%] [Generator loss: 0.8033%]\n",
            "4533 [Discriminator loss: 0.6836%, acc.: 51.56%] [Generator loss: 0.7963%]\n",
            "4534 [Discriminator loss: 0.6605%, acc.: 57.81%] [Generator loss: 0.8211%]\n",
            "4535 [Discriminator loss: 0.6554%, acc.: 62.11%] [Generator loss: 0.8061%]\n",
            "4536 [Discriminator loss: 0.6669%, acc.: 60.55%] [Generator loss: 0.8031%]\n",
            "4537 [Discriminator loss: 0.6840%, acc.: 54.69%] [Generator loss: 0.7879%]\n",
            "4538 [Discriminator loss: 0.6826%, acc.: 57.42%] [Generator loss: 0.7836%]\n",
            "4539 [Discriminator loss: 0.6743%, acc.: 55.47%] [Generator loss: 0.7873%]\n",
            "4540 [Discriminator loss: 0.7005%, acc.: 52.34%] [Generator loss: 0.7688%]\n",
            "4541 [Discriminator loss: 0.6842%, acc.: 52.34%] [Generator loss: 0.7678%]\n",
            "4542 [Discriminator loss: 0.6797%, acc.: 55.08%] [Generator loss: 0.7765%]\n",
            "4543 [Discriminator loss: 0.6721%, acc.: 58.20%] [Generator loss: 0.7816%]\n",
            "4544 [Discriminator loss: 0.6786%, acc.: 56.25%] [Generator loss: 0.7832%]\n",
            "4545 [Discriminator loss: 0.6704%, acc.: 57.03%] [Generator loss: 0.7830%]\n",
            "4546 [Discriminator loss: 0.6723%, acc.: 57.03%] [Generator loss: 0.7871%]\n",
            "4547 [Discriminator loss: 0.6707%, acc.: 59.38%] [Generator loss: 0.8224%]\n",
            "4548 [Discriminator loss: 0.6781%, acc.: 53.91%] [Generator loss: 0.8065%]\n",
            "4549 [Discriminator loss: 0.6790%, acc.: 58.20%] [Generator loss: 0.7922%]\n",
            "4550 [Discriminator loss: 0.6782%, acc.: 57.03%] [Generator loss: 0.7826%]\n",
            "4551 [Discriminator loss: 0.6783%, acc.: 57.81%] [Generator loss: 0.7816%]\n",
            "4552 [Discriminator loss: 0.6886%, acc.: 55.08%] [Generator loss: 0.7871%]\n",
            "4553 [Discriminator loss: 0.6732%, acc.: 57.81%] [Generator loss: 0.7800%]\n",
            "4554 [Discriminator loss: 0.6665%, acc.: 57.03%] [Generator loss: 0.7808%]\n",
            "4555 [Discriminator loss: 0.6860%, acc.: 55.47%] [Generator loss: 0.7908%]\n",
            "4556 [Discriminator loss: 0.6833%, acc.: 55.86%] [Generator loss: 0.7851%]\n",
            "4557 [Discriminator loss: 0.6697%, acc.: 55.86%] [Generator loss: 0.7929%]\n",
            "4558 [Discriminator loss: 0.6839%, acc.: 56.64%] [Generator loss: 0.7913%]\n",
            "4559 [Discriminator loss: 0.6881%, acc.: 54.69%] [Generator loss: 0.7878%]\n",
            "4560 [Discriminator loss: 0.6910%, acc.: 54.30%] [Generator loss: 0.7588%]\n",
            "4561 [Discriminator loss: 0.6813%, acc.: 53.12%] [Generator loss: 0.7609%]\n",
            "4562 [Discriminator loss: 0.6984%, acc.: 49.22%] [Generator loss: 0.7653%]\n",
            "4563 [Discriminator loss: 0.6776%, acc.: 58.59%] [Generator loss: 0.8009%]\n",
            "4564 [Discriminator loss: 0.6830%, acc.: 59.77%] [Generator loss: 0.7818%]\n",
            "4565 [Discriminator loss: 0.6860%, acc.: 51.95%] [Generator loss: 0.7786%]\n",
            "4566 [Discriminator loss: 0.6691%, acc.: 59.38%] [Generator loss: 0.7800%]\n",
            "4567 [Discriminator loss: 0.6845%, acc.: 53.91%] [Generator loss: 0.8058%]\n",
            "4568 [Discriminator loss: 0.6904%, acc.: 52.73%] [Generator loss: 0.8078%]\n",
            "4569 [Discriminator loss: 0.6963%, acc.: 48.44%] [Generator loss: 0.7860%]\n",
            "4570 [Discriminator loss: 0.6992%, acc.: 49.61%] [Generator loss: 0.7953%]\n",
            "4571 [Discriminator loss: 0.6819%, acc.: 53.52%] [Generator loss: 0.7787%]\n",
            "4572 [Discriminator loss: 0.6790%, acc.: 53.12%] [Generator loss: 0.7926%]\n",
            "4573 [Discriminator loss: 0.6801%, acc.: 57.03%] [Generator loss: 0.7966%]\n",
            "4574 [Discriminator loss: 0.6728%, acc.: 55.86%] [Generator loss: 0.7911%]\n",
            "4575 [Discriminator loss: 0.6831%, acc.: 56.64%] [Generator loss: 0.7917%]\n",
            "4576 [Discriminator loss: 0.6780%, acc.: 54.69%] [Generator loss: 0.7994%]\n",
            "4577 [Discriminator loss: 0.6606%, acc.: 60.94%] [Generator loss: 0.7985%]\n",
            "4578 [Discriminator loss: 0.6658%, acc.: 57.03%] [Generator loss: 0.8189%]\n",
            "4579 [Discriminator loss: 0.6796%, acc.: 59.38%] [Generator loss: 0.8114%]\n",
            "4580 [Discriminator loss: 0.6949%, acc.: 51.56%] [Generator loss: 0.7969%]\n",
            "4581 [Discriminator loss: 0.6762%, acc.: 58.20%] [Generator loss: 0.7794%]\n",
            "4582 [Discriminator loss: 0.6804%, acc.: 50.00%] [Generator loss: 0.7850%]\n",
            "4583 [Discriminator loss: 0.6962%, acc.: 50.39%] [Generator loss: 0.7936%]\n",
            "4584 [Discriminator loss: 0.6849%, acc.: 57.81%] [Generator loss: 0.7767%]\n",
            "4585 [Discriminator loss: 0.6675%, acc.: 55.86%] [Generator loss: 0.7873%]\n",
            "4586 [Discriminator loss: 0.6666%, acc.: 54.69%] [Generator loss: 0.8058%]\n",
            "4587 [Discriminator loss: 0.6762%, acc.: 53.52%] [Generator loss: 0.7835%]\n",
            "4588 [Discriminator loss: 0.6715%, acc.: 55.86%] [Generator loss: 0.8029%]\n",
            "4589 [Discriminator loss: 0.6737%, acc.: 56.25%] [Generator loss: 0.7974%]\n",
            "4590 [Discriminator loss: 0.6864%, acc.: 56.25%] [Generator loss: 0.7800%]\n",
            "4591 [Discriminator loss: 0.7190%, acc.: 50.39%] [Generator loss: 0.7969%]\n",
            "4592 [Discriminator loss: 0.6615%, acc.: 59.77%] [Generator loss: 0.8021%]\n",
            "4593 [Discriminator loss: 0.6863%, acc.: 56.25%] [Generator loss: 0.7957%]\n",
            "4594 [Discriminator loss: 0.6861%, acc.: 55.08%] [Generator loss: 0.8003%]\n",
            "4595 [Discriminator loss: 0.6937%, acc.: 52.34%] [Generator loss: 0.7899%]\n",
            "4596 [Discriminator loss: 0.6925%, acc.: 55.86%] [Generator loss: 0.8062%]\n",
            "4597 [Discriminator loss: 0.6868%, acc.: 52.34%] [Generator loss: 0.7935%]\n",
            "4598 [Discriminator loss: 0.6945%, acc.: 53.91%] [Generator loss: 0.7732%]\n",
            "4599 [Discriminator loss: 0.6752%, acc.: 57.03%] [Generator loss: 0.7687%]\n",
            "4600 [Discriminator loss: 0.6569%, acc.: 60.55%] [Generator loss: 0.7953%]\n",
            "4601 [Discriminator loss: 0.6756%, acc.: 56.64%] [Generator loss: 0.7648%]\n",
            "4602 [Discriminator loss: 0.6915%, acc.: 51.95%] [Generator loss: 0.7836%]\n",
            "4603 [Discriminator loss: 0.6756%, acc.: 56.64%] [Generator loss: 0.7704%]\n",
            "4604 [Discriminator loss: 0.6702%, acc.: 58.59%] [Generator loss: 0.7854%]\n",
            "4605 [Discriminator loss: 0.6600%, acc.: 61.33%] [Generator loss: 0.7814%]\n",
            "4606 [Discriminator loss: 0.6704%, acc.: 57.81%] [Generator loss: 0.8079%]\n",
            "4607 [Discriminator loss: 0.6604%, acc.: 60.94%] [Generator loss: 0.7855%]\n",
            "4608 [Discriminator loss: 0.6678%, acc.: 61.33%] [Generator loss: 0.7974%]\n",
            "4609 [Discriminator loss: 0.6802%, acc.: 52.73%] [Generator loss: 0.8100%]\n",
            "4610 [Discriminator loss: 0.6698%, acc.: 60.94%] [Generator loss: 0.7909%]\n",
            "4611 [Discriminator loss: 0.6885%, acc.: 59.38%] [Generator loss: 0.7926%]\n",
            "4612 [Discriminator loss: 0.6710%, acc.: 58.98%] [Generator loss: 0.7918%]\n",
            "4613 [Discriminator loss: 0.6744%, acc.: 55.86%] [Generator loss: 0.8032%]\n",
            "4614 [Discriminator loss: 0.6625%, acc.: 61.33%] [Generator loss: 0.7981%]\n",
            "4615 [Discriminator loss: 0.6688%, acc.: 57.03%] [Generator loss: 0.7850%]\n",
            "4616 [Discriminator loss: 0.6710%, acc.: 58.59%] [Generator loss: 0.7981%]\n",
            "4617 [Discriminator loss: 0.6740%, acc.: 56.25%] [Generator loss: 0.7905%]\n",
            "4618 [Discriminator loss: 0.6688%, acc.: 58.20%] [Generator loss: 0.7982%]\n",
            "4619 [Discriminator loss: 0.6925%, acc.: 55.08%] [Generator loss: 0.7954%]\n",
            "4620 [Discriminator loss: 0.6732%, acc.: 55.86%] [Generator loss: 0.8025%]\n",
            "4621 [Discriminator loss: 0.6855%, acc.: 55.08%] [Generator loss: 0.8058%]\n",
            "4622 [Discriminator loss: 0.6774%, acc.: 57.03%] [Generator loss: 0.7944%]\n",
            "4623 [Discriminator loss: 0.6623%, acc.: 62.89%] [Generator loss: 0.7848%]\n",
            "4624 [Discriminator loss: 0.6819%, acc.: 58.59%] [Generator loss: 0.7810%]\n",
            "4625 [Discriminator loss: 0.6782%, acc.: 55.86%] [Generator loss: 0.7780%]\n",
            "4626 [Discriminator loss: 0.6799%, acc.: 61.72%] [Generator loss: 0.8180%]\n",
            "4627 [Discriminator loss: 0.6807%, acc.: 58.20%] [Generator loss: 0.7876%]\n",
            "4628 [Discriminator loss: 0.6983%, acc.: 53.52%] [Generator loss: 0.7935%]\n",
            "4629 [Discriminator loss: 0.6826%, acc.: 57.42%] [Generator loss: 0.7966%]\n",
            "4630 [Discriminator loss: 0.6756%, acc.: 57.03%] [Generator loss: 0.8012%]\n",
            "4631 [Discriminator loss: 0.6946%, acc.: 56.64%] [Generator loss: 0.7761%]\n",
            "4632 [Discriminator loss: 0.6752%, acc.: 56.64%] [Generator loss: 0.7738%]\n",
            "4633 [Discriminator loss: 0.6721%, acc.: 62.11%] [Generator loss: 0.7809%]\n",
            "4634 [Discriminator loss: 0.6814%, acc.: 57.42%] [Generator loss: 0.7864%]\n",
            "4635 [Discriminator loss: 0.6607%, acc.: 66.41%] [Generator loss: 0.7702%]\n",
            "4636 [Discriminator loss: 0.7001%, acc.: 51.17%] [Generator loss: 0.7856%]\n",
            "4637 [Discriminator loss: 0.6770%, acc.: 56.64%] [Generator loss: 0.7699%]\n",
            "4638 [Discriminator loss: 0.6829%, acc.: 58.98%] [Generator loss: 0.7821%]\n",
            "4639 [Discriminator loss: 0.6862%, acc.: 52.34%] [Generator loss: 0.7852%]\n",
            "4640 [Discriminator loss: 0.6704%, acc.: 58.20%] [Generator loss: 0.7938%]\n",
            "4641 [Discriminator loss: 0.6822%, acc.: 54.69%] [Generator loss: 0.7939%]\n",
            "4642 [Discriminator loss: 0.6805%, acc.: 56.25%] [Generator loss: 0.7655%]\n",
            "4643 [Discriminator loss: 0.6834%, acc.: 56.64%] [Generator loss: 0.7954%]\n",
            "4644 [Discriminator loss: 0.6676%, acc.: 61.33%] [Generator loss: 0.7801%]\n",
            "4645 [Discriminator loss: 0.6650%, acc.: 58.59%] [Generator loss: 0.7834%]\n",
            "4646 [Discriminator loss: 0.7026%, acc.: 51.56%] [Generator loss: 0.7975%]\n",
            "4647 [Discriminator loss: 0.6854%, acc.: 55.08%] [Generator loss: 0.7959%]\n",
            "4648 [Discriminator loss: 0.6752%, acc.: 57.03%] [Generator loss: 0.7872%]\n",
            "4649 [Discriminator loss: 0.6874%, acc.: 56.25%] [Generator loss: 0.7871%]\n",
            "4650 [Discriminator loss: 0.6858%, acc.: 56.64%] [Generator loss: 0.7958%]\n",
            "4651 [Discriminator loss: 0.6698%, acc.: 58.59%] [Generator loss: 0.7955%]\n",
            "4652 [Discriminator loss: 0.6644%, acc.: 59.38%] [Generator loss: 0.7788%]\n",
            "4653 [Discriminator loss: 0.6682%, acc.: 56.64%] [Generator loss: 0.7721%]\n",
            "4654 [Discriminator loss: 0.6982%, acc.: 50.78%] [Generator loss: 0.7959%]\n",
            "4655 [Discriminator loss: 0.6810%, acc.: 55.08%] [Generator loss: 0.7865%]\n",
            "4656 [Discriminator loss: 0.6696%, acc.: 56.64%] [Generator loss: 0.7898%]\n",
            "4657 [Discriminator loss: 0.6675%, acc.: 60.55%] [Generator loss: 0.7837%]\n",
            "4658 [Discriminator loss: 0.6735%, acc.: 57.03%] [Generator loss: 0.7622%]\n",
            "4659 [Discriminator loss: 0.6768%, acc.: 57.03%] [Generator loss: 0.7776%]\n",
            "4660 [Discriminator loss: 0.6667%, acc.: 60.55%] [Generator loss: 0.7760%]\n",
            "4661 [Discriminator loss: 0.6884%, acc.: 51.95%] [Generator loss: 0.7996%]\n",
            "4662 [Discriminator loss: 0.6830%, acc.: 55.86%] [Generator loss: 0.8183%]\n",
            "4663 [Discriminator loss: 0.6751%, acc.: 55.08%] [Generator loss: 0.7910%]\n",
            "4664 [Discriminator loss: 0.6855%, acc.: 56.64%] [Generator loss: 0.8007%]\n",
            "4665 [Discriminator loss: 0.6886%, acc.: 51.95%] [Generator loss: 0.7932%]\n",
            "4666 [Discriminator loss: 0.6535%, acc.: 64.06%] [Generator loss: 0.7965%]\n",
            "4667 [Discriminator loss: 0.6676%, acc.: 60.94%] [Generator loss: 0.7972%]\n",
            "4668 [Discriminator loss: 0.6801%, acc.: 58.20%] [Generator loss: 0.8100%]\n",
            "4669 [Discriminator loss: 0.6756%, acc.: 57.42%] [Generator loss: 0.8133%]\n",
            "4670 [Discriminator loss: 0.6692%, acc.: 60.16%] [Generator loss: 0.8014%]\n",
            "4671 [Discriminator loss: 0.6754%, acc.: 57.03%] [Generator loss: 0.7808%]\n",
            "4672 [Discriminator loss: 0.6551%, acc.: 59.77%] [Generator loss: 0.8038%]\n",
            "4673 [Discriminator loss: 0.6688%, acc.: 58.59%] [Generator loss: 0.7796%]\n",
            "4674 [Discriminator loss: 0.6779%, acc.: 55.08%] [Generator loss: 0.7696%]\n",
            "4675 [Discriminator loss: 0.6640%, acc.: 58.59%] [Generator loss: 0.7927%]\n",
            "4676 [Discriminator loss: 0.6756%, acc.: 54.30%] [Generator loss: 0.7892%]\n",
            "4677 [Discriminator loss: 0.6705%, acc.: 61.33%] [Generator loss: 0.7782%]\n",
            "4678 [Discriminator loss: 0.6661%, acc.: 62.89%] [Generator loss: 0.8011%]\n",
            "4679 [Discriminator loss: 0.6703%, acc.: 59.77%] [Generator loss: 0.7762%]\n",
            "4680 [Discriminator loss: 0.6669%, acc.: 63.28%] [Generator loss: 0.7814%]\n",
            "4681 [Discriminator loss: 0.6634%, acc.: 60.94%] [Generator loss: 0.7802%]\n",
            "4682 [Discriminator loss: 0.6719%, acc.: 57.81%] [Generator loss: 0.8105%]\n",
            "4683 [Discriminator loss: 0.6653%, acc.: 62.50%] [Generator loss: 0.7610%]\n",
            "4684 [Discriminator loss: 0.6636%, acc.: 60.16%] [Generator loss: 0.8034%]\n",
            "4685 [Discriminator loss: 0.6683%, acc.: 55.86%] [Generator loss: 0.7977%]\n",
            "4686 [Discriminator loss: 0.6913%, acc.: 54.30%] [Generator loss: 0.7921%]\n",
            "4687 [Discriminator loss: 0.6682%, acc.: 58.98%] [Generator loss: 0.8079%]\n",
            "4688 [Discriminator loss: 0.6536%, acc.: 62.11%] [Generator loss: 0.8044%]\n",
            "4689 [Discriminator loss: 0.6489%, acc.: 63.67%] [Generator loss: 0.7888%]\n",
            "4690 [Discriminator loss: 0.6857%, acc.: 53.52%] [Generator loss: 0.7691%]\n",
            "4691 [Discriminator loss: 0.6678%, acc.: 58.20%] [Generator loss: 0.7931%]\n",
            "4692 [Discriminator loss: 0.6706%, acc.: 55.08%] [Generator loss: 0.7833%]\n",
            "4693 [Discriminator loss: 0.6707%, acc.: 56.64%] [Generator loss: 0.7902%]\n",
            "4694 [Discriminator loss: 0.6797%, acc.: 54.69%] [Generator loss: 0.7776%]\n",
            "4695 [Discriminator loss: 0.6775%, acc.: 58.20%] [Generator loss: 0.7885%]\n",
            "4696 [Discriminator loss: 0.6818%, acc.: 49.61%] [Generator loss: 0.7690%]\n",
            "4697 [Discriminator loss: 0.6651%, acc.: 60.55%] [Generator loss: 0.7865%]\n",
            "4698 [Discriminator loss: 0.6789%, acc.: 58.98%] [Generator loss: 0.7600%]\n",
            "4699 [Discriminator loss: 0.6517%, acc.: 61.33%] [Generator loss: 0.7935%]\n",
            "4700 [Discriminator loss: 0.6738%, acc.: 58.98%] [Generator loss: 0.7776%]\n",
            "4701 [Discriminator loss: 0.6791%, acc.: 53.91%] [Generator loss: 0.7917%]\n",
            "4702 [Discriminator loss: 0.6745%, acc.: 59.38%] [Generator loss: 0.7913%]\n",
            "4703 [Discriminator loss: 0.6717%, acc.: 56.25%] [Generator loss: 0.7850%]\n",
            "4704 [Discriminator loss: 0.6848%, acc.: 52.73%] [Generator loss: 0.7804%]\n",
            "4705 [Discriminator loss: 0.6788%, acc.: 56.25%] [Generator loss: 0.7845%]\n",
            "4706 [Discriminator loss: 0.6725%, acc.: 56.64%] [Generator loss: 0.7817%]\n",
            "4707 [Discriminator loss: 0.6871%, acc.: 53.91%] [Generator loss: 0.7801%]\n",
            "4708 [Discriminator loss: 0.6815%, acc.: 52.73%] [Generator loss: 0.8002%]\n",
            "4709 [Discriminator loss: 0.6645%, acc.: 60.94%] [Generator loss: 0.7894%]\n",
            "4710 [Discriminator loss: 0.6859%, acc.: 55.47%] [Generator loss: 0.7904%]\n",
            "4711 [Discriminator loss: 0.6830%, acc.: 52.34%] [Generator loss: 0.8041%]\n",
            "4712 [Discriminator loss: 0.6813%, acc.: 54.69%] [Generator loss: 0.7797%]\n",
            "4713 [Discriminator loss: 0.6804%, acc.: 54.30%] [Generator loss: 0.7760%]\n",
            "4714 [Discriminator loss: 0.6887%, acc.: 52.73%] [Generator loss: 0.8020%]\n",
            "4715 [Discriminator loss: 0.6795%, acc.: 54.69%] [Generator loss: 0.7864%]\n",
            "4716 [Discriminator loss: 0.6672%, acc.: 60.55%] [Generator loss: 0.7864%]\n",
            "4717 [Discriminator loss: 0.6833%, acc.: 52.34%] [Generator loss: 0.7856%]\n",
            "4718 [Discriminator loss: 0.6705%, acc.: 60.94%] [Generator loss: 0.7926%]\n",
            "4719 [Discriminator loss: 0.6706%, acc.: 56.64%] [Generator loss: 0.7744%]\n",
            "4720 [Discriminator loss: 0.6656%, acc.: 58.98%] [Generator loss: 0.7995%]\n",
            "4721 [Discriminator loss: 0.6855%, acc.: 51.56%] [Generator loss: 0.8067%]\n",
            "4722 [Discriminator loss: 0.6753%, acc.: 60.16%] [Generator loss: 0.7888%]\n",
            "4723 [Discriminator loss: 0.6793%, acc.: 55.08%] [Generator loss: 0.7692%]\n",
            "4724 [Discriminator loss: 0.6768%, acc.: 52.73%] [Generator loss: 0.7843%]\n",
            "4725 [Discriminator loss: 0.6564%, acc.: 61.72%] [Generator loss: 0.7825%]\n",
            "4726 [Discriminator loss: 0.6567%, acc.: 63.67%] [Generator loss: 0.7917%]\n",
            "4727 [Discriminator loss: 0.6650%, acc.: 60.55%] [Generator loss: 0.7804%]\n",
            "4728 [Discriminator loss: 0.6807%, acc.: 56.25%] [Generator loss: 0.7849%]\n",
            "4729 [Discriminator loss: 0.6888%, acc.: 53.52%] [Generator loss: 0.7835%]\n",
            "4730 [Discriminator loss: 0.6886%, acc.: 52.34%] [Generator loss: 0.7861%]\n",
            "4731 [Discriminator loss: 0.6849%, acc.: 53.12%] [Generator loss: 0.8132%]\n",
            "4732 [Discriminator loss: 0.6840%, acc.: 54.69%] [Generator loss: 0.7926%]\n",
            "4733 [Discriminator loss: 0.6727%, acc.: 59.38%] [Generator loss: 0.8087%]\n",
            "4734 [Discriminator loss: 0.6756%, acc.: 58.59%] [Generator loss: 0.7902%]\n",
            "4735 [Discriminator loss: 0.6872%, acc.: 53.12%] [Generator loss: 0.8004%]\n",
            "4736 [Discriminator loss: 0.6682%, acc.: 58.59%] [Generator loss: 0.8007%]\n",
            "4737 [Discriminator loss: 0.6661%, acc.: 58.20%] [Generator loss: 0.7721%]\n",
            "4738 [Discriminator loss: 0.6852%, acc.: 56.25%] [Generator loss: 0.7976%]\n",
            "4739 [Discriminator loss: 0.6530%, acc.: 62.89%] [Generator loss: 0.8094%]\n",
            "4740 [Discriminator loss: 0.6706%, acc.: 58.98%] [Generator loss: 0.8098%]\n",
            "4741 [Discriminator loss: 0.6894%, acc.: 53.12%] [Generator loss: 0.8117%]\n",
            "4742 [Discriminator loss: 0.6626%, acc.: 58.59%] [Generator loss: 0.7983%]\n",
            "4743 [Discriminator loss: 0.6676%, acc.: 57.81%] [Generator loss: 0.8118%]\n",
            "4744 [Discriminator loss: 0.6601%, acc.: 58.20%] [Generator loss: 0.7999%]\n",
            "4745 [Discriminator loss: 0.6619%, acc.: 60.55%] [Generator loss: 0.8007%]\n",
            "4746 [Discriminator loss: 0.6509%, acc.: 67.58%] [Generator loss: 0.8056%]\n",
            "4747 [Discriminator loss: 0.6566%, acc.: 62.11%] [Generator loss: 0.7907%]\n",
            "4748 [Discriminator loss: 0.6690%, acc.: 56.64%] [Generator loss: 0.7894%]\n",
            "4749 [Discriminator loss: 0.6707%, acc.: 56.25%] [Generator loss: 0.7924%]\n",
            "4750 [Discriminator loss: 0.6630%, acc.: 64.84%] [Generator loss: 0.7841%]\n",
            "4751 [Discriminator loss: 0.6878%, acc.: 57.81%] [Generator loss: 0.7853%]\n",
            "4752 [Discriminator loss: 0.6698%, acc.: 58.98%] [Generator loss: 0.7794%]\n",
            "4753 [Discriminator loss: 0.6720%, acc.: 56.64%] [Generator loss: 0.7783%]\n",
            "4754 [Discriminator loss: 0.6728%, acc.: 55.47%] [Generator loss: 0.7830%]\n",
            "4755 [Discriminator loss: 0.6650%, acc.: 60.16%] [Generator loss: 0.7763%]\n",
            "4756 [Discriminator loss: 0.6615%, acc.: 61.33%] [Generator loss: 0.7599%]\n",
            "4757 [Discriminator loss: 0.6614%, acc.: 61.33%] [Generator loss: 0.7890%]\n",
            "4758 [Discriminator loss: 0.6451%, acc.: 65.62%] [Generator loss: 0.7903%]\n",
            "4759 [Discriminator loss: 0.6544%, acc.: 62.89%] [Generator loss: 0.7818%]\n",
            "4760 [Discriminator loss: 0.6617%, acc.: 58.98%] [Generator loss: 0.8019%]\n",
            "4761 [Discriminator loss: 0.6580%, acc.: 62.11%] [Generator loss: 0.7890%]\n",
            "4762 [Discriminator loss: 0.6443%, acc.: 67.58%] [Generator loss: 0.7911%]\n",
            "4763 [Discriminator loss: 0.6579%, acc.: 62.50%] [Generator loss: 0.8017%]\n",
            "4764 [Discriminator loss: 0.6838%, acc.: 57.03%] [Generator loss: 0.8192%]\n",
            "4765 [Discriminator loss: 0.6481%, acc.: 64.84%] [Generator loss: 0.8222%]\n",
            "4766 [Discriminator loss: 0.6568%, acc.: 67.97%] [Generator loss: 0.7976%]\n",
            "4767 [Discriminator loss: 0.6554%, acc.: 62.89%] [Generator loss: 0.7914%]\n",
            "4768 [Discriminator loss: 0.6440%, acc.: 65.23%] [Generator loss: 0.7997%]\n",
            "4769 [Discriminator loss: 0.6517%, acc.: 61.33%] [Generator loss: 0.8004%]\n",
            "4770 [Discriminator loss: 0.6464%, acc.: 58.98%] [Generator loss: 0.7920%]\n",
            "4771 [Discriminator loss: 0.6546%, acc.: 61.72%] [Generator loss: 0.8046%]\n",
            "4772 [Discriminator loss: 0.6678%, acc.: 58.98%] [Generator loss: 0.7990%]\n",
            "4773 [Discriminator loss: 0.6539%, acc.: 58.59%] [Generator loss: 0.7995%]\n",
            "4774 [Discriminator loss: 0.6557%, acc.: 61.33%] [Generator loss: 0.8099%]\n",
            "4775 [Discriminator loss: 0.6616%, acc.: 62.11%] [Generator loss: 0.7931%]\n",
            "4776 [Discriminator loss: 0.6637%, acc.: 60.16%] [Generator loss: 0.7755%]\n",
            "4777 [Discriminator loss: 0.6556%, acc.: 61.33%] [Generator loss: 0.7764%]\n",
            "4778 [Discriminator loss: 0.6394%, acc.: 56.25%] [Generator loss: 0.8055%]\n",
            "4779 [Discriminator loss: 0.6626%, acc.: 60.16%] [Generator loss: 0.7941%]\n",
            "4780 [Discriminator loss: 0.6567%, acc.: 63.28%] [Generator loss: 0.7776%]\n",
            "4781 [Discriminator loss: 0.6550%, acc.: 60.94%] [Generator loss: 0.8035%]\n",
            "4782 [Discriminator loss: 0.6716%, acc.: 57.81%] [Generator loss: 0.7955%]\n",
            "4783 [Discriminator loss: 0.6679%, acc.: 57.42%] [Generator loss: 0.8042%]\n",
            "4784 [Discriminator loss: 0.6666%, acc.: 60.16%] [Generator loss: 0.8186%]\n",
            "4785 [Discriminator loss: 0.6666%, acc.: 58.59%] [Generator loss: 0.8032%]\n",
            "4786 [Discriminator loss: 0.6546%, acc.: 64.84%] [Generator loss: 0.8164%]\n",
            "4787 [Discriminator loss: 0.6511%, acc.: 67.19%] [Generator loss: 0.7989%]\n",
            "4788 [Discriminator loss: 0.6551%, acc.: 62.89%] [Generator loss: 0.7703%]\n",
            "4789 [Discriminator loss: 0.6685%, acc.: 62.89%] [Generator loss: 0.7860%]\n",
            "4790 [Discriminator loss: 0.6731%, acc.: 56.64%] [Generator loss: 0.7656%]\n",
            "4791 [Discriminator loss: 0.6650%, acc.: 60.16%] [Generator loss: 0.7897%]\n",
            "4792 [Discriminator loss: 0.6702%, acc.: 60.55%] [Generator loss: 0.7904%]\n",
            "4793 [Discriminator loss: 0.6533%, acc.: 66.80%] [Generator loss: 0.8177%]\n",
            "4794 [Discriminator loss: 0.6723%, acc.: 56.25%] [Generator loss: 0.8102%]\n",
            "4795 [Discriminator loss: 0.6595%, acc.: 63.67%] [Generator loss: 0.8127%]\n",
            "4796 [Discriminator loss: 0.6769%, acc.: 55.86%] [Generator loss: 0.8076%]\n",
            "4797 [Discriminator loss: 0.6704%, acc.: 54.30%] [Generator loss: 0.7836%]\n",
            "4798 [Discriminator loss: 0.6634%, acc.: 59.77%] [Generator loss: 0.7816%]\n",
            "4799 [Discriminator loss: 0.6820%, acc.: 51.95%] [Generator loss: 0.7852%]\n",
            "4800 [Discriminator loss: 0.6624%, acc.: 59.38%] [Generator loss: 0.7874%]\n",
            "4801 [Discriminator loss: 0.6625%, acc.: 59.77%] [Generator loss: 0.8076%]\n",
            "4802 [Discriminator loss: 0.6592%, acc.: 58.20%] [Generator loss: 0.8115%]\n",
            "4803 [Discriminator loss: 0.6762%, acc.: 57.42%] [Generator loss: 0.8094%]\n",
            "4804 [Discriminator loss: 0.6696%, acc.: 54.30%] [Generator loss: 0.7877%]\n",
            "4805 [Discriminator loss: 0.6646%, acc.: 58.98%] [Generator loss: 0.7750%]\n",
            "4806 [Discriminator loss: 0.6771%, acc.: 53.12%] [Generator loss: 0.7862%]\n",
            "4807 [Discriminator loss: 0.6624%, acc.: 62.50%] [Generator loss: 0.8113%]\n",
            "4808 [Discriminator loss: 0.6680%, acc.: 62.11%] [Generator loss: 0.7910%]\n",
            "4809 [Discriminator loss: 0.6648%, acc.: 56.25%] [Generator loss: 0.8050%]\n",
            "4810 [Discriminator loss: 0.6663%, acc.: 57.81%] [Generator loss: 0.8241%]\n",
            "4811 [Discriminator loss: 0.6730%, acc.: 57.42%] [Generator loss: 0.8216%]\n",
            "4812 [Discriminator loss: 0.6658%, acc.: 58.20%] [Generator loss: 0.8203%]\n",
            "4813 [Discriminator loss: 0.6746%, acc.: 57.03%] [Generator loss: 0.8012%]\n",
            "4814 [Discriminator loss: 0.6770%, acc.: 56.64%] [Generator loss: 0.7927%]\n",
            "4815 [Discriminator loss: 0.6841%, acc.: 47.66%] [Generator loss: 0.7778%]\n",
            "4816 [Discriminator loss: 0.6652%, acc.: 57.03%] [Generator loss: 0.7809%]\n",
            "4817 [Discriminator loss: 0.6784%, acc.: 55.86%] [Generator loss: 0.7869%]\n",
            "4818 [Discriminator loss: 0.6760%, acc.: 55.08%] [Generator loss: 0.7764%]\n",
            "4819 [Discriminator loss: 0.6865%, acc.: 53.12%] [Generator loss: 0.7773%]\n",
            "4820 [Discriminator loss: 0.6839%, acc.: 54.69%] [Generator loss: 0.7771%]\n",
            "4821 [Discriminator loss: 0.6658%, acc.: 57.42%] [Generator loss: 0.8111%]\n",
            "4822 [Discriminator loss: 0.6724%, acc.: 57.81%] [Generator loss: 0.7933%]\n",
            "4823 [Discriminator loss: 0.7074%, acc.: 46.48%] [Generator loss: 0.7939%]\n",
            "4824 [Discriminator loss: 0.6763%, acc.: 55.47%] [Generator loss: 0.7863%]\n",
            "4825 [Discriminator loss: 0.6786%, acc.: 58.59%] [Generator loss: 0.7764%]\n",
            "4826 [Discriminator loss: 0.6847%, acc.: 57.03%] [Generator loss: 0.7756%]\n",
            "4827 [Discriminator loss: 0.6796%, acc.: 58.59%] [Generator loss: 0.7838%]\n",
            "4828 [Discriminator loss: 0.7107%, acc.: 51.17%] [Generator loss: 0.7529%]\n",
            "4829 [Discriminator loss: 0.6729%, acc.: 57.81%] [Generator loss: 0.7743%]\n",
            "4830 [Discriminator loss: 0.6771%, acc.: 57.42%] [Generator loss: 0.7991%]\n",
            "4831 [Discriminator loss: 0.6859%, acc.: 50.78%] [Generator loss: 0.8126%]\n",
            "4832 [Discriminator loss: 0.6634%, acc.: 60.55%] [Generator loss: 0.7886%]\n",
            "4833 [Discriminator loss: 0.6739%, acc.: 58.20%] [Generator loss: 0.8143%]\n",
            "4834 [Discriminator loss: 0.6795%, acc.: 57.81%] [Generator loss: 0.8283%]\n",
            "4835 [Discriminator loss: 0.6753%, acc.: 55.47%] [Generator loss: 0.8056%]\n",
            "4836 [Discriminator loss: 0.6813%, acc.: 57.42%] [Generator loss: 0.8192%]\n",
            "4837 [Discriminator loss: 0.6847%, acc.: 55.47%] [Generator loss: 0.8060%]\n",
            "4838 [Discriminator loss: 0.6795%, acc.: 55.47%] [Generator loss: 0.8076%]\n",
            "4839 [Discriminator loss: 0.6868%, acc.: 53.91%] [Generator loss: 0.8357%]\n",
            "4840 [Discriminator loss: 0.6770%, acc.: 56.25%] [Generator loss: 0.8202%]\n",
            "4841 [Discriminator loss: 0.6802%, acc.: 57.03%] [Generator loss: 0.7887%]\n",
            "4842 [Discriminator loss: 0.6776%, acc.: 56.64%] [Generator loss: 0.8074%]\n",
            "4843 [Discriminator loss: 0.6645%, acc.: 58.59%] [Generator loss: 0.8075%]\n",
            "4844 [Discriminator loss: 0.6619%, acc.: 60.94%] [Generator loss: 0.8123%]\n",
            "4845 [Discriminator loss: 0.6719%, acc.: 57.81%] [Generator loss: 0.7938%]\n",
            "4846 [Discriminator loss: 0.6681%, acc.: 60.16%] [Generator loss: 0.7797%]\n",
            "4847 [Discriminator loss: 0.6635%, acc.: 58.59%] [Generator loss: 0.8047%]\n",
            "4848 [Discriminator loss: 0.6710%, acc.: 57.42%] [Generator loss: 0.8160%]\n",
            "4849 [Discriminator loss: 0.6617%, acc.: 57.42%] [Generator loss: 0.8152%]\n",
            "4850 [Discriminator loss: 0.6821%, acc.: 56.25%] [Generator loss: 0.8079%]\n",
            "4851 [Discriminator loss: 0.6651%, acc.: 60.55%] [Generator loss: 0.7799%]\n",
            "4852 [Discriminator loss: 0.6697%, acc.: 55.86%] [Generator loss: 0.8090%]\n",
            "4853 [Discriminator loss: 0.6510%, acc.: 58.59%] [Generator loss: 0.8192%]\n",
            "4854 [Discriminator loss: 0.6492%, acc.: 62.89%] [Generator loss: 0.8152%]\n",
            "4855 [Discriminator loss: 0.6405%, acc.: 64.45%] [Generator loss: 0.7995%]\n",
            "4856 [Discriminator loss: 0.6565%, acc.: 63.28%] [Generator loss: 0.8185%]\n",
            "4857 [Discriminator loss: 0.6723%, acc.: 55.86%] [Generator loss: 0.8116%]\n",
            "4858 [Discriminator loss: 0.6605%, acc.: 60.55%] [Generator loss: 0.8196%]\n",
            "4859 [Discriminator loss: 0.6504%, acc.: 63.28%] [Generator loss: 0.8103%]\n",
            "4860 [Discriminator loss: 0.6675%, acc.: 60.16%] [Generator loss: 0.8123%]\n",
            "4861 [Discriminator loss: 0.6613%, acc.: 61.33%] [Generator loss: 0.7883%]\n",
            "4862 [Discriminator loss: 0.6512%, acc.: 62.50%] [Generator loss: 0.7984%]\n",
            "4863 [Discriminator loss: 0.6519%, acc.: 64.06%] [Generator loss: 0.8124%]\n",
            "4864 [Discriminator loss: 0.6701%, acc.: 54.69%] [Generator loss: 0.8119%]\n",
            "4865 [Discriminator loss: 0.6645%, acc.: 59.38%] [Generator loss: 0.8100%]\n",
            "4866 [Discriminator loss: 0.6814%, acc.: 50.78%] [Generator loss: 0.8098%]\n",
            "4867 [Discriminator loss: 0.6585%, acc.: 62.50%] [Generator loss: 0.7689%]\n",
            "4868 [Discriminator loss: 0.6715%, acc.: 57.81%] [Generator loss: 0.7796%]\n",
            "4869 [Discriminator loss: 0.6605%, acc.: 58.98%] [Generator loss: 0.7836%]\n",
            "4870 [Discriminator loss: 0.6663%, acc.: 59.38%] [Generator loss: 0.7869%]\n",
            "4871 [Discriminator loss: 0.6634%, acc.: 60.94%] [Generator loss: 0.8004%]\n",
            "4872 [Discriminator loss: 0.6687%, acc.: 55.47%] [Generator loss: 0.8070%]\n",
            "4873 [Discriminator loss: 0.6689%, acc.: 56.64%] [Generator loss: 0.8069%]\n",
            "4874 [Discriminator loss: 0.6704%, acc.: 60.16%] [Generator loss: 0.8154%]\n",
            "4875 [Discriminator loss: 0.6765%, acc.: 53.12%] [Generator loss: 0.8168%]\n",
            "4876 [Discriminator loss: 0.6911%, acc.: 52.34%] [Generator loss: 0.7840%]\n",
            "4877 [Discriminator loss: 0.6629%, acc.: 57.81%] [Generator loss: 0.7953%]\n",
            "4878 [Discriminator loss: 0.6946%, acc.: 51.95%] [Generator loss: 0.7990%]\n",
            "4879 [Discriminator loss: 0.6636%, acc.: 60.94%] [Generator loss: 0.8154%]\n",
            "4880 [Discriminator loss: 0.6839%, acc.: 53.12%] [Generator loss: 0.8108%]\n",
            "4881 [Discriminator loss: 0.6653%, acc.: 63.28%] [Generator loss: 0.8155%]\n",
            "4882 [Discriminator loss: 0.6762%, acc.: 55.47%] [Generator loss: 0.8118%]\n",
            "4883 [Discriminator loss: 0.6699%, acc.: 57.81%] [Generator loss: 0.8292%]\n",
            "4884 [Discriminator loss: 0.6811%, acc.: 54.69%] [Generator loss: 0.7958%]\n",
            "4885 [Discriminator loss: 0.6767%, acc.: 56.64%] [Generator loss: 0.7872%]\n",
            "4886 [Discriminator loss: 0.6852%, acc.: 50.39%] [Generator loss: 0.8131%]\n",
            "4887 [Discriminator loss: 0.6722%, acc.: 58.98%] [Generator loss: 0.8057%]\n",
            "4888 [Discriminator loss: 0.6718%, acc.: 58.59%] [Generator loss: 0.8063%]\n",
            "4889 [Discriminator loss: 0.6850%, acc.: 52.34%] [Generator loss: 0.8083%]\n",
            "4890 [Discriminator loss: 0.6781%, acc.: 56.64%] [Generator loss: 0.7964%]\n",
            "4891 [Discriminator loss: 0.6976%, acc.: 49.22%] [Generator loss: 0.7906%]\n",
            "4892 [Discriminator loss: 0.6703%, acc.: 57.81%] [Generator loss: 0.8008%]\n",
            "4893 [Discriminator loss: 0.6700%, acc.: 56.25%] [Generator loss: 0.8038%]\n",
            "4894 [Discriminator loss: 0.6692%, acc.: 61.33%] [Generator loss: 0.8043%]\n",
            "4895 [Discriminator loss: 0.6633%, acc.: 59.38%] [Generator loss: 0.8141%]\n",
            "4896 [Discriminator loss: 0.6712%, acc.: 56.64%] [Generator loss: 0.8109%]\n",
            "4897 [Discriminator loss: 0.6807%, acc.: 55.86%] [Generator loss: 0.8045%]\n",
            "4898 [Discriminator loss: 0.6642%, acc.: 57.81%] [Generator loss: 0.8048%]\n",
            "4899 [Discriminator loss: 0.6623%, acc.: 59.38%] [Generator loss: 0.7898%]\n",
            "4900 [Discriminator loss: 0.6690%, acc.: 57.81%] [Generator loss: 0.8148%]\n",
            "4901 [Discriminator loss: 0.6709%, acc.: 57.81%] [Generator loss: 0.7980%]\n",
            "4902 [Discriminator loss: 0.6679%, acc.: 61.72%] [Generator loss: 0.8071%]\n",
            "4903 [Discriminator loss: 0.6496%, acc.: 65.23%] [Generator loss: 0.8097%]\n",
            "4904 [Discriminator loss: 0.6665%, acc.: 60.16%] [Generator loss: 0.8169%]\n",
            "4905 [Discriminator loss: 0.6381%, acc.: 62.50%] [Generator loss: 0.8150%]\n",
            "4906 [Discriminator loss: 0.6692%, acc.: 60.94%] [Generator loss: 0.8002%]\n",
            "4907 [Discriminator loss: 0.6413%, acc.: 63.28%] [Generator loss: 0.8139%]\n",
            "4908 [Discriminator loss: 0.6447%, acc.: 62.89%] [Generator loss: 0.8050%]\n",
            "4909 [Discriminator loss: 0.6663%, acc.: 56.25%] [Generator loss: 0.8213%]\n",
            "4910 [Discriminator loss: 0.6526%, acc.: 60.94%] [Generator loss: 0.8373%]\n",
            "4911 [Discriminator loss: 0.6558%, acc.: 63.28%] [Generator loss: 0.8216%]\n",
            "4912 [Discriminator loss: 0.6600%, acc.: 65.62%] [Generator loss: 0.8397%]\n",
            "4913 [Discriminator loss: 0.6478%, acc.: 67.19%] [Generator loss: 0.8114%]\n",
            "4914 [Discriminator loss: 0.6644%, acc.: 57.42%] [Generator loss: 0.8227%]\n",
            "4915 [Discriminator loss: 0.6627%, acc.: 57.81%] [Generator loss: 0.8237%]\n",
            "4916 [Discriminator loss: 0.6458%, acc.: 64.45%] [Generator loss: 0.7985%]\n",
            "4917 [Discriminator loss: 0.6829%, acc.: 54.69%] [Generator loss: 0.8073%]\n",
            "4918 [Discriminator loss: 0.6524%, acc.: 66.02%] [Generator loss: 0.8125%]\n",
            "4919 [Discriminator loss: 0.6746%, acc.: 56.64%] [Generator loss: 0.8178%]\n",
            "4920 [Discriminator loss: 0.6714%, acc.: 56.25%] [Generator loss: 0.8098%]\n",
            "4921 [Discriminator loss: 0.6574%, acc.: 63.67%] [Generator loss: 0.8184%]\n",
            "4922 [Discriminator loss: 0.6435%, acc.: 64.06%] [Generator loss: 0.7992%]\n",
            "4923 [Discriminator loss: 0.6623%, acc.: 61.72%] [Generator loss: 0.8088%]\n",
            "4924 [Discriminator loss: 0.6620%, acc.: 59.38%] [Generator loss: 0.8207%]\n",
            "4925 [Discriminator loss: 0.6908%, acc.: 57.03%] [Generator loss: 0.8243%]\n",
            "4926 [Discriminator loss: 0.6813%, acc.: 57.81%] [Generator loss: 0.8230%]\n",
            "4927 [Discriminator loss: 0.6775%, acc.: 54.69%] [Generator loss: 0.8143%]\n",
            "4928 [Discriminator loss: 0.6864%, acc.: 52.73%] [Generator loss: 0.8078%]\n",
            "4929 [Discriminator loss: 0.6869%, acc.: 56.64%] [Generator loss: 0.8045%]\n",
            "4930 [Discriminator loss: 0.6797%, acc.: 55.47%] [Generator loss: 0.8263%]\n",
            "4931 [Discriminator loss: 0.6675%, acc.: 56.64%] [Generator loss: 0.8213%]\n",
            "4932 [Discriminator loss: 0.6623%, acc.: 61.33%] [Generator loss: 0.8092%]\n",
            "4933 [Discriminator loss: 0.6849%, acc.: 51.95%] [Generator loss: 0.8324%]\n",
            "4934 [Discriminator loss: 0.6729%, acc.: 56.25%] [Generator loss: 0.8185%]\n",
            "4935 [Discriminator loss: 0.6770%, acc.: 58.98%] [Generator loss: 0.8093%]\n",
            "4936 [Discriminator loss: 0.6670%, acc.: 58.98%] [Generator loss: 0.8106%]\n",
            "4937 [Discriminator loss: 0.6695%, acc.: 61.33%] [Generator loss: 0.8110%]\n",
            "4938 [Discriminator loss: 0.6787%, acc.: 51.56%] [Generator loss: 0.8016%]\n",
            "4939 [Discriminator loss: 0.6822%, acc.: 56.64%] [Generator loss: 0.8070%]\n",
            "4940 [Discriminator loss: 0.6769%, acc.: 54.30%] [Generator loss: 0.7959%]\n",
            "4941 [Discriminator loss: 0.6806%, acc.: 56.64%] [Generator loss: 0.7986%]\n",
            "4942 [Discriminator loss: 0.6768%, acc.: 55.47%] [Generator loss: 0.7951%]\n",
            "4943 [Discriminator loss: 0.6874%, acc.: 54.30%] [Generator loss: 0.7667%]\n",
            "4944 [Discriminator loss: 0.6635%, acc.: 61.72%] [Generator loss: 0.7790%]\n",
            "4945 [Discriminator loss: 0.6578%, acc.: 63.67%] [Generator loss: 0.7784%]\n",
            "4946 [Discriminator loss: 0.6598%, acc.: 61.33%] [Generator loss: 0.7803%]\n",
            "4947 [Discriminator loss: 0.6515%, acc.: 66.80%] [Generator loss: 0.7704%]\n",
            "4948 [Discriminator loss: 0.6682%, acc.: 58.20%] [Generator loss: 0.7778%]\n",
            "4949 [Discriminator loss: 0.6747%, acc.: 57.03%] [Generator loss: 0.7885%]\n",
            "4950 [Discriminator loss: 0.6771%, acc.: 57.81%] [Generator loss: 0.8136%]\n",
            "4951 [Discriminator loss: 0.6834%, acc.: 54.30%] [Generator loss: 0.8107%]\n",
            "4952 [Discriminator loss: 0.6700%, acc.: 57.42%] [Generator loss: 0.8172%]\n",
            "4953 [Discriminator loss: 0.6578%, acc.: 61.72%] [Generator loss: 0.7953%]\n",
            "4954 [Discriminator loss: 0.6818%, acc.: 59.77%] [Generator loss: 0.7860%]\n",
            "4955 [Discriminator loss: 0.6712%, acc.: 60.94%] [Generator loss: 0.7889%]\n",
            "4956 [Discriminator loss: 0.6777%, acc.: 58.98%] [Generator loss: 0.7898%]\n",
            "4957 [Discriminator loss: 0.6809%, acc.: 50.78%] [Generator loss: 0.7988%]\n",
            "4958 [Discriminator loss: 0.6740%, acc.: 60.55%] [Generator loss: 0.7908%]\n",
            "4959 [Discriminator loss: 0.6903%, acc.: 56.64%] [Generator loss: 0.8087%]\n",
            "4960 [Discriminator loss: 0.6697%, acc.: 60.94%] [Generator loss: 0.7902%]\n",
            "4961 [Discriminator loss: 0.6773%, acc.: 55.47%] [Generator loss: 0.7900%]\n",
            "4962 [Discriminator loss: 0.6748%, acc.: 53.91%] [Generator loss: 0.8010%]\n",
            "4963 [Discriminator loss: 0.6689%, acc.: 58.98%] [Generator loss: 0.7771%]\n",
            "4964 [Discriminator loss: 0.6872%, acc.: 53.52%] [Generator loss: 0.7727%]\n",
            "4965 [Discriminator loss: 0.6813%, acc.: 56.64%] [Generator loss: 0.7719%]\n",
            "4966 [Discriminator loss: 0.6583%, acc.: 63.67%] [Generator loss: 0.7825%]\n",
            "4967 [Discriminator loss: 0.7040%, acc.: 51.17%] [Generator loss: 0.7995%]\n",
            "4968 [Discriminator loss: 0.6665%, acc.: 54.69%] [Generator loss: 0.7980%]\n",
            "4969 [Discriminator loss: 0.6722%, acc.: 53.91%] [Generator loss: 0.8071%]\n",
            "4970 [Discriminator loss: 0.6511%, acc.: 62.50%] [Generator loss: 0.7878%]\n",
            "4971 [Discriminator loss: 0.6776%, acc.: 55.08%] [Generator loss: 0.7669%]\n",
            "4972 [Discriminator loss: 0.6856%, acc.: 58.20%] [Generator loss: 0.7820%]\n",
            "4973 [Discriminator loss: 0.6840%, acc.: 56.25%] [Generator loss: 0.7636%]\n",
            "4974 [Discriminator loss: 0.6967%, acc.: 52.34%] [Generator loss: 0.7812%]\n",
            "4975 [Discriminator loss: 0.6750%, acc.: 54.69%] [Generator loss: 0.7691%]\n",
            "4976 [Discriminator loss: 0.6681%, acc.: 57.42%] [Generator loss: 0.7879%]\n",
            "4977 [Discriminator loss: 0.6713%, acc.: 55.86%] [Generator loss: 0.7991%]\n",
            "4978 [Discriminator loss: 0.6898%, acc.: 51.95%] [Generator loss: 0.7818%]\n",
            "4979 [Discriminator loss: 0.6752%, acc.: 55.08%] [Generator loss: 0.7840%]\n",
            "4980 [Discriminator loss: 0.6849%, acc.: 55.08%] [Generator loss: 0.7693%]\n",
            "4981 [Discriminator loss: 0.6640%, acc.: 62.89%] [Generator loss: 0.7826%]\n",
            "4982 [Discriminator loss: 0.6912%, acc.: 51.56%] [Generator loss: 0.7594%]\n",
            "4983 [Discriminator loss: 0.6640%, acc.: 63.67%] [Generator loss: 0.7723%]\n",
            "4984 [Discriminator loss: 0.6990%, acc.: 48.83%] [Generator loss: 0.7676%]\n",
            "4985 [Discriminator loss: 0.6613%, acc.: 61.72%] [Generator loss: 0.7790%]\n",
            "4986 [Discriminator loss: 0.6743%, acc.: 56.25%] [Generator loss: 0.7707%]\n",
            "4987 [Discriminator loss: 0.6845%, acc.: 57.42%] [Generator loss: 0.7620%]\n",
            "4988 [Discriminator loss: 0.6802%, acc.: 56.64%] [Generator loss: 0.7829%]\n",
            "4989 [Discriminator loss: 0.6748%, acc.: 58.20%] [Generator loss: 0.7552%]\n",
            "4990 [Discriminator loss: 0.6722%, acc.: 56.25%] [Generator loss: 0.7833%]\n",
            "4991 [Discriminator loss: 0.6645%, acc.: 60.55%] [Generator loss: 0.7812%]\n",
            "4992 [Discriminator loss: 0.6791%, acc.: 60.16%] [Generator loss: 0.7907%]\n",
            "4993 [Discriminator loss: 0.6794%, acc.: 54.69%] [Generator loss: 0.7898%]\n",
            "4994 [Discriminator loss: 0.6611%, acc.: 60.16%] [Generator loss: 0.8034%]\n",
            "4995 [Discriminator loss: 0.6738%, acc.: 56.64%] [Generator loss: 0.7962%]\n",
            "4996 [Discriminator loss: 0.6728%, acc.: 56.25%] [Generator loss: 0.8004%]\n",
            "4997 [Discriminator loss: 0.6664%, acc.: 55.86%] [Generator loss: 0.7927%]\n",
            "4998 [Discriminator loss: 0.6658%, acc.: 57.03%] [Generator loss: 0.7914%]\n",
            "4999 [Discriminator loss: 0.6562%, acc.: 60.55%] [Generator loss: 0.8039%]\n",
            "5000 [Discriminator loss: 0.6666%, acc.: 56.64%] [Generator loss: 0.7856%]\n",
            "5001 [Discriminator loss: 0.6648%, acc.: 58.98%] [Generator loss: 0.7853%]\n",
            "5002 [Discriminator loss: 0.6765%, acc.: 53.91%] [Generator loss: 0.7957%]\n",
            "5003 [Discriminator loss: 0.6621%, acc.: 59.38%] [Generator loss: 0.7828%]\n",
            "5004 [Discriminator loss: 0.6576%, acc.: 61.33%] [Generator loss: 0.8064%]\n",
            "5005 [Discriminator loss: 0.6666%, acc.: 51.56%] [Generator loss: 0.8042%]\n",
            "5006 [Discriminator loss: 0.6598%, acc.: 58.59%] [Generator loss: 0.7977%]\n",
            "5007 [Discriminator loss: 0.6674%, acc.: 57.42%] [Generator loss: 0.8239%]\n",
            "5008 [Discriminator loss: 0.6722%, acc.: 60.55%] [Generator loss: 0.7863%]\n",
            "5009 [Discriminator loss: 0.6663%, acc.: 59.38%] [Generator loss: 0.7960%]\n",
            "5010 [Discriminator loss: 0.6638%, acc.: 60.55%] [Generator loss: 0.8008%]\n",
            "5011 [Discriminator loss: 0.6565%, acc.: 62.89%] [Generator loss: 0.8020%]\n",
            "5012 [Discriminator loss: 0.6619%, acc.: 59.38%] [Generator loss: 0.7743%]\n",
            "5013 [Discriminator loss: 0.6619%, acc.: 58.98%] [Generator loss: 0.7966%]\n",
            "5014 [Discriminator loss: 0.6766%, acc.: 54.30%] [Generator loss: 0.7929%]\n",
            "5015 [Discriminator loss: 0.6516%, acc.: 59.77%] [Generator loss: 0.7723%]\n",
            "5016 [Discriminator loss: 0.6582%, acc.: 62.50%] [Generator loss: 0.8119%]\n",
            "5017 [Discriminator loss: 0.6633%, acc.: 59.38%] [Generator loss: 0.8146%]\n",
            "5018 [Discriminator loss: 0.6635%, acc.: 60.55%] [Generator loss: 0.7895%]\n",
            "5019 [Discriminator loss: 0.6827%, acc.: 53.91%] [Generator loss: 0.7953%]\n",
            "5020 [Discriminator loss: 0.6582%, acc.: 55.08%] [Generator loss: 0.7950%]\n",
            "5021 [Discriminator loss: 0.6597%, acc.: 58.98%] [Generator loss: 0.7961%]\n",
            "5022 [Discriminator loss: 0.6727%, acc.: 55.86%] [Generator loss: 0.7840%]\n",
            "5023 [Discriminator loss: 0.6585%, acc.: 56.64%] [Generator loss: 0.8019%]\n",
            "5024 [Discriminator loss: 0.6755%, acc.: 57.42%] [Generator loss: 0.8020%]\n",
            "5025 [Discriminator loss: 0.6708%, acc.: 55.08%] [Generator loss: 0.8054%]\n",
            "5026 [Discriminator loss: 0.6913%, acc.: 51.17%] [Generator loss: 0.7715%]\n",
            "5027 [Discriminator loss: 0.6659%, acc.: 59.77%] [Generator loss: 0.7674%]\n",
            "5028 [Discriminator loss: 0.6774%, acc.: 55.47%] [Generator loss: 0.7855%]\n",
            "5029 [Discriminator loss: 0.6599%, acc.: 57.03%] [Generator loss: 0.8098%]\n",
            "5030 [Discriminator loss: 0.6536%, acc.: 58.59%] [Generator loss: 0.7895%]\n",
            "5031 [Discriminator loss: 0.6906%, acc.: 50.78%] [Generator loss: 0.7901%]\n",
            "5032 [Discriminator loss: 0.6777%, acc.: 55.47%] [Generator loss: 0.7930%]\n",
            "5033 [Discriminator loss: 0.6721%, acc.: 58.59%] [Generator loss: 0.8061%]\n",
            "5034 [Discriminator loss: 0.6760%, acc.: 55.08%] [Generator loss: 0.8026%]\n",
            "5035 [Discriminator loss: 0.6728%, acc.: 58.98%] [Generator loss: 0.7901%]\n",
            "5036 [Discriminator loss: 0.6718%, acc.: 56.64%] [Generator loss: 0.8006%]\n",
            "5037 [Discriminator loss: 0.6579%, acc.: 59.38%] [Generator loss: 0.7971%]\n",
            "5038 [Discriminator loss: 0.6658%, acc.: 58.20%] [Generator loss: 0.8032%]\n",
            "5039 [Discriminator loss: 0.6739%, acc.: 52.73%] [Generator loss: 0.8254%]\n",
            "5040 [Discriminator loss: 0.6645%, acc.: 58.20%] [Generator loss: 0.8000%]\n",
            "5041 [Discriminator loss: 0.6752%, acc.: 55.08%] [Generator loss: 0.8050%]\n",
            "5042 [Discriminator loss: 0.6691%, acc.: 55.86%] [Generator loss: 0.8064%]\n",
            "5043 [Discriminator loss: 0.6675%, acc.: 58.20%] [Generator loss: 0.7928%]\n",
            "5044 [Discriminator loss: 0.6878%, acc.: 53.52%] [Generator loss: 0.7966%]\n",
            "5045 [Discriminator loss: 0.6504%, acc.: 61.72%] [Generator loss: 0.7985%]\n",
            "5046 [Discriminator loss: 0.6987%, acc.: 54.69%] [Generator loss: 0.7911%]\n",
            "5047 [Discriminator loss: 0.6755%, acc.: 55.86%] [Generator loss: 0.8280%]\n",
            "5048 [Discriminator loss: 0.6666%, acc.: 55.86%] [Generator loss: 0.8126%]\n",
            "5049 [Discriminator loss: 0.6678%, acc.: 56.25%] [Generator loss: 0.8026%]\n",
            "5050 [Discriminator loss: 0.6519%, acc.: 57.81%] [Generator loss: 0.8034%]\n",
            "5051 [Discriminator loss: 0.6703%, acc.: 51.95%] [Generator loss: 0.8198%]\n",
            "5052 [Discriminator loss: 0.6616%, acc.: 61.72%] [Generator loss: 0.7989%]\n",
            "5053 [Discriminator loss: 0.6681%, acc.: 58.59%] [Generator loss: 0.8000%]\n",
            "5054 [Discriminator loss: 0.6707%, acc.: 55.08%] [Generator loss: 0.7871%]\n",
            "5055 [Discriminator loss: 0.6800%, acc.: 58.20%] [Generator loss: 0.8065%]\n",
            "5056 [Discriminator loss: 0.6585%, acc.: 56.25%] [Generator loss: 0.8119%]\n",
            "5057 [Discriminator loss: 0.6477%, acc.: 60.94%] [Generator loss: 0.7979%]\n",
            "5058 [Discriminator loss: 0.6733%, acc.: 55.86%] [Generator loss: 0.8232%]\n",
            "5059 [Discriminator loss: 0.6677%, acc.: 57.42%] [Generator loss: 0.8007%]\n",
            "5060 [Discriminator loss: 0.6681%, acc.: 57.03%] [Generator loss: 0.7827%]\n",
            "5061 [Discriminator loss: 0.6658%, acc.: 57.03%] [Generator loss: 0.7927%]\n",
            "5062 [Discriminator loss: 0.6822%, acc.: 55.86%] [Generator loss: 0.7993%]\n",
            "5063 [Discriminator loss: 0.6722%, acc.: 55.86%] [Generator loss: 0.8018%]\n",
            "5064 [Discriminator loss: 0.6569%, acc.: 60.94%] [Generator loss: 0.8171%]\n",
            "5065 [Discriminator loss: 0.6831%, acc.: 55.08%] [Generator loss: 0.7969%]\n",
            "5066 [Discriminator loss: 0.6878%, acc.: 54.30%] [Generator loss: 0.8107%]\n",
            "5067 [Discriminator loss: 0.6723%, acc.: 58.98%] [Generator loss: 0.7820%]\n",
            "5068 [Discriminator loss: 0.6697%, acc.: 56.64%] [Generator loss: 0.7913%]\n",
            "5069 [Discriminator loss: 0.6571%, acc.: 62.11%] [Generator loss: 0.7967%]\n",
            "5070 [Discriminator loss: 0.6677%, acc.: 59.77%] [Generator loss: 0.8069%]\n",
            "5071 [Discriminator loss: 0.6686%, acc.: 58.98%] [Generator loss: 0.8087%]\n",
            "5072 [Discriminator loss: 0.6656%, acc.: 57.03%] [Generator loss: 0.7992%]\n",
            "5073 [Discriminator loss: 0.6627%, acc.: 61.72%] [Generator loss: 0.8056%]\n",
            "5074 [Discriminator loss: 0.6803%, acc.: 58.98%] [Generator loss: 0.8019%]\n",
            "5075 [Discriminator loss: 0.6586%, acc.: 59.38%] [Generator loss: 0.8100%]\n",
            "5076 [Discriminator loss: 0.6741%, acc.: 58.20%] [Generator loss: 0.7888%]\n",
            "5077 [Discriminator loss: 0.6782%, acc.: 53.52%] [Generator loss: 0.7988%]\n",
            "5078 [Discriminator loss: 0.6538%, acc.: 60.16%] [Generator loss: 0.7928%]\n",
            "5079 [Discriminator loss: 0.6570%, acc.: 62.11%] [Generator loss: 0.7793%]\n",
            "5080 [Discriminator loss: 0.6665%, acc.: 56.25%] [Generator loss: 0.8159%]\n",
            "5081 [Discriminator loss: 0.6496%, acc.: 62.89%] [Generator loss: 0.7881%]\n",
            "5082 [Discriminator loss: 0.6808%, acc.: 52.34%] [Generator loss: 0.8047%]\n",
            "5083 [Discriminator loss: 0.6469%, acc.: 61.72%] [Generator loss: 0.8029%]\n",
            "5084 [Discriminator loss: 0.6617%, acc.: 57.42%] [Generator loss: 0.8190%]\n",
            "5085 [Discriminator loss: 0.6506%, acc.: 60.94%] [Generator loss: 0.8033%]\n",
            "5086 [Discriminator loss: 0.6427%, acc.: 62.89%] [Generator loss: 0.8431%]\n",
            "5087 [Discriminator loss: 0.6624%, acc.: 58.59%] [Generator loss: 0.7961%]\n",
            "5088 [Discriminator loss: 0.6389%, acc.: 67.19%] [Generator loss: 0.8075%]\n",
            "5089 [Discriminator loss: 0.6618%, acc.: 61.72%] [Generator loss: 0.8066%]\n",
            "5090 [Discriminator loss: 0.6538%, acc.: 59.38%] [Generator loss: 0.8132%]\n",
            "5091 [Discriminator loss: 0.6632%, acc.: 60.94%] [Generator loss: 0.8054%]\n",
            "5092 [Discriminator loss: 0.6559%, acc.: 62.50%] [Generator loss: 0.8261%]\n",
            "5093 [Discriminator loss: 0.6626%, acc.: 62.11%] [Generator loss: 0.8201%]\n",
            "5094 [Discriminator loss: 0.6420%, acc.: 68.75%] [Generator loss: 0.8207%]\n",
            "5095 [Discriminator loss: 0.6472%, acc.: 63.28%] [Generator loss: 0.8027%]\n",
            "5096 [Discriminator loss: 0.6580%, acc.: 62.11%] [Generator loss: 0.8189%]\n",
            "5097 [Discriminator loss: 0.6511%, acc.: 64.45%] [Generator loss: 0.8169%]\n",
            "5098 [Discriminator loss: 0.6491%, acc.: 61.33%] [Generator loss: 0.8384%]\n",
            "5099 [Discriminator loss: 0.6487%, acc.: 62.50%] [Generator loss: 0.8201%]\n",
            "5100 [Discriminator loss: 0.6454%, acc.: 63.67%] [Generator loss: 0.8247%]\n",
            "5101 [Discriminator loss: 0.6384%, acc.: 65.62%] [Generator loss: 0.7941%]\n",
            "5102 [Discriminator loss: 0.6521%, acc.: 59.77%] [Generator loss: 0.7930%]\n",
            "5103 [Discriminator loss: 0.6593%, acc.: 63.28%] [Generator loss: 0.8068%]\n",
            "5104 [Discriminator loss: 0.6544%, acc.: 63.28%] [Generator loss: 0.7962%]\n",
            "5105 [Discriminator loss: 0.6593%, acc.: 60.16%] [Generator loss: 0.7985%]\n",
            "5106 [Discriminator loss: 0.6602%, acc.: 58.20%] [Generator loss: 0.8009%]\n",
            "5107 [Discriminator loss: 0.6634%, acc.: 59.38%] [Generator loss: 0.8123%]\n",
            "5108 [Discriminator loss: 0.6625%, acc.: 55.86%] [Generator loss: 0.8259%]\n",
            "5109 [Discriminator loss: 0.6647%, acc.: 59.38%] [Generator loss: 0.8107%]\n",
            "5110 [Discriminator loss: 0.6819%, acc.: 55.08%] [Generator loss: 0.8060%]\n",
            "5111 [Discriminator loss: 0.6540%, acc.: 63.67%] [Generator loss: 0.8064%]\n",
            "5112 [Discriminator loss: 0.6565%, acc.: 62.50%] [Generator loss: 0.8023%]\n",
            "5113 [Discriminator loss: 0.6652%, acc.: 63.67%] [Generator loss: 0.7845%]\n",
            "5114 [Discriminator loss: 0.6657%, acc.: 59.77%] [Generator loss: 0.7842%]\n",
            "5115 [Discriminator loss: 0.6778%, acc.: 56.25%] [Generator loss: 0.8056%]\n",
            "5116 [Discriminator loss: 0.6597%, acc.: 61.72%] [Generator loss: 0.8152%]\n",
            "5117 [Discriminator loss: 0.6594%, acc.: 64.06%] [Generator loss: 0.7912%]\n",
            "5118 [Discriminator loss: 0.6497%, acc.: 59.38%] [Generator loss: 0.7907%]\n",
            "5119 [Discriminator loss: 0.6605%, acc.: 60.55%] [Generator loss: 0.8044%]\n",
            "5120 [Discriminator loss: 0.6753%, acc.: 55.47%] [Generator loss: 0.8023%]\n",
            "5121 [Discriminator loss: 0.6603%, acc.: 57.81%] [Generator loss: 0.8205%]\n",
            "5122 [Discriminator loss: 0.6811%, acc.: 57.03%] [Generator loss: 0.8053%]\n",
            "5123 [Discriminator loss: 0.6517%, acc.: 59.77%] [Generator loss: 0.8161%]\n",
            "5124 [Discriminator loss: 0.6476%, acc.: 64.45%] [Generator loss: 0.7994%]\n",
            "5125 [Discriminator loss: 0.6636%, acc.: 61.72%] [Generator loss: 0.8197%]\n",
            "5126 [Discriminator loss: 0.6681%, acc.: 57.81%] [Generator loss: 0.8307%]\n",
            "5127 [Discriminator loss: 0.6663%, acc.: 60.16%] [Generator loss: 0.8406%]\n",
            "5128 [Discriminator loss: 0.6722%, acc.: 59.38%] [Generator loss: 0.8185%]\n",
            "5129 [Discriminator loss: 0.6405%, acc.: 64.06%] [Generator loss: 0.8106%]\n",
            "5130 [Discriminator loss: 0.6498%, acc.: 64.45%] [Generator loss: 0.8223%]\n",
            "5131 [Discriminator loss: 0.6577%, acc.: 60.94%] [Generator loss: 0.8254%]\n",
            "5132 [Discriminator loss: 0.6811%, acc.: 53.52%] [Generator loss: 0.8011%]\n",
            "5133 [Discriminator loss: 0.6666%, acc.: 58.98%] [Generator loss: 0.8205%]\n",
            "5134 [Discriminator loss: 0.6658%, acc.: 60.16%] [Generator loss: 0.8069%]\n",
            "5135 [Discriminator loss: 0.6743%, acc.: 57.03%] [Generator loss: 0.8104%]\n",
            "5136 [Discriminator loss: 0.6790%, acc.: 54.30%] [Generator loss: 0.8033%]\n",
            "5137 [Discriminator loss: 0.6912%, acc.: 57.03%] [Generator loss: 0.8260%]\n",
            "5138 [Discriminator loss: 0.6435%, acc.: 64.06%] [Generator loss: 0.8355%]\n",
            "5139 [Discriminator loss: 0.6724%, acc.: 58.20%] [Generator loss: 0.7995%]\n",
            "5140 [Discriminator loss: 0.6665%, acc.: 58.20%] [Generator loss: 0.8188%]\n",
            "5141 [Discriminator loss: 0.6771%, acc.: 54.69%] [Generator loss: 0.8084%]\n",
            "5142 [Discriminator loss: 0.6985%, acc.: 47.27%] [Generator loss: 0.8119%]\n",
            "5143 [Discriminator loss: 0.6648%, acc.: 58.59%] [Generator loss: 0.8144%]\n",
            "5144 [Discriminator loss: 0.6751%, acc.: 55.47%] [Generator loss: 0.8124%]\n",
            "5145 [Discriminator loss: 0.6812%, acc.: 54.30%] [Generator loss: 0.8053%]\n",
            "5146 [Discriminator loss: 0.6600%, acc.: 62.11%] [Generator loss: 0.8073%]\n",
            "5147 [Discriminator loss: 0.6858%, acc.: 54.30%] [Generator loss: 0.7761%]\n",
            "5148 [Discriminator loss: 0.6726%, acc.: 56.25%] [Generator loss: 0.8126%]\n",
            "5149 [Discriminator loss: 0.6935%, acc.: 55.47%] [Generator loss: 0.8035%]\n",
            "5150 [Discriminator loss: 0.6555%, acc.: 60.55%] [Generator loss: 0.7921%]\n",
            "5151 [Discriminator loss: 0.6465%, acc.: 64.06%] [Generator loss: 0.8229%]\n",
            "5152 [Discriminator loss: 0.6669%, acc.: 58.20%] [Generator loss: 0.8032%]\n",
            "5153 [Discriminator loss: 0.6801%, acc.: 53.91%] [Generator loss: 0.8272%]\n",
            "5154 [Discriminator loss: 0.6893%, acc.: 57.03%] [Generator loss: 0.7991%]\n",
            "5155 [Discriminator loss: 0.6832%, acc.: 56.25%] [Generator loss: 0.8092%]\n",
            "5156 [Discriminator loss: 0.6934%, acc.: 55.47%] [Generator loss: 0.8214%]\n",
            "5157 [Discriminator loss: 0.6662%, acc.: 64.06%] [Generator loss: 0.8042%]\n",
            "5158 [Discriminator loss: 0.6532%, acc.: 62.50%] [Generator loss: 0.8099%]\n",
            "5159 [Discriminator loss: 0.6769%, acc.: 57.42%] [Generator loss: 0.8172%]\n",
            "5160 [Discriminator loss: 0.6664%, acc.: 60.94%] [Generator loss: 0.8117%]\n",
            "5161 [Discriminator loss: 0.6735%, acc.: 58.59%] [Generator loss: 0.7916%]\n",
            "5162 [Discriminator loss: 0.6583%, acc.: 61.72%] [Generator loss: 0.7969%]\n",
            "5163 [Discriminator loss: 0.6718%, acc.: 59.38%] [Generator loss: 0.8005%]\n",
            "5164 [Discriminator loss: 0.6767%, acc.: 59.38%] [Generator loss: 0.7853%]\n",
            "5165 [Discriminator loss: 0.6479%, acc.: 63.28%] [Generator loss: 0.7951%]\n",
            "5166 [Discriminator loss: 0.6665%, acc.: 61.33%] [Generator loss: 0.8027%]\n",
            "5167 [Discriminator loss: 0.6562%, acc.: 56.64%] [Generator loss: 0.7747%]\n",
            "5168 [Discriminator loss: 0.6561%, acc.: 60.16%] [Generator loss: 0.7795%]\n",
            "5169 [Discriminator loss: 0.6814%, acc.: 55.47%] [Generator loss: 0.8027%]\n",
            "5170 [Discriminator loss: 0.7006%, acc.: 50.78%] [Generator loss: 0.8135%]\n",
            "5171 [Discriminator loss: 0.6698%, acc.: 58.20%] [Generator loss: 0.8080%]\n",
            "5172 [Discriminator loss: 0.6843%, acc.: 54.69%] [Generator loss: 0.8038%]\n",
            "5173 [Discriminator loss: 0.6907%, acc.: 56.64%] [Generator loss: 0.8007%]\n",
            "5174 [Discriminator loss: 0.6681%, acc.: 60.16%] [Generator loss: 0.7937%]\n",
            "5175 [Discriminator loss: 0.6672%, acc.: 61.72%] [Generator loss: 0.8048%]\n",
            "5176 [Discriminator loss: 0.6365%, acc.: 67.58%] [Generator loss: 0.7787%]\n",
            "5177 [Discriminator loss: 0.6627%, acc.: 59.77%] [Generator loss: 0.7873%]\n",
            "5178 [Discriminator loss: 0.6766%, acc.: 58.98%] [Generator loss: 0.8159%]\n",
            "5179 [Discriminator loss: 0.6665%, acc.: 61.33%] [Generator loss: 0.7951%]\n",
            "5180 [Discriminator loss: 0.6641%, acc.: 56.64%] [Generator loss: 0.7939%]\n",
            "5181 [Discriminator loss: 0.6732%, acc.: 56.25%] [Generator loss: 0.8120%]\n",
            "5182 [Discriminator loss: 0.6726%, acc.: 57.81%] [Generator loss: 0.7923%]\n",
            "5183 [Discriminator loss: 0.6766%, acc.: 59.77%] [Generator loss: 0.8104%]\n",
            "5184 [Discriminator loss: 0.6758%, acc.: 56.25%] [Generator loss: 0.8027%]\n",
            "5185 [Discriminator loss: 0.6708%, acc.: 59.38%] [Generator loss: 0.8159%]\n",
            "5186 [Discriminator loss: 0.6767%, acc.: 58.98%] [Generator loss: 0.7923%]\n",
            "5187 [Discriminator loss: 0.6766%, acc.: 53.91%] [Generator loss: 0.7927%]\n",
            "5188 [Discriminator loss: 0.6666%, acc.: 59.38%] [Generator loss: 0.8065%]\n",
            "5189 [Discriminator loss: 0.6632%, acc.: 62.11%] [Generator loss: 0.8050%]\n",
            "5190 [Discriminator loss: 0.6664%, acc.: 56.64%] [Generator loss: 0.8197%]\n",
            "5191 [Discriminator loss: 0.6649%, acc.: 60.55%] [Generator loss: 0.8180%]\n",
            "5192 [Discriminator loss: 0.6720%, acc.: 59.77%] [Generator loss: 0.7776%]\n",
            "5193 [Discriminator loss: 0.6630%, acc.: 59.38%] [Generator loss: 0.8020%]\n",
            "5194 [Discriminator loss: 0.6633%, acc.: 59.77%] [Generator loss: 0.7887%]\n",
            "5195 [Discriminator loss: 0.6717%, acc.: 54.30%] [Generator loss: 0.7850%]\n",
            "5196 [Discriminator loss: 0.6621%, acc.: 59.38%] [Generator loss: 0.7889%]\n",
            "5197 [Discriminator loss: 0.6638%, acc.: 58.98%] [Generator loss: 0.7875%]\n",
            "5198 [Discriminator loss: 0.6668%, acc.: 59.38%] [Generator loss: 0.8070%]\n",
            "5199 [Discriminator loss: 0.6749%, acc.: 61.72%] [Generator loss: 0.7990%]\n",
            "5200 [Discriminator loss: 0.6683%, acc.: 54.69%] [Generator loss: 0.7742%]\n",
            "5201 [Discriminator loss: 0.6546%, acc.: 61.72%] [Generator loss: 0.7726%]\n",
            "5202 [Discriminator loss: 0.6634%, acc.: 60.94%] [Generator loss: 0.8049%]\n",
            "5203 [Discriminator loss: 0.6731%, acc.: 57.42%] [Generator loss: 0.7941%]\n",
            "5204 [Discriminator loss: 0.6514%, acc.: 63.28%] [Generator loss: 0.7967%]\n",
            "5205 [Discriminator loss: 0.6662%, acc.: 60.16%] [Generator loss: 0.7659%]\n",
            "5206 [Discriminator loss: 0.6677%, acc.: 58.20%] [Generator loss: 0.8063%]\n",
            "5207 [Discriminator loss: 0.6698%, acc.: 60.55%] [Generator loss: 0.8033%]\n",
            "5208 [Discriminator loss: 0.6597%, acc.: 59.77%] [Generator loss: 0.8099%]\n",
            "5209 [Discriminator loss: 0.6695%, acc.: 57.42%] [Generator loss: 0.7881%]\n",
            "5210 [Discriminator loss: 0.6628%, acc.: 58.98%] [Generator loss: 0.7729%]\n",
            "5211 [Discriminator loss: 0.6638%, acc.: 61.72%] [Generator loss: 0.8185%]\n",
            "5212 [Discriminator loss: 0.6474%, acc.: 62.89%] [Generator loss: 0.8058%]\n",
            "5213 [Discriminator loss: 0.6905%, acc.: 57.03%] [Generator loss: 0.8078%]\n",
            "5214 [Discriminator loss: 0.6594%, acc.: 64.06%] [Generator loss: 0.7846%]\n",
            "5215 [Discriminator loss: 0.6716%, acc.: 58.98%] [Generator loss: 0.7935%]\n",
            "5216 [Discriminator loss: 0.6664%, acc.: 58.20%] [Generator loss: 0.8085%]\n",
            "5217 [Discriminator loss: 0.6815%, acc.: 56.25%] [Generator loss: 0.8078%]\n",
            "5218 [Discriminator loss: 0.6676%, acc.: 58.20%] [Generator loss: 0.7918%]\n",
            "5219 [Discriminator loss: 0.7010%, acc.: 51.56%] [Generator loss: 0.8032%]\n",
            "5220 [Discriminator loss: 0.6979%, acc.: 53.91%] [Generator loss: 0.8040%]\n",
            "5221 [Discriminator loss: 0.6491%, acc.: 58.20%] [Generator loss: 0.7973%]\n",
            "5222 [Discriminator loss: 0.6713%, acc.: 58.59%] [Generator loss: 0.8024%]\n",
            "5223 [Discriminator loss: 0.6750%, acc.: 57.42%] [Generator loss: 0.7818%]\n",
            "5224 [Discriminator loss: 0.6755%, acc.: 53.12%] [Generator loss: 0.8126%]\n",
            "5225 [Discriminator loss: 0.6724%, acc.: 57.03%] [Generator loss: 0.8060%]\n",
            "5226 [Discriminator loss: 0.6744%, acc.: 54.30%] [Generator loss: 0.7999%]\n",
            "5227 [Discriminator loss: 0.6664%, acc.: 58.20%] [Generator loss: 0.8125%]\n",
            "5228 [Discriminator loss: 0.6672%, acc.: 57.42%] [Generator loss: 0.8246%]\n",
            "5229 [Discriminator loss: 0.6566%, acc.: 64.84%] [Generator loss: 0.7827%]\n",
            "5230 [Discriminator loss: 0.6681%, acc.: 58.59%] [Generator loss: 0.7833%]\n",
            "5231 [Discriminator loss: 0.6922%, acc.: 48.83%] [Generator loss: 0.7908%]\n",
            "5232 [Discriminator loss: 0.6767%, acc.: 57.03%] [Generator loss: 0.8235%]\n",
            "5233 [Discriminator loss: 0.6619%, acc.: 58.59%] [Generator loss: 0.8253%]\n",
            "5234 [Discriminator loss: 0.6463%, acc.: 66.80%] [Generator loss: 0.8137%]\n",
            "5235 [Discriminator loss: 0.6635%, acc.: 61.33%] [Generator loss: 0.8393%]\n",
            "5236 [Discriminator loss: 0.6587%, acc.: 60.55%] [Generator loss: 0.8059%]\n",
            "5237 [Discriminator loss: 0.6641%, acc.: 62.89%] [Generator loss: 0.8068%]\n",
            "5238 [Discriminator loss: 0.6786%, acc.: 53.91%] [Generator loss: 0.8088%]\n",
            "5239 [Discriminator loss: 0.6565%, acc.: 59.38%] [Generator loss: 0.8120%]\n",
            "5240 [Discriminator loss: 0.6585%, acc.: 58.98%] [Generator loss: 0.8236%]\n",
            "5241 [Discriminator loss: 0.6655%, acc.: 60.94%] [Generator loss: 0.8172%]\n",
            "5242 [Discriminator loss: 0.6648%, acc.: 58.20%] [Generator loss: 0.8085%]\n",
            "5243 [Discriminator loss: 0.6666%, acc.: 58.98%] [Generator loss: 0.8136%]\n",
            "5244 [Discriminator loss: 0.6416%, acc.: 66.02%] [Generator loss: 0.8157%]\n",
            "5245 [Discriminator loss: 0.6767%, acc.: 57.03%] [Generator loss: 0.8228%]\n",
            "5246 [Discriminator loss: 0.6476%, acc.: 65.23%] [Generator loss: 0.8238%]\n",
            "5247 [Discriminator loss: 0.6592%, acc.: 62.11%] [Generator loss: 0.8243%]\n",
            "5248 [Discriminator loss: 0.6654%, acc.: 60.55%] [Generator loss: 0.7994%]\n",
            "5249 [Discriminator loss: 0.6454%, acc.: 66.02%] [Generator loss: 0.8021%]\n",
            "5250 [Discriminator loss: 0.6482%, acc.: 63.28%] [Generator loss: 0.8114%]\n",
            "5251 [Discriminator loss: 0.6810%, acc.: 53.91%] [Generator loss: 0.7970%]\n",
            "5252 [Discriminator loss: 0.6694%, acc.: 55.86%] [Generator loss: 0.8082%]\n",
            "5253 [Discriminator loss: 0.6419%, acc.: 63.67%] [Generator loss: 0.7971%]\n",
            "5254 [Discriminator loss: 0.6481%, acc.: 60.94%] [Generator loss: 0.8035%]\n",
            "5255 [Discriminator loss: 0.6700%, acc.: 59.38%] [Generator loss: 0.8191%]\n",
            "5256 [Discriminator loss: 0.6691%, acc.: 55.86%] [Generator loss: 0.8111%]\n",
            "5257 [Discriminator loss: 0.6585%, acc.: 60.55%] [Generator loss: 0.7825%]\n",
            "5258 [Discriminator loss: 0.6664%, acc.: 57.03%] [Generator loss: 0.7831%]\n",
            "5259 [Discriminator loss: 0.6529%, acc.: 66.80%] [Generator loss: 0.8462%]\n",
            "5260 [Discriminator loss: 0.6943%, acc.: 51.56%] [Generator loss: 0.8145%]\n",
            "5261 [Discriminator loss: 0.6658%, acc.: 55.86%] [Generator loss: 0.7959%]\n",
            "5262 [Discriminator loss: 0.6765%, acc.: 61.33%] [Generator loss: 0.8122%]\n",
            "5263 [Discriminator loss: 0.6868%, acc.: 50.39%] [Generator loss: 0.8223%]\n",
            "5264 [Discriminator loss: 0.6772%, acc.: 54.69%] [Generator loss: 0.7920%]\n",
            "5265 [Discriminator loss: 0.6851%, acc.: 51.17%] [Generator loss: 0.7759%]\n",
            "5266 [Discriminator loss: 0.6734%, acc.: 58.98%] [Generator loss: 0.7950%]\n",
            "5267 [Discriminator loss: 0.6702%, acc.: 58.59%] [Generator loss: 0.8005%]\n",
            "5268 [Discriminator loss: 0.6702%, acc.: 60.94%] [Generator loss: 0.7882%]\n",
            "5269 [Discriminator loss: 0.6793%, acc.: 54.30%] [Generator loss: 0.7940%]\n",
            "5270 [Discriminator loss: 0.6776%, acc.: 56.64%] [Generator loss: 0.7918%]\n",
            "5271 [Discriminator loss: 0.6620%, acc.: 57.42%] [Generator loss: 0.8207%]\n",
            "5272 [Discriminator loss: 0.6656%, acc.: 60.55%] [Generator loss: 0.8292%]\n",
            "5273 [Discriminator loss: 0.6891%, acc.: 54.30%] [Generator loss: 0.7945%]\n",
            "5274 [Discriminator loss: 0.6787%, acc.: 53.91%] [Generator loss: 0.7998%]\n",
            "5275 [Discriminator loss: 0.6860%, acc.: 51.95%] [Generator loss: 0.7943%]\n",
            "5276 [Discriminator loss: 0.6978%, acc.: 51.95%] [Generator loss: 0.7947%]\n",
            "5277 [Discriminator loss: 0.6706%, acc.: 55.08%] [Generator loss: 0.7725%]\n",
            "5278 [Discriminator loss: 0.6625%, acc.: 58.59%] [Generator loss: 0.7523%]\n",
            "5279 [Discriminator loss: 0.6784%, acc.: 54.30%] [Generator loss: 0.7869%]\n",
            "5280 [Discriminator loss: 0.6613%, acc.: 57.81%] [Generator loss: 0.7955%]\n",
            "5281 [Discriminator loss: 0.6828%, acc.: 52.73%] [Generator loss: 0.7877%]\n",
            "5282 [Discriminator loss: 0.6763%, acc.: 56.25%] [Generator loss: 0.8015%]\n",
            "5283 [Discriminator loss: 0.6527%, acc.: 61.72%] [Generator loss: 0.8272%]\n",
            "5284 [Discriminator loss: 0.6742%, acc.: 56.25%] [Generator loss: 0.7867%]\n",
            "5285 [Discriminator loss: 0.6916%, acc.: 55.08%] [Generator loss: 0.7990%]\n",
            "5286 [Discriminator loss: 0.6780%, acc.: 54.30%] [Generator loss: 0.7778%]\n",
            "5287 [Discriminator loss: 0.6734%, acc.: 55.08%] [Generator loss: 0.7685%]\n",
            "5288 [Discriminator loss: 0.6834%, acc.: 56.25%] [Generator loss: 0.7779%]\n",
            "5289 [Discriminator loss: 0.6741%, acc.: 53.12%] [Generator loss: 0.7729%]\n",
            "5290 [Discriminator loss: 0.6609%, acc.: 61.33%] [Generator loss: 0.7947%]\n",
            "5291 [Discriminator loss: 0.6629%, acc.: 61.72%] [Generator loss: 0.7749%]\n",
            "5292 [Discriminator loss: 0.6871%, acc.: 53.52%] [Generator loss: 0.7745%]\n",
            "5293 [Discriminator loss: 0.6785%, acc.: 57.03%] [Generator loss: 0.7878%]\n",
            "5294 [Discriminator loss: 0.6625%, acc.: 60.16%] [Generator loss: 0.7774%]\n",
            "5295 [Discriminator loss: 0.6552%, acc.: 62.89%] [Generator loss: 0.7931%]\n",
            "5296 [Discriminator loss: 0.6927%, acc.: 50.00%] [Generator loss: 0.8001%]\n",
            "5297 [Discriminator loss: 0.6531%, acc.: 62.11%] [Generator loss: 0.7918%]\n",
            "5298 [Discriminator loss: 0.6681%, acc.: 63.28%] [Generator loss: 0.8059%]\n",
            "5299 [Discriminator loss: 0.6729%, acc.: 55.47%] [Generator loss: 0.8001%]\n",
            "5300 [Discriminator loss: 0.6720%, acc.: 54.69%] [Generator loss: 0.7804%]\n",
            "5301 [Discriminator loss: 0.6920%, acc.: 53.12%] [Generator loss: 0.7956%]\n",
            "5302 [Discriminator loss: 0.6631%, acc.: 60.55%] [Generator loss: 0.7770%]\n",
            "5303 [Discriminator loss: 0.6570%, acc.: 62.50%] [Generator loss: 0.7890%]\n",
            "5304 [Discriminator loss: 0.6603%, acc.: 63.67%] [Generator loss: 0.8043%]\n",
            "5305 [Discriminator loss: 0.6481%, acc.: 62.50%] [Generator loss: 0.8039%]\n",
            "5306 [Discriminator loss: 0.6676%, acc.: 58.59%] [Generator loss: 0.8166%]\n",
            "5307 [Discriminator loss: 0.6625%, acc.: 62.89%] [Generator loss: 0.7973%]\n",
            "5308 [Discriminator loss: 0.6526%, acc.: 64.45%] [Generator loss: 0.7824%]\n",
            "5309 [Discriminator loss: 0.6801%, acc.: 55.86%] [Generator loss: 0.8025%]\n",
            "5310 [Discriminator loss: 0.6632%, acc.: 60.16%] [Generator loss: 0.8344%]\n",
            "5311 [Discriminator loss: 0.6715%, acc.: 57.42%] [Generator loss: 0.8190%]\n",
            "5312 [Discriminator loss: 0.6656%, acc.: 55.86%] [Generator loss: 0.8479%]\n",
            "5313 [Discriminator loss: 0.6572%, acc.: 61.33%] [Generator loss: 0.8120%]\n",
            "5314 [Discriminator loss: 0.6798%, acc.: 57.81%] [Generator loss: 0.8304%]\n",
            "5315 [Discriminator loss: 0.6723%, acc.: 60.94%] [Generator loss: 0.8058%]\n",
            "5316 [Discriminator loss: 0.6650%, acc.: 62.89%] [Generator loss: 0.8230%]\n",
            "5317 [Discriminator loss: 0.6693%, acc.: 57.81%] [Generator loss: 0.8149%]\n",
            "5318 [Discriminator loss: 0.6708%, acc.: 53.52%] [Generator loss: 0.8121%]\n",
            "5319 [Discriminator loss: 0.6548%, acc.: 58.59%] [Generator loss: 0.8111%]\n",
            "5320 [Discriminator loss: 0.6565%, acc.: 59.77%] [Generator loss: 0.8025%]\n",
            "5321 [Discriminator loss: 0.6759%, acc.: 56.64%] [Generator loss: 0.7928%]\n",
            "5322 [Discriminator loss: 0.6726%, acc.: 58.98%] [Generator loss: 0.7933%]\n",
            "5323 [Discriminator loss: 0.6569%, acc.: 65.23%] [Generator loss: 0.8130%]\n",
            "5324 [Discriminator loss: 0.6854%, acc.: 54.69%] [Generator loss: 0.8143%]\n",
            "5325 [Discriminator loss: 0.6689%, acc.: 56.64%] [Generator loss: 0.8057%]\n",
            "5326 [Discriminator loss: 0.6531%, acc.: 62.50%] [Generator loss: 0.8176%]\n",
            "5327 [Discriminator loss: 0.6809%, acc.: 55.08%] [Generator loss: 0.8060%]\n",
            "5328 [Discriminator loss: 0.6926%, acc.: 51.56%] [Generator loss: 0.8060%]\n",
            "5329 [Discriminator loss: 0.6704%, acc.: 58.20%] [Generator loss: 0.8070%]\n",
            "5330 [Discriminator loss: 0.6745%, acc.: 60.55%] [Generator loss: 0.8025%]\n",
            "5331 [Discriminator loss: 0.6684%, acc.: 60.55%] [Generator loss: 0.7776%]\n",
            "5332 [Discriminator loss: 0.6724%, acc.: 60.55%] [Generator loss: 0.8071%]\n",
            "5333 [Discriminator loss: 0.6725%, acc.: 60.16%] [Generator loss: 0.7778%]\n",
            "5334 [Discriminator loss: 0.6614%, acc.: 62.11%] [Generator loss: 0.7817%]\n",
            "5335 [Discriminator loss: 0.6678%, acc.: 62.50%] [Generator loss: 0.7896%]\n",
            "5336 [Discriminator loss: 0.6787%, acc.: 56.25%] [Generator loss: 0.7762%]\n",
            "5337 [Discriminator loss: 0.6767%, acc.: 57.03%] [Generator loss: 0.8144%]\n",
            "5338 [Discriminator loss: 0.6675%, acc.: 61.72%] [Generator loss: 0.8039%]\n",
            "5339 [Discriminator loss: 0.6747%, acc.: 57.03%] [Generator loss: 0.8165%]\n",
            "5340 [Discriminator loss: 0.6809%, acc.: 55.86%] [Generator loss: 0.7957%]\n",
            "5341 [Discriminator loss: 0.6656%, acc.: 55.47%] [Generator loss: 0.7919%]\n",
            "5342 [Discriminator loss: 0.6836%, acc.: 53.12%] [Generator loss: 0.7946%]\n",
            "5343 [Discriminator loss: 0.6724%, acc.: 55.86%] [Generator loss: 0.8018%]\n",
            "5344 [Discriminator loss: 0.6801%, acc.: 54.69%] [Generator loss: 0.8085%]\n",
            "5345 [Discriminator loss: 0.6947%, acc.: 50.00%] [Generator loss: 0.8005%]\n",
            "5346 [Discriminator loss: 0.6861%, acc.: 54.69%] [Generator loss: 0.8017%]\n",
            "5347 [Discriminator loss: 0.6850%, acc.: 55.86%] [Generator loss: 0.8031%]\n",
            "5348 [Discriminator loss: 0.6665%, acc.: 62.50%] [Generator loss: 0.8150%]\n",
            "5349 [Discriminator loss: 0.7055%, acc.: 49.22%] [Generator loss: 0.8239%]\n",
            "5350 [Discriminator loss: 0.6762%, acc.: 59.38%] [Generator loss: 0.8287%]\n",
            "5351 [Discriminator loss: 0.6701%, acc.: 60.94%] [Generator loss: 0.8270%]\n",
            "5352 [Discriminator loss: 0.6832%, acc.: 53.52%] [Generator loss: 0.7914%]\n",
            "5353 [Discriminator loss: 0.6885%, acc.: 55.47%] [Generator loss: 0.8132%]\n",
            "5354 [Discriminator loss: 0.6718%, acc.: 59.77%] [Generator loss: 0.8069%]\n",
            "5355 [Discriminator loss: 0.6508%, acc.: 66.80%] [Generator loss: 0.8004%]\n",
            "5356 [Discriminator loss: 0.6838%, acc.: 55.08%] [Generator loss: 0.7872%]\n",
            "5357 [Discriminator loss: 0.6754%, acc.: 57.81%] [Generator loss: 0.7918%]\n",
            "5358 [Discriminator loss: 0.6691%, acc.: 55.47%] [Generator loss: 0.7957%]\n",
            "5359 [Discriminator loss: 0.6752%, acc.: 57.81%] [Generator loss: 0.7989%]\n",
            "5360 [Discriminator loss: 0.6617%, acc.: 60.16%] [Generator loss: 0.8025%]\n",
            "5361 [Discriminator loss: 0.6793%, acc.: 57.81%] [Generator loss: 0.8111%]\n",
            "5362 [Discriminator loss: 0.6405%, acc.: 68.75%] [Generator loss: 0.8005%]\n",
            "5363 [Discriminator loss: 0.6744%, acc.: 54.30%] [Generator loss: 0.8014%]\n",
            "5364 [Discriminator loss: 0.6620%, acc.: 64.06%] [Generator loss: 0.7876%]\n",
            "5365 [Discriminator loss: 0.6570%, acc.: 62.50%] [Generator loss: 0.7886%]\n",
            "5366 [Discriminator loss: 0.6631%, acc.: 58.20%] [Generator loss: 0.7892%]\n",
            "5367 [Discriminator loss: 0.6693%, acc.: 58.98%] [Generator loss: 0.7799%]\n",
            "5368 [Discriminator loss: 0.6660%, acc.: 57.42%] [Generator loss: 0.7919%]\n",
            "5369 [Discriminator loss: 0.6724%, acc.: 55.47%] [Generator loss: 0.7891%]\n",
            "5370 [Discriminator loss: 0.6560%, acc.: 64.84%] [Generator loss: 0.7970%]\n",
            "5371 [Discriminator loss: 0.6624%, acc.: 64.84%] [Generator loss: 0.8041%]\n",
            "5372 [Discriminator loss: 0.6682%, acc.: 58.98%] [Generator loss: 0.7978%]\n",
            "5373 [Discriminator loss: 0.6593%, acc.: 59.77%] [Generator loss: 0.8098%]\n",
            "5374 [Discriminator loss: 0.6678%, acc.: 58.59%] [Generator loss: 0.8362%]\n",
            "5375 [Discriminator loss: 0.6657%, acc.: 57.81%] [Generator loss: 0.8274%]\n",
            "5376 [Discriminator loss: 0.6669%, acc.: 62.89%] [Generator loss: 0.8022%]\n",
            "5377 [Discriminator loss: 0.6668%, acc.: 59.77%] [Generator loss: 0.7939%]\n",
            "5378 [Discriminator loss: 0.6746%, acc.: 55.86%] [Generator loss: 0.7914%]\n",
            "5379 [Discriminator loss: 0.6932%, acc.: 48.83%] [Generator loss: 0.7742%]\n",
            "5380 [Discriminator loss: 0.6741%, acc.: 57.81%] [Generator loss: 0.8041%]\n",
            "5381 [Discriminator loss: 0.6655%, acc.: 59.38%] [Generator loss: 0.7947%]\n",
            "5382 [Discriminator loss: 0.6643%, acc.: 60.94%] [Generator loss: 0.7769%]\n",
            "5383 [Discriminator loss: 0.6640%, acc.: 60.55%] [Generator loss: 0.7692%]\n",
            "5384 [Discriminator loss: 0.6652%, acc.: 60.94%] [Generator loss: 0.7929%]\n",
            "5385 [Discriminator loss: 0.6583%, acc.: 60.94%] [Generator loss: 0.7755%]\n",
            "5386 [Discriminator loss: 0.6790%, acc.: 55.47%] [Generator loss: 0.7872%]\n",
            "5387 [Discriminator loss: 0.6734%, acc.: 60.16%] [Generator loss: 0.7714%]\n",
            "5388 [Discriminator loss: 0.6696%, acc.: 56.25%] [Generator loss: 0.7777%]\n",
            "5389 [Discriminator loss: 0.6667%, acc.: 58.20%] [Generator loss: 0.7763%]\n",
            "5390 [Discriminator loss: 0.6954%, acc.: 49.22%] [Generator loss: 0.7770%]\n",
            "5391 [Discriminator loss: 0.6695%, acc.: 57.81%] [Generator loss: 0.7734%]\n",
            "5392 [Discriminator loss: 0.6823%, acc.: 56.25%] [Generator loss: 0.7799%]\n",
            "5393 [Discriminator loss: 0.6614%, acc.: 58.98%] [Generator loss: 0.7914%]\n",
            "5394 [Discriminator loss: 0.6610%, acc.: 61.33%] [Generator loss: 0.7851%]\n",
            "5395 [Discriminator loss: 0.6883%, acc.: 50.39%] [Generator loss: 0.7933%]\n",
            "5396 [Discriminator loss: 0.6765%, acc.: 55.08%] [Generator loss: 0.7835%]\n",
            "5397 [Discriminator loss: 0.6656%, acc.: 60.94%] [Generator loss: 0.7841%]\n",
            "5398 [Discriminator loss: 0.6813%, acc.: 55.47%] [Generator loss: 0.7936%]\n",
            "5399 [Discriminator loss: 0.7033%, acc.: 50.78%] [Generator loss: 0.7684%]\n",
            "5400 [Discriminator loss: 0.6806%, acc.: 50.39%] [Generator loss: 0.7846%]\n",
            "5401 [Discriminator loss: 0.6766%, acc.: 57.42%] [Generator loss: 0.7787%]\n",
            "5402 [Discriminator loss: 0.6845%, acc.: 58.20%] [Generator loss: 0.7756%]\n",
            "5403 [Discriminator loss: 0.6807%, acc.: 52.73%] [Generator loss: 0.7695%]\n",
            "5404 [Discriminator loss: 0.6657%, acc.: 55.08%] [Generator loss: 0.8115%]\n",
            "5405 [Discriminator loss: 0.6598%, acc.: 62.11%] [Generator loss: 0.8070%]\n",
            "5406 [Discriminator loss: 0.6859%, acc.: 53.52%] [Generator loss: 0.7842%]\n",
            "5407 [Discriminator loss: 0.6896%, acc.: 51.95%] [Generator loss: 0.7898%]\n",
            "5408 [Discriminator loss: 0.6843%, acc.: 53.52%] [Generator loss: 0.7916%]\n",
            "5409 [Discriminator loss: 0.6796%, acc.: 56.25%] [Generator loss: 0.7978%]\n",
            "5410 [Discriminator loss: 0.6881%, acc.: 53.91%] [Generator loss: 0.7799%]\n",
            "5411 [Discriminator loss: 0.6651%, acc.: 60.16%] [Generator loss: 0.7897%]\n",
            "5412 [Discriminator loss: 0.6910%, acc.: 51.17%] [Generator loss: 0.8021%]\n",
            "5413 [Discriminator loss: 0.7071%, acc.: 46.09%] [Generator loss: 0.7875%]\n",
            "5414 [Discriminator loss: 0.6888%, acc.: 52.73%] [Generator loss: 0.7950%]\n",
            "5415 [Discriminator loss: 0.6767%, acc.: 60.55%] [Generator loss: 0.7795%]\n",
            "5416 [Discriminator loss: 0.6807%, acc.: 55.47%] [Generator loss: 0.8018%]\n",
            "5417 [Discriminator loss: 0.7062%, acc.: 46.48%] [Generator loss: 0.7754%]\n",
            "5418 [Discriminator loss: 0.6956%, acc.: 53.52%] [Generator loss: 0.7787%]\n",
            "5419 [Discriminator loss: 0.6852%, acc.: 56.64%] [Generator loss: 0.7742%]\n",
            "5420 [Discriminator loss: 0.6963%, acc.: 51.95%] [Generator loss: 0.7633%]\n",
            "5421 [Discriminator loss: 0.6847%, acc.: 54.30%] [Generator loss: 0.7692%]\n",
            "5422 [Discriminator loss: 0.6594%, acc.: 64.84%] [Generator loss: 0.7661%]\n",
            "5423 [Discriminator loss: 0.6945%, acc.: 50.39%] [Generator loss: 0.7795%]\n",
            "5424 [Discriminator loss: 0.6854%, acc.: 58.20%] [Generator loss: 0.7658%]\n",
            "5425 [Discriminator loss: 0.6719%, acc.: 58.98%] [Generator loss: 0.7684%]\n",
            "5426 [Discriminator loss: 0.6814%, acc.: 54.69%] [Generator loss: 0.7797%]\n",
            "5427 [Discriminator loss: 0.6790%, acc.: 57.81%] [Generator loss: 0.7644%]\n",
            "5428 [Discriminator loss: 0.6832%, acc.: 55.08%] [Generator loss: 0.7806%]\n",
            "5429 [Discriminator loss: 0.6949%, acc.: 52.34%] [Generator loss: 0.7804%]\n",
            "5430 [Discriminator loss: 0.6810%, acc.: 55.86%] [Generator loss: 0.7777%]\n",
            "5431 [Discriminator loss: 0.6726%, acc.: 55.86%] [Generator loss: 0.7793%]\n",
            "5432 [Discriminator loss: 0.6714%, acc.: 55.86%] [Generator loss: 0.7813%]\n",
            "5433 [Discriminator loss: 0.6784%, acc.: 52.73%] [Generator loss: 0.7883%]\n",
            "5434 [Discriminator loss: 0.6847%, acc.: 55.86%] [Generator loss: 0.7775%]\n",
            "5435 [Discriminator loss: 0.6679%, acc.: 59.77%] [Generator loss: 0.7823%]\n",
            "5436 [Discriminator loss: 0.6807%, acc.: 53.12%] [Generator loss: 0.7760%]\n",
            "5437 [Discriminator loss: 0.6866%, acc.: 55.86%] [Generator loss: 0.7760%]\n",
            "5438 [Discriminator loss: 0.6698%, acc.: 58.20%] [Generator loss: 0.7845%]\n",
            "5439 [Discriminator loss: 0.6620%, acc.: 57.03%] [Generator loss: 0.8048%]\n",
            "5440 [Discriminator loss: 0.6620%, acc.: 61.72%] [Generator loss: 0.7853%]\n",
            "5441 [Discriminator loss: 0.6786%, acc.: 55.86%] [Generator loss: 0.7602%]\n",
            "5442 [Discriminator loss: 0.6737%, acc.: 56.25%] [Generator loss: 0.7637%]\n",
            "5443 [Discriminator loss: 0.6798%, acc.: 56.64%] [Generator loss: 0.7844%]\n",
            "5444 [Discriminator loss: 0.6805%, acc.: 59.38%] [Generator loss: 0.7927%]\n",
            "5445 [Discriminator loss: 0.6667%, acc.: 62.11%] [Generator loss: 0.7699%]\n",
            "5446 [Discriminator loss: 0.6803%, acc.: 60.55%] [Generator loss: 0.7690%]\n",
            "5447 [Discriminator loss: 0.6732%, acc.: 55.08%] [Generator loss: 0.7610%]\n",
            "5448 [Discriminator loss: 0.6897%, acc.: 56.25%] [Generator loss: 0.7872%]\n",
            "5449 [Discriminator loss: 0.6686%, acc.: 62.50%] [Generator loss: 0.7710%]\n",
            "5450 [Discriminator loss: 0.6874%, acc.: 51.95%] [Generator loss: 0.7946%]\n",
            "5451 [Discriminator loss: 0.6875%, acc.: 53.91%] [Generator loss: 0.7822%]\n",
            "5452 [Discriminator loss: 0.6633%, acc.: 61.72%] [Generator loss: 0.7876%]\n",
            "5453 [Discriminator loss: 0.6652%, acc.: 60.16%] [Generator loss: 0.7813%]\n",
            "5454 [Discriminator loss: 0.6851%, acc.: 53.91%] [Generator loss: 0.7717%]\n",
            "5455 [Discriminator loss: 0.6914%, acc.: 50.00%] [Generator loss: 0.7914%]\n",
            "5456 [Discriminator loss: 0.6868%, acc.: 54.30%] [Generator loss: 0.7891%]\n",
            "5457 [Discriminator loss: 0.6717%, acc.: 58.59%] [Generator loss: 0.7813%]\n",
            "5458 [Discriminator loss: 0.6838%, acc.: 53.91%] [Generator loss: 0.7691%]\n",
            "5459 [Discriminator loss: 0.6653%, acc.: 61.33%] [Generator loss: 0.7877%]\n",
            "5460 [Discriminator loss: 0.6897%, acc.: 56.25%] [Generator loss: 0.7671%]\n",
            "5461 [Discriminator loss: 0.6814%, acc.: 59.38%] [Generator loss: 0.7640%]\n",
            "5462 [Discriminator loss: 0.6740%, acc.: 57.81%] [Generator loss: 0.7825%]\n",
            "5463 [Discriminator loss: 0.6749%, acc.: 58.98%] [Generator loss: 0.7876%]\n",
            "5464 [Discriminator loss: 0.6839%, acc.: 54.30%] [Generator loss: 0.7812%]\n",
            "5465 [Discriminator loss: 0.6854%, acc.: 55.08%] [Generator loss: 0.7667%]\n",
            "5466 [Discriminator loss: 0.6761%, acc.: 60.16%] [Generator loss: 0.8100%]\n",
            "5467 [Discriminator loss: 0.6619%, acc.: 62.50%] [Generator loss: 0.7984%]\n",
            "5468 [Discriminator loss: 0.6840%, acc.: 55.08%] [Generator loss: 0.7847%]\n",
            "5469 [Discriminator loss: 0.6777%, acc.: 57.03%] [Generator loss: 0.7907%]\n",
            "5470 [Discriminator loss: 0.6604%, acc.: 60.16%] [Generator loss: 0.7780%]\n",
            "5471 [Discriminator loss: 0.6994%, acc.: 53.12%] [Generator loss: 0.7811%]\n",
            "5472 [Discriminator loss: 0.6891%, acc.: 50.78%] [Generator loss: 0.7829%]\n",
            "5473 [Discriminator loss: 0.6607%, acc.: 60.16%] [Generator loss: 0.7754%]\n",
            "5474 [Discriminator loss: 0.6609%, acc.: 58.20%] [Generator loss: 0.7915%]\n",
            "5475 [Discriminator loss: 0.6849%, acc.: 55.47%] [Generator loss: 0.7726%]\n",
            "5476 [Discriminator loss: 0.6693%, acc.: 60.16%] [Generator loss: 0.7904%]\n",
            "5477 [Discriminator loss: 0.6871%, acc.: 55.86%] [Generator loss: 0.7764%]\n",
            "5478 [Discriminator loss: 0.6686%, acc.: 58.20%] [Generator loss: 0.7931%]\n",
            "5479 [Discriminator loss: 0.6889%, acc.: 53.52%] [Generator loss: 0.7699%]\n",
            "5480 [Discriminator loss: 0.6653%, acc.: 61.33%] [Generator loss: 0.7775%]\n",
            "5481 [Discriminator loss: 0.6699%, acc.: 56.64%] [Generator loss: 0.7848%]\n",
            "5482 [Discriminator loss: 0.6725%, acc.: 57.42%] [Generator loss: 0.7711%]\n",
            "5483 [Discriminator loss: 0.6724%, acc.: 56.25%] [Generator loss: 0.7765%]\n",
            "5484 [Discriminator loss: 0.6886%, acc.: 54.69%] [Generator loss: 0.7868%]\n",
            "5485 [Discriminator loss: 0.6699%, acc.: 58.20%] [Generator loss: 0.7624%]\n",
            "5486 [Discriminator loss: 0.6756%, acc.: 59.77%] [Generator loss: 0.7849%]\n",
            "5487 [Discriminator loss: 0.6660%, acc.: 58.98%] [Generator loss: 0.7839%]\n",
            "5488 [Discriminator loss: 0.6734%, acc.: 62.50%] [Generator loss: 0.7698%]\n",
            "5489 [Discriminator loss: 0.6907%, acc.: 53.52%] [Generator loss: 0.7740%]\n",
            "5490 [Discriminator loss: 0.6796%, acc.: 55.08%] [Generator loss: 0.7808%]\n",
            "5491 [Discriminator loss: 0.6694%, acc.: 59.77%] [Generator loss: 0.7961%]\n",
            "5492 [Discriminator loss: 0.6857%, acc.: 55.86%] [Generator loss: 0.7764%]\n",
            "5493 [Discriminator loss: 0.6833%, acc.: 57.42%] [Generator loss: 0.7712%]\n",
            "5494 [Discriminator loss: 0.6798%, acc.: 54.30%] [Generator loss: 0.7784%]\n",
            "5495 [Discriminator loss: 0.6840%, acc.: 52.73%] [Generator loss: 0.7989%]\n",
            "5496 [Discriminator loss: 0.6864%, acc.: 53.12%] [Generator loss: 0.7733%]\n",
            "5497 [Discriminator loss: 0.6697%, acc.: 58.98%] [Generator loss: 0.8023%]\n",
            "5498 [Discriminator loss: 0.6785%, acc.: 60.55%] [Generator loss: 0.8359%]\n",
            "5499 [Discriminator loss: 0.6827%, acc.: 53.12%] [Generator loss: 0.7933%]\n",
            "5500 [Discriminator loss: 0.6951%, acc.: 51.17%] [Generator loss: 0.7761%]\n",
            "5501 [Discriminator loss: 0.6861%, acc.: 53.91%] [Generator loss: 0.7744%]\n",
            "5502 [Discriminator loss: 0.6736%, acc.: 58.20%] [Generator loss: 0.7762%]\n",
            "5503 [Discriminator loss: 0.6834%, acc.: 53.52%] [Generator loss: 0.7800%]\n",
            "5504 [Discriminator loss: 0.6848%, acc.: 54.69%] [Generator loss: 0.7773%]\n",
            "5505 [Discriminator loss: 0.6824%, acc.: 51.17%] [Generator loss: 0.7696%]\n",
            "5506 [Discriminator loss: 0.6744%, acc.: 58.59%] [Generator loss: 0.7856%]\n",
            "5507 [Discriminator loss: 0.6699%, acc.: 62.50%] [Generator loss: 0.7830%]\n",
            "5508 [Discriminator loss: 0.6756%, acc.: 58.20%] [Generator loss: 0.7902%]\n",
            "5509 [Discriminator loss: 0.6773%, acc.: 51.95%] [Generator loss: 0.7865%]\n",
            "5510 [Discriminator loss: 0.6912%, acc.: 50.00%] [Generator loss: 0.7953%]\n",
            "5511 [Discriminator loss: 0.6867%, acc.: 56.25%] [Generator loss: 0.7710%]\n",
            "5512 [Discriminator loss: 0.6841%, acc.: 56.64%] [Generator loss: 0.8070%]\n",
            "5513 [Discriminator loss: 0.6754%, acc.: 57.42%] [Generator loss: 0.8192%]\n",
            "5514 [Discriminator loss: 0.6766%, acc.: 58.98%] [Generator loss: 0.7885%]\n",
            "5515 [Discriminator loss: 0.6696%, acc.: 61.72%] [Generator loss: 0.7946%]\n",
            "5516 [Discriminator loss: 0.6814%, acc.: 57.81%] [Generator loss: 0.7982%]\n",
            "5517 [Discriminator loss: 0.6824%, acc.: 58.59%] [Generator loss: 0.7953%]\n",
            "5518 [Discriminator loss: 0.6854%, acc.: 50.39%] [Generator loss: 0.7718%]\n",
            "5519 [Discriminator loss: 0.6752%, acc.: 58.59%] [Generator loss: 0.7563%]\n",
            "5520 [Discriminator loss: 0.6725%, acc.: 60.16%] [Generator loss: 0.7951%]\n",
            "5521 [Discriminator loss: 0.6944%, acc.: 55.47%] [Generator loss: 0.7840%]\n",
            "5522 [Discriminator loss: 0.6932%, acc.: 52.34%] [Generator loss: 0.7771%]\n",
            "5523 [Discriminator loss: 0.6845%, acc.: 55.86%] [Generator loss: 0.8071%]\n",
            "5524 [Discriminator loss: 0.6767%, acc.: 56.64%] [Generator loss: 0.8010%]\n",
            "5525 [Discriminator loss: 0.6741%, acc.: 58.59%] [Generator loss: 0.7587%]\n",
            "5526 [Discriminator loss: 0.6708%, acc.: 60.55%] [Generator loss: 0.7836%]\n",
            "5527 [Discriminator loss: 0.6821%, acc.: 56.64%] [Generator loss: 0.7826%]\n",
            "5528 [Discriminator loss: 0.6660%, acc.: 62.11%] [Generator loss: 0.7735%]\n",
            "5529 [Discriminator loss: 0.6741%, acc.: 56.25%] [Generator loss: 0.7586%]\n",
            "5530 [Discriminator loss: 0.6782%, acc.: 56.25%] [Generator loss: 0.7784%]\n",
            "5531 [Discriminator loss: 0.6791%, acc.: 58.20%] [Generator loss: 0.7790%]\n",
            "5532 [Discriminator loss: 0.6677%, acc.: 60.94%] [Generator loss: 0.7899%]\n",
            "5533 [Discriminator loss: 0.6690%, acc.: 60.55%] [Generator loss: 0.7727%]\n",
            "5534 [Discriminator loss: 0.6752%, acc.: 58.59%] [Generator loss: 0.7962%]\n",
            "5535 [Discriminator loss: 0.6760%, acc.: 56.25%] [Generator loss: 0.7922%]\n",
            "5536 [Discriminator loss: 0.6883%, acc.: 55.08%] [Generator loss: 0.8041%]\n",
            "5537 [Discriminator loss: 0.6837%, acc.: 55.08%] [Generator loss: 0.7853%]\n",
            "5538 [Discriminator loss: 0.6819%, acc.: 56.64%] [Generator loss: 0.7801%]\n",
            "5539 [Discriminator loss: 0.6726%, acc.: 57.42%] [Generator loss: 0.8109%]\n",
            "5540 [Discriminator loss: 0.6692%, acc.: 54.69%] [Generator loss: 0.7830%]\n",
            "5541 [Discriminator loss: 0.6699%, acc.: 58.20%] [Generator loss: 0.7977%]\n",
            "5542 [Discriminator loss: 0.6967%, acc.: 49.22%] [Generator loss: 0.7848%]\n",
            "5543 [Discriminator loss: 0.6925%, acc.: 55.08%] [Generator loss: 0.7714%]\n",
            "5544 [Discriminator loss: 0.6800%, acc.: 57.42%] [Generator loss: 0.7959%]\n",
            "5545 [Discriminator loss: 0.6710%, acc.: 59.38%] [Generator loss: 0.7811%]\n",
            "5546 [Discriminator loss: 0.6823%, acc.: 55.08%] [Generator loss: 0.7892%]\n",
            "5547 [Discriminator loss: 0.6758%, acc.: 54.30%] [Generator loss: 0.7850%]\n",
            "5548 [Discriminator loss: 0.6962%, acc.: 50.00%] [Generator loss: 0.7530%]\n",
            "5549 [Discriminator loss: 0.6717%, acc.: 60.55%] [Generator loss: 0.7861%]\n",
            "5550 [Discriminator loss: 0.6780%, acc.: 54.69%] [Generator loss: 0.7827%]\n",
            "5551 [Discriminator loss: 0.6757%, acc.: 57.81%] [Generator loss: 0.7797%]\n",
            "5552 [Discriminator loss: 0.6792%, acc.: 53.91%] [Generator loss: 0.7755%]\n",
            "5553 [Discriminator loss: 0.6764%, acc.: 59.38%] [Generator loss: 0.7873%]\n",
            "5554 [Discriminator loss: 0.6688%, acc.: 55.47%] [Generator loss: 0.7808%]\n",
            "5555 [Discriminator loss: 0.6827%, acc.: 53.52%] [Generator loss: 0.7930%]\n",
            "5556 [Discriminator loss: 0.6921%, acc.: 49.61%] [Generator loss: 0.7915%]\n",
            "5557 [Discriminator loss: 0.6778%, acc.: 56.64%] [Generator loss: 0.7840%]\n",
            "5558 [Discriminator loss: 0.6742%, acc.: 53.91%] [Generator loss: 0.7704%]\n",
            "5559 [Discriminator loss: 0.6880%, acc.: 54.30%] [Generator loss: 0.7660%]\n",
            "5560 [Discriminator loss: 0.6843%, acc.: 57.81%] [Generator loss: 0.7624%]\n",
            "5561 [Discriminator loss: 0.6721%, acc.: 53.52%] [Generator loss: 0.7597%]\n",
            "5562 [Discriminator loss: 0.6741%, acc.: 53.12%] [Generator loss: 0.7715%]\n",
            "5563 [Discriminator loss: 0.6728%, acc.: 60.16%] [Generator loss: 0.7636%]\n",
            "5564 [Discriminator loss: 0.6938%, acc.: 53.12%] [Generator loss: 0.7885%]\n",
            "5565 [Discriminator loss: 0.6924%, acc.: 51.56%] [Generator loss: 0.7871%]\n",
            "5566 [Discriminator loss: 0.6847%, acc.: 53.91%] [Generator loss: 0.7699%]\n",
            "5567 [Discriminator loss: 0.6786%, acc.: 55.86%] [Generator loss: 0.7799%]\n",
            "5568 [Discriminator loss: 0.6676%, acc.: 61.33%] [Generator loss: 0.7884%]\n",
            "5569 [Discriminator loss: 0.6822%, acc.: 52.73%] [Generator loss: 0.7817%]\n",
            "5570 [Discriminator loss: 0.6703%, acc.: 58.59%] [Generator loss: 0.7924%]\n",
            "5571 [Discriminator loss: 0.6811%, acc.: 56.64%] [Generator loss: 0.7985%]\n",
            "5572 [Discriminator loss: 0.6636%, acc.: 61.33%] [Generator loss: 0.7959%]\n",
            "5573 [Discriminator loss: 0.6787%, acc.: 56.64%] [Generator loss: 0.7895%]\n",
            "5574 [Discriminator loss: 0.6685%, acc.: 61.72%] [Generator loss: 0.7798%]\n",
            "5575 [Discriminator loss: 0.6630%, acc.: 60.16%] [Generator loss: 0.7830%]\n",
            "5576 [Discriminator loss: 0.6711%, acc.: 59.38%] [Generator loss: 0.7773%]\n",
            "5577 [Discriminator loss: 0.6619%, acc.: 58.98%] [Generator loss: 0.7700%]\n",
            "5578 [Discriminator loss: 0.6662%, acc.: 56.25%] [Generator loss: 0.7822%]\n",
            "5579 [Discriminator loss: 0.6729%, acc.: 57.42%] [Generator loss: 0.7834%]\n",
            "5580 [Discriminator loss: 0.6711%, acc.: 57.42%] [Generator loss: 0.7826%]\n",
            "5581 [Discriminator loss: 0.6587%, acc.: 59.77%] [Generator loss: 0.7940%]\n",
            "5582 [Discriminator loss: 0.6617%, acc.: 58.98%] [Generator loss: 0.7881%]\n",
            "5583 [Discriminator loss: 0.6631%, acc.: 57.03%] [Generator loss: 0.8176%]\n",
            "5584 [Discriminator loss: 0.6534%, acc.: 62.11%] [Generator loss: 0.7978%]\n",
            "5585 [Discriminator loss: 0.6921%, acc.: 53.52%] [Generator loss: 0.7732%]\n",
            "5586 [Discriminator loss: 0.6701%, acc.: 59.77%] [Generator loss: 0.7812%]\n",
            "5587 [Discriminator loss: 0.6601%, acc.: 58.98%] [Generator loss: 0.7890%]\n",
            "5588 [Discriminator loss: 0.6732%, acc.: 55.47%] [Generator loss: 0.7646%]\n",
            "5589 [Discriminator loss: 0.6527%, acc.: 60.55%] [Generator loss: 0.8130%]\n",
            "5590 [Discriminator loss: 0.6895%, acc.: 54.30%] [Generator loss: 0.7712%]\n",
            "5591 [Discriminator loss: 0.6642%, acc.: 62.50%] [Generator loss: 0.8069%]\n",
            "5592 [Discriminator loss: 0.6763%, acc.: 53.12%] [Generator loss: 0.7993%]\n",
            "5593 [Discriminator loss: 0.6552%, acc.: 62.89%] [Generator loss: 0.8020%]\n",
            "5594 [Discriminator loss: 0.6762%, acc.: 54.30%] [Generator loss: 0.8114%]\n",
            "5595 [Discriminator loss: 0.6411%, acc.: 66.41%] [Generator loss: 0.8072%]\n",
            "5596 [Discriminator loss: 0.6657%, acc.: 58.59%] [Generator loss: 0.8194%]\n",
            "5597 [Discriminator loss: 0.6476%, acc.: 65.62%] [Generator loss: 0.8091%]\n",
            "5598 [Discriminator loss: 0.6507%, acc.: 66.02%] [Generator loss: 0.8055%]\n",
            "5599 [Discriminator loss: 0.6626%, acc.: 59.77%] [Generator loss: 0.7956%]\n",
            "5600 [Discriminator loss: 0.6830%, acc.: 52.73%] [Generator loss: 0.7919%]\n",
            "5601 [Discriminator loss: 0.6557%, acc.: 60.55%] [Generator loss: 0.8045%]\n",
            "5602 [Discriminator loss: 0.6666%, acc.: 58.20%] [Generator loss: 0.8182%]\n",
            "5603 [Discriminator loss: 0.6493%, acc.: 62.89%] [Generator loss: 0.8379%]\n",
            "5604 [Discriminator loss: 0.6519%, acc.: 60.55%] [Generator loss: 0.8155%]\n",
            "5605 [Discriminator loss: 0.6613%, acc.: 61.72%] [Generator loss: 0.7899%]\n",
            "5606 [Discriminator loss: 0.6652%, acc.: 57.42%] [Generator loss: 0.8147%]\n",
            "5607 [Discriminator loss: 0.6631%, acc.: 59.38%] [Generator loss: 0.8155%]\n",
            "5608 [Discriminator loss: 0.6678%, acc.: 55.08%] [Generator loss: 0.7921%]\n",
            "5609 [Discriminator loss: 0.6526%, acc.: 60.55%] [Generator loss: 0.8096%]\n",
            "5610 [Discriminator loss: 0.6673%, acc.: 60.16%] [Generator loss: 0.7941%]\n",
            "5611 [Discriminator loss: 0.6602%, acc.: 60.55%] [Generator loss: 0.8030%]\n",
            "5612 [Discriminator loss: 0.6454%, acc.: 62.89%] [Generator loss: 0.8004%]\n",
            "5613 [Discriminator loss: 0.6565%, acc.: 59.38%] [Generator loss: 0.7850%]\n",
            "5614 [Discriminator loss: 0.6615%, acc.: 57.81%] [Generator loss: 0.8012%]\n",
            "5615 [Discriminator loss: 0.6537%, acc.: 62.89%] [Generator loss: 0.7988%]\n",
            "5616 [Discriminator loss: 0.6467%, acc.: 65.23%] [Generator loss: 0.8339%]\n",
            "5617 [Discriminator loss: 0.6629%, acc.: 62.50%] [Generator loss: 0.8217%]\n",
            "5618 [Discriminator loss: 0.6626%, acc.: 58.98%] [Generator loss: 0.8120%]\n",
            "5619 [Discriminator loss: 0.6456%, acc.: 64.45%] [Generator loss: 0.8177%]\n",
            "5620 [Discriminator loss: 0.6683%, acc.: 58.20%] [Generator loss: 0.8186%]\n",
            "5621 [Discriminator loss: 0.6504%, acc.: 62.89%] [Generator loss: 0.8211%]\n",
            "5622 [Discriminator loss: 0.6593%, acc.: 58.20%] [Generator loss: 0.8183%]\n",
            "5623 [Discriminator loss: 0.6471%, acc.: 62.89%] [Generator loss: 0.8117%]\n",
            "5624 [Discriminator loss: 0.6678%, acc.: 57.03%] [Generator loss: 0.8260%]\n",
            "5625 [Discriminator loss: 0.6691%, acc.: 59.38%] [Generator loss: 0.8231%]\n",
            "5626 [Discriminator loss: 0.6636%, acc.: 59.38%] [Generator loss: 0.8228%]\n",
            "5627 [Discriminator loss: 0.6535%, acc.: 62.50%] [Generator loss: 0.7875%]\n",
            "5628 [Discriminator loss: 0.6403%, acc.: 66.41%] [Generator loss: 0.8135%]\n",
            "5629 [Discriminator loss: 0.6351%, acc.: 66.80%] [Generator loss: 0.7993%]\n",
            "5630 [Discriminator loss: 0.6533%, acc.: 64.84%] [Generator loss: 0.8148%]\n",
            "5631 [Discriminator loss: 0.6695%, acc.: 58.20%] [Generator loss: 0.8207%]\n",
            "5632 [Discriminator loss: 0.6711%, acc.: 57.42%] [Generator loss: 0.7852%]\n",
            "5633 [Discriminator loss: 0.6661%, acc.: 58.59%] [Generator loss: 0.7895%]\n",
            "5634 [Discriminator loss: 0.6632%, acc.: 63.28%] [Generator loss: 0.8143%]\n",
            "5635 [Discriminator loss: 0.6552%, acc.: 67.97%] [Generator loss: 0.8137%]\n",
            "5636 [Discriminator loss: 0.6576%, acc.: 60.16%] [Generator loss: 0.8039%]\n",
            "5637 [Discriminator loss: 0.6832%, acc.: 54.30%] [Generator loss: 0.8191%]\n",
            "5638 [Discriminator loss: 0.6650%, acc.: 62.89%] [Generator loss: 0.8031%]\n",
            "5639 [Discriminator loss: 0.6520%, acc.: 62.50%] [Generator loss: 0.8097%]\n",
            "5640 [Discriminator loss: 0.6801%, acc.: 57.81%] [Generator loss: 0.7862%]\n",
            "5641 [Discriminator loss: 0.6621%, acc.: 58.98%] [Generator loss: 0.8002%]\n",
            "5642 [Discriminator loss: 0.6554%, acc.: 59.38%] [Generator loss: 0.8145%]\n",
            "5643 [Discriminator loss: 0.6448%, acc.: 65.23%] [Generator loss: 0.7739%]\n",
            "5644 [Discriminator loss: 0.6740%, acc.: 58.59%] [Generator loss: 0.7665%]\n",
            "5645 [Discriminator loss: 0.6752%, acc.: 57.81%] [Generator loss: 0.8027%]\n",
            "5646 [Discriminator loss: 0.6783%, acc.: 57.42%] [Generator loss: 0.7764%]\n",
            "5647 [Discriminator loss: 0.6742%, acc.: 55.47%] [Generator loss: 0.7881%]\n",
            "5648 [Discriminator loss: 0.6805%, acc.: 59.38%] [Generator loss: 0.8162%]\n",
            "5649 [Discriminator loss: 0.6634%, acc.: 59.77%] [Generator loss: 0.7873%]\n",
            "5650 [Discriminator loss: 0.6794%, acc.: 57.42%] [Generator loss: 0.8101%]\n",
            "5651 [Discriminator loss: 0.6577%, acc.: 61.33%] [Generator loss: 0.8176%]\n",
            "5652 [Discriminator loss: 0.6709%, acc.: 58.98%] [Generator loss: 0.8312%]\n",
            "5653 [Discriminator loss: 0.6812%, acc.: 55.86%] [Generator loss: 0.7972%]\n",
            "5654 [Discriminator loss: 0.6604%, acc.: 62.11%] [Generator loss: 0.7959%]\n",
            "5655 [Discriminator loss: 0.6825%, acc.: 54.69%] [Generator loss: 0.7899%]\n",
            "5656 [Discriminator loss: 0.6860%, acc.: 57.03%] [Generator loss: 0.7873%]\n",
            "5657 [Discriminator loss: 0.6783%, acc.: 56.64%] [Generator loss: 0.7987%]\n",
            "5658 [Discriminator loss: 0.6699%, acc.: 61.72%] [Generator loss: 0.8133%]\n",
            "5659 [Discriminator loss: 0.6850%, acc.: 56.25%] [Generator loss: 0.8017%]\n",
            "5660 [Discriminator loss: 0.6902%, acc.: 52.73%] [Generator loss: 0.8256%]\n",
            "5661 [Discriminator loss: 0.6686%, acc.: 60.55%] [Generator loss: 0.8029%]\n",
            "5662 [Discriminator loss: 0.6829%, acc.: 55.47%] [Generator loss: 0.8106%]\n",
            "5663 [Discriminator loss: 0.6757%, acc.: 57.03%] [Generator loss: 0.8090%]\n",
            "5664 [Discriminator loss: 0.6791%, acc.: 55.47%] [Generator loss: 0.7898%]\n",
            "5665 [Discriminator loss: 0.6918%, acc.: 53.12%] [Generator loss: 0.7911%]\n",
            "5666 [Discriminator loss: 0.6675%, acc.: 58.59%] [Generator loss: 0.7961%]\n",
            "5667 [Discriminator loss: 0.6648%, acc.: 58.98%] [Generator loss: 0.7910%]\n",
            "5668 [Discriminator loss: 0.6763%, acc.: 60.94%] [Generator loss: 0.7815%]\n",
            "5669 [Discriminator loss: 0.6745%, acc.: 55.86%] [Generator loss: 0.7752%]\n",
            "5670 [Discriminator loss: 0.6765%, acc.: 56.64%] [Generator loss: 0.7879%]\n",
            "5671 [Discriminator loss: 0.6698%, acc.: 57.81%] [Generator loss: 0.7987%]\n",
            "5672 [Discriminator loss: 0.6747%, acc.: 55.08%] [Generator loss: 0.7966%]\n",
            "5673 [Discriminator loss: 0.6696%, acc.: 59.77%] [Generator loss: 0.7802%]\n",
            "5674 [Discriminator loss: 0.6766%, acc.: 56.64%] [Generator loss: 0.8032%]\n",
            "5675 [Discriminator loss: 0.6829%, acc.: 55.47%] [Generator loss: 0.8091%]\n",
            "5676 [Discriminator loss: 0.6860%, acc.: 56.64%] [Generator loss: 0.7878%]\n",
            "5677 [Discriminator loss: 0.6855%, acc.: 55.47%] [Generator loss: 0.7877%]\n",
            "5678 [Discriminator loss: 0.6821%, acc.: 54.69%] [Generator loss: 0.8148%]\n",
            "5679 [Discriminator loss: 0.6758%, acc.: 60.16%] [Generator loss: 0.7881%]\n",
            "5680 [Discriminator loss: 0.6841%, acc.: 55.08%] [Generator loss: 0.8070%]\n",
            "5681 [Discriminator loss: 0.6908%, acc.: 55.86%] [Generator loss: 0.7952%]\n",
            "5682 [Discriminator loss: 0.6935%, acc.: 51.56%] [Generator loss: 0.7778%]\n",
            "5683 [Discriminator loss: 0.6760%, acc.: 54.69%] [Generator loss: 0.7876%]\n",
            "5684 [Discriminator loss: 0.6802%, acc.: 53.52%] [Generator loss: 0.8101%]\n",
            "5685 [Discriminator loss: 0.6923%, acc.: 56.25%] [Generator loss: 0.7802%]\n",
            "5686 [Discriminator loss: 0.6736%, acc.: 55.86%] [Generator loss: 0.7820%]\n",
            "5687 [Discriminator loss: 0.6724%, acc.: 58.59%] [Generator loss: 0.7956%]\n",
            "5688 [Discriminator loss: 0.6770%, acc.: 58.20%] [Generator loss: 0.7597%]\n",
            "5689 [Discriminator loss: 0.6751%, acc.: 54.69%] [Generator loss: 0.7999%]\n",
            "5690 [Discriminator loss: 0.6894%, acc.: 52.73%] [Generator loss: 0.7785%]\n",
            "5691 [Discriminator loss: 0.6974%, acc.: 48.83%] [Generator loss: 0.7888%]\n",
            "5692 [Discriminator loss: 0.7039%, acc.: 51.17%] [Generator loss: 0.8090%]\n",
            "5693 [Discriminator loss: 0.6950%, acc.: 53.12%] [Generator loss: 0.7834%]\n",
            "5694 [Discriminator loss: 0.6856%, acc.: 55.86%] [Generator loss: 0.7925%]\n",
            "5695 [Discriminator loss: 0.6852%, acc.: 53.91%] [Generator loss: 0.7838%]\n",
            "5696 [Discriminator loss: 0.6908%, acc.: 54.69%] [Generator loss: 0.7723%]\n",
            "5697 [Discriminator loss: 0.6905%, acc.: 50.78%] [Generator loss: 0.7687%]\n",
            "5698 [Discriminator loss: 0.6931%, acc.: 51.95%] [Generator loss: 0.7864%]\n",
            "5699 [Discriminator loss: 0.6992%, acc.: 47.66%] [Generator loss: 0.7673%]\n",
            "5700 [Discriminator loss: 0.6789%, acc.: 55.47%] [Generator loss: 0.7555%]\n",
            "5701 [Discriminator loss: 0.6739%, acc.: 55.47%] [Generator loss: 0.7734%]\n",
            "5702 [Discriminator loss: 0.6651%, acc.: 61.33%] [Generator loss: 0.7793%]\n",
            "5703 [Discriminator loss: 0.6983%, acc.: 49.22%] [Generator loss: 0.7783%]\n",
            "5704 [Discriminator loss: 0.6833%, acc.: 56.64%] [Generator loss: 0.7725%]\n",
            "5705 [Discriminator loss: 0.6799%, acc.: 53.12%] [Generator loss: 0.8034%]\n",
            "5706 [Discriminator loss: 0.6880%, acc.: 54.69%] [Generator loss: 0.8051%]\n",
            "5707 [Discriminator loss: 0.7061%, acc.: 52.73%] [Generator loss: 0.7773%]\n",
            "5708 [Discriminator loss: 0.6945%, acc.: 51.95%] [Generator loss: 0.7831%]\n",
            "5709 [Discriminator loss: 0.6729%, acc.: 54.69%] [Generator loss: 0.7802%]\n",
            "5710 [Discriminator loss: 0.6818%, acc.: 58.59%] [Generator loss: 0.7782%]\n",
            "5711 [Discriminator loss: 0.6845%, acc.: 54.30%] [Generator loss: 0.7985%]\n",
            "5712 [Discriminator loss: 0.6670%, acc.: 59.38%] [Generator loss: 0.7877%]\n",
            "5713 [Discriminator loss: 0.6756%, acc.: 56.64%] [Generator loss: 0.7708%]\n",
            "5714 [Discriminator loss: 0.6686%, acc.: 62.11%] [Generator loss: 0.7834%]\n",
            "5715 [Discriminator loss: 0.6514%, acc.: 61.33%] [Generator loss: 0.7783%]\n",
            "5716 [Discriminator loss: 0.6636%, acc.: 60.94%] [Generator loss: 0.7733%]\n",
            "5717 [Discriminator loss: 0.6830%, acc.: 58.98%] [Generator loss: 0.7721%]\n",
            "5718 [Discriminator loss: 0.6664%, acc.: 58.20%] [Generator loss: 0.7718%]\n",
            "5719 [Discriminator loss: 0.6658%, acc.: 61.72%] [Generator loss: 0.7702%]\n",
            "5720 [Discriminator loss: 0.6767%, acc.: 56.25%] [Generator loss: 0.7796%]\n",
            "5721 [Discriminator loss: 0.6799%, acc.: 57.03%] [Generator loss: 0.7962%]\n",
            "5722 [Discriminator loss: 0.6654%, acc.: 60.16%] [Generator loss: 0.7783%]\n",
            "5723 [Discriminator loss: 0.6778%, acc.: 57.03%] [Generator loss: 0.7785%]\n",
            "5724 [Discriminator loss: 0.6691%, acc.: 57.03%] [Generator loss: 0.7901%]\n",
            "5725 [Discriminator loss: 0.6705%, acc.: 56.64%] [Generator loss: 0.7800%]\n",
            "5726 [Discriminator loss: 0.6808%, acc.: 54.69%] [Generator loss: 0.7962%]\n",
            "5727 [Discriminator loss: 0.6836%, acc.: 50.39%] [Generator loss: 0.7962%]\n",
            "5728 [Discriminator loss: 0.6702%, acc.: 56.64%] [Generator loss: 0.7844%]\n",
            "5729 [Discriminator loss: 0.6773%, acc.: 54.30%] [Generator loss: 0.8187%]\n",
            "5730 [Discriminator loss: 0.6682%, acc.: 59.38%] [Generator loss: 0.7871%]\n",
            "5731 [Discriminator loss: 0.6914%, acc.: 52.73%] [Generator loss: 0.7876%]\n",
            "5732 [Discriminator loss: 0.6789%, acc.: 57.03%] [Generator loss: 0.7764%]\n",
            "5733 [Discriminator loss: 0.6843%, acc.: 52.73%] [Generator loss: 0.7900%]\n",
            "5734 [Discriminator loss: 0.6840%, acc.: 55.47%] [Generator loss: 0.7976%]\n",
            "5735 [Discriminator loss: 0.6812%, acc.: 54.69%] [Generator loss: 0.8216%]\n",
            "5736 [Discriminator loss: 0.6644%, acc.: 62.89%] [Generator loss: 0.7780%]\n",
            "5737 [Discriminator loss: 0.6887%, acc.: 50.39%] [Generator loss: 0.7954%]\n",
            "5738 [Discriminator loss: 0.6724%, acc.: 55.47%] [Generator loss: 0.7980%]\n",
            "5739 [Discriminator loss: 0.6643%, acc.: 57.81%] [Generator loss: 0.7953%]\n",
            "5740 [Discriminator loss: 0.6783%, acc.: 53.12%] [Generator loss: 0.7964%]\n",
            "5741 [Discriminator loss: 0.6772%, acc.: 56.64%] [Generator loss: 0.7865%]\n",
            "5742 [Discriminator loss: 0.6882%, acc.: 53.12%] [Generator loss: 0.7861%]\n",
            "5743 [Discriminator loss: 0.6746%, acc.: 56.25%] [Generator loss: 0.8040%]\n",
            "5744 [Discriminator loss: 0.6676%, acc.: 60.94%] [Generator loss: 0.7983%]\n",
            "5745 [Discriminator loss: 0.6878%, acc.: 55.47%] [Generator loss: 0.7987%]\n",
            "5746 [Discriminator loss: 0.6714%, acc.: 58.98%] [Generator loss: 0.7902%]\n",
            "5747 [Discriminator loss: 0.6808%, acc.: 57.03%] [Generator loss: 0.7874%]\n",
            "5748 [Discriminator loss: 0.6571%, acc.: 62.11%] [Generator loss: 0.7909%]\n",
            "5749 [Discriminator loss: 0.6512%, acc.: 65.62%] [Generator loss: 0.7916%]\n",
            "5750 [Discriminator loss: 0.6771%, acc.: 54.69%] [Generator loss: 0.8004%]\n",
            "5751 [Discriminator loss: 0.6819%, acc.: 56.64%] [Generator loss: 0.8041%]\n",
            "5752 [Discriminator loss: 0.6713%, acc.: 57.03%] [Generator loss: 0.7874%]\n",
            "5753 [Discriminator loss: 0.6559%, acc.: 59.38%] [Generator loss: 0.7558%]\n",
            "5754 [Discriminator loss: 0.6825%, acc.: 55.08%] [Generator loss: 0.7564%]\n",
            "5755 [Discriminator loss: 0.6678%, acc.: 58.20%] [Generator loss: 0.7704%]\n",
            "5756 [Discriminator loss: 0.6657%, acc.: 57.81%] [Generator loss: 0.7763%]\n",
            "5757 [Discriminator loss: 0.6642%, acc.: 58.59%] [Generator loss: 0.7752%]\n",
            "5758 [Discriminator loss: 0.6741%, acc.: 59.77%] [Generator loss: 0.7868%]\n",
            "5759 [Discriminator loss: 0.6599%, acc.: 60.16%] [Generator loss: 0.7843%]\n",
            "5760 [Discriminator loss: 0.6746%, acc.: 57.42%] [Generator loss: 0.7739%]\n",
            "5761 [Discriminator loss: 0.6920%, acc.: 58.59%] [Generator loss: 0.7837%]\n",
            "5762 [Discriminator loss: 0.6795%, acc.: 53.12%] [Generator loss: 0.7799%]\n",
            "5763 [Discriminator loss: 0.6549%, acc.: 60.16%] [Generator loss: 0.7894%]\n",
            "5764 [Discriminator loss: 0.6860%, acc.: 53.91%] [Generator loss: 0.7802%]\n",
            "5765 [Discriminator loss: 0.6940%, acc.: 51.56%] [Generator loss: 0.7881%]\n",
            "5766 [Discriminator loss: 0.6598%, acc.: 59.38%] [Generator loss: 0.7698%]\n",
            "5767 [Discriminator loss: 0.6604%, acc.: 60.16%] [Generator loss: 0.7523%]\n",
            "5768 [Discriminator loss: 0.6763%, acc.: 58.98%] [Generator loss: 0.7830%]\n",
            "5769 [Discriminator loss: 0.6678%, acc.: 59.77%] [Generator loss: 0.7672%]\n",
            "5770 [Discriminator loss: 0.7023%, acc.: 53.52%] [Generator loss: 0.7641%]\n",
            "5771 [Discriminator loss: 0.6763%, acc.: 57.03%] [Generator loss: 0.7707%]\n",
            "5772 [Discriminator loss: 0.6820%, acc.: 53.52%] [Generator loss: 0.7603%]\n",
            "5773 [Discriminator loss: 0.6764%, acc.: 55.08%] [Generator loss: 0.7744%]\n",
            "5774 [Discriminator loss: 0.6657%, acc.: 58.98%] [Generator loss: 0.7722%]\n",
            "5775 [Discriminator loss: 0.6840%, acc.: 49.22%] [Generator loss: 0.7690%]\n",
            "5776 [Discriminator loss: 0.6907%, acc.: 54.30%] [Generator loss: 0.7670%]\n",
            "5777 [Discriminator loss: 0.6773%, acc.: 55.47%] [Generator loss: 0.7805%]\n",
            "5778 [Discriminator loss: 0.6767%, acc.: 55.86%] [Generator loss: 0.7753%]\n",
            "5779 [Discriminator loss: 0.6777%, acc.: 52.34%] [Generator loss: 0.7754%]\n",
            "5780 [Discriminator loss: 0.6886%, acc.: 55.08%] [Generator loss: 0.7840%]\n",
            "5781 [Discriminator loss: 0.6750%, acc.: 59.77%] [Generator loss: 0.7938%]\n",
            "5782 [Discriminator loss: 0.6715%, acc.: 53.91%] [Generator loss: 0.7834%]\n",
            "5783 [Discriminator loss: 0.6731%, acc.: 58.59%] [Generator loss: 0.7778%]\n",
            "5784 [Discriminator loss: 0.6805%, acc.: 55.47%] [Generator loss: 0.7652%]\n",
            "5785 [Discriminator loss: 0.6818%, acc.: 57.03%] [Generator loss: 0.7530%]\n",
            "5786 [Discriminator loss: 0.6783%, acc.: 51.95%] [Generator loss: 0.7703%]\n",
            "5787 [Discriminator loss: 0.6809%, acc.: 57.03%] [Generator loss: 0.7784%]\n",
            "5788 [Discriminator loss: 0.6758%, acc.: 55.47%] [Generator loss: 0.7812%]\n",
            "5789 [Discriminator loss: 0.6848%, acc.: 53.52%] [Generator loss: 0.7820%]\n",
            "5790 [Discriminator loss: 0.6662%, acc.: 62.11%] [Generator loss: 0.7844%]\n",
            "5791 [Discriminator loss: 0.6743%, acc.: 57.03%] [Generator loss: 0.8012%]\n",
            "5792 [Discriminator loss: 0.6910%, acc.: 57.42%] [Generator loss: 0.7652%]\n",
            "5793 [Discriminator loss: 0.6917%, acc.: 53.52%] [Generator loss: 0.7678%]\n",
            "5794 [Discriminator loss: 0.6773%, acc.: 55.47%] [Generator loss: 0.7985%]\n",
            "5795 [Discriminator loss: 0.7057%, acc.: 46.88%] [Generator loss: 0.8063%]\n",
            "5796 [Discriminator loss: 0.6789%, acc.: 53.52%] [Generator loss: 0.7693%]\n",
            "5797 [Discriminator loss: 0.6891%, acc.: 51.95%] [Generator loss: 0.7817%]\n",
            "5798 [Discriminator loss: 0.6882%, acc.: 51.95%] [Generator loss: 0.7875%]\n",
            "5799 [Discriminator loss: 0.6873%, acc.: 52.73%] [Generator loss: 0.8159%]\n",
            "5800 [Discriminator loss: 0.6597%, acc.: 59.38%] [Generator loss: 0.7828%]\n",
            "5801 [Discriminator loss: 0.6767%, acc.: 60.16%] [Generator loss: 0.8111%]\n",
            "5802 [Discriminator loss: 0.6704%, acc.: 60.94%] [Generator loss: 0.8197%]\n",
            "5803 [Discriminator loss: 0.6689%, acc.: 57.03%] [Generator loss: 0.7717%]\n",
            "5804 [Discriminator loss: 0.6864%, acc.: 50.39%] [Generator loss: 0.7894%]\n",
            "5805 [Discriminator loss: 0.6815%, acc.: 55.86%] [Generator loss: 0.7990%]\n",
            "5806 [Discriminator loss: 0.6793%, acc.: 54.30%] [Generator loss: 0.7938%]\n",
            "5807 [Discriminator loss: 0.6923%, acc.: 53.12%] [Generator loss: 0.7733%]\n",
            "5808 [Discriminator loss: 0.6914%, acc.: 53.12%] [Generator loss: 0.7921%]\n",
            "5809 [Discriminator loss: 0.6666%, acc.: 57.42%] [Generator loss: 0.7914%]\n",
            "5810 [Discriminator loss: 0.6820%, acc.: 54.69%] [Generator loss: 0.8086%]\n",
            "5811 [Discriminator loss: 0.6693%, acc.: 59.38%] [Generator loss: 0.8058%]\n",
            "5812 [Discriminator loss: 0.6684%, acc.: 57.03%] [Generator loss: 0.7851%]\n",
            "5813 [Discriminator loss: 0.6654%, acc.: 56.64%] [Generator loss: 0.8090%]\n",
            "5814 [Discriminator loss: 0.6698%, acc.: 56.64%] [Generator loss: 0.7981%]\n",
            "5815 [Discriminator loss: 0.6783%, acc.: 55.86%] [Generator loss: 0.7921%]\n",
            "5816 [Discriminator loss: 0.6785%, acc.: 57.81%] [Generator loss: 0.8017%]\n",
            "5817 [Discriminator loss: 0.6758%, acc.: 56.25%] [Generator loss: 0.7792%]\n",
            "5818 [Discriminator loss: 0.6599%, acc.: 59.77%] [Generator loss: 0.7888%]\n",
            "5819 [Discriminator loss: 0.6712%, acc.: 56.64%] [Generator loss: 0.7863%]\n",
            "5820 [Discriminator loss: 0.6761%, acc.: 55.86%] [Generator loss: 0.8161%]\n",
            "5821 [Discriminator loss: 0.6927%, acc.: 52.73%] [Generator loss: 0.7869%]\n",
            "5822 [Discriminator loss: 0.6721%, acc.: 55.86%] [Generator loss: 0.7972%]\n",
            "5823 [Discriminator loss: 0.6752%, acc.: 57.81%] [Generator loss: 0.8094%]\n",
            "5824 [Discriminator loss: 0.6680%, acc.: 62.50%] [Generator loss: 0.7907%]\n",
            "5825 [Discriminator loss: 0.6750%, acc.: 57.42%] [Generator loss: 0.8096%]\n",
            "5826 [Discriminator loss: 0.6763%, acc.: 55.47%] [Generator loss: 0.7889%]\n",
            "5827 [Discriminator loss: 0.6894%, acc.: 50.78%] [Generator loss: 0.7912%]\n",
            "5828 [Discriminator loss: 0.6970%, acc.: 48.83%] [Generator loss: 0.7973%]\n",
            "5829 [Discriminator loss: 0.6601%, acc.: 55.47%] [Generator loss: 0.7813%]\n",
            "5830 [Discriminator loss: 0.6669%, acc.: 60.16%] [Generator loss: 0.7890%]\n",
            "5831 [Discriminator loss: 0.6729%, acc.: 53.91%] [Generator loss: 0.7991%]\n",
            "5832 [Discriminator loss: 0.6825%, acc.: 58.59%] [Generator loss: 0.8044%]\n",
            "5833 [Discriminator loss: 0.7028%, acc.: 49.61%] [Generator loss: 0.7893%]\n",
            "5834 [Discriminator loss: 0.6813%, acc.: 52.34%] [Generator loss: 0.8054%]\n",
            "5835 [Discriminator loss: 0.6795%, acc.: 57.42%] [Generator loss: 0.7834%]\n",
            "5836 [Discriminator loss: 0.6820%, acc.: 55.08%] [Generator loss: 0.7878%]\n",
            "5837 [Discriminator loss: 0.6854%, acc.: 55.08%] [Generator loss: 0.7863%]\n",
            "5838 [Discriminator loss: 0.6628%, acc.: 59.77%] [Generator loss: 0.8028%]\n",
            "5839 [Discriminator loss: 0.6702%, acc.: 55.47%] [Generator loss: 0.8036%]\n",
            "5840 [Discriminator loss: 0.6855%, acc.: 53.91%] [Generator loss: 0.7800%]\n",
            "5841 [Discriminator loss: 0.6948%, acc.: 50.39%] [Generator loss: 0.7706%]\n",
            "5842 [Discriminator loss: 0.6716%, acc.: 53.52%] [Generator loss: 0.7739%]\n",
            "5843 [Discriminator loss: 0.6541%, acc.: 58.59%] [Generator loss: 0.7640%]\n",
            "5844 [Discriminator loss: 0.6942%, acc.: 50.00%] [Generator loss: 0.7601%]\n",
            "5845 [Discriminator loss: 0.6533%, acc.: 61.33%] [Generator loss: 0.7835%]\n",
            "5846 [Discriminator loss: 0.6912%, acc.: 53.52%] [Generator loss: 0.7660%]\n",
            "5847 [Discriminator loss: 0.6766%, acc.: 58.59%] [Generator loss: 0.7941%]\n",
            "5848 [Discriminator loss: 0.6750%, acc.: 60.16%] [Generator loss: 0.7858%]\n",
            "5849 [Discriminator loss: 0.6665%, acc.: 60.55%] [Generator loss: 0.7727%]\n",
            "5850 [Discriminator loss: 0.6925%, acc.: 49.61%] [Generator loss: 0.7915%]\n",
            "5851 [Discriminator loss: 0.6806%, acc.: 51.56%] [Generator loss: 0.7568%]\n",
            "5852 [Discriminator loss: 0.6543%, acc.: 58.59%] [Generator loss: 0.7776%]\n",
            "5853 [Discriminator loss: 0.6735%, acc.: 56.25%] [Generator loss: 0.7850%]\n",
            "5854 [Discriminator loss: 0.6669%, acc.: 56.25%] [Generator loss: 0.7820%]\n",
            "5855 [Discriminator loss: 0.6783%, acc.: 55.86%] [Generator loss: 0.7945%]\n",
            "5856 [Discriminator loss: 0.6798%, acc.: 53.12%] [Generator loss: 0.7769%]\n",
            "5857 [Discriminator loss: 0.6812%, acc.: 56.25%] [Generator loss: 0.7716%]\n",
            "5858 [Discriminator loss: 0.6770%, acc.: 54.30%] [Generator loss: 0.7785%]\n",
            "5859 [Discriminator loss: 0.6764%, acc.: 60.16%] [Generator loss: 0.7852%]\n",
            "5860 [Discriminator loss: 0.6647%, acc.: 60.16%] [Generator loss: 0.7693%]\n",
            "5861 [Discriminator loss: 0.6684%, acc.: 57.42%] [Generator loss: 0.8026%]\n",
            "5862 [Discriminator loss: 0.6729%, acc.: 56.25%] [Generator loss: 0.7847%]\n",
            "5863 [Discriminator loss: 0.6843%, acc.: 56.64%] [Generator loss: 0.7780%]\n",
            "5864 [Discriminator loss: 0.6654%, acc.: 58.59%] [Generator loss: 0.8087%]\n",
            "5865 [Discriminator loss: 0.7001%, acc.: 52.34%] [Generator loss: 0.7751%]\n",
            "5866 [Discriminator loss: 0.6821%, acc.: 54.30%] [Generator loss: 0.7700%]\n",
            "5867 [Discriminator loss: 0.6560%, acc.: 61.33%] [Generator loss: 0.7882%]\n",
            "5868 [Discriminator loss: 0.6811%, acc.: 52.34%] [Generator loss: 0.7754%]\n",
            "5869 [Discriminator loss: 0.6897%, acc.: 57.42%] [Generator loss: 0.7793%]\n",
            "5870 [Discriminator loss: 0.6905%, acc.: 53.12%] [Generator loss: 0.7720%]\n",
            "5871 [Discriminator loss: 0.6720%, acc.: 59.38%] [Generator loss: 0.7802%]\n",
            "5872 [Discriminator loss: 0.6856%, acc.: 54.30%] [Generator loss: 0.7919%]\n",
            "5873 [Discriminator loss: 0.6757%, acc.: 58.98%] [Generator loss: 0.8011%]\n",
            "5874 [Discriminator loss: 0.6952%, acc.: 52.34%] [Generator loss: 0.7944%]\n",
            "5875 [Discriminator loss: 0.6799%, acc.: 57.03%] [Generator loss: 0.7819%]\n",
            "5876 [Discriminator loss: 0.6836%, acc.: 53.52%] [Generator loss: 0.7844%]\n",
            "5877 [Discriminator loss: 0.6792%, acc.: 57.81%] [Generator loss: 0.7882%]\n",
            "5878 [Discriminator loss: 0.6905%, acc.: 52.73%] [Generator loss: 0.7868%]\n",
            "5879 [Discriminator loss: 0.6822%, acc.: 53.91%] [Generator loss: 0.7853%]\n",
            "5880 [Discriminator loss: 0.6773%, acc.: 57.81%] [Generator loss: 0.7877%]\n",
            "5881 [Discriminator loss: 0.6848%, acc.: 53.12%] [Generator loss: 0.7811%]\n",
            "5882 [Discriminator loss: 0.7043%, acc.: 51.56%] [Generator loss: 0.7699%]\n",
            "5883 [Discriminator loss: 0.6869%, acc.: 53.91%] [Generator loss: 0.7750%]\n",
            "5884 [Discriminator loss: 0.6831%, acc.: 52.73%] [Generator loss: 0.7699%]\n",
            "5885 [Discriminator loss: 0.7049%, acc.: 50.78%] [Generator loss: 0.8037%]\n",
            "5886 [Discriminator loss: 0.6922%, acc.: 49.61%] [Generator loss: 0.7833%]\n",
            "5887 [Discriminator loss: 0.6810%, acc.: 54.69%] [Generator loss: 0.7847%]\n",
            "5888 [Discriminator loss: 0.6782%, acc.: 54.69%] [Generator loss: 0.7985%]\n",
            "5889 [Discriminator loss: 0.6551%, acc.: 60.16%] [Generator loss: 0.7907%]\n",
            "5890 [Discriminator loss: 0.6846%, acc.: 53.52%] [Generator loss: 0.7790%]\n",
            "5891 [Discriminator loss: 0.6940%, acc.: 51.56%] [Generator loss: 0.7916%]\n",
            "5892 [Discriminator loss: 0.6827%, acc.: 57.42%] [Generator loss: 0.7832%]\n",
            "5893 [Discriminator loss: 0.6805%, acc.: 55.86%] [Generator loss: 0.7703%]\n",
            "5894 [Discriminator loss: 0.6900%, acc.: 50.00%] [Generator loss: 0.7894%]\n",
            "5895 [Discriminator loss: 0.6807%, acc.: 57.42%] [Generator loss: 0.7624%]\n",
            "5896 [Discriminator loss: 0.6954%, acc.: 51.95%] [Generator loss: 0.7621%]\n",
            "5897 [Discriminator loss: 0.6741%, acc.: 56.64%] [Generator loss: 0.7681%]\n",
            "5898 [Discriminator loss: 0.6858%, acc.: 52.73%] [Generator loss: 0.7554%]\n",
            "5899 [Discriminator loss: 0.6917%, acc.: 54.30%] [Generator loss: 0.7900%]\n",
            "5900 [Discriminator loss: 0.6803%, acc.: 59.38%] [Generator loss: 0.7611%]\n",
            "5901 [Discriminator loss: 0.6793%, acc.: 57.03%] [Generator loss: 0.7460%]\n",
            "5902 [Discriminator loss: 0.6609%, acc.: 61.33%] [Generator loss: 0.7803%]\n",
            "5903 [Discriminator loss: 0.6859%, acc.: 52.73%] [Generator loss: 0.7635%]\n",
            "5904 [Discriminator loss: 0.6805%, acc.: 52.34%] [Generator loss: 0.7899%]\n",
            "5905 [Discriminator loss: 0.6857%, acc.: 55.86%] [Generator loss: 0.7767%]\n",
            "5906 [Discriminator loss: 0.6636%, acc.: 58.98%] [Generator loss: 0.7941%]\n",
            "5907 [Discriminator loss: 0.6902%, acc.: 51.95%] [Generator loss: 0.7974%]\n",
            "5908 [Discriminator loss: 0.6734%, acc.: 54.30%] [Generator loss: 0.7958%]\n",
            "5909 [Discriminator loss: 0.6603%, acc.: 62.50%] [Generator loss: 0.8108%]\n",
            "5910 [Discriminator loss: 0.6681%, acc.: 60.16%] [Generator loss: 0.7835%]\n",
            "5911 [Discriminator loss: 0.6685%, acc.: 60.16%] [Generator loss: 0.8087%]\n",
            "5912 [Discriminator loss: 0.6711%, acc.: 57.03%] [Generator loss: 0.7923%]\n",
            "5913 [Discriminator loss: 0.6640%, acc.: 60.55%] [Generator loss: 0.7933%]\n",
            "5914 [Discriminator loss: 0.6726%, acc.: 55.86%] [Generator loss: 0.8158%]\n",
            "5915 [Discriminator loss: 0.6583%, acc.: 63.67%] [Generator loss: 0.7773%]\n",
            "5916 [Discriminator loss: 0.6811%, acc.: 56.64%] [Generator loss: 0.7953%]\n",
            "5917 [Discriminator loss: 0.6572%, acc.: 61.72%] [Generator loss: 0.7896%]\n",
            "5918 [Discriminator loss: 0.6639%, acc.: 60.16%] [Generator loss: 0.7871%]\n",
            "5919 [Discriminator loss: 0.6717%, acc.: 61.33%] [Generator loss: 0.8156%]\n",
            "5920 [Discriminator loss: 0.6634%, acc.: 60.94%] [Generator loss: 0.7912%]\n",
            "5921 [Discriminator loss: 0.6809%, acc.: 56.25%] [Generator loss: 0.7908%]\n",
            "5922 [Discriminator loss: 0.6598%, acc.: 60.55%] [Generator loss: 0.7952%]\n",
            "5923 [Discriminator loss: 0.6647%, acc.: 57.42%] [Generator loss: 0.7900%]\n",
            "5924 [Discriminator loss: 0.6715%, acc.: 57.42%] [Generator loss: 0.8125%]\n",
            "5925 [Discriminator loss: 0.6618%, acc.: 60.94%] [Generator loss: 0.7893%]\n",
            "5926 [Discriminator loss: 0.6857%, acc.: 55.08%] [Generator loss: 0.7704%]\n",
            "5927 [Discriminator loss: 0.6831%, acc.: 57.03%] [Generator loss: 0.7678%]\n",
            "5928 [Discriminator loss: 0.6652%, acc.: 60.94%] [Generator loss: 0.7861%]\n",
            "5929 [Discriminator loss: 0.6727%, acc.: 59.38%] [Generator loss: 0.7912%]\n",
            "5930 [Discriminator loss: 0.6714%, acc.: 55.47%] [Generator loss: 0.7800%]\n",
            "5931 [Discriminator loss: 0.6614%, acc.: 61.33%] [Generator loss: 0.8056%]\n",
            "5932 [Discriminator loss: 0.6739%, acc.: 55.86%] [Generator loss: 0.7817%]\n",
            "5933 [Discriminator loss: 0.6638%, acc.: 61.72%] [Generator loss: 0.7690%]\n",
            "5934 [Discriminator loss: 0.6687%, acc.: 58.59%] [Generator loss: 0.7736%]\n",
            "5935 [Discriminator loss: 0.6881%, acc.: 54.30%] [Generator loss: 0.7799%]\n",
            "5936 [Discriminator loss: 0.6682%, acc.: 57.81%] [Generator loss: 0.7906%]\n",
            "5937 [Discriminator loss: 0.6903%, acc.: 49.61%] [Generator loss: 0.7906%]\n",
            "5938 [Discriminator loss: 0.6689%, acc.: 59.38%] [Generator loss: 0.7936%]\n",
            "5939 [Discriminator loss: 0.6827%, acc.: 54.69%] [Generator loss: 0.7796%]\n",
            "5940 [Discriminator loss: 0.6878%, acc.: 53.91%] [Generator loss: 0.7872%]\n",
            "5941 [Discriminator loss: 0.6580%, acc.: 60.55%] [Generator loss: 0.7865%]\n",
            "5942 [Discriminator loss: 0.6660%, acc.: 58.98%] [Generator loss: 0.8083%]\n",
            "5943 [Discriminator loss: 0.6770%, acc.: 57.81%] [Generator loss: 0.8018%]\n",
            "5944 [Discriminator loss: 0.6954%, acc.: 51.17%] [Generator loss: 0.7977%]\n",
            "5945 [Discriminator loss: 0.6832%, acc.: 55.08%] [Generator loss: 0.8081%]\n",
            "5946 [Discriminator loss: 0.6771%, acc.: 53.52%] [Generator loss: 0.8209%]\n",
            "5947 [Discriminator loss: 0.6856%, acc.: 54.69%] [Generator loss: 0.7943%]\n",
            "5948 [Discriminator loss: 0.6817%, acc.: 52.73%] [Generator loss: 0.8158%]\n",
            "5949 [Discriminator loss: 0.6618%, acc.: 57.42%] [Generator loss: 0.7919%]\n",
            "5950 [Discriminator loss: 0.6929%, acc.: 52.34%] [Generator loss: 0.7811%]\n",
            "5951 [Discriminator loss: 0.6931%, acc.: 53.52%] [Generator loss: 0.7865%]\n",
            "5952 [Discriminator loss: 0.6725%, acc.: 56.64%] [Generator loss: 0.7995%]\n",
            "5953 [Discriminator loss: 0.6758%, acc.: 54.69%] [Generator loss: 0.8004%]\n",
            "5954 [Discriminator loss: 0.6634%, acc.: 58.98%] [Generator loss: 0.8136%]\n",
            "5955 [Discriminator loss: 0.6747%, acc.: 55.47%] [Generator loss: 0.8065%]\n",
            "5956 [Discriminator loss: 0.6690%, acc.: 59.38%] [Generator loss: 0.8128%]\n",
            "5957 [Discriminator loss: 0.6881%, acc.: 56.25%] [Generator loss: 0.8171%]\n",
            "5958 [Discriminator loss: 0.6668%, acc.: 60.16%] [Generator loss: 0.8086%]\n",
            "5959 [Discriminator loss: 0.6784%, acc.: 56.64%] [Generator loss: 0.7927%]\n",
            "5960 [Discriminator loss: 0.6813%, acc.: 55.86%] [Generator loss: 0.7762%]\n",
            "5961 [Discriminator loss: 0.6640%, acc.: 62.50%] [Generator loss: 0.7689%]\n",
            "5962 [Discriminator loss: 0.6900%, acc.: 51.95%] [Generator loss: 0.7938%]\n",
            "5963 [Discriminator loss: 0.6710%, acc.: 55.47%] [Generator loss: 0.7863%]\n",
            "5964 [Discriminator loss: 0.6604%, acc.: 62.11%] [Generator loss: 0.7815%]\n",
            "5965 [Discriminator loss: 0.6601%, acc.: 59.38%] [Generator loss: 0.7785%]\n",
            "5966 [Discriminator loss: 0.6816%, acc.: 52.34%] [Generator loss: 0.7698%]\n",
            "5967 [Discriminator loss: 0.6651%, acc.: 58.59%] [Generator loss: 0.7754%]\n",
            "5968 [Discriminator loss: 0.6760%, acc.: 58.20%] [Generator loss: 0.8088%]\n",
            "5969 [Discriminator loss: 0.6660%, acc.: 54.69%] [Generator loss: 0.7791%]\n",
            "5970 [Discriminator loss: 0.6736%, acc.: 58.20%] [Generator loss: 0.7826%]\n",
            "5971 [Discriminator loss: 0.6534%, acc.: 61.72%] [Generator loss: 0.8017%]\n",
            "5972 [Discriminator loss: 0.6604%, acc.: 58.59%] [Generator loss: 0.8048%]\n",
            "5973 [Discriminator loss: 0.6731%, acc.: 58.59%] [Generator loss: 0.8105%]\n",
            "5974 [Discriminator loss: 0.6628%, acc.: 60.55%] [Generator loss: 0.7950%]\n",
            "5975 [Discriminator loss: 0.6721%, acc.: 57.03%] [Generator loss: 0.7799%]\n",
            "5976 [Discriminator loss: 0.6659%, acc.: 55.47%] [Generator loss: 0.8123%]\n",
            "5977 [Discriminator loss: 0.6912%, acc.: 55.08%] [Generator loss: 0.7918%]\n",
            "5978 [Discriminator loss: 0.6630%, acc.: 60.55%] [Generator loss: 0.7891%]\n",
            "5979 [Discriminator loss: 0.6765%, acc.: 57.03%] [Generator loss: 0.8131%]\n",
            "5980 [Discriminator loss: 0.6672%, acc.: 58.59%] [Generator loss: 0.8124%]\n",
            "5981 [Discriminator loss: 0.6942%, acc.: 54.30%] [Generator loss: 0.8205%]\n",
            "5982 [Discriminator loss: 0.6661%, acc.: 61.33%] [Generator loss: 0.8078%]\n",
            "5983 [Discriminator loss: 0.6895%, acc.: 49.22%] [Generator loss: 0.8002%]\n",
            "5984 [Discriminator loss: 0.6636%, acc.: 60.16%] [Generator loss: 0.7955%]\n",
            "5985 [Discriminator loss: 0.6731%, acc.: 58.59%] [Generator loss: 0.8087%]\n",
            "5986 [Discriminator loss: 0.6720%, acc.: 58.98%] [Generator loss: 0.8144%]\n",
            "5987 [Discriminator loss: 0.6801%, acc.: 51.56%] [Generator loss: 0.7790%]\n",
            "5988 [Discriminator loss: 0.6688%, acc.: 58.59%] [Generator loss: 0.7695%]\n",
            "5989 [Discriminator loss: 0.6547%, acc.: 62.11%] [Generator loss: 0.7743%]\n",
            "5990 [Discriminator loss: 0.6664%, acc.: 60.16%] [Generator loss: 0.7824%]\n",
            "5991 [Discriminator loss: 0.6670%, acc.: 57.03%] [Generator loss: 0.8067%]\n",
            "5992 [Discriminator loss: 0.6857%, acc.: 53.91%] [Generator loss: 0.8012%]\n",
            "5993 [Discriminator loss: 0.6641%, acc.: 59.38%] [Generator loss: 0.8081%]\n",
            "5994 [Discriminator loss: 0.6557%, acc.: 59.38%] [Generator loss: 0.8037%]\n",
            "5995 [Discriminator loss: 0.6759%, acc.: 57.03%] [Generator loss: 0.7839%]\n",
            "5996 [Discriminator loss: 0.6585%, acc.: 62.50%] [Generator loss: 0.7835%]\n",
            "5997 [Discriminator loss: 0.6637%, acc.: 60.55%] [Generator loss: 0.7741%]\n",
            "5998 [Discriminator loss: 0.6834%, acc.: 55.47%] [Generator loss: 0.7736%]\n",
            "5999 [Discriminator loss: 0.6737%, acc.: 59.38%] [Generator loss: 0.7722%]\n",
            "6000 [Discriminator loss: 0.6773%, acc.: 58.20%] [Generator loss: 0.7666%]\n",
            "6001 [Discriminator loss: 0.6709%, acc.: 60.55%] [Generator loss: 0.7805%]\n",
            "6002 [Discriminator loss: 0.6759%, acc.: 56.64%] [Generator loss: 0.7715%]\n",
            "6003 [Discriminator loss: 0.6781%, acc.: 60.16%] [Generator loss: 0.7968%]\n",
            "6004 [Discriminator loss: 0.6747%, acc.: 58.20%] [Generator loss: 0.7782%]\n",
            "6005 [Discriminator loss: 0.6683%, acc.: 60.94%] [Generator loss: 0.7802%]\n",
            "6006 [Discriminator loss: 0.6726%, acc.: 56.25%] [Generator loss: 0.7893%]\n",
            "6007 [Discriminator loss: 0.6749%, acc.: 59.77%] [Generator loss: 0.8006%]\n",
            "6008 [Discriminator loss: 0.6804%, acc.: 58.20%] [Generator loss: 0.7792%]\n",
            "6009 [Discriminator loss: 0.6743%, acc.: 55.86%] [Generator loss: 0.7787%]\n",
            "6010 [Discriminator loss: 0.6899%, acc.: 53.12%] [Generator loss: 0.7858%]\n",
            "6011 [Discriminator loss: 0.6687%, acc.: 58.20%] [Generator loss: 0.7825%]\n",
            "6012 [Discriminator loss: 0.6747%, acc.: 61.72%] [Generator loss: 0.7869%]\n",
            "6013 [Discriminator loss: 0.6690%, acc.: 58.98%] [Generator loss: 0.7829%]\n",
            "6014 [Discriminator loss: 0.6840%, acc.: 56.25%] [Generator loss: 0.7701%]\n",
            "6015 [Discriminator loss: 0.6811%, acc.: 58.20%] [Generator loss: 0.7645%]\n",
            "6016 [Discriminator loss: 0.6668%, acc.: 59.38%] [Generator loss: 0.7840%]\n",
            "6017 [Discriminator loss: 0.6530%, acc.: 61.72%] [Generator loss: 0.8016%]\n",
            "6018 [Discriminator loss: 0.6557%, acc.: 60.55%] [Generator loss: 0.7973%]\n",
            "6019 [Discriminator loss: 0.6698%, acc.: 57.81%] [Generator loss: 0.7862%]\n",
            "6020 [Discriminator loss: 0.6722%, acc.: 57.03%] [Generator loss: 0.7767%]\n",
            "6021 [Discriminator loss: 0.7025%, acc.: 47.66%] [Generator loss: 0.7965%]\n",
            "6022 [Discriminator loss: 0.6737%, acc.: 61.72%] [Generator loss: 0.7832%]\n",
            "6023 [Discriminator loss: 0.6789%, acc.: 57.03%] [Generator loss: 0.7893%]\n",
            "6024 [Discriminator loss: 0.6686%, acc.: 60.16%] [Generator loss: 0.7971%]\n",
            "6025 [Discriminator loss: 0.7026%, acc.: 48.05%] [Generator loss: 0.7961%]\n",
            "6026 [Discriminator loss: 0.6833%, acc.: 57.03%] [Generator loss: 0.7802%]\n",
            "6027 [Discriminator loss: 0.6804%, acc.: 55.47%] [Generator loss: 0.8020%]\n",
            "6028 [Discriminator loss: 0.6755%, acc.: 57.03%] [Generator loss: 0.7896%]\n",
            "6029 [Discriminator loss: 0.6818%, acc.: 57.81%] [Generator loss: 0.8053%]\n",
            "6030 [Discriminator loss: 0.6705%, acc.: 58.59%] [Generator loss: 0.7683%]\n",
            "6031 [Discriminator loss: 0.6808%, acc.: 54.69%] [Generator loss: 0.7898%]\n",
            "6032 [Discriminator loss: 0.6871%, acc.: 55.86%] [Generator loss: 0.7763%]\n",
            "6033 [Discriminator loss: 0.6991%, acc.: 52.34%] [Generator loss: 0.7573%]\n",
            "6034 [Discriminator loss: 0.7046%, acc.: 50.39%] [Generator loss: 0.7692%]\n",
            "6035 [Discriminator loss: 0.6979%, acc.: 50.39%] [Generator loss: 0.7772%]\n",
            "6036 [Discriminator loss: 0.7114%, acc.: 44.53%] [Generator loss: 0.7709%]\n",
            "6037 [Discriminator loss: 0.6677%, acc.: 57.42%] [Generator loss: 0.7769%]\n",
            "6038 [Discriminator loss: 0.6729%, acc.: 56.64%] [Generator loss: 0.7706%]\n",
            "6039 [Discriminator loss: 0.6805%, acc.: 57.81%] [Generator loss: 0.7841%]\n",
            "6040 [Discriminator loss: 0.6768%, acc.: 58.59%] [Generator loss: 0.7862%]\n",
            "6041 [Discriminator loss: 0.6840%, acc.: 55.47%] [Generator loss: 0.8009%]\n",
            "6042 [Discriminator loss: 0.6740%, acc.: 58.98%] [Generator loss: 0.8008%]\n",
            "6043 [Discriminator loss: 0.6952%, acc.: 55.47%] [Generator loss: 0.7674%]\n",
            "6044 [Discriminator loss: 0.6632%, acc.: 60.16%] [Generator loss: 0.7772%]\n",
            "6045 [Discriminator loss: 0.6897%, acc.: 51.17%] [Generator loss: 0.7696%]\n",
            "6046 [Discriminator loss: 0.7018%, acc.: 49.22%] [Generator loss: 0.8129%]\n",
            "6047 [Discriminator loss: 0.6746%, acc.: 57.42%] [Generator loss: 0.7833%]\n",
            "6048 [Discriminator loss: 0.6840%, acc.: 55.47%] [Generator loss: 0.7949%]\n",
            "6049 [Discriminator loss: 0.6809%, acc.: 55.08%] [Generator loss: 0.7933%]\n",
            "6050 [Discriminator loss: 0.6846%, acc.: 55.47%] [Generator loss: 0.7830%]\n",
            "6051 [Discriminator loss: 0.6667%, acc.: 59.38%] [Generator loss: 0.8003%]\n",
            "6052 [Discriminator loss: 0.6732%, acc.: 57.03%] [Generator loss: 0.7952%]\n",
            "6053 [Discriminator loss: 0.6702%, acc.: 56.25%] [Generator loss: 0.7972%]\n",
            "6054 [Discriminator loss: 0.6624%, acc.: 59.77%] [Generator loss: 0.7925%]\n",
            "6055 [Discriminator loss: 0.6741%, acc.: 58.59%] [Generator loss: 0.7658%]\n",
            "6056 [Discriminator loss: 0.6829%, acc.: 56.25%] [Generator loss: 0.7640%]\n",
            "6057 [Discriminator loss: 0.6687%, acc.: 57.03%] [Generator loss: 0.7929%]\n",
            "6058 [Discriminator loss: 0.6783%, acc.: 57.03%] [Generator loss: 0.7828%]\n",
            "6059 [Discriminator loss: 0.6769%, acc.: 57.81%] [Generator loss: 0.7927%]\n",
            "6060 [Discriminator loss: 0.6669%, acc.: 58.59%] [Generator loss: 0.7943%]\n",
            "6061 [Discriminator loss: 0.6777%, acc.: 57.42%] [Generator loss: 0.8023%]\n",
            "6062 [Discriminator loss: 0.6774%, acc.: 60.16%] [Generator loss: 0.7868%]\n",
            "6063 [Discriminator loss: 0.6804%, acc.: 54.69%] [Generator loss: 0.7859%]\n",
            "6064 [Discriminator loss: 0.6696%, acc.: 58.20%] [Generator loss: 0.7992%]\n",
            "6065 [Discriminator loss: 0.6667%, acc.: 64.06%] [Generator loss: 0.7945%]\n",
            "6066 [Discriminator loss: 0.6659%, acc.: 62.11%] [Generator loss: 0.8076%]\n",
            "6067 [Discriminator loss: 0.6760%, acc.: 58.98%] [Generator loss: 0.8063%]\n",
            "6068 [Discriminator loss: 0.6818%, acc.: 55.47%] [Generator loss: 0.7958%]\n",
            "6069 [Discriminator loss: 0.6919%, acc.: 54.30%] [Generator loss: 0.8176%]\n",
            "6070 [Discriminator loss: 0.6870%, acc.: 54.69%] [Generator loss: 0.8091%]\n",
            "6071 [Discriminator loss: 0.6863%, acc.: 55.08%] [Generator loss: 0.8111%]\n",
            "6072 [Discriminator loss: 0.6787%, acc.: 59.77%] [Generator loss: 0.7809%]\n",
            "6073 [Discriminator loss: 0.6524%, acc.: 62.50%] [Generator loss: 0.7721%]\n",
            "6074 [Discriminator loss: 0.6719%, acc.: 57.03%] [Generator loss: 0.7885%]\n",
            "6075 [Discriminator loss: 0.6896%, acc.: 53.52%] [Generator loss: 0.7891%]\n",
            "6076 [Discriminator loss: 0.6813%, acc.: 56.25%] [Generator loss: 0.7612%]\n",
            "6077 [Discriminator loss: 0.6901%, acc.: 55.08%] [Generator loss: 0.7589%]\n",
            "6078 [Discriminator loss: 0.6776%, acc.: 58.59%] [Generator loss: 0.7766%]\n",
            "6079 [Discriminator loss: 0.6816%, acc.: 55.86%] [Generator loss: 0.7728%]\n",
            "6080 [Discriminator loss: 0.6927%, acc.: 53.52%] [Generator loss: 0.7981%]\n",
            "6081 [Discriminator loss: 0.6736%, acc.: 59.77%] [Generator loss: 0.7829%]\n",
            "6082 [Discriminator loss: 0.6880%, acc.: 58.98%] [Generator loss: 0.7867%]\n",
            "6083 [Discriminator loss: 0.6969%, acc.: 50.78%] [Generator loss: 0.8117%]\n",
            "6084 [Discriminator loss: 0.6986%, acc.: 47.27%] [Generator loss: 0.8015%]\n",
            "6085 [Discriminator loss: 0.6808%, acc.: 56.25%] [Generator loss: 0.7939%]\n",
            "6086 [Discriminator loss: 0.6872%, acc.: 56.25%] [Generator loss: 0.7903%]\n",
            "6087 [Discriminator loss: 0.6943%, acc.: 53.52%] [Generator loss: 0.7786%]\n",
            "6088 [Discriminator loss: 0.6761%, acc.: 57.42%] [Generator loss: 0.8011%]\n",
            "6089 [Discriminator loss: 0.6903%, acc.: 57.03%] [Generator loss: 0.8008%]\n",
            "6090 [Discriminator loss: 0.6770%, acc.: 57.42%] [Generator loss: 0.7918%]\n",
            "6091 [Discriminator loss: 0.6910%, acc.: 49.61%] [Generator loss: 0.8135%]\n",
            "6092 [Discriminator loss: 0.6772%, acc.: 57.03%] [Generator loss: 0.8035%]\n",
            "6093 [Discriminator loss: 0.6734%, acc.: 56.64%] [Generator loss: 0.7928%]\n",
            "6094 [Discriminator loss: 0.6914%, acc.: 52.73%] [Generator loss: 0.7791%]\n",
            "6095 [Discriminator loss: 0.6786%, acc.: 54.30%] [Generator loss: 0.7927%]\n",
            "6096 [Discriminator loss: 0.6935%, acc.: 47.27%] [Generator loss: 0.8080%]\n",
            "6097 [Discriminator loss: 0.6445%, acc.: 64.06%] [Generator loss: 0.7922%]\n",
            "6098 [Discriminator loss: 0.6844%, acc.: 53.52%] [Generator loss: 0.7612%]\n",
            "6099 [Discriminator loss: 0.6773%, acc.: 54.69%] [Generator loss: 0.7919%]\n",
            "6100 [Discriminator loss: 0.6662%, acc.: 62.11%] [Generator loss: 0.7853%]\n",
            "6101 [Discriminator loss: 0.6857%, acc.: 53.91%] [Generator loss: 0.7764%]\n",
            "6102 [Discriminator loss: 0.6774%, acc.: 59.77%] [Generator loss: 0.7823%]\n",
            "6103 [Discriminator loss: 0.6704%, acc.: 58.59%] [Generator loss: 0.7932%]\n",
            "6104 [Discriminator loss: 0.6995%, acc.: 49.22%] [Generator loss: 0.7970%]\n",
            "6105 [Discriminator loss: 0.6904%, acc.: 50.00%] [Generator loss: 0.7821%]\n",
            "6106 [Discriminator loss: 0.6846%, acc.: 51.56%] [Generator loss: 0.7763%]\n",
            "6107 [Discriminator loss: 0.6889%, acc.: 52.73%] [Generator loss: 0.8096%]\n",
            "6108 [Discriminator loss: 0.6757%, acc.: 54.69%] [Generator loss: 0.7902%]\n",
            "6109 [Discriminator loss: 0.6753%, acc.: 57.81%] [Generator loss: 0.8088%]\n",
            "6110 [Discriminator loss: 0.6942%, acc.: 53.12%] [Generator loss: 0.7934%]\n",
            "6111 [Discriminator loss: 0.6690%, acc.: 59.77%] [Generator loss: 0.7856%]\n",
            "6112 [Discriminator loss: 0.6724%, acc.: 60.55%] [Generator loss: 0.7744%]\n",
            "6113 [Discriminator loss: 0.6612%, acc.: 59.77%] [Generator loss: 0.7711%]\n",
            "6114 [Discriminator loss: 0.6877%, acc.: 54.30%] [Generator loss: 0.7808%]\n",
            "6115 [Discriminator loss: 0.6854%, acc.: 53.52%] [Generator loss: 0.7747%]\n",
            "6116 [Discriminator loss: 0.6782%, acc.: 56.25%] [Generator loss: 0.7892%]\n",
            "6117 [Discriminator loss: 0.6708%, acc.: 58.20%] [Generator loss: 0.7752%]\n",
            "6118 [Discriminator loss: 0.6800%, acc.: 55.47%] [Generator loss: 0.7633%]\n",
            "6119 [Discriminator loss: 0.6973%, acc.: 52.34%] [Generator loss: 0.7721%]\n",
            "6120 [Discriminator loss: 0.6958%, acc.: 50.78%] [Generator loss: 0.7640%]\n",
            "6121 [Discriminator loss: 0.6845%, acc.: 53.52%] [Generator loss: 0.8039%]\n",
            "6122 [Discriminator loss: 0.6842%, acc.: 52.34%] [Generator loss: 0.7787%]\n",
            "6123 [Discriminator loss: 0.6932%, acc.: 52.34%] [Generator loss: 0.7819%]\n",
            "6124 [Discriminator loss: 0.6737%, acc.: 57.03%] [Generator loss: 0.7507%]\n",
            "6125 [Discriminator loss: 0.6972%, acc.: 53.52%] [Generator loss: 0.7801%]\n",
            "6126 [Discriminator loss: 0.6819%, acc.: 55.86%] [Generator loss: 0.7748%]\n",
            "6127 [Discriminator loss: 0.6994%, acc.: 53.91%] [Generator loss: 0.7740%]\n",
            "6128 [Discriminator loss: 0.6740%, acc.: 56.64%] [Generator loss: 0.7845%]\n",
            "6129 [Discriminator loss: 0.6882%, acc.: 53.52%] [Generator loss: 0.7781%]\n",
            "6130 [Discriminator loss: 0.6875%, acc.: 55.08%] [Generator loss: 0.7752%]\n",
            "6131 [Discriminator loss: 0.6802%, acc.: 53.52%] [Generator loss: 0.7881%]\n",
            "6132 [Discriminator loss: 0.6708%, acc.: 58.59%] [Generator loss: 0.7782%]\n",
            "6133 [Discriminator loss: 0.6770%, acc.: 56.25%] [Generator loss: 0.7852%]\n",
            "6134 [Discriminator loss: 0.6816%, acc.: 59.77%] [Generator loss: 0.7897%]\n",
            "6135 [Discriminator loss: 0.6818%, acc.: 52.73%] [Generator loss: 0.7814%]\n",
            "6136 [Discriminator loss: 0.6799%, acc.: 57.81%] [Generator loss: 0.7841%]\n",
            "6137 [Discriminator loss: 0.6648%, acc.: 58.59%] [Generator loss: 0.7776%]\n",
            "6138 [Discriminator loss: 0.6826%, acc.: 53.91%] [Generator loss: 0.7877%]\n",
            "6139 [Discriminator loss: 0.6764%, acc.: 57.03%] [Generator loss: 0.8074%]\n",
            "6140 [Discriminator loss: 0.6881%, acc.: 53.12%] [Generator loss: 0.7772%]\n",
            "6141 [Discriminator loss: 0.6597%, acc.: 62.89%] [Generator loss: 0.7637%]\n",
            "6142 [Discriminator loss: 0.6945%, acc.: 51.17%] [Generator loss: 0.7615%]\n",
            "6143 [Discriminator loss: 0.6884%, acc.: 53.91%] [Generator loss: 0.7496%]\n",
            "6144 [Discriminator loss: 0.6781%, acc.: 54.69%] [Generator loss: 0.7482%]\n",
            "6145 [Discriminator loss: 0.6869%, acc.: 54.30%] [Generator loss: 0.7742%]\n",
            "6146 [Discriminator loss: 0.6791%, acc.: 53.91%] [Generator loss: 0.7870%]\n",
            "6147 [Discriminator loss: 0.6745%, acc.: 57.03%] [Generator loss: 0.7780%]\n",
            "6148 [Discriminator loss: 0.6669%, acc.: 58.20%] [Generator loss: 0.7690%]\n",
            "6149 [Discriminator loss: 0.6724%, acc.: 58.59%] [Generator loss: 0.7930%]\n",
            "6150 [Discriminator loss: 0.6847%, acc.: 56.64%] [Generator loss: 0.7816%]\n",
            "6151 [Discriminator loss: 0.6941%, acc.: 53.52%] [Generator loss: 0.7914%]\n",
            "6152 [Discriminator loss: 0.6858%, acc.: 53.91%] [Generator loss: 0.7978%]\n",
            "6153 [Discriminator loss: 0.6861%, acc.: 58.20%] [Generator loss: 0.7725%]\n",
            "6154 [Discriminator loss: 0.6712%, acc.: 59.38%] [Generator loss: 0.7732%]\n",
            "6155 [Discriminator loss: 0.6657%, acc.: 55.08%] [Generator loss: 0.7787%]\n",
            "6156 [Discriminator loss: 0.6748%, acc.: 56.25%] [Generator loss: 0.7875%]\n",
            "6157 [Discriminator loss: 0.6772%, acc.: 56.25%] [Generator loss: 0.7907%]\n",
            "6158 [Discriminator loss: 0.6977%, acc.: 51.17%] [Generator loss: 0.7816%]\n",
            "6159 [Discriminator loss: 0.7043%, acc.: 48.44%] [Generator loss: 0.7792%]\n",
            "6160 [Discriminator loss: 0.6917%, acc.: 50.39%] [Generator loss: 0.7737%]\n",
            "6161 [Discriminator loss: 0.6820%, acc.: 57.81%] [Generator loss: 0.7778%]\n",
            "6162 [Discriminator loss: 0.6833%, acc.: 54.69%] [Generator loss: 0.7472%]\n",
            "6163 [Discriminator loss: 0.6929%, acc.: 51.95%] [Generator loss: 0.7603%]\n",
            "6164 [Discriminator loss: 0.6984%, acc.: 50.78%] [Generator loss: 0.7661%]\n",
            "6165 [Discriminator loss: 0.6824%, acc.: 55.08%] [Generator loss: 0.7485%]\n",
            "6166 [Discriminator loss: 0.6853%, acc.: 53.91%] [Generator loss: 0.7316%]\n",
            "6167 [Discriminator loss: 0.6808%, acc.: 53.52%] [Generator loss: 0.7579%]\n",
            "6168 [Discriminator loss: 0.6966%, acc.: 49.61%] [Generator loss: 0.7551%]\n",
            "6169 [Discriminator loss: 0.6716%, acc.: 58.59%] [Generator loss: 0.7823%]\n",
            "6170 [Discriminator loss: 0.6738%, acc.: 58.59%] [Generator loss: 0.7736%]\n",
            "6171 [Discriminator loss: 0.6767%, acc.: 59.77%] [Generator loss: 0.7825%]\n",
            "6172 [Discriminator loss: 0.6882%, acc.: 50.78%] [Generator loss: 0.7839%]\n",
            "6173 [Discriminator loss: 0.6717%, acc.: 59.38%] [Generator loss: 0.7872%]\n",
            "6174 [Discriminator loss: 0.6773%, acc.: 56.25%] [Generator loss: 0.7924%]\n",
            "6175 [Discriminator loss: 0.6687%, acc.: 60.94%] [Generator loss: 0.8043%]\n",
            "6176 [Discriminator loss: 0.6915%, acc.: 53.91%] [Generator loss: 0.7758%]\n",
            "6177 [Discriminator loss: 0.6796%, acc.: 55.47%] [Generator loss: 0.7798%]\n",
            "6178 [Discriminator loss: 0.6879%, acc.: 55.86%] [Generator loss: 0.7761%]\n",
            "6179 [Discriminator loss: 0.6835%, acc.: 57.03%] [Generator loss: 0.7711%]\n",
            "6180 [Discriminator loss: 0.6832%, acc.: 55.47%] [Generator loss: 0.7793%]\n",
            "6181 [Discriminator loss: 0.6804%, acc.: 51.56%] [Generator loss: 0.7984%]\n",
            "6182 [Discriminator loss: 0.6898%, acc.: 54.69%] [Generator loss: 0.7811%]\n",
            "6183 [Discriminator loss: 0.6861%, acc.: 52.73%] [Generator loss: 0.7922%]\n",
            "6184 [Discriminator loss: 0.6906%, acc.: 53.12%] [Generator loss: 0.7897%]\n",
            "6185 [Discriminator loss: 0.6874%, acc.: 50.39%] [Generator loss: 0.7937%]\n",
            "6186 [Discriminator loss: 0.6714%, acc.: 58.98%] [Generator loss: 0.7786%]\n",
            "6187 [Discriminator loss: 0.6742%, acc.: 55.86%] [Generator loss: 0.7896%]\n",
            "6188 [Discriminator loss: 0.6850%, acc.: 55.47%] [Generator loss: 0.7871%]\n",
            "6189 [Discriminator loss: 0.6755%, acc.: 57.81%] [Generator loss: 0.8084%]\n",
            "6190 [Discriminator loss: 0.6702%, acc.: 58.59%] [Generator loss: 0.7904%]\n",
            "6191 [Discriminator loss: 0.6871%, acc.: 53.12%] [Generator loss: 0.7704%]\n",
            "6192 [Discriminator loss: 0.6828%, acc.: 55.86%] [Generator loss: 0.7618%]\n",
            "6193 [Discriminator loss: 0.6839%, acc.: 52.73%] [Generator loss: 0.7682%]\n",
            "6194 [Discriminator loss: 0.6686%, acc.: 58.20%] [Generator loss: 0.7757%]\n",
            "6195 [Discriminator loss: 0.6675%, acc.: 58.98%] [Generator loss: 0.7988%]\n",
            "6196 [Discriminator loss: 0.6797%, acc.: 57.42%] [Generator loss: 0.7872%]\n",
            "6197 [Discriminator loss: 0.6817%, acc.: 54.69%] [Generator loss: 0.7753%]\n",
            "6198 [Discriminator loss: 0.6839%, acc.: 55.86%] [Generator loss: 0.7424%]\n",
            "6199 [Discriminator loss: 0.6843%, acc.: 55.86%] [Generator loss: 0.7737%]\n",
            "6200 [Discriminator loss: 0.6766%, acc.: 57.81%] [Generator loss: 0.7657%]\n",
            "6201 [Discriminator loss: 0.6830%, acc.: 57.03%] [Generator loss: 0.7718%]\n",
            "6202 [Discriminator loss: 0.6797%, acc.: 56.25%] [Generator loss: 0.7720%]\n",
            "6203 [Discriminator loss: 0.6734%, acc.: 59.77%] [Generator loss: 0.7774%]\n",
            "6204 [Discriminator loss: 0.6832%, acc.: 57.03%] [Generator loss: 0.7759%]\n",
            "6205 [Discriminator loss: 0.6907%, acc.: 56.25%] [Generator loss: 0.7783%]\n",
            "6206 [Discriminator loss: 0.6729%, acc.: 59.38%] [Generator loss: 0.7740%]\n",
            "6207 [Discriminator loss: 0.6787%, acc.: 56.25%] [Generator loss: 0.7810%]\n",
            "6208 [Discriminator loss: 0.6812%, acc.: 55.47%] [Generator loss: 0.7745%]\n",
            "6209 [Discriminator loss: 0.6747%, acc.: 57.03%] [Generator loss: 0.8013%]\n",
            "6210 [Discriminator loss: 0.6679%, acc.: 61.33%] [Generator loss: 0.8211%]\n",
            "6211 [Discriminator loss: 0.6839%, acc.: 54.30%] [Generator loss: 0.7710%]\n",
            "6212 [Discriminator loss: 0.6972%, acc.: 52.34%] [Generator loss: 0.7773%]\n",
            "6213 [Discriminator loss: 0.6872%, acc.: 55.08%] [Generator loss: 0.7873%]\n",
            "6214 [Discriminator loss: 0.6727%, acc.: 62.11%] [Generator loss: 0.7768%]\n",
            "6215 [Discriminator loss: 0.6621%, acc.: 62.11%] [Generator loss: 0.8028%]\n",
            "6216 [Discriminator loss: 0.6736%, acc.: 57.03%] [Generator loss: 0.7820%]\n",
            "6217 [Discriminator loss: 0.6708%, acc.: 55.86%] [Generator loss: 0.7971%]\n",
            "6218 [Discriminator loss: 0.6684%, acc.: 59.38%] [Generator loss: 0.7993%]\n",
            "6219 [Discriminator loss: 0.6808%, acc.: 55.86%] [Generator loss: 0.7929%]\n",
            "6220 [Discriminator loss: 0.6954%, acc.: 53.12%] [Generator loss: 0.7817%]\n",
            "6221 [Discriminator loss: 0.6650%, acc.: 62.11%] [Generator loss: 0.7903%]\n",
            "6222 [Discriminator loss: 0.6707%, acc.: 57.03%] [Generator loss: 0.7822%]\n",
            "6223 [Discriminator loss: 0.6609%, acc.: 60.55%] [Generator loss: 0.7900%]\n",
            "6224 [Discriminator loss: 0.6794%, acc.: 55.47%] [Generator loss: 0.7977%]\n",
            "6225 [Discriminator loss: 0.6830%, acc.: 56.64%] [Generator loss: 0.7857%]\n",
            "6226 [Discriminator loss: 0.6756%, acc.: 54.69%] [Generator loss: 0.7863%]\n",
            "6227 [Discriminator loss: 0.6523%, acc.: 65.23%] [Generator loss: 0.7819%]\n",
            "6228 [Discriminator loss: 0.6806%, acc.: 55.86%] [Generator loss: 0.7844%]\n",
            "6229 [Discriminator loss: 0.6653%, acc.: 62.50%] [Generator loss: 0.7935%]\n",
            "6230 [Discriminator loss: 0.6655%, acc.: 62.89%] [Generator loss: 0.7773%]\n",
            "6231 [Discriminator loss: 0.6765%, acc.: 55.08%] [Generator loss: 0.8057%]\n",
            "6232 [Discriminator loss: 0.6681%, acc.: 59.77%] [Generator loss: 0.7743%]\n",
            "6233 [Discriminator loss: 0.6769%, acc.: 55.86%] [Generator loss: 0.7720%]\n",
            "6234 [Discriminator loss: 0.6713%, acc.: 57.42%] [Generator loss: 0.7787%]\n",
            "6235 [Discriminator loss: 0.6603%, acc.: 59.38%] [Generator loss: 0.7627%]\n",
            "6236 [Discriminator loss: 0.6667%, acc.: 62.89%] [Generator loss: 0.7891%]\n",
            "6237 [Discriminator loss: 0.6754%, acc.: 55.47%] [Generator loss: 0.7848%]\n",
            "6238 [Discriminator loss: 0.6510%, acc.: 64.06%] [Generator loss: 0.7905%]\n",
            "6239 [Discriminator loss: 0.6816%, acc.: 59.77%] [Generator loss: 0.8141%]\n",
            "6240 [Discriminator loss: 0.6710%, acc.: 59.77%] [Generator loss: 0.7822%]\n",
            "6241 [Discriminator loss: 0.6790%, acc.: 58.59%] [Generator loss: 0.8025%]\n",
            "6242 [Discriminator loss: 0.6678%, acc.: 58.98%] [Generator loss: 0.8089%]\n",
            "6243 [Discriminator loss: 0.6816%, acc.: 57.42%] [Generator loss: 0.7923%]\n",
            "6244 [Discriminator loss: 0.6560%, acc.: 63.67%] [Generator loss: 0.7843%]\n",
            "6245 [Discriminator loss: 0.6788%, acc.: 59.77%] [Generator loss: 0.7724%]\n",
            "6246 [Discriminator loss: 0.6813%, acc.: 55.47%] [Generator loss: 0.8062%]\n",
            "6247 [Discriminator loss: 0.6610%, acc.: 58.98%] [Generator loss: 0.7674%]\n",
            "6248 [Discriminator loss: 0.6796%, acc.: 56.25%] [Generator loss: 0.7855%]\n",
            "6249 [Discriminator loss: 0.6596%, acc.: 65.23%] [Generator loss: 0.7949%]\n",
            "6250 [Discriminator loss: 0.6708%, acc.: 61.33%] [Generator loss: 0.7749%]\n",
            "6251 [Discriminator loss: 0.6744%, acc.: 56.64%] [Generator loss: 0.7970%]\n",
            "6252 [Discriminator loss: 0.6682%, acc.: 56.25%] [Generator loss: 0.8077%]\n",
            "6253 [Discriminator loss: 0.6699%, acc.: 59.77%] [Generator loss: 0.7919%]\n",
            "6254 [Discriminator loss: 0.6626%, acc.: 60.55%] [Generator loss: 0.8022%]\n",
            "6255 [Discriminator loss: 0.6724%, acc.: 58.59%] [Generator loss: 0.7866%]\n",
            "6256 [Discriminator loss: 0.6710%, acc.: 61.72%] [Generator loss: 0.7983%]\n",
            "6257 [Discriminator loss: 0.6731%, acc.: 59.38%] [Generator loss: 0.8009%]\n",
            "6258 [Discriminator loss: 0.6617%, acc.: 59.38%] [Generator loss: 0.7996%]\n",
            "6259 [Discriminator loss: 0.6649%, acc.: 58.20%] [Generator loss: 0.7958%]\n",
            "6260 [Discriminator loss: 0.6802%, acc.: 58.59%] [Generator loss: 0.7921%]\n",
            "6261 [Discriminator loss: 0.6520%, acc.: 63.67%] [Generator loss: 0.8208%]\n",
            "6262 [Discriminator loss: 0.6660%, acc.: 61.72%] [Generator loss: 0.8187%]\n",
            "6263 [Discriminator loss: 0.6733%, acc.: 57.81%] [Generator loss: 0.7990%]\n",
            "6264 [Discriminator loss: 0.6757%, acc.: 58.59%] [Generator loss: 0.7953%]\n",
            "6265 [Discriminator loss: 0.6806%, acc.: 55.08%] [Generator loss: 0.7930%]\n",
            "6266 [Discriminator loss: 0.6713%, acc.: 58.20%] [Generator loss: 0.7951%]\n",
            "6267 [Discriminator loss: 0.6922%, acc.: 51.95%] [Generator loss: 0.7783%]\n",
            "6268 [Discriminator loss: 0.6705%, acc.: 56.64%] [Generator loss: 0.7833%]\n",
            "6269 [Discriminator loss: 0.6823%, acc.: 56.64%] [Generator loss: 0.7873%]\n",
            "6270 [Discriminator loss: 0.6848%, acc.: 56.64%] [Generator loss: 0.8050%]\n",
            "6271 [Discriminator loss: 0.6846%, acc.: 55.08%] [Generator loss: 0.7900%]\n",
            "6272 [Discriminator loss: 0.6546%, acc.: 63.67%] [Generator loss: 0.8066%]\n",
            "6273 [Discriminator loss: 0.6752%, acc.: 54.69%] [Generator loss: 0.7964%]\n",
            "6274 [Discriminator loss: 0.6908%, acc.: 52.34%] [Generator loss: 0.7924%]\n",
            "6275 [Discriminator loss: 0.6872%, acc.: 51.95%] [Generator loss: 0.7742%]\n",
            "6276 [Discriminator loss: 0.6875%, acc.: 52.73%] [Generator loss: 0.7799%]\n",
            "6277 [Discriminator loss: 0.7129%, acc.: 49.22%] [Generator loss: 0.7745%]\n",
            "6278 [Discriminator loss: 0.6754%, acc.: 58.59%] [Generator loss: 0.7856%]\n",
            "6279 [Discriminator loss: 0.6850%, acc.: 56.64%] [Generator loss: 0.7766%]\n",
            "6280 [Discriminator loss: 0.6755%, acc.: 58.59%] [Generator loss: 0.7891%]\n",
            "6281 [Discriminator loss: 0.6699%, acc.: 58.98%] [Generator loss: 0.7866%]\n",
            "6282 [Discriminator loss: 0.6739%, acc.: 55.86%] [Generator loss: 0.7762%]\n",
            "6283 [Discriminator loss: 0.6714%, acc.: 57.03%] [Generator loss: 0.7689%]\n",
            "6284 [Discriminator loss: 0.6790%, acc.: 55.86%] [Generator loss: 0.7685%]\n",
            "6285 [Discriminator loss: 0.6718%, acc.: 56.25%] [Generator loss: 0.7659%]\n",
            "6286 [Discriminator loss: 0.6671%, acc.: 55.86%] [Generator loss: 0.7610%]\n",
            "6287 [Discriminator loss: 0.6840%, acc.: 53.52%] [Generator loss: 0.7751%]\n",
            "6288 [Discriminator loss: 0.6726%, acc.: 58.20%] [Generator loss: 0.7946%]\n",
            "6289 [Discriminator loss: 0.6714%, acc.: 57.03%] [Generator loss: 0.8068%]\n",
            "6290 [Discriminator loss: 0.6542%, acc.: 60.55%] [Generator loss: 0.8048%]\n",
            "6291 [Discriminator loss: 0.6649%, acc.: 60.94%] [Generator loss: 0.8143%]\n",
            "6292 [Discriminator loss: 0.6784%, acc.: 58.20%] [Generator loss: 0.7857%]\n",
            "6293 [Discriminator loss: 0.6546%, acc.: 64.45%] [Generator loss: 0.8245%]\n",
            "6294 [Discriminator loss: 0.6682%, acc.: 57.81%] [Generator loss: 0.7989%]\n",
            "6295 [Discriminator loss: 0.6609%, acc.: 58.20%] [Generator loss: 0.8166%]\n",
            "6296 [Discriminator loss: 0.6544%, acc.: 60.55%] [Generator loss: 0.8029%]\n",
            "6297 [Discriminator loss: 0.6560%, acc.: 66.02%] [Generator loss: 0.7941%]\n",
            "6298 [Discriminator loss: 0.6611%, acc.: 57.03%] [Generator loss: 0.8003%]\n",
            "6299 [Discriminator loss: 0.6620%, acc.: 63.28%] [Generator loss: 0.8005%]\n",
            "6300 [Discriminator loss: 0.6543%, acc.: 62.11%] [Generator loss: 0.8248%]\n",
            "6301 [Discriminator loss: 0.6514%, acc.: 65.62%] [Generator loss: 0.7873%]\n",
            "6302 [Discriminator loss: 0.6487%, acc.: 57.42%] [Generator loss: 0.8140%]\n",
            "6303 [Discriminator loss: 0.6465%, acc.: 62.89%] [Generator loss: 0.8018%]\n",
            "6304 [Discriminator loss: 0.6599%, acc.: 60.16%] [Generator loss: 0.7892%]\n",
            "6305 [Discriminator loss: 0.6529%, acc.: 60.94%] [Generator loss: 0.7851%]\n",
            "6306 [Discriminator loss: 0.6708%, acc.: 57.42%] [Generator loss: 0.8103%]\n",
            "6307 [Discriminator loss: 0.6580%, acc.: 60.16%] [Generator loss: 0.7891%]\n",
            "6308 [Discriminator loss: 0.6469%, acc.: 58.98%] [Generator loss: 0.7795%]\n",
            "6309 [Discriminator loss: 0.6442%, acc.: 61.33%] [Generator loss: 0.7954%]\n",
            "6310 [Discriminator loss: 0.6614%, acc.: 58.98%] [Generator loss: 0.7761%]\n",
            "6311 [Discriminator loss: 0.6503%, acc.: 58.98%] [Generator loss: 0.8057%]\n",
            "6312 [Discriminator loss: 0.6574%, acc.: 59.77%] [Generator loss: 0.7773%]\n",
            "6313 [Discriminator loss: 0.6395%, acc.: 61.33%] [Generator loss: 0.8107%]\n",
            "6314 [Discriminator loss: 0.6643%, acc.: 57.42%] [Generator loss: 0.8130%]\n",
            "6315 [Discriminator loss: 0.6493%, acc.: 62.89%] [Generator loss: 0.7907%]\n",
            "6316 [Discriminator loss: 0.6694%, acc.: 60.55%] [Generator loss: 0.7997%]\n",
            "6317 [Discriminator loss: 0.6569%, acc.: 60.94%] [Generator loss: 0.8008%]\n",
            "6318 [Discriminator loss: 0.6608%, acc.: 62.89%] [Generator loss: 0.7987%]\n",
            "6319 [Discriminator loss: 0.6585%, acc.: 64.06%] [Generator loss: 0.8068%]\n",
            "6320 [Discriminator loss: 0.6650%, acc.: 62.11%] [Generator loss: 0.8073%]\n",
            "6321 [Discriminator loss: 0.6633%, acc.: 58.98%] [Generator loss: 0.7899%]\n",
            "6322 [Discriminator loss: 0.6819%, acc.: 54.30%] [Generator loss: 0.7914%]\n",
            "6323 [Discriminator loss: 0.6688%, acc.: 59.77%] [Generator loss: 0.7619%]\n",
            "6324 [Discriminator loss: 0.6602%, acc.: 62.11%] [Generator loss: 0.7997%]\n",
            "6325 [Discriminator loss: 0.6670%, acc.: 58.20%] [Generator loss: 0.7826%]\n",
            "6326 [Discriminator loss: 0.6580%, acc.: 61.33%] [Generator loss: 0.8098%]\n",
            "6327 [Discriminator loss: 0.6791%, acc.: 58.20%] [Generator loss: 0.7882%]\n",
            "6328 [Discriminator loss: 0.6774%, acc.: 54.69%] [Generator loss: 0.8015%]\n",
            "6329 [Discriminator loss: 0.6721%, acc.: 58.98%] [Generator loss: 0.7982%]\n",
            "6330 [Discriminator loss: 0.6702%, acc.: 57.03%] [Generator loss: 0.8332%]\n",
            "6331 [Discriminator loss: 0.6755%, acc.: 59.38%] [Generator loss: 0.8247%]\n",
            "6332 [Discriminator loss: 0.6646%, acc.: 59.77%] [Generator loss: 0.8100%]\n",
            "6333 [Discriminator loss: 0.6857%, acc.: 54.69%] [Generator loss: 0.7790%]\n",
            "6334 [Discriminator loss: 0.6620%, acc.: 62.50%] [Generator loss: 0.8060%]\n",
            "6335 [Discriminator loss: 0.6799%, acc.: 56.25%] [Generator loss: 0.7635%]\n",
            "6336 [Discriminator loss: 0.6749%, acc.: 55.86%] [Generator loss: 0.7926%]\n",
            "6337 [Discriminator loss: 0.6797%, acc.: 54.69%] [Generator loss: 0.7800%]\n",
            "6338 [Discriminator loss: 0.7035%, acc.: 53.91%] [Generator loss: 0.7745%]\n",
            "6339 [Discriminator loss: 0.6718%, acc.: 53.52%] [Generator loss: 0.7928%]\n",
            "6340 [Discriminator loss: 0.6722%, acc.: 60.55%] [Generator loss: 0.7826%]\n",
            "6341 [Discriminator loss: 0.6804%, acc.: 56.64%] [Generator loss: 0.7646%]\n",
            "6342 [Discriminator loss: 0.6665%, acc.: 56.25%] [Generator loss: 0.7853%]\n",
            "6343 [Discriminator loss: 0.6953%, acc.: 52.34%] [Generator loss: 0.8044%]\n",
            "6344 [Discriminator loss: 0.6696%, acc.: 57.03%] [Generator loss: 0.7809%]\n",
            "6345 [Discriminator loss: 0.6732%, acc.: 57.81%] [Generator loss: 0.7914%]\n",
            "6346 [Discriminator loss: 0.6612%, acc.: 62.11%] [Generator loss: 0.7961%]\n",
            "6347 [Discriminator loss: 0.6598%, acc.: 62.50%] [Generator loss: 0.7994%]\n",
            "6348 [Discriminator loss: 0.6926%, acc.: 53.52%] [Generator loss: 0.8060%]\n",
            "6349 [Discriminator loss: 0.6794%, acc.: 55.47%] [Generator loss: 0.8030%]\n",
            "6350 [Discriminator loss: 0.6704%, acc.: 59.77%] [Generator loss: 0.8040%]\n",
            "6351 [Discriminator loss: 0.6761%, acc.: 58.20%] [Generator loss: 0.7856%]\n",
            "6352 [Discriminator loss: 0.6625%, acc.: 63.28%] [Generator loss: 0.7950%]\n",
            "6353 [Discriminator loss: 0.6702%, acc.: 62.50%] [Generator loss: 0.7981%]\n",
            "6354 [Discriminator loss: 0.6901%, acc.: 53.91%] [Generator loss: 0.7872%]\n",
            "6355 [Discriminator loss: 0.6788%, acc.: 56.25%] [Generator loss: 0.7914%]\n",
            "6356 [Discriminator loss: 0.6879%, acc.: 53.52%] [Generator loss: 0.7847%]\n",
            "6357 [Discriminator loss: 0.6525%, acc.: 62.89%] [Generator loss: 0.7854%]\n",
            "6358 [Discriminator loss: 0.6703%, acc.: 60.16%] [Generator loss: 0.7820%]\n",
            "6359 [Discriminator loss: 0.6776%, acc.: 57.42%] [Generator loss: 0.7756%]\n",
            "6360 [Discriminator loss: 0.6745%, acc.: 56.25%] [Generator loss: 0.7903%]\n",
            "6361 [Discriminator loss: 0.6714%, acc.: 58.20%] [Generator loss: 0.7714%]\n",
            "6362 [Discriminator loss: 0.6630%, acc.: 61.72%] [Generator loss: 0.7997%]\n",
            "6363 [Discriminator loss: 0.6846%, acc.: 54.30%] [Generator loss: 0.7793%]\n",
            "6364 [Discriminator loss: 0.6621%, acc.: 59.38%] [Generator loss: 0.7736%]\n",
            "6365 [Discriminator loss: 0.6742%, acc.: 54.30%] [Generator loss: 0.7725%]\n",
            "6366 [Discriminator loss: 0.6649%, acc.: 61.33%] [Generator loss: 0.7670%]\n",
            "6367 [Discriminator loss: 0.6858%, acc.: 54.30%] [Generator loss: 0.7821%]\n",
            "6368 [Discriminator loss: 0.6684%, acc.: 59.38%] [Generator loss: 0.7752%]\n",
            "6369 [Discriminator loss: 0.6689%, acc.: 58.59%] [Generator loss: 0.7856%]\n",
            "6370 [Discriminator loss: 0.6792%, acc.: 54.30%] [Generator loss: 0.7905%]\n",
            "6371 [Discriminator loss: 0.6598%, acc.: 62.50%] [Generator loss: 0.8025%]\n",
            "6372 [Discriminator loss: 0.6646%, acc.: 59.38%] [Generator loss: 0.7857%]\n",
            "6373 [Discriminator loss: 0.6785%, acc.: 55.47%] [Generator loss: 0.7810%]\n",
            "6374 [Discriminator loss: 0.6720%, acc.: 57.42%] [Generator loss: 0.8082%]\n",
            "6375 [Discriminator loss: 0.6727%, acc.: 59.77%] [Generator loss: 0.8003%]\n",
            "6376 [Discriminator loss: 0.6699%, acc.: 58.59%] [Generator loss: 0.7940%]\n",
            "6377 [Discriminator loss: 0.6726%, acc.: 58.20%] [Generator loss: 0.8178%]\n",
            "6378 [Discriminator loss: 0.6835%, acc.: 52.34%] [Generator loss: 0.8014%]\n",
            "6379 [Discriminator loss: 0.6738%, acc.: 57.42%] [Generator loss: 0.7811%]\n",
            "6380 [Discriminator loss: 0.6812%, acc.: 55.08%] [Generator loss: 0.7797%]\n",
            "6381 [Discriminator loss: 0.6743%, acc.: 55.08%] [Generator loss: 0.8050%]\n",
            "6382 [Discriminator loss: 0.6714%, acc.: 56.64%] [Generator loss: 0.7782%]\n",
            "6383 [Discriminator loss: 0.6859%, acc.: 56.25%] [Generator loss: 0.7633%]\n",
            "6384 [Discriminator loss: 0.6903%, acc.: 55.86%] [Generator loss: 0.7802%]\n",
            "6385 [Discriminator loss: 0.6833%, acc.: 54.69%] [Generator loss: 0.7779%]\n",
            "6386 [Discriminator loss: 0.6913%, acc.: 55.86%] [Generator loss: 0.7669%]\n",
            "6387 [Discriminator loss: 0.6651%, acc.: 58.98%] [Generator loss: 0.7859%]\n",
            "6388 [Discriminator loss: 0.6776%, acc.: 59.38%] [Generator loss: 0.7979%]\n",
            "6389 [Discriminator loss: 0.6964%, acc.: 53.91%] [Generator loss: 0.7680%]\n",
            "6390 [Discriminator loss: 0.6914%, acc.: 51.17%] [Generator loss: 0.7856%]\n",
            "6391 [Discriminator loss: 0.6974%, acc.: 50.00%] [Generator loss: 0.7873%]\n",
            "6392 [Discriminator loss: 0.6617%, acc.: 60.55%] [Generator loss: 0.7659%]\n",
            "6393 [Discriminator loss: 0.6767%, acc.: 56.64%] [Generator loss: 0.7725%]\n",
            "6394 [Discriminator loss: 0.6823%, acc.: 53.91%] [Generator loss: 0.7704%]\n",
            "6395 [Discriminator loss: 0.6742%, acc.: 58.20%] [Generator loss: 0.7610%]\n",
            "6396 [Discriminator loss: 0.6748%, acc.: 55.86%] [Generator loss: 0.7844%]\n",
            "6397 [Discriminator loss: 0.6720%, acc.: 57.42%] [Generator loss: 0.7783%]\n",
            "6398 [Discriminator loss: 0.6930%, acc.: 55.47%] [Generator loss: 0.7914%]\n",
            "6399 [Discriminator loss: 0.6877%, acc.: 50.00%] [Generator loss: 0.7970%]\n",
            "6400 [Discriminator loss: 0.6704%, acc.: 58.98%] [Generator loss: 0.7994%]\n",
            "6401 [Discriminator loss: 0.6930%, acc.: 54.69%] [Generator loss: 0.7786%]\n",
            "6402 [Discriminator loss: 0.6882%, acc.: 55.08%] [Generator loss: 0.7607%]\n",
            "6403 [Discriminator loss: 0.6824%, acc.: 59.38%] [Generator loss: 0.7951%]\n",
            "6404 [Discriminator loss: 0.6797%, acc.: 59.38%] [Generator loss: 0.7647%]\n",
            "6405 [Discriminator loss: 0.6895%, acc.: 52.73%] [Generator loss: 0.7775%]\n",
            "6406 [Discriminator loss: 0.6946%, acc.: 50.78%] [Generator loss: 0.8059%]\n",
            "6407 [Discriminator loss: 0.6733%, acc.: 56.64%] [Generator loss: 0.7886%]\n",
            "6408 [Discriminator loss: 0.6859%, acc.: 52.73%] [Generator loss: 0.7718%]\n",
            "6409 [Discriminator loss: 0.6816%, acc.: 55.86%] [Generator loss: 0.7484%]\n",
            "6410 [Discriminator loss: 0.6962%, acc.: 53.12%] [Generator loss: 0.7536%]\n",
            "6411 [Discriminator loss: 0.6893%, acc.: 53.91%] [Generator loss: 0.7736%]\n",
            "6412 [Discriminator loss: 0.6771%, acc.: 60.55%] [Generator loss: 0.7663%]\n",
            "6413 [Discriminator loss: 0.6741%, acc.: 55.08%] [Generator loss: 0.7725%]\n",
            "6414 [Discriminator loss: 0.6810%, acc.: 51.95%] [Generator loss: 0.7781%]\n",
            "6415 [Discriminator loss: 0.6772%, acc.: 57.42%] [Generator loss: 0.7596%]\n",
            "6416 [Discriminator loss: 0.6864%, acc.: 58.20%] [Generator loss: 0.7846%]\n",
            "6417 [Discriminator loss: 0.6732%, acc.: 57.42%] [Generator loss: 0.7653%]\n",
            "6418 [Discriminator loss: 0.6884%, acc.: 52.73%] [Generator loss: 0.7884%]\n",
            "6419 [Discriminator loss: 0.6687%, acc.: 58.20%] [Generator loss: 0.8090%]\n",
            "6420 [Discriminator loss: 0.6893%, acc.: 52.34%] [Generator loss: 0.8132%]\n",
            "6421 [Discriminator loss: 0.6862%, acc.: 52.73%] [Generator loss: 0.7930%]\n",
            "6422 [Discriminator loss: 0.6816%, acc.: 57.81%] [Generator loss: 0.7967%]\n",
            "6423 [Discriminator loss: 0.6671%, acc.: 61.72%] [Generator loss: 0.7923%]\n",
            "6424 [Discriminator loss: 0.6790%, acc.: 57.03%] [Generator loss: 0.7882%]\n",
            "6425 [Discriminator loss: 0.6793%, acc.: 55.86%] [Generator loss: 0.7714%]\n",
            "6426 [Discriminator loss: 0.6977%, acc.: 53.52%] [Generator loss: 0.7965%]\n",
            "6427 [Discriminator loss: 0.6756%, acc.: 57.81%] [Generator loss: 0.7966%]\n",
            "6428 [Discriminator loss: 0.6772%, acc.: 54.69%] [Generator loss: 0.8028%]\n",
            "6429 [Discriminator loss: 0.6679%, acc.: 58.59%] [Generator loss: 0.7971%]\n",
            "6430 [Discriminator loss: 0.6860%, acc.: 55.47%] [Generator loss: 0.7973%]\n",
            "6431 [Discriminator loss: 0.6790%, acc.: 56.64%] [Generator loss: 0.7697%]\n",
            "6432 [Discriminator loss: 0.6735%, acc.: 60.16%] [Generator loss: 0.7671%]\n",
            "6433 [Discriminator loss: 0.6728%, acc.: 58.98%] [Generator loss: 0.7851%]\n",
            "6434 [Discriminator loss: 0.6670%, acc.: 62.89%] [Generator loss: 0.7840%]\n",
            "6435 [Discriminator loss: 0.6917%, acc.: 51.56%] [Generator loss: 0.7720%]\n",
            "6436 [Discriminator loss: 0.6655%, acc.: 62.89%] [Generator loss: 0.7786%]\n",
            "6437 [Discriminator loss: 0.6707%, acc.: 57.81%] [Generator loss: 0.7690%]\n",
            "6438 [Discriminator loss: 0.6777%, acc.: 57.81%] [Generator loss: 0.7948%]\n",
            "6439 [Discriminator loss: 0.6675%, acc.: 55.86%] [Generator loss: 0.7870%]\n",
            "6440 [Discriminator loss: 0.6900%, acc.: 51.17%] [Generator loss: 0.7894%]\n",
            "6441 [Discriminator loss: 0.6861%, acc.: 55.47%] [Generator loss: 0.7700%]\n",
            "6442 [Discriminator loss: 0.6834%, acc.: 55.47%] [Generator loss: 0.7868%]\n",
            "6443 [Discriminator loss: 0.6859%, acc.: 54.30%] [Generator loss: 0.7978%]\n",
            "6444 [Discriminator loss: 0.6757%, acc.: 56.25%] [Generator loss: 0.8059%]\n",
            "6445 [Discriminator loss: 0.6670%, acc.: 60.55%] [Generator loss: 0.7967%]\n",
            "6446 [Discriminator loss: 0.6822%, acc.: 54.69%] [Generator loss: 0.7978%]\n",
            "6447 [Discriminator loss: 0.6865%, acc.: 55.08%] [Generator loss: 0.7874%]\n",
            "6448 [Discriminator loss: 0.6877%, acc.: 50.39%] [Generator loss: 0.7924%]\n",
            "6449 [Discriminator loss: 0.6962%, acc.: 47.66%] [Generator loss: 0.7846%]\n",
            "6450 [Discriminator loss: 0.6700%, acc.: 57.81%] [Generator loss: 0.7876%]\n",
            "6451 [Discriminator loss: 0.6890%, acc.: 53.91%] [Generator loss: 0.7617%]\n",
            "6452 [Discriminator loss: 0.6679%, acc.: 63.28%] [Generator loss: 0.7557%]\n",
            "6453 [Discriminator loss: 0.6804%, acc.: 55.47%] [Generator loss: 0.7710%]\n",
            "6454 [Discriminator loss: 0.6939%, acc.: 54.30%] [Generator loss: 0.7816%]\n",
            "6455 [Discriminator loss: 0.6683%, acc.: 60.94%] [Generator loss: 0.7782%]\n",
            "6456 [Discriminator loss: 0.6845%, acc.: 51.95%] [Generator loss: 0.7714%]\n",
            "6457 [Discriminator loss: 0.6870%, acc.: 55.47%] [Generator loss: 0.7743%]\n",
            "6458 [Discriminator loss: 0.6719%, acc.: 58.59%] [Generator loss: 0.7867%]\n",
            "6459 [Discriminator loss: 0.6722%, acc.: 56.25%] [Generator loss: 0.8081%]\n",
            "6460 [Discriminator loss: 0.6891%, acc.: 51.56%] [Generator loss: 0.7820%]\n",
            "6461 [Discriminator loss: 0.6710%, acc.: 56.25%] [Generator loss: 0.8022%]\n",
            "6462 [Discriminator loss: 0.6786%, acc.: 57.03%] [Generator loss: 0.7857%]\n",
            "6463 [Discriminator loss: 0.6814%, acc.: 54.30%] [Generator loss: 0.8138%]\n",
            "6464 [Discriminator loss: 0.6763%, acc.: 55.47%] [Generator loss: 0.7918%]\n",
            "6465 [Discriminator loss: 0.6905%, acc.: 55.08%] [Generator loss: 0.7976%]\n",
            "6466 [Discriminator loss: 0.6872%, acc.: 57.03%] [Generator loss: 0.8051%]\n",
            "6467 [Discriminator loss: 0.6949%, acc.: 52.73%] [Generator loss: 0.7966%]\n",
            "6468 [Discriminator loss: 0.6865%, acc.: 54.69%] [Generator loss: 0.7937%]\n",
            "6469 [Discriminator loss: 0.6777%, acc.: 54.69%] [Generator loss: 0.7924%]\n",
            "6470 [Discriminator loss: 0.6748%, acc.: 57.42%] [Generator loss: 0.7991%]\n",
            "6471 [Discriminator loss: 0.6742%, acc.: 59.38%] [Generator loss: 0.7976%]\n",
            "6472 [Discriminator loss: 0.6802%, acc.: 56.64%] [Generator loss: 0.7981%]\n",
            "6473 [Discriminator loss: 0.6719%, acc.: 55.86%] [Generator loss: 0.7844%]\n",
            "6474 [Discriminator loss: 0.6855%, acc.: 55.86%] [Generator loss: 0.7810%]\n",
            "6475 [Discriminator loss: 0.6797%, acc.: 56.25%] [Generator loss: 0.7698%]\n",
            "6476 [Discriminator loss: 0.6784%, acc.: 57.03%] [Generator loss: 0.7548%]\n",
            "6477 [Discriminator loss: 0.6669%, acc.: 58.59%] [Generator loss: 0.7618%]\n",
            "6478 [Discriminator loss: 0.6862%, acc.: 49.22%] [Generator loss: 0.7698%]\n",
            "6479 [Discriminator loss: 0.6778%, acc.: 53.91%] [Generator loss: 0.7933%]\n",
            "6480 [Discriminator loss: 0.6748%, acc.: 58.59%] [Generator loss: 0.7743%]\n",
            "6481 [Discriminator loss: 0.6783%, acc.: 58.20%] [Generator loss: 0.7608%]\n",
            "6482 [Discriminator loss: 0.6775%, acc.: 54.30%] [Generator loss: 0.7781%]\n",
            "6483 [Discriminator loss: 0.6773%, acc.: 52.73%] [Generator loss: 0.7804%]\n",
            "6484 [Discriminator loss: 0.6847%, acc.: 57.03%] [Generator loss: 0.7518%]\n",
            "6485 [Discriminator loss: 0.6654%, acc.: 58.98%] [Generator loss: 0.7895%]\n",
            "6486 [Discriminator loss: 0.6907%, acc.: 52.73%] [Generator loss: 0.7816%]\n",
            "6487 [Discriminator loss: 0.6715%, acc.: 55.47%] [Generator loss: 0.7892%]\n",
            "6488 [Discriminator loss: 0.6808%, acc.: 54.69%] [Generator loss: 0.7979%]\n",
            "6489 [Discriminator loss: 0.6660%, acc.: 60.94%] [Generator loss: 0.8080%]\n",
            "6490 [Discriminator loss: 0.6855%, acc.: 56.25%] [Generator loss: 0.7989%]\n",
            "6491 [Discriminator loss: 0.6875%, acc.: 56.64%] [Generator loss: 0.8013%]\n",
            "6492 [Discriminator loss: 0.6711%, acc.: 62.89%] [Generator loss: 0.8063%]\n",
            "6493 [Discriminator loss: 0.6742%, acc.: 62.11%] [Generator loss: 0.8007%]\n",
            "6494 [Discriminator loss: 0.6801%, acc.: 56.64%] [Generator loss: 0.7849%]\n",
            "6495 [Discriminator loss: 0.6927%, acc.: 51.95%] [Generator loss: 0.7984%]\n",
            "6496 [Discriminator loss: 0.6846%, acc.: 58.98%] [Generator loss: 0.7858%]\n",
            "6497 [Discriminator loss: 0.6984%, acc.: 52.34%] [Generator loss: 0.7871%]\n",
            "6498 [Discriminator loss: 0.6662%, acc.: 62.50%] [Generator loss: 0.7795%]\n",
            "6499 [Discriminator loss: 0.6723%, acc.: 57.42%] [Generator loss: 0.7916%]\n",
            "6500 [Discriminator loss: 0.6675%, acc.: 64.06%] [Generator loss: 0.8019%]\n",
            "6501 [Discriminator loss: 0.6783%, acc.: 55.47%] [Generator loss: 0.7891%]\n",
            "6502 [Discriminator loss: 0.6665%, acc.: 60.16%] [Generator loss: 0.7704%]\n",
            "6503 [Discriminator loss: 0.6709%, acc.: 62.11%] [Generator loss: 0.8044%]\n",
            "6504 [Discriminator loss: 0.6817%, acc.: 59.38%] [Generator loss: 0.7961%]\n",
            "6505 [Discriminator loss: 0.6881%, acc.: 52.73%] [Generator loss: 0.7930%]\n",
            "6506 [Discriminator loss: 0.6714%, acc.: 59.77%] [Generator loss: 0.8079%]\n",
            "6507 [Discriminator loss: 0.6680%, acc.: 59.38%] [Generator loss: 0.7857%]\n",
            "6508 [Discriminator loss: 0.6497%, acc.: 67.97%] [Generator loss: 0.7738%]\n",
            "6509 [Discriminator loss: 0.6575%, acc.: 61.72%] [Generator loss: 0.7810%]\n",
            "6510 [Discriminator loss: 0.6641%, acc.: 62.11%] [Generator loss: 0.7950%]\n",
            "6511 [Discriminator loss: 0.6735%, acc.: 58.20%] [Generator loss: 0.7769%]\n",
            "6512 [Discriminator loss: 0.6624%, acc.: 60.94%] [Generator loss: 0.7785%]\n",
            "6513 [Discriminator loss: 0.6671%, acc.: 58.98%] [Generator loss: 0.7920%]\n",
            "6514 [Discriminator loss: 0.6828%, acc.: 52.73%] [Generator loss: 0.7718%]\n",
            "6515 [Discriminator loss: 0.6573%, acc.: 60.16%] [Generator loss: 0.7984%]\n",
            "6516 [Discriminator loss: 0.6653%, acc.: 59.77%] [Generator loss: 0.7941%]\n",
            "6517 [Discriminator loss: 0.6533%, acc.: 61.72%] [Generator loss: 0.7889%]\n",
            "6518 [Discriminator loss: 0.6720%, acc.: 57.03%] [Generator loss: 0.7951%]\n",
            "6519 [Discriminator loss: 0.6761%, acc.: 56.64%] [Generator loss: 0.8021%]\n",
            "6520 [Discriminator loss: 0.6654%, acc.: 60.16%] [Generator loss: 0.8063%]\n",
            "6521 [Discriminator loss: 0.6834%, acc.: 57.42%] [Generator loss: 0.8008%]\n",
            "6522 [Discriminator loss: 0.6687%, acc.: 62.50%] [Generator loss: 0.7859%]\n",
            "6523 [Discriminator loss: 0.6757%, acc.: 58.98%] [Generator loss: 0.8019%]\n",
            "6524 [Discriminator loss: 0.6664%, acc.: 60.16%] [Generator loss: 0.7854%]\n",
            "6525 [Discriminator loss: 0.6577%, acc.: 61.33%] [Generator loss: 0.7875%]\n",
            "6526 [Discriminator loss: 0.6513%, acc.: 63.28%] [Generator loss: 0.7879%]\n",
            "6527 [Discriminator loss: 0.6529%, acc.: 63.28%] [Generator loss: 0.7812%]\n",
            "6528 [Discriminator loss: 0.6442%, acc.: 63.67%] [Generator loss: 0.7969%]\n",
            "6529 [Discriminator loss: 0.6518%, acc.: 62.50%] [Generator loss: 0.7775%]\n",
            "6530 [Discriminator loss: 0.6740%, acc.: 53.12%] [Generator loss: 0.7789%]\n",
            "6531 [Discriminator loss: 0.6706%, acc.: 56.64%] [Generator loss: 0.7963%]\n",
            "6532 [Discriminator loss: 0.6632%, acc.: 55.86%] [Generator loss: 0.7875%]\n",
            "6533 [Discriminator loss: 0.6629%, acc.: 57.42%] [Generator loss: 0.7985%]\n",
            "6534 [Discriminator loss: 0.6682%, acc.: 57.42%] [Generator loss: 0.8142%]\n",
            "6535 [Discriminator loss: 0.6763%, acc.: 57.81%] [Generator loss: 0.7889%]\n",
            "6536 [Discriminator loss: 0.6607%, acc.: 60.94%] [Generator loss: 0.8087%]\n",
            "6537 [Discriminator loss: 0.6631%, acc.: 60.16%] [Generator loss: 0.7910%]\n",
            "6538 [Discriminator loss: 0.6516%, acc.: 62.11%] [Generator loss: 0.7839%]\n",
            "6539 [Discriminator loss: 0.6795%, acc.: 57.42%] [Generator loss: 0.7784%]\n",
            "6540 [Discriminator loss: 0.6743%, acc.: 53.91%] [Generator loss: 0.7876%]\n",
            "6541 [Discriminator loss: 0.6748%, acc.: 55.86%] [Generator loss: 0.7896%]\n",
            "6542 [Discriminator loss: 0.6667%, acc.: 61.33%] [Generator loss: 0.7914%]\n",
            "6543 [Discriminator loss: 0.6596%, acc.: 62.89%] [Generator loss: 0.7767%]\n",
            "6544 [Discriminator loss: 0.6625%, acc.: 57.81%] [Generator loss: 0.7761%]\n",
            "6545 [Discriminator loss: 0.6750%, acc.: 62.11%] [Generator loss: 0.7873%]\n",
            "6546 [Discriminator loss: 0.6737%, acc.: 57.81%] [Generator loss: 0.7824%]\n",
            "6547 [Discriminator loss: 0.6773%, acc.: 56.64%] [Generator loss: 0.7875%]\n",
            "6548 [Discriminator loss: 0.6595%, acc.: 63.28%] [Generator loss: 0.7727%]\n",
            "6549 [Discriminator loss: 0.6673%, acc.: 60.16%] [Generator loss: 0.7919%]\n",
            "6550 [Discriminator loss: 0.6862%, acc.: 57.03%] [Generator loss: 0.8090%]\n",
            "6551 [Discriminator loss: 0.6833%, acc.: 59.38%] [Generator loss: 0.7971%]\n",
            "6552 [Discriminator loss: 0.6655%, acc.: 59.38%] [Generator loss: 0.7936%]\n",
            "6553 [Discriminator loss: 0.6751%, acc.: 57.42%] [Generator loss: 0.7908%]\n",
            "6554 [Discriminator loss: 0.6736%, acc.: 60.55%] [Generator loss: 0.7931%]\n",
            "6555 [Discriminator loss: 0.6841%, acc.: 57.03%] [Generator loss: 0.8023%]\n",
            "6556 [Discriminator loss: 0.6889%, acc.: 51.95%] [Generator loss: 0.7628%]\n",
            "6557 [Discriminator loss: 0.6598%, acc.: 63.67%] [Generator loss: 0.7874%]\n",
            "6558 [Discriminator loss: 0.6724%, acc.: 60.16%] [Generator loss: 0.7752%]\n",
            "6559 [Discriminator loss: 0.6840%, acc.: 55.86%] [Generator loss: 0.7780%]\n",
            "6560 [Discriminator loss: 0.6719%, acc.: 53.91%] [Generator loss: 0.7776%]\n",
            "6561 [Discriminator loss: 0.6674%, acc.: 56.25%] [Generator loss: 0.7937%]\n",
            "6562 [Discriminator loss: 0.6713%, acc.: 57.03%] [Generator loss: 0.8083%]\n",
            "6563 [Discriminator loss: 0.6835%, acc.: 54.69%] [Generator loss: 0.8041%]\n",
            "6564 [Discriminator loss: 0.6937%, acc.: 50.00%] [Generator loss: 0.7652%]\n",
            "6565 [Discriminator loss: 0.6749%, acc.: 57.03%] [Generator loss: 0.7609%]\n",
            "6566 [Discriminator loss: 0.6713%, acc.: 58.59%] [Generator loss: 0.7723%]\n",
            "6567 [Discriminator loss: 0.6806%, acc.: 57.42%] [Generator loss: 0.7813%]\n",
            "6568 [Discriminator loss: 0.6772%, acc.: 52.34%] [Generator loss: 0.7916%]\n",
            "6569 [Discriminator loss: 0.7021%, acc.: 50.78%] [Generator loss: 0.7677%]\n",
            "6570 [Discriminator loss: 0.6795%, acc.: 54.30%] [Generator loss: 0.7521%]\n",
            "6571 [Discriminator loss: 0.6761%, acc.: 57.81%] [Generator loss: 0.7698%]\n",
            "6572 [Discriminator loss: 0.6715%, acc.: 56.64%] [Generator loss: 0.7756%]\n",
            "6573 [Discriminator loss: 0.6804%, acc.: 55.47%] [Generator loss: 0.7599%]\n",
            "6574 [Discriminator loss: 0.6873%, acc.: 54.69%] [Generator loss: 0.7656%]\n",
            "6575 [Discriminator loss: 0.6801%, acc.: 55.08%] [Generator loss: 0.7623%]\n",
            "6576 [Discriminator loss: 0.6735%, acc.: 56.64%] [Generator loss: 0.7888%]\n",
            "6577 [Discriminator loss: 0.6914%, acc.: 52.73%] [Generator loss: 0.7791%]\n",
            "6578 [Discriminator loss: 0.6895%, acc.: 53.12%] [Generator loss: 0.7844%]\n",
            "6579 [Discriminator loss: 0.6842%, acc.: 55.47%] [Generator loss: 0.7893%]\n",
            "6580 [Discriminator loss: 0.6895%, acc.: 56.25%] [Generator loss: 0.7769%]\n",
            "6581 [Discriminator loss: 0.6722%, acc.: 57.81%] [Generator loss: 0.7989%]\n",
            "6582 [Discriminator loss: 0.6738%, acc.: 60.94%] [Generator loss: 0.8061%]\n",
            "6583 [Discriminator loss: 0.6759%, acc.: 55.86%] [Generator loss: 0.7779%]\n",
            "6584 [Discriminator loss: 0.6674%, acc.: 61.33%] [Generator loss: 0.7936%]\n",
            "6585 [Discriminator loss: 0.6747%, acc.: 60.55%] [Generator loss: 0.8014%]\n",
            "6586 [Discriminator loss: 0.6713%, acc.: 61.72%] [Generator loss: 0.7747%]\n",
            "6587 [Discriminator loss: 0.6786%, acc.: 55.86%] [Generator loss: 0.7691%]\n",
            "6588 [Discriminator loss: 0.6981%, acc.: 53.91%] [Generator loss: 0.7517%]\n",
            "6589 [Discriminator loss: 0.6850%, acc.: 57.03%] [Generator loss: 0.7514%]\n",
            "6590 [Discriminator loss: 0.6753%, acc.: 58.59%] [Generator loss: 0.7781%]\n",
            "6591 [Discriminator loss: 0.6840%, acc.: 55.47%] [Generator loss: 0.8012%]\n",
            "6592 [Discriminator loss: 0.6802%, acc.: 56.25%] [Generator loss: 0.8001%]\n",
            "6593 [Discriminator loss: 0.6870%, acc.: 54.30%] [Generator loss: 0.7816%]\n",
            "6594 [Discriminator loss: 0.6879%, acc.: 52.34%] [Generator loss: 0.7895%]\n",
            "6595 [Discriminator loss: 0.6985%, acc.: 52.73%] [Generator loss: 0.7934%]\n",
            "6596 [Discriminator loss: 0.6875%, acc.: 54.69%] [Generator loss: 0.7921%]\n",
            "6597 [Discriminator loss: 0.6828%, acc.: 52.73%] [Generator loss: 0.7675%]\n",
            "6598 [Discriminator loss: 0.6947%, acc.: 50.78%] [Generator loss: 0.7804%]\n",
            "6599 [Discriminator loss: 0.6784%, acc.: 57.42%] [Generator loss: 0.7783%]\n",
            "6600 [Discriminator loss: 0.6625%, acc.: 55.08%] [Generator loss: 0.7943%]\n",
            "6601 [Discriminator loss: 0.6547%, acc.: 61.33%] [Generator loss: 0.7972%]\n",
            "6602 [Discriminator loss: 0.6826%, acc.: 58.20%] [Generator loss: 0.7836%]\n",
            "6603 [Discriminator loss: 0.6956%, acc.: 51.95%] [Generator loss: 0.7693%]\n",
            "6604 [Discriminator loss: 0.6801%, acc.: 54.30%] [Generator loss: 0.7752%]\n",
            "6605 [Discriminator loss: 0.6618%, acc.: 63.28%] [Generator loss: 0.7883%]\n",
            "6606 [Discriminator loss: 0.6760%, acc.: 57.81%] [Generator loss: 0.7604%]\n",
            "6607 [Discriminator loss: 0.6736%, acc.: 60.55%] [Generator loss: 0.7784%]\n",
            "6608 [Discriminator loss: 0.6840%, acc.: 57.42%] [Generator loss: 0.7665%]\n",
            "6609 [Discriminator loss: 0.6837%, acc.: 57.81%] [Generator loss: 0.7921%]\n",
            "6610 [Discriminator loss: 0.6879%, acc.: 54.69%] [Generator loss: 0.7894%]\n",
            "6611 [Discriminator loss: 0.6763%, acc.: 53.91%] [Generator loss: 0.7696%]\n",
            "6612 [Discriminator loss: 0.6820%, acc.: 55.86%] [Generator loss: 0.7872%]\n",
            "6613 [Discriminator loss: 0.6783%, acc.: 55.08%] [Generator loss: 0.7834%]\n",
            "6614 [Discriminator loss: 0.6673%, acc.: 57.81%] [Generator loss: 0.7664%]\n",
            "6615 [Discriminator loss: 0.6852%, acc.: 58.20%] [Generator loss: 0.7654%]\n",
            "6616 [Discriminator loss: 0.6844%, acc.: 52.73%] [Generator loss: 0.7729%]\n",
            "6617 [Discriminator loss: 0.6761%, acc.: 56.25%] [Generator loss: 0.7844%]\n",
            "6618 [Discriminator loss: 0.6827%, acc.: 54.69%] [Generator loss: 0.7602%]\n",
            "6619 [Discriminator loss: 0.6822%, acc.: 56.64%] [Generator loss: 0.7790%]\n",
            "6620 [Discriminator loss: 0.6849%, acc.: 57.42%] [Generator loss: 0.7733%]\n",
            "6621 [Discriminator loss: 0.6718%, acc.: 60.55%] [Generator loss: 0.7789%]\n",
            "6622 [Discriminator loss: 0.6883%, acc.: 54.30%] [Generator loss: 0.7825%]\n",
            "6623 [Discriminator loss: 0.6840%, acc.: 56.64%] [Generator loss: 0.7859%]\n",
            "6624 [Discriminator loss: 0.6761%, acc.: 57.42%] [Generator loss: 0.7774%]\n",
            "6625 [Discriminator loss: 0.6888%, acc.: 57.03%] [Generator loss: 0.7746%]\n",
            "6626 [Discriminator loss: 0.6893%, acc.: 53.91%] [Generator loss: 0.7920%]\n",
            "6627 [Discriminator loss: 0.6854%, acc.: 56.25%] [Generator loss: 0.7975%]\n",
            "6628 [Discriminator loss: 0.6790%, acc.: 59.77%] [Generator loss: 0.7844%]\n",
            "6629 [Discriminator loss: 0.6903%, acc.: 54.30%] [Generator loss: 0.7829%]\n",
            "6630 [Discriminator loss: 0.6864%, acc.: 55.47%] [Generator loss: 0.7840%]\n",
            "6631 [Discriminator loss: 0.6800%, acc.: 59.38%] [Generator loss: 0.7838%]\n",
            "6632 [Discriminator loss: 0.6927%, acc.: 54.30%] [Generator loss: 0.7966%]\n",
            "6633 [Discriminator loss: 0.6898%, acc.: 57.42%] [Generator loss: 0.7817%]\n",
            "6634 [Discriminator loss: 0.6997%, acc.: 51.95%] [Generator loss: 0.7918%]\n",
            "6635 [Discriminator loss: 0.6603%, acc.: 60.94%] [Generator loss: 0.7883%]\n",
            "6636 [Discriminator loss: 0.6751%, acc.: 54.69%] [Generator loss: 0.7871%]\n",
            "6637 [Discriminator loss: 0.6814%, acc.: 56.64%] [Generator loss: 0.7925%]\n",
            "6638 [Discriminator loss: 0.6630%, acc.: 60.16%] [Generator loss: 0.7846%]\n",
            "6639 [Discriminator loss: 0.6779%, acc.: 56.25%] [Generator loss: 0.7821%]\n",
            "6640 [Discriminator loss: 0.6633%, acc.: 62.50%] [Generator loss: 0.7953%]\n",
            "6641 [Discriminator loss: 0.6808%, acc.: 58.98%] [Generator loss: 0.7765%]\n",
            "6642 [Discriminator loss: 0.6683%, acc.: 57.03%] [Generator loss: 0.7823%]\n",
            "6643 [Discriminator loss: 0.6755%, acc.: 58.20%] [Generator loss: 0.7810%]\n",
            "6644 [Discriminator loss: 0.6752%, acc.: 57.42%] [Generator loss: 0.7597%]\n",
            "6645 [Discriminator loss: 0.7037%, acc.: 53.52%] [Generator loss: 0.7614%]\n",
            "6646 [Discriminator loss: 0.6762%, acc.: 55.08%] [Generator loss: 0.7690%]\n",
            "6647 [Discriminator loss: 0.6738%, acc.: 54.30%] [Generator loss: 0.7838%]\n",
            "6648 [Discriminator loss: 0.6862%, acc.: 54.69%] [Generator loss: 0.7812%]\n",
            "6649 [Discriminator loss: 0.6759%, acc.: 53.52%] [Generator loss: 0.7864%]\n",
            "6650 [Discriminator loss: 0.6819%, acc.: 56.25%] [Generator loss: 0.7825%]\n",
            "6651 [Discriminator loss: 0.6783%, acc.: 52.34%] [Generator loss: 0.7734%]\n",
            "6652 [Discriminator loss: 0.6728%, acc.: 56.25%] [Generator loss: 0.7959%]\n",
            "6653 [Discriminator loss: 0.6802%, acc.: 55.08%] [Generator loss: 0.7867%]\n",
            "6654 [Discriminator loss: 0.6725%, acc.: 58.20%] [Generator loss: 0.7632%]\n",
            "6655 [Discriminator loss: 0.6710%, acc.: 57.42%] [Generator loss: 0.7758%]\n",
            "6656 [Discriminator loss: 0.6779%, acc.: 55.47%] [Generator loss: 0.7925%]\n",
            "6657 [Discriminator loss: 0.6850%, acc.: 55.86%] [Generator loss: 0.7925%]\n",
            "6658 [Discriminator loss: 0.6682%, acc.: 60.16%] [Generator loss: 0.7885%]\n",
            "6659 [Discriminator loss: 0.6917%, acc.: 51.56%] [Generator loss: 0.7940%]\n",
            "6660 [Discriminator loss: 0.6731%, acc.: 56.64%] [Generator loss: 0.7882%]\n",
            "6661 [Discriminator loss: 0.6603%, acc.: 63.28%] [Generator loss: 0.7604%]\n",
            "6662 [Discriminator loss: 0.6663%, acc.: 60.16%] [Generator loss: 0.7596%]\n",
            "6663 [Discriminator loss: 0.6821%, acc.: 52.34%] [Generator loss: 0.7846%]\n",
            "6664 [Discriminator loss: 0.6636%, acc.: 61.72%] [Generator loss: 0.7682%]\n",
            "6665 [Discriminator loss: 0.6769%, acc.: 57.42%] [Generator loss: 0.7866%]\n",
            "6666 [Discriminator loss: 0.6743%, acc.: 58.20%] [Generator loss: 0.7916%]\n",
            "6667 [Discriminator loss: 0.6561%, acc.: 63.67%] [Generator loss: 0.7850%]\n",
            "6668 [Discriminator loss: 0.6645%, acc.: 60.55%] [Generator loss: 0.7971%]\n",
            "6669 [Discriminator loss: 0.6488%, acc.: 69.53%] [Generator loss: 0.7943%]\n",
            "6670 [Discriminator loss: 0.6471%, acc.: 67.19%] [Generator loss: 0.7785%]\n",
            "6671 [Discriminator loss: 0.6689%, acc.: 59.77%] [Generator loss: 0.7738%]\n",
            "6672 [Discriminator loss: 0.6829%, acc.: 54.69%] [Generator loss: 0.7647%]\n",
            "6673 [Discriminator loss: 0.6776%, acc.: 57.03%] [Generator loss: 0.7710%]\n",
            "6674 [Discriminator loss: 0.6690%, acc.: 58.20%] [Generator loss: 0.7668%]\n",
            "6675 [Discriminator loss: 0.6555%, acc.: 59.77%] [Generator loss: 0.7938%]\n",
            "6676 [Discriminator loss: 0.6722%, acc.: 57.81%] [Generator loss: 0.7874%]\n",
            "6677 [Discriminator loss: 0.6480%, acc.: 62.11%] [Generator loss: 0.7949%]\n",
            "6678 [Discriminator loss: 0.6587%, acc.: 60.16%] [Generator loss: 0.7783%]\n",
            "6679 [Discriminator loss: 0.6586%, acc.: 62.11%] [Generator loss: 0.7813%]\n",
            "6680 [Discriminator loss: 0.6733%, acc.: 60.16%] [Generator loss: 0.7930%]\n",
            "6681 [Discriminator loss: 0.6739%, acc.: 53.52%] [Generator loss: 0.7986%]\n",
            "6682 [Discriminator loss: 0.6690%, acc.: 59.38%] [Generator loss: 0.7816%]\n",
            "6683 [Discriminator loss: 0.6678%, acc.: 60.16%] [Generator loss: 0.8053%]\n",
            "6684 [Discriminator loss: 0.6607%, acc.: 64.45%] [Generator loss: 0.7966%]\n",
            "6685 [Discriminator loss: 0.6802%, acc.: 58.20%] [Generator loss: 0.8083%]\n",
            "6686 [Discriminator loss: 0.6807%, acc.: 56.64%] [Generator loss: 0.7780%]\n",
            "6687 [Discriminator loss: 0.6658%, acc.: 58.98%] [Generator loss: 0.7837%]\n",
            "6688 [Discriminator loss: 0.6805%, acc.: 56.64%] [Generator loss: 0.7759%]\n",
            "6689 [Discriminator loss: 0.6650%, acc.: 63.67%] [Generator loss: 0.7974%]\n",
            "6690 [Discriminator loss: 0.6729%, acc.: 58.59%] [Generator loss: 0.7872%]\n",
            "6691 [Discriminator loss: 0.6745%, acc.: 55.86%] [Generator loss: 0.7813%]\n",
            "6692 [Discriminator loss: 0.6624%, acc.: 62.50%] [Generator loss: 0.8096%]\n",
            "6693 [Discriminator loss: 0.6723%, acc.: 60.16%] [Generator loss: 0.7866%]\n",
            "6694 [Discriminator loss: 0.6726%, acc.: 58.59%] [Generator loss: 0.8295%]\n",
            "6695 [Discriminator loss: 0.6578%, acc.: 61.72%] [Generator loss: 0.8152%]\n",
            "6696 [Discriminator loss: 0.6660%, acc.: 60.94%] [Generator loss: 0.7802%]\n",
            "6697 [Discriminator loss: 0.6653%, acc.: 60.55%] [Generator loss: 0.7639%]\n",
            "6698 [Discriminator loss: 0.6816%, acc.: 52.73%] [Generator loss: 0.7574%]\n",
            "6699 [Discriminator loss: 0.6750%, acc.: 57.81%] [Generator loss: 0.7679%]\n",
            "6700 [Discriminator loss: 0.6836%, acc.: 51.17%] [Generator loss: 0.7800%]\n",
            "6701 [Discriminator loss: 0.6735%, acc.: 57.42%] [Generator loss: 0.7711%]\n",
            "6702 [Discriminator loss: 0.6758%, acc.: 57.81%] [Generator loss: 0.7944%]\n",
            "6703 [Discriminator loss: 0.6713%, acc.: 60.55%] [Generator loss: 0.8002%]\n",
            "6704 [Discriminator loss: 0.6758%, acc.: 62.11%] [Generator loss: 0.7901%]\n",
            "6705 [Discriminator loss: 0.6781%, acc.: 58.59%] [Generator loss: 0.7970%]\n",
            "6706 [Discriminator loss: 0.6566%, acc.: 64.45%] [Generator loss: 0.8094%]\n",
            "6707 [Discriminator loss: 0.6655%, acc.: 63.28%] [Generator loss: 0.8084%]\n",
            "6708 [Discriminator loss: 0.6668%, acc.: 62.89%] [Generator loss: 0.7719%]\n",
            "6709 [Discriminator loss: 0.6733%, acc.: 57.81%] [Generator loss: 0.7772%]\n",
            "6710 [Discriminator loss: 0.6837%, acc.: 57.81%] [Generator loss: 0.7915%]\n",
            "6711 [Discriminator loss: 0.6659%, acc.: 59.77%] [Generator loss: 0.7804%]\n",
            "6712 [Discriminator loss: 0.6554%, acc.: 65.23%] [Generator loss: 0.7750%]\n",
            "6713 [Discriminator loss: 0.6799%, acc.: 57.03%] [Generator loss: 0.7895%]\n",
            "6714 [Discriminator loss: 0.6679%, acc.: 62.89%] [Generator loss: 0.7951%]\n",
            "6715 [Discriminator loss: 0.6628%, acc.: 63.28%] [Generator loss: 0.7814%]\n",
            "6716 [Discriminator loss: 0.6778%, acc.: 58.98%] [Generator loss: 0.7884%]\n",
            "6717 [Discriminator loss: 0.6641%, acc.: 62.11%] [Generator loss: 0.7687%]\n",
            "6718 [Discriminator loss: 0.6726%, acc.: 57.81%] [Generator loss: 0.7802%]\n",
            "6719 [Discriminator loss: 0.6643%, acc.: 63.67%] [Generator loss: 0.7776%]\n",
            "6720 [Discriminator loss: 0.6675%, acc.: 59.77%] [Generator loss: 0.7573%]\n",
            "6721 [Discriminator loss: 0.6581%, acc.: 64.45%] [Generator loss: 0.7800%]\n",
            "6722 [Discriminator loss: 0.6640%, acc.: 62.50%] [Generator loss: 0.7691%]\n",
            "6723 [Discriminator loss: 0.6741%, acc.: 56.64%] [Generator loss: 0.7651%]\n",
            "6724 [Discriminator loss: 0.6778%, acc.: 57.03%] [Generator loss: 0.7738%]\n",
            "6725 [Discriminator loss: 0.6870%, acc.: 52.34%] [Generator loss: 0.7797%]\n",
            "6726 [Discriminator loss: 0.6797%, acc.: 57.03%] [Generator loss: 0.7883%]\n",
            "6727 [Discriminator loss: 0.6860%, acc.: 55.47%] [Generator loss: 0.7612%]\n",
            "6728 [Discriminator loss: 0.6767%, acc.: 58.98%] [Generator loss: 0.7651%]\n",
            "6729 [Discriminator loss: 0.6948%, acc.: 52.73%] [Generator loss: 0.7559%]\n",
            "6730 [Discriminator loss: 0.6558%, acc.: 62.11%] [Generator loss: 0.7768%]\n",
            "6731 [Discriminator loss: 0.6778%, acc.: 58.20%] [Generator loss: 0.7625%]\n",
            "6732 [Discriminator loss: 0.6720%, acc.: 59.77%] [Generator loss: 0.7590%]\n",
            "6733 [Discriminator loss: 0.6734%, acc.: 60.55%] [Generator loss: 0.8112%]\n",
            "6734 [Discriminator loss: 0.6651%, acc.: 61.72%] [Generator loss: 0.7618%]\n",
            "6735 [Discriminator loss: 0.6759%, acc.: 57.42%] [Generator loss: 0.7842%]\n",
            "6736 [Discriminator loss: 0.6717%, acc.: 58.20%] [Generator loss: 0.7909%]\n",
            "6737 [Discriminator loss: 0.6744%, acc.: 60.16%] [Generator loss: 0.7737%]\n",
            "6738 [Discriminator loss: 0.6690%, acc.: 57.81%] [Generator loss: 0.7729%]\n",
            "6739 [Discriminator loss: 0.6676%, acc.: 58.20%] [Generator loss: 0.7890%]\n",
            "6740 [Discriminator loss: 0.6820%, acc.: 57.42%] [Generator loss: 0.7780%]\n",
            "6741 [Discriminator loss: 0.6755%, acc.: 57.03%] [Generator loss: 0.7696%]\n",
            "6742 [Discriminator loss: 0.6781%, acc.: 54.69%] [Generator loss: 0.7919%]\n",
            "6743 [Discriminator loss: 0.6781%, acc.: 56.64%] [Generator loss: 0.7830%]\n",
            "6744 [Discriminator loss: 0.6851%, acc.: 53.91%] [Generator loss: 0.8000%]\n",
            "6745 [Discriminator loss: 0.6773%, acc.: 56.25%] [Generator loss: 0.7670%]\n",
            "6746 [Discriminator loss: 0.6846%, acc.: 54.30%] [Generator loss: 0.7995%]\n",
            "6747 [Discriminator loss: 0.6952%, acc.: 53.12%] [Generator loss: 0.7918%]\n",
            "6748 [Discriminator loss: 0.6810%, acc.: 55.08%] [Generator loss: 0.7893%]\n",
            "6749 [Discriminator loss: 0.6781%, acc.: 55.86%] [Generator loss: 0.7749%]\n",
            "6750 [Discriminator loss: 0.6910%, acc.: 51.56%] [Generator loss: 0.7765%]\n",
            "6751 [Discriminator loss: 0.6762%, acc.: 58.20%] [Generator loss: 0.7684%]\n",
            "6752 [Discriminator loss: 0.6769%, acc.: 55.08%] [Generator loss: 0.7857%]\n",
            "6753 [Discriminator loss: 0.6820%, acc.: 57.03%] [Generator loss: 0.7782%]\n",
            "6754 [Discriminator loss: 0.6797%, acc.: 55.47%] [Generator loss: 0.7568%]\n",
            "6755 [Discriminator loss: 0.6941%, acc.: 49.61%] [Generator loss: 0.7790%]\n",
            "6756 [Discriminator loss: 0.6815%, acc.: 55.86%] [Generator loss: 0.8014%]\n",
            "6757 [Discriminator loss: 0.6664%, acc.: 60.94%] [Generator loss: 0.7823%]\n",
            "6758 [Discriminator loss: 0.6896%, acc.: 50.39%] [Generator loss: 0.7731%]\n",
            "6759 [Discriminator loss: 0.6718%, acc.: 57.03%] [Generator loss: 0.7586%]\n",
            "6760 [Discriminator loss: 0.6731%, acc.: 56.25%] [Generator loss: 0.7727%]\n",
            "6761 [Discriminator loss: 0.6942%, acc.: 51.95%] [Generator loss: 0.7723%]\n",
            "6762 [Discriminator loss: 0.6705%, acc.: 59.38%] [Generator loss: 0.7800%]\n",
            "6763 [Discriminator loss: 0.6836%, acc.: 54.30%] [Generator loss: 0.7966%]\n",
            "6764 [Discriminator loss: 0.6702%, acc.: 56.64%] [Generator loss: 0.7809%]\n",
            "6765 [Discriminator loss: 0.6783%, acc.: 53.91%] [Generator loss: 0.7820%]\n",
            "6766 [Discriminator loss: 0.6676%, acc.: 60.55%] [Generator loss: 0.7546%]\n",
            "6767 [Discriminator loss: 0.6740%, acc.: 57.81%] [Generator loss: 0.7740%]\n",
            "6768 [Discriminator loss: 0.6916%, acc.: 53.12%] [Generator loss: 0.7782%]\n",
            "6769 [Discriminator loss: 0.6809%, acc.: 57.81%] [Generator loss: 0.7772%]\n",
            "6770 [Discriminator loss: 0.6701%, acc.: 60.94%] [Generator loss: 0.7695%]\n",
            "6771 [Discriminator loss: 0.6795%, acc.: 57.42%] [Generator loss: 0.7791%]\n",
            "6772 [Discriminator loss: 0.6793%, acc.: 57.42%] [Generator loss: 0.7590%]\n",
            "6773 [Discriminator loss: 0.6937%, acc.: 53.52%] [Generator loss: 0.7636%]\n",
            "6774 [Discriminator loss: 0.6773%, acc.: 56.64%] [Generator loss: 0.7693%]\n",
            "6775 [Discriminator loss: 0.6846%, acc.: 55.47%] [Generator loss: 0.7817%]\n",
            "6776 [Discriminator loss: 0.6816%, acc.: 53.52%] [Generator loss: 0.7688%]\n",
            "6777 [Discriminator loss: 0.6848%, acc.: 54.30%] [Generator loss: 0.7682%]\n",
            "6778 [Discriminator loss: 0.6852%, acc.: 52.73%] [Generator loss: 0.7728%]\n",
            "6779 [Discriminator loss: 0.6820%, acc.: 57.03%] [Generator loss: 0.7720%]\n",
            "6780 [Discriminator loss: 0.6840%, acc.: 54.30%] [Generator loss: 0.7754%]\n",
            "6781 [Discriminator loss: 0.6665%, acc.: 57.81%] [Generator loss: 0.7711%]\n",
            "6782 [Discriminator loss: 0.6853%, acc.: 53.12%] [Generator loss: 0.7751%]\n",
            "6783 [Discriminator loss: 0.6825%, acc.: 53.91%] [Generator loss: 0.7820%]\n",
            "6784 [Discriminator loss: 0.7033%, acc.: 51.17%] [Generator loss: 0.7675%]\n",
            "6785 [Discriminator loss: 0.6801%, acc.: 52.73%] [Generator loss: 0.7852%]\n",
            "6786 [Discriminator loss: 0.6801%, acc.: 53.12%] [Generator loss: 0.8102%]\n",
            "6787 [Discriminator loss: 0.6778%, acc.: 55.08%] [Generator loss: 0.7940%]\n",
            "6788 [Discriminator loss: 0.6755%, acc.: 57.42%] [Generator loss: 0.7738%]\n",
            "6789 [Discriminator loss: 0.6767%, acc.: 58.59%] [Generator loss: 0.7750%]\n",
            "6790 [Discriminator loss: 0.6654%, acc.: 63.67%] [Generator loss: 0.7885%]\n",
            "6791 [Discriminator loss: 0.6860%, acc.: 53.52%] [Generator loss: 0.7793%]\n",
            "6792 [Discriminator loss: 0.6823%, acc.: 53.91%] [Generator loss: 0.7870%]\n",
            "6793 [Discriminator loss: 0.6735%, acc.: 57.42%] [Generator loss: 0.7904%]\n",
            "6794 [Discriminator loss: 0.6551%, acc.: 62.50%] [Generator loss: 0.7963%]\n",
            "6795 [Discriminator loss: 0.6736%, acc.: 56.64%] [Generator loss: 0.7889%]\n",
            "6796 [Discriminator loss: 0.6688%, acc.: 57.03%] [Generator loss: 0.7995%]\n",
            "6797 [Discriminator loss: 0.6861%, acc.: 51.95%] [Generator loss: 0.7939%]\n",
            "6798 [Discriminator loss: 0.6631%, acc.: 62.89%] [Generator loss: 0.7898%]\n",
            "6799 [Discriminator loss: 0.6763%, acc.: 55.08%] [Generator loss: 0.7849%]\n",
            "6800 [Discriminator loss: 0.6694%, acc.: 57.42%] [Generator loss: 0.7940%]\n",
            "6801 [Discriminator loss: 0.6649%, acc.: 60.94%] [Generator loss: 0.7972%]\n",
            "6802 [Discriminator loss: 0.6815%, acc.: 55.86%] [Generator loss: 0.7897%]\n",
            "6803 [Discriminator loss: 0.6686%, acc.: 57.42%] [Generator loss: 0.7699%]\n",
            "6804 [Discriminator loss: 0.6838%, acc.: 53.12%] [Generator loss: 0.7725%]\n",
            "6805 [Discriminator loss: 0.6629%, acc.: 60.94%] [Generator loss: 0.7656%]\n",
            "6806 [Discriminator loss: 0.6899%, acc.: 52.34%] [Generator loss: 0.7731%]\n",
            "6807 [Discriminator loss: 0.6805%, acc.: 55.08%] [Generator loss: 0.7776%]\n",
            "6808 [Discriminator loss: 0.6758%, acc.: 57.81%] [Generator loss: 0.7850%]\n",
            "6809 [Discriminator loss: 0.6696%, acc.: 60.94%] [Generator loss: 0.7898%]\n",
            "6810 [Discriminator loss: 0.6762%, acc.: 58.20%] [Generator loss: 0.8020%]\n",
            "6811 [Discriminator loss: 0.6811%, acc.: 58.20%] [Generator loss: 0.7892%]\n",
            "6812 [Discriminator loss: 0.6845%, acc.: 53.12%] [Generator loss: 0.7857%]\n",
            "6813 [Discriminator loss: 0.6845%, acc.: 53.52%] [Generator loss: 0.7748%]\n",
            "6814 [Discriminator loss: 0.6757%, acc.: 57.81%] [Generator loss: 0.7880%]\n",
            "6815 [Discriminator loss: 0.6622%, acc.: 58.59%] [Generator loss: 0.7789%]\n",
            "6816 [Discriminator loss: 0.6644%, acc.: 61.33%] [Generator loss: 0.7775%]\n",
            "6817 [Discriminator loss: 0.6587%, acc.: 60.94%] [Generator loss: 0.7923%]\n",
            "6818 [Discriminator loss: 0.6788%, acc.: 57.81%] [Generator loss: 0.7777%]\n",
            "6819 [Discriminator loss: 0.6869%, acc.: 57.03%] [Generator loss: 0.8025%]\n",
            "6820 [Discriminator loss: 0.6599%, acc.: 58.20%] [Generator loss: 0.7805%]\n",
            "6821 [Discriminator loss: 0.6732%, acc.: 58.20%] [Generator loss: 0.7769%]\n",
            "6822 [Discriminator loss: 0.6679%, acc.: 60.55%] [Generator loss: 0.7996%]\n",
            "6823 [Discriminator loss: 0.6651%, acc.: 61.33%] [Generator loss: 0.7757%]\n",
            "6824 [Discriminator loss: 0.6663%, acc.: 60.55%] [Generator loss: 0.7932%]\n",
            "6825 [Discriminator loss: 0.6887%, acc.: 56.25%] [Generator loss: 0.8072%]\n",
            "6826 [Discriminator loss: 0.6892%, acc.: 54.69%] [Generator loss: 0.7941%]\n",
            "6827 [Discriminator loss: 0.6545%, acc.: 63.67%] [Generator loss: 0.7870%]\n",
            "6828 [Discriminator loss: 0.6604%, acc.: 62.11%] [Generator loss: 0.8043%]\n",
            "6829 [Discriminator loss: 0.6691%, acc.: 59.38%] [Generator loss: 0.7972%]\n",
            "6830 [Discriminator loss: 0.6831%, acc.: 57.42%] [Generator loss: 0.7659%]\n",
            "6831 [Discriminator loss: 0.6746%, acc.: 53.91%] [Generator loss: 0.8080%]\n",
            "6832 [Discriminator loss: 0.6638%, acc.: 60.16%] [Generator loss: 0.8126%]\n",
            "6833 [Discriminator loss: 0.6710%, acc.: 55.08%] [Generator loss: 0.7989%]\n",
            "6834 [Discriminator loss: 0.6518%, acc.: 62.50%] [Generator loss: 0.8037%]\n",
            "6835 [Discriminator loss: 0.6743%, acc.: 58.98%] [Generator loss: 0.7839%]\n",
            "6836 [Discriminator loss: 0.6674%, acc.: 58.20%] [Generator loss: 0.7898%]\n",
            "6837 [Discriminator loss: 0.6701%, acc.: 59.77%] [Generator loss: 0.7957%]\n",
            "6838 [Discriminator loss: 0.6795%, acc.: 56.25%] [Generator loss: 0.7868%]\n",
            "6839 [Discriminator loss: 0.6774%, acc.: 59.38%] [Generator loss: 0.7922%]\n",
            "6840 [Discriminator loss: 0.6585%, acc.: 62.50%] [Generator loss: 0.7866%]\n",
            "6841 [Discriminator loss: 0.6756%, acc.: 56.25%] [Generator loss: 0.7620%]\n",
            "6842 [Discriminator loss: 0.6663%, acc.: 65.62%] [Generator loss: 0.7728%]\n",
            "6843 [Discriminator loss: 0.6810%, acc.: 55.08%] [Generator loss: 0.7893%]\n",
            "6844 [Discriminator loss: 0.6643%, acc.: 59.77%] [Generator loss: 0.7838%]\n",
            "6845 [Discriminator loss: 0.6696%, acc.: 58.59%] [Generator loss: 0.7821%]\n",
            "6846 [Discriminator loss: 0.6582%, acc.: 65.23%] [Generator loss: 0.7685%]\n",
            "6847 [Discriminator loss: 0.6594%, acc.: 63.67%] [Generator loss: 0.7968%]\n",
            "6848 [Discriminator loss: 0.6869%, acc.: 55.08%] [Generator loss: 0.8116%]\n",
            "6849 [Discriminator loss: 0.6877%, acc.: 57.03%] [Generator loss: 0.7662%]\n",
            "6850 [Discriminator loss: 0.6660%, acc.: 60.16%] [Generator loss: 0.7729%]\n",
            "6851 [Discriminator loss: 0.6752%, acc.: 57.42%] [Generator loss: 0.7781%]\n",
            "6852 [Discriminator loss: 0.6930%, acc.: 54.69%] [Generator loss: 0.7961%]\n",
            "6853 [Discriminator loss: 0.6767%, acc.: 56.25%] [Generator loss: 0.7910%]\n",
            "6854 [Discriminator loss: 0.6734%, acc.: 55.47%] [Generator loss: 0.7805%]\n",
            "6855 [Discriminator loss: 0.6658%, acc.: 57.81%] [Generator loss: 0.7873%]\n",
            "6856 [Discriminator loss: 0.6690%, acc.: 58.98%] [Generator loss: 0.7952%]\n",
            "6857 [Discriminator loss: 0.6914%, acc.: 51.17%] [Generator loss: 0.8084%]\n",
            "6858 [Discriminator loss: 0.6730%, acc.: 59.38%] [Generator loss: 0.7973%]\n",
            "6859 [Discriminator loss: 0.6887%, acc.: 52.73%] [Generator loss: 0.7654%]\n",
            "6860 [Discriminator loss: 0.6617%, acc.: 59.38%] [Generator loss: 0.7599%]\n",
            "6861 [Discriminator loss: 0.6766%, acc.: 54.69%] [Generator loss: 0.7996%]\n",
            "6862 [Discriminator loss: 0.6732%, acc.: 60.94%] [Generator loss: 0.7739%]\n",
            "6863 [Discriminator loss: 0.6764%, acc.: 55.47%] [Generator loss: 0.7700%]\n",
            "6864 [Discriminator loss: 0.6659%, acc.: 62.89%] [Generator loss: 0.7848%]\n",
            "6865 [Discriminator loss: 0.6764%, acc.: 56.64%] [Generator loss: 0.7767%]\n",
            "6866 [Discriminator loss: 0.6806%, acc.: 55.86%] [Generator loss: 0.7865%]\n",
            "6867 [Discriminator loss: 0.6746%, acc.: 53.91%] [Generator loss: 0.7801%]\n",
            "6868 [Discriminator loss: 0.6689%, acc.: 56.64%] [Generator loss: 0.7934%]\n",
            "6869 [Discriminator loss: 0.6646%, acc.: 63.67%] [Generator loss: 0.7807%]\n",
            "6870 [Discriminator loss: 0.6682%, acc.: 59.38%] [Generator loss: 0.7837%]\n",
            "6871 [Discriminator loss: 0.6704%, acc.: 59.77%] [Generator loss: 0.7668%]\n",
            "6872 [Discriminator loss: 0.6542%, acc.: 62.89%] [Generator loss: 0.7776%]\n",
            "6873 [Discriminator loss: 0.6904%, acc.: 49.61%] [Generator loss: 0.7549%]\n",
            "6874 [Discriminator loss: 0.6473%, acc.: 64.84%] [Generator loss: 0.7715%]\n",
            "6875 [Discriminator loss: 0.6701%, acc.: 56.25%] [Generator loss: 0.7746%]\n",
            "6876 [Discriminator loss: 0.6887%, acc.: 56.64%] [Generator loss: 0.7707%]\n",
            "6877 [Discriminator loss: 0.6748%, acc.: 56.64%] [Generator loss: 0.7658%]\n",
            "6878 [Discriminator loss: 0.6717%, acc.: 58.20%] [Generator loss: 0.7647%]\n",
            "6879 [Discriminator loss: 0.6876%, acc.: 56.64%] [Generator loss: 0.7692%]\n",
            "6880 [Discriminator loss: 0.6702%, acc.: 57.42%] [Generator loss: 0.7613%]\n",
            "6881 [Discriminator loss: 0.6742%, acc.: 58.20%] [Generator loss: 0.7835%]\n",
            "6882 [Discriminator loss: 0.6812%, acc.: 55.47%] [Generator loss: 0.7698%]\n",
            "6883 [Discriminator loss: 0.6581%, acc.: 60.16%] [Generator loss: 0.7808%]\n",
            "6884 [Discriminator loss: 0.6769%, acc.: 57.03%] [Generator loss: 0.7830%]\n",
            "6885 [Discriminator loss: 0.6523%, acc.: 63.67%] [Generator loss: 0.7696%]\n",
            "6886 [Discriminator loss: 0.6745%, acc.: 61.33%] [Generator loss: 0.7815%]\n",
            "6887 [Discriminator loss: 0.6709%, acc.: 57.03%] [Generator loss: 0.7773%]\n",
            "6888 [Discriminator loss: 0.6518%, acc.: 63.28%] [Generator loss: 0.7618%]\n",
            "6889 [Discriminator loss: 0.6748%, acc.: 55.47%] [Generator loss: 0.7655%]\n",
            "6890 [Discriminator loss: 0.6770%, acc.: 56.25%] [Generator loss: 0.7625%]\n",
            "6891 [Discriminator loss: 0.6715%, acc.: 57.42%] [Generator loss: 0.7656%]\n",
            "6892 [Discriminator loss: 0.6652%, acc.: 57.81%] [Generator loss: 0.7539%]\n",
            "6893 [Discriminator loss: 0.6779%, acc.: 55.47%] [Generator loss: 0.7596%]\n",
            "6894 [Discriminator loss: 0.6851%, acc.: 52.73%] [Generator loss: 0.7631%]\n",
            "6895 [Discriminator loss: 0.6799%, acc.: 54.69%] [Generator loss: 0.7517%]\n",
            "6896 [Discriminator loss: 0.6676%, acc.: 62.89%] [Generator loss: 0.7679%]\n",
            "6897 [Discriminator loss: 0.6638%, acc.: 62.50%] [Generator loss: 0.7577%]\n",
            "6898 [Discriminator loss: 0.6668%, acc.: 63.67%] [Generator loss: 0.7415%]\n",
            "6899 [Discriminator loss: 0.6629%, acc.: 64.84%] [Generator loss: 0.7684%]\n",
            "6900 [Discriminator loss: 0.6684%, acc.: 58.20%] [Generator loss: 0.7626%]\n",
            "6901 [Discriminator loss: 0.6536%, acc.: 64.84%] [Generator loss: 0.7429%]\n",
            "6902 [Discriminator loss: 0.6869%, acc.: 56.64%] [Generator loss: 0.7573%]\n",
            "6903 [Discriminator loss: 0.6787%, acc.: 58.59%] [Generator loss: 0.7621%]\n",
            "6904 [Discriminator loss: 0.6857%, acc.: 58.20%] [Generator loss: 0.7618%]\n",
            "6905 [Discriminator loss: 0.6769%, acc.: 52.34%] [Generator loss: 0.7627%]\n",
            "6906 [Discriminator loss: 0.6759%, acc.: 55.86%] [Generator loss: 0.7651%]\n",
            "6907 [Discriminator loss: 0.6767%, acc.: 56.64%] [Generator loss: 0.7885%]\n",
            "6908 [Discriminator loss: 0.6872%, acc.: 56.25%] [Generator loss: 0.7727%]\n",
            "6909 [Discriminator loss: 0.6523%, acc.: 66.02%] [Generator loss: 0.7821%]\n",
            "6910 [Discriminator loss: 0.6619%, acc.: 61.72%] [Generator loss: 0.7810%]\n",
            "6911 [Discriminator loss: 0.6602%, acc.: 61.33%] [Generator loss: 0.7714%]\n",
            "6912 [Discriminator loss: 0.6687%, acc.: 59.38%] [Generator loss: 0.7731%]\n",
            "6913 [Discriminator loss: 0.6809%, acc.: 58.20%] [Generator loss: 0.7915%]\n",
            "6914 [Discriminator loss: 0.6671%, acc.: 61.33%] [Generator loss: 0.7853%]\n",
            "6915 [Discriminator loss: 0.6834%, acc.: 57.03%] [Generator loss: 0.7748%]\n",
            "6916 [Discriminator loss: 0.6801%, acc.: 58.98%] [Generator loss: 0.7880%]\n",
            "6917 [Discriminator loss: 0.6640%, acc.: 59.38%] [Generator loss: 0.7856%]\n",
            "6918 [Discriminator loss: 0.6777%, acc.: 57.42%] [Generator loss: 0.7892%]\n",
            "6919 [Discriminator loss: 0.6624%, acc.: 60.55%] [Generator loss: 0.7847%]\n",
            "6920 [Discriminator loss: 0.6810%, acc.: 56.25%] [Generator loss: 0.7834%]\n",
            "6921 [Discriminator loss: 0.6910%, acc.: 50.39%] [Generator loss: 0.7739%]\n",
            "6922 [Discriminator loss: 0.6709%, acc.: 57.81%] [Generator loss: 0.7675%]\n",
            "6923 [Discriminator loss: 0.6711%, acc.: 56.64%] [Generator loss: 0.7778%]\n",
            "6924 [Discriminator loss: 0.6836%, acc.: 51.95%] [Generator loss: 0.7498%]\n",
            "6925 [Discriminator loss: 0.6578%, acc.: 58.98%] [Generator loss: 0.7654%]\n",
            "6926 [Discriminator loss: 0.6587%, acc.: 57.81%] [Generator loss: 0.7792%]\n",
            "6927 [Discriminator loss: 0.6758%, acc.: 58.20%] [Generator loss: 0.7745%]\n",
            "6928 [Discriminator loss: 0.6746%, acc.: 58.98%] [Generator loss: 0.7753%]\n",
            "6929 [Discriminator loss: 0.6648%, acc.: 57.03%] [Generator loss: 0.7756%]\n",
            "6930 [Discriminator loss: 0.6695%, acc.: 56.64%] [Generator loss: 0.7806%]\n",
            "6931 [Discriminator loss: 0.6798%, acc.: 56.25%] [Generator loss: 0.7755%]\n",
            "6932 [Discriminator loss: 0.6885%, acc.: 53.91%] [Generator loss: 0.7754%]\n",
            "6933 [Discriminator loss: 0.6727%, acc.: 57.81%] [Generator loss: 0.7811%]\n",
            "6934 [Discriminator loss: 0.6728%, acc.: 55.86%] [Generator loss: 0.7830%]\n",
            "6935 [Discriminator loss: 0.6913%, acc.: 55.08%] [Generator loss: 0.7729%]\n",
            "6936 [Discriminator loss: 0.6799%, acc.: 54.69%] [Generator loss: 0.7927%]\n",
            "6937 [Discriminator loss: 0.6745%, acc.: 56.25%] [Generator loss: 0.7743%]\n",
            "6938 [Discriminator loss: 0.6871%, acc.: 51.17%] [Generator loss: 0.7734%]\n",
            "6939 [Discriminator loss: 0.6646%, acc.: 61.72%] [Generator loss: 0.7797%]\n",
            "6940 [Discriminator loss: 0.6617%, acc.: 59.38%] [Generator loss: 0.7755%]\n",
            "6941 [Discriminator loss: 0.6759%, acc.: 57.81%] [Generator loss: 0.7818%]\n",
            "6942 [Discriminator loss: 0.6785%, acc.: 55.86%] [Generator loss: 0.8087%]\n",
            "6943 [Discriminator loss: 0.6524%, acc.: 62.50%] [Generator loss: 0.8078%]\n",
            "6944 [Discriminator loss: 0.6726%, acc.: 59.77%] [Generator loss: 0.7875%]\n",
            "6945 [Discriminator loss: 0.6718%, acc.: 59.38%] [Generator loss: 0.7955%]\n",
            "6946 [Discriminator loss: 0.6671%, acc.: 59.77%] [Generator loss: 0.7723%]\n",
            "6947 [Discriminator loss: 0.6842%, acc.: 55.47%] [Generator loss: 0.7717%]\n",
            "6948 [Discriminator loss: 0.6675%, acc.: 58.59%] [Generator loss: 0.7743%]\n",
            "6949 [Discriminator loss: 0.6814%, acc.: 55.08%] [Generator loss: 0.7675%]\n",
            "6950 [Discriminator loss: 0.6740%, acc.: 60.16%] [Generator loss: 0.7756%]\n",
            "6951 [Discriminator loss: 0.6656%, acc.: 61.72%] [Generator loss: 0.7912%]\n",
            "6952 [Discriminator loss: 0.6893%, acc.: 55.08%] [Generator loss: 0.7766%]\n",
            "6953 [Discriminator loss: 0.6776%, acc.: 51.95%] [Generator loss: 0.8132%]\n",
            "6954 [Discriminator loss: 0.6829%, acc.: 51.95%] [Generator loss: 0.8134%]\n",
            "6955 [Discriminator loss: 0.6522%, acc.: 62.89%] [Generator loss: 0.8007%]\n",
            "6956 [Discriminator loss: 0.6948%, acc.: 52.73%] [Generator loss: 0.7899%]\n",
            "6957 [Discriminator loss: 0.6757%, acc.: 55.86%] [Generator loss: 0.7709%]\n",
            "6958 [Discriminator loss: 0.6760%, acc.: 58.98%] [Generator loss: 0.7800%]\n",
            "6959 [Discriminator loss: 0.6867%, acc.: 55.08%] [Generator loss: 0.7795%]\n",
            "6960 [Discriminator loss: 0.6680%, acc.: 59.38%] [Generator loss: 0.7962%]\n",
            "6961 [Discriminator loss: 0.6721%, acc.: 58.98%] [Generator loss: 0.7911%]\n",
            "6962 [Discriminator loss: 0.6751%, acc.: 59.77%] [Generator loss: 0.7665%]\n",
            "6963 [Discriminator loss: 0.6869%, acc.: 57.03%] [Generator loss: 0.7775%]\n",
            "6964 [Discriminator loss: 0.6896%, acc.: 53.12%] [Generator loss: 0.7637%]\n",
            "6965 [Discriminator loss: 0.7021%, acc.: 51.17%] [Generator loss: 0.7942%]\n",
            "6966 [Discriminator loss: 0.6739%, acc.: 57.42%] [Generator loss: 0.7771%]\n",
            "6967 [Discriminator loss: 0.6685%, acc.: 58.98%] [Generator loss: 0.7873%]\n",
            "6968 [Discriminator loss: 0.6561%, acc.: 63.28%] [Generator loss: 0.7819%]\n",
            "6969 [Discriminator loss: 0.6935%, acc.: 51.17%] [Generator loss: 0.7773%]\n",
            "6970 [Discriminator loss: 0.6927%, acc.: 48.44%] [Generator loss: 0.7811%]\n",
            "6971 [Discriminator loss: 0.6859%, acc.: 56.25%] [Generator loss: 0.7918%]\n",
            "6972 [Discriminator loss: 0.6708%, acc.: 59.77%] [Generator loss: 0.7738%]\n",
            "6973 [Discriminator loss: 0.6737%, acc.: 59.77%] [Generator loss: 0.8006%]\n",
            "6974 [Discriminator loss: 0.6880%, acc.: 53.12%] [Generator loss: 0.7605%]\n",
            "6975 [Discriminator loss: 0.6783%, acc.: 57.03%] [Generator loss: 0.7679%]\n",
            "6976 [Discriminator loss: 0.6951%, acc.: 52.73%] [Generator loss: 0.7653%]\n",
            "6977 [Discriminator loss: 0.6815%, acc.: 53.52%] [Generator loss: 0.7651%]\n",
            "6978 [Discriminator loss: 0.6735%, acc.: 56.25%] [Generator loss: 0.7681%]\n",
            "6979 [Discriminator loss: 0.6798%, acc.: 60.94%] [Generator loss: 0.7653%]\n",
            "6980 [Discriminator loss: 0.6909%, acc.: 51.95%] [Generator loss: 0.7779%]\n",
            "6981 [Discriminator loss: 0.6850%, acc.: 55.86%] [Generator loss: 0.7861%]\n",
            "6982 [Discriminator loss: 0.6615%, acc.: 58.20%] [Generator loss: 0.7674%]\n",
            "6983 [Discriminator loss: 0.6731%, acc.: 58.59%] [Generator loss: 0.7748%]\n",
            "6984 [Discriminator loss: 0.6725%, acc.: 59.77%] [Generator loss: 0.7627%]\n",
            "6985 [Discriminator loss: 0.6736%, acc.: 58.59%] [Generator loss: 0.7735%]\n",
            "6986 [Discriminator loss: 0.6894%, acc.: 55.08%] [Generator loss: 0.7640%]\n",
            "6987 [Discriminator loss: 0.6821%, acc.: 53.12%] [Generator loss: 0.7672%]\n",
            "6988 [Discriminator loss: 0.6778%, acc.: 54.30%] [Generator loss: 0.7777%]\n",
            "6989 [Discriminator loss: 0.6741%, acc.: 59.38%] [Generator loss: 0.7738%]\n",
            "6990 [Discriminator loss: 0.6820%, acc.: 53.91%] [Generator loss: 0.7776%]\n",
            "6991 [Discriminator loss: 0.6682%, acc.: 58.98%] [Generator loss: 0.7786%]\n",
            "6992 [Discriminator loss: 0.6674%, acc.: 57.03%] [Generator loss: 0.7510%]\n",
            "6993 [Discriminator loss: 0.6876%, acc.: 55.86%] [Generator loss: 0.7813%]\n",
            "6994 [Discriminator loss: 0.6795%, acc.: 54.69%] [Generator loss: 0.7806%]\n",
            "6995 [Discriminator loss: 0.6590%, acc.: 61.72%] [Generator loss: 0.7873%]\n",
            "6996 [Discriminator loss: 0.6654%, acc.: 58.59%] [Generator loss: 0.7669%]\n",
            "6997 [Discriminator loss: 0.6634%, acc.: 60.55%] [Generator loss: 0.7771%]\n",
            "6998 [Discriminator loss: 0.6689%, acc.: 59.38%] [Generator loss: 0.7750%]\n",
            "6999 [Discriminator loss: 0.6792%, acc.: 55.08%] [Generator loss: 0.7780%]\n",
            "7000 [Discriminator loss: 0.6696%, acc.: 61.33%] [Generator loss: 0.7866%]\n",
            "7001 [Discriminator loss: 0.6743%, acc.: 60.94%] [Generator loss: 0.7943%]\n",
            "7002 [Discriminator loss: 0.6714%, acc.: 56.25%] [Generator loss: 0.7725%]\n",
            "7003 [Discriminator loss: 0.7020%, acc.: 51.56%] [Generator loss: 0.7922%]\n",
            "7004 [Discriminator loss: 0.6863%, acc.: 58.20%] [Generator loss: 0.8044%]\n",
            "7005 [Discriminator loss: 0.6772%, acc.: 56.25%] [Generator loss: 0.7946%]\n",
            "7006 [Discriminator loss: 0.6880%, acc.: 54.30%] [Generator loss: 0.7949%]\n",
            "7007 [Discriminator loss: 0.6731%, acc.: 58.20%] [Generator loss: 0.7871%]\n",
            "7008 [Discriminator loss: 0.6708%, acc.: 59.38%] [Generator loss: 0.7677%]\n",
            "7009 [Discriminator loss: 0.6636%, acc.: 62.50%] [Generator loss: 0.7808%]\n",
            "7010 [Discriminator loss: 0.6907%, acc.: 53.12%] [Generator loss: 0.7612%]\n",
            "7011 [Discriminator loss: 0.6595%, acc.: 59.77%] [Generator loss: 0.7927%]\n",
            "7012 [Discriminator loss: 0.6885%, acc.: 53.52%] [Generator loss: 0.7630%]\n",
            "7013 [Discriminator loss: 0.6846%, acc.: 52.73%] [Generator loss: 0.7627%]\n",
            "7014 [Discriminator loss: 0.6741%, acc.: 57.03%] [Generator loss: 0.7806%]\n",
            "7015 [Discriminator loss: 0.6982%, acc.: 53.91%] [Generator loss: 0.7660%]\n",
            "7016 [Discriminator loss: 0.6776%, acc.: 55.86%] [Generator loss: 0.7784%]\n",
            "7017 [Discriminator loss: 0.6916%, acc.: 54.69%] [Generator loss: 0.7778%]\n",
            "7018 [Discriminator loss: 0.6716%, acc.: 57.81%] [Generator loss: 0.7695%]\n",
            "7019 [Discriminator loss: 0.6789%, acc.: 54.69%] [Generator loss: 0.7741%]\n",
            "7020 [Discriminator loss: 0.6771%, acc.: 55.86%] [Generator loss: 0.7772%]\n",
            "7021 [Discriminator loss: 0.6801%, acc.: 57.42%] [Generator loss: 0.7713%]\n",
            "7022 [Discriminator loss: 0.6731%, acc.: 59.77%] [Generator loss: 0.7786%]\n",
            "7023 [Discriminator loss: 0.6744%, acc.: 56.64%] [Generator loss: 0.7754%]\n",
            "7024 [Discriminator loss: 0.6688%, acc.: 60.16%] [Generator loss: 0.7764%]\n",
            "7025 [Discriminator loss: 0.6715%, acc.: 57.42%] [Generator loss: 0.7844%]\n",
            "7026 [Discriminator loss: 0.6778%, acc.: 56.25%] [Generator loss: 0.7836%]\n",
            "7027 [Discriminator loss: 0.6806%, acc.: 58.98%] [Generator loss: 0.7887%]\n",
            "7028 [Discriminator loss: 0.6638%, acc.: 62.89%] [Generator loss: 0.7542%]\n",
            "7029 [Discriminator loss: 0.6780%, acc.: 56.25%] [Generator loss: 0.7647%]\n",
            "7030 [Discriminator loss: 0.6671%, acc.: 60.16%] [Generator loss: 0.7652%]\n",
            "7031 [Discriminator loss: 0.6675%, acc.: 59.38%] [Generator loss: 0.7667%]\n",
            "7032 [Discriminator loss: 0.6663%, acc.: 64.06%] [Generator loss: 0.7691%]\n",
            "7033 [Discriminator loss: 0.6889%, acc.: 58.20%] [Generator loss: 0.7856%]\n",
            "7034 [Discriminator loss: 0.6702%, acc.: 57.42%] [Generator loss: 0.7761%]\n",
            "7035 [Discriminator loss: 0.6793%, acc.: 59.38%] [Generator loss: 0.8002%]\n",
            "7036 [Discriminator loss: 0.6757%, acc.: 60.16%] [Generator loss: 0.7835%]\n",
            "7037 [Discriminator loss: 0.6734%, acc.: 59.77%] [Generator loss: 0.7968%]\n",
            "7038 [Discriminator loss: 0.6859%, acc.: 55.47%] [Generator loss: 0.7991%]\n",
            "7039 [Discriminator loss: 0.6703%, acc.: 60.94%] [Generator loss: 0.8132%]\n",
            "7040 [Discriminator loss: 0.6773%, acc.: 58.20%] [Generator loss: 0.8336%]\n",
            "7041 [Discriminator loss: 0.6825%, acc.: 57.03%] [Generator loss: 0.8040%]\n",
            "7042 [Discriminator loss: 0.6718%, acc.: 62.11%] [Generator loss: 0.7904%]\n",
            "7043 [Discriminator loss: 0.6966%, acc.: 52.34%] [Generator loss: 0.7820%]\n",
            "7044 [Discriminator loss: 0.6781%, acc.: 58.20%] [Generator loss: 0.7750%]\n",
            "7045 [Discriminator loss: 0.7005%, acc.: 52.34%] [Generator loss: 0.7907%]\n",
            "7046 [Discriminator loss: 0.6762%, acc.: 58.59%] [Generator loss: 0.7775%]\n",
            "7047 [Discriminator loss: 0.6679%, acc.: 57.81%] [Generator loss: 0.8122%]\n",
            "7048 [Discriminator loss: 0.6778%, acc.: 56.25%] [Generator loss: 0.7935%]\n",
            "7049 [Discriminator loss: 0.6544%, acc.: 63.67%] [Generator loss: 0.8201%]\n",
            "7050 [Discriminator loss: 0.6748%, acc.: 58.59%] [Generator loss: 0.8093%]\n",
            "7051 [Discriminator loss: 0.6664%, acc.: 59.38%] [Generator loss: 0.8100%]\n",
            "7052 [Discriminator loss: 0.6530%, acc.: 66.80%] [Generator loss: 0.7990%]\n",
            "7053 [Discriminator loss: 0.6658%, acc.: 61.33%] [Generator loss: 0.8073%]\n",
            "7054 [Discriminator loss: 0.6750%, acc.: 59.77%] [Generator loss: 0.7988%]\n",
            "7055 [Discriminator loss: 0.6747%, acc.: 62.50%] [Generator loss: 0.7800%]\n",
            "7056 [Discriminator loss: 0.6735%, acc.: 57.42%] [Generator loss: 0.7758%]\n",
            "7057 [Discriminator loss: 0.6681%, acc.: 60.16%] [Generator loss: 0.7942%]\n",
            "7058 [Discriminator loss: 0.6631%, acc.: 63.28%] [Generator loss: 0.7881%]\n",
            "7059 [Discriminator loss: 0.6799%, acc.: 54.69%] [Generator loss: 0.7689%]\n",
            "7060 [Discriminator loss: 0.6950%, acc.: 50.00%] [Generator loss: 0.7759%]\n",
            "7061 [Discriminator loss: 0.6766%, acc.: 56.25%] [Generator loss: 0.7819%]\n",
            "7062 [Discriminator loss: 0.6741%, acc.: 58.59%] [Generator loss: 0.7654%]\n",
            "7063 [Discriminator loss: 0.6637%, acc.: 61.72%] [Generator loss: 0.7798%]\n",
            "7064 [Discriminator loss: 0.6750%, acc.: 55.47%] [Generator loss: 0.7630%]\n",
            "7065 [Discriminator loss: 0.6849%, acc.: 56.64%] [Generator loss: 0.7770%]\n",
            "7066 [Discriminator loss: 0.6735%, acc.: 57.42%] [Generator loss: 0.7942%]\n",
            "7067 [Discriminator loss: 0.6907%, acc.: 53.91%] [Generator loss: 0.7930%]\n",
            "7068 [Discriminator loss: 0.6788%, acc.: 57.42%] [Generator loss: 0.7814%]\n",
            "7069 [Discriminator loss: 0.6730%, acc.: 57.42%] [Generator loss: 0.7861%]\n",
            "7070 [Discriminator loss: 0.6848%, acc.: 56.25%] [Generator loss: 0.7776%]\n",
            "7071 [Discriminator loss: 0.6755%, acc.: 59.38%] [Generator loss: 0.7745%]\n",
            "7072 [Discriminator loss: 0.6913%, acc.: 55.86%] [Generator loss: 0.7886%]\n",
            "7073 [Discriminator loss: 0.6695%, acc.: 60.55%] [Generator loss: 0.7820%]\n",
            "7074 [Discriminator loss: 0.6556%, acc.: 60.55%] [Generator loss: 0.7657%]\n",
            "7075 [Discriminator loss: 0.6633%, acc.: 62.11%] [Generator loss: 0.7784%]\n",
            "7076 [Discriminator loss: 0.6660%, acc.: 61.72%] [Generator loss: 0.7672%]\n",
            "7077 [Discriminator loss: 0.6786%, acc.: 57.03%] [Generator loss: 0.7847%]\n",
            "7078 [Discriminator loss: 0.6496%, acc.: 63.28%] [Generator loss: 0.7849%]\n",
            "7079 [Discriminator loss: 0.6674%, acc.: 56.64%] [Generator loss: 0.7812%]\n",
            "7080 [Discriminator loss: 0.6830%, acc.: 56.64%] [Generator loss: 0.7879%]\n",
            "7081 [Discriminator loss: 0.6717%, acc.: 62.11%] [Generator loss: 0.7976%]\n",
            "7082 [Discriminator loss: 0.6680%, acc.: 61.33%] [Generator loss: 0.8130%]\n",
            "7083 [Discriminator loss: 0.6553%, acc.: 61.33%] [Generator loss: 0.7953%]\n",
            "7084 [Discriminator loss: 0.6734%, acc.: 59.77%] [Generator loss: 0.7860%]\n",
            "7085 [Discriminator loss: 0.6772%, acc.: 58.59%] [Generator loss: 0.7971%]\n",
            "7086 [Discriminator loss: 0.6739%, acc.: 59.38%] [Generator loss: 0.7809%]\n",
            "7087 [Discriminator loss: 0.6779%, acc.: 55.08%] [Generator loss: 0.7846%]\n",
            "7088 [Discriminator loss: 0.6784%, acc.: 55.47%] [Generator loss: 0.7804%]\n",
            "7089 [Discriminator loss: 0.6811%, acc.: 54.69%] [Generator loss: 0.8116%]\n",
            "7090 [Discriminator loss: 0.6776%, acc.: 55.86%] [Generator loss: 0.7787%]\n",
            "7091 [Discriminator loss: 0.6995%, acc.: 48.83%] [Generator loss: 0.7980%]\n",
            "7092 [Discriminator loss: 0.6906%, acc.: 55.86%] [Generator loss: 0.7838%]\n",
            "7093 [Discriminator loss: 0.6653%, acc.: 61.33%] [Generator loss: 0.7926%]\n",
            "7094 [Discriminator loss: 0.6727%, acc.: 57.42%] [Generator loss: 0.7760%]\n",
            "7095 [Discriminator loss: 0.6680%, acc.: 59.77%] [Generator loss: 0.8042%]\n",
            "7096 [Discriminator loss: 0.6676%, acc.: 58.59%] [Generator loss: 0.7845%]\n",
            "7097 [Discriminator loss: 0.6846%, acc.: 54.69%] [Generator loss: 0.7899%]\n",
            "7098 [Discriminator loss: 0.6734%, acc.: 56.64%] [Generator loss: 0.7731%]\n",
            "7099 [Discriminator loss: 0.6679%, acc.: 58.98%] [Generator loss: 0.8047%]\n",
            "7100 [Discriminator loss: 0.6807%, acc.: 57.03%] [Generator loss: 0.7944%]\n",
            "7101 [Discriminator loss: 0.6868%, acc.: 53.12%] [Generator loss: 0.7834%]\n",
            "7102 [Discriminator loss: 0.6751%, acc.: 57.81%] [Generator loss: 0.7907%]\n",
            "7103 [Discriminator loss: 0.6729%, acc.: 57.42%] [Generator loss: 0.7689%]\n",
            "7104 [Discriminator loss: 0.6561%, acc.: 60.94%] [Generator loss: 0.7766%]\n",
            "7105 [Discriminator loss: 0.6792%, acc.: 55.86%] [Generator loss: 0.7783%]\n",
            "7106 [Discriminator loss: 0.6803%, acc.: 56.64%] [Generator loss: 0.7805%]\n",
            "7107 [Discriminator loss: 0.6724%, acc.: 55.86%] [Generator loss: 0.7745%]\n",
            "7108 [Discriminator loss: 0.6862%, acc.: 53.91%] [Generator loss: 0.7514%]\n",
            "7109 [Discriminator loss: 0.6762%, acc.: 57.42%] [Generator loss: 0.7763%]\n",
            "7110 [Discriminator loss: 0.6670%, acc.: 62.89%] [Generator loss: 0.7835%]\n",
            "7111 [Discriminator loss: 0.6861%, acc.: 53.91%] [Generator loss: 0.7909%]\n",
            "7112 [Discriminator loss: 0.6712%, acc.: 56.25%] [Generator loss: 0.7746%]\n",
            "7113 [Discriminator loss: 0.6623%, acc.: 61.33%] [Generator loss: 0.7659%]\n",
            "7114 [Discriminator loss: 0.6609%, acc.: 59.38%] [Generator loss: 0.7865%]\n",
            "7115 [Discriminator loss: 0.6691%, acc.: 60.55%] [Generator loss: 0.7742%]\n",
            "7116 [Discriminator loss: 0.6682%, acc.: 58.20%] [Generator loss: 0.7893%]\n",
            "7117 [Discriminator loss: 0.6802%, acc.: 56.64%] [Generator loss: 0.7922%]\n",
            "7118 [Discriminator loss: 0.6572%, acc.: 63.67%] [Generator loss: 0.8032%]\n",
            "7119 [Discriminator loss: 0.6768%, acc.: 57.03%] [Generator loss: 0.7868%]\n",
            "7120 [Discriminator loss: 0.6700%, acc.: 57.81%] [Generator loss: 0.8110%]\n",
            "7121 [Discriminator loss: 0.6572%, acc.: 62.89%] [Generator loss: 0.8000%]\n",
            "7122 [Discriminator loss: 0.6707%, acc.: 59.38%] [Generator loss: 0.8067%]\n",
            "7123 [Discriminator loss: 0.6618%, acc.: 61.33%] [Generator loss: 0.8067%]\n",
            "7124 [Discriminator loss: 0.6813%, acc.: 52.73%] [Generator loss: 0.7917%]\n",
            "7125 [Discriminator loss: 0.6602%, acc.: 63.67%] [Generator loss: 0.7863%]\n",
            "7126 [Discriminator loss: 0.6935%, acc.: 51.95%] [Generator loss: 0.7882%]\n",
            "7127 [Discriminator loss: 0.6793%, acc.: 57.03%] [Generator loss: 0.8047%]\n",
            "7128 [Discriminator loss: 0.6632%, acc.: 57.81%] [Generator loss: 0.7950%]\n",
            "7129 [Discriminator loss: 0.6556%, acc.: 61.72%] [Generator loss: 0.7967%]\n",
            "7130 [Discriminator loss: 0.6815%, acc.: 55.08%] [Generator loss: 0.7874%]\n",
            "7131 [Discriminator loss: 0.6562%, acc.: 61.72%] [Generator loss: 0.8102%]\n",
            "7132 [Discriminator loss: 0.6796%, acc.: 57.81%] [Generator loss: 0.7855%]\n",
            "7133 [Discriminator loss: 0.6744%, acc.: 59.77%] [Generator loss: 0.8062%]\n",
            "7134 [Discriminator loss: 0.6798%, acc.: 52.73%] [Generator loss: 0.8127%]\n",
            "7135 [Discriminator loss: 0.6860%, acc.: 56.64%] [Generator loss: 0.8095%]\n",
            "7136 [Discriminator loss: 0.6735%, acc.: 58.20%] [Generator loss: 0.8164%]\n",
            "7137 [Discriminator loss: 0.6661%, acc.: 62.11%] [Generator loss: 0.8128%]\n",
            "7138 [Discriminator loss: 0.6788%, acc.: 52.34%] [Generator loss: 0.7897%]\n",
            "7139 [Discriminator loss: 0.6884%, acc.: 55.47%] [Generator loss: 0.7779%]\n",
            "7140 [Discriminator loss: 0.6672%, acc.: 56.25%] [Generator loss: 0.8160%]\n",
            "7141 [Discriminator loss: 0.6886%, acc.: 53.52%] [Generator loss: 0.7681%]\n",
            "7142 [Discriminator loss: 0.6685%, acc.: 58.59%] [Generator loss: 0.7881%]\n",
            "7143 [Discriminator loss: 0.6660%, acc.: 61.33%] [Generator loss: 0.7768%]\n",
            "7144 [Discriminator loss: 0.6734%, acc.: 57.81%] [Generator loss: 0.7743%]\n",
            "7145 [Discriminator loss: 0.6688%, acc.: 60.55%] [Generator loss: 0.7620%]\n",
            "7146 [Discriminator loss: 0.6679%, acc.: 55.86%] [Generator loss: 0.8075%]\n",
            "7147 [Discriminator loss: 0.6718%, acc.: 57.03%] [Generator loss: 0.7973%]\n",
            "7148 [Discriminator loss: 0.6683%, acc.: 55.08%] [Generator loss: 0.7933%]\n",
            "7149 [Discriminator loss: 0.6745%, acc.: 58.98%] [Generator loss: 0.7960%]\n",
            "7150 [Discriminator loss: 0.6550%, acc.: 62.89%] [Generator loss: 0.7997%]\n",
            "7151 [Discriminator loss: 0.6668%, acc.: 62.50%] [Generator loss: 0.7919%]\n",
            "7152 [Discriminator loss: 0.6715%, acc.: 60.16%] [Generator loss: 0.7876%]\n",
            "7153 [Discriminator loss: 0.6818%, acc.: 54.69%] [Generator loss: 0.7805%]\n",
            "7154 [Discriminator loss: 0.6748%, acc.: 59.38%] [Generator loss: 0.7637%]\n",
            "7155 [Discriminator loss: 0.6846%, acc.: 53.52%] [Generator loss: 0.7745%]\n",
            "7156 [Discriminator loss: 0.6623%, acc.: 59.77%] [Generator loss: 0.8060%]\n",
            "7157 [Discriminator loss: 0.6684%, acc.: 60.16%] [Generator loss: 0.7520%]\n",
            "7158 [Discriminator loss: 0.6654%, acc.: 60.94%] [Generator loss: 0.7851%]\n",
            "7159 [Discriminator loss: 0.6756%, acc.: 56.25%] [Generator loss: 0.7624%]\n",
            "7160 [Discriminator loss: 0.6755%, acc.: 56.25%] [Generator loss: 0.7697%]\n",
            "7161 [Discriminator loss: 0.6671%, acc.: 60.55%] [Generator loss: 0.7783%]\n",
            "7162 [Discriminator loss: 0.6718%, acc.: 58.20%] [Generator loss: 0.7525%]\n",
            "7163 [Discriminator loss: 0.6707%, acc.: 57.42%] [Generator loss: 0.7789%]\n",
            "7164 [Discriminator loss: 0.6713%, acc.: 59.38%] [Generator loss: 0.7629%]\n",
            "7165 [Discriminator loss: 0.6716%, acc.: 59.38%] [Generator loss: 0.7745%]\n",
            "7166 [Discriminator loss: 0.6716%, acc.: 57.81%] [Generator loss: 0.7962%]\n",
            "7167 [Discriminator loss: 0.6764%, acc.: 62.89%] [Generator loss: 0.8060%]\n",
            "7168 [Discriminator loss: 0.6567%, acc.: 58.59%] [Generator loss: 0.7971%]\n",
            "7169 [Discriminator loss: 0.6592%, acc.: 62.11%] [Generator loss: 0.7873%]\n",
            "7170 [Discriminator loss: 0.6753%, acc.: 55.47%] [Generator loss: 0.7722%]\n",
            "7171 [Discriminator loss: 0.6515%, acc.: 62.89%] [Generator loss: 0.7808%]\n",
            "7172 [Discriminator loss: 0.6630%, acc.: 58.98%] [Generator loss: 0.7856%]\n",
            "7173 [Discriminator loss: 0.6784%, acc.: 54.69%] [Generator loss: 0.7987%]\n",
            "7174 [Discriminator loss: 0.6740%, acc.: 58.20%] [Generator loss: 0.7848%]\n",
            "7175 [Discriminator loss: 0.6687%, acc.: 57.42%] [Generator loss: 0.7756%]\n",
            "7176 [Discriminator loss: 0.6754%, acc.: 57.42%] [Generator loss: 0.7969%]\n",
            "7177 [Discriminator loss: 0.6798%, acc.: 56.25%] [Generator loss: 0.8005%]\n",
            "7178 [Discriminator loss: 0.6670%, acc.: 60.94%] [Generator loss: 0.7899%]\n",
            "7179 [Discriminator loss: 0.6685%, acc.: 58.98%] [Generator loss: 0.7871%]\n",
            "7180 [Discriminator loss: 0.6724%, acc.: 57.42%] [Generator loss: 0.7868%]\n",
            "7181 [Discriminator loss: 0.6688%, acc.: 60.94%] [Generator loss: 0.7827%]\n",
            "7182 [Discriminator loss: 0.6643%, acc.: 64.06%] [Generator loss: 0.7831%]\n",
            "7183 [Discriminator loss: 0.6651%, acc.: 60.55%] [Generator loss: 0.7918%]\n",
            "7184 [Discriminator loss: 0.6658%, acc.: 62.11%] [Generator loss: 0.7832%]\n",
            "7185 [Discriminator loss: 0.6908%, acc.: 51.56%] [Generator loss: 0.7990%]\n",
            "7186 [Discriminator loss: 0.6849%, acc.: 56.64%] [Generator loss: 0.7778%]\n",
            "7187 [Discriminator loss: 0.6404%, acc.: 66.41%] [Generator loss: 0.7960%]\n",
            "7188 [Discriminator loss: 0.6591%, acc.: 63.28%] [Generator loss: 0.7849%]\n",
            "7189 [Discriminator loss: 0.6708%, acc.: 59.77%] [Generator loss: 0.7779%]\n",
            "7190 [Discriminator loss: 0.6742%, acc.: 56.25%] [Generator loss: 0.8004%]\n",
            "7191 [Discriminator loss: 0.6728%, acc.: 58.20%] [Generator loss: 0.7808%]\n",
            "7192 [Discriminator loss: 0.6656%, acc.: 58.59%] [Generator loss: 0.7842%]\n",
            "7193 [Discriminator loss: 0.6801%, acc.: 54.69%] [Generator loss: 0.7883%]\n",
            "7194 [Discriminator loss: 0.6763%, acc.: 61.72%] [Generator loss: 0.7883%]\n",
            "7195 [Discriminator loss: 0.6864%, acc.: 56.64%] [Generator loss: 0.7856%]\n",
            "7196 [Discriminator loss: 0.6814%, acc.: 57.03%] [Generator loss: 0.7684%]\n",
            "7197 [Discriminator loss: 0.6780%, acc.: 57.81%] [Generator loss: 0.7962%]\n",
            "7198 [Discriminator loss: 0.6821%, acc.: 58.20%] [Generator loss: 0.7812%]\n",
            "7199 [Discriminator loss: 0.6739%, acc.: 59.38%] [Generator loss: 0.7649%]\n",
            "7200 [Discriminator loss: 0.6806%, acc.: 58.59%] [Generator loss: 0.8086%]\n",
            "7201 [Discriminator loss: 0.6789%, acc.: 57.81%] [Generator loss: 0.7897%]\n",
            "7202 [Discriminator loss: 0.6895%, acc.: 53.52%] [Generator loss: 0.7581%]\n",
            "7203 [Discriminator loss: 0.6706%, acc.: 60.16%] [Generator loss: 0.7534%]\n",
            "7204 [Discriminator loss: 0.6644%, acc.: 60.16%] [Generator loss: 0.7780%]\n",
            "7205 [Discriminator loss: 0.6763%, acc.: 57.03%] [Generator loss: 0.7955%]\n",
            "7206 [Discriminator loss: 0.6838%, acc.: 53.91%] [Generator loss: 0.7786%]\n",
            "7207 [Discriminator loss: 0.6725%, acc.: 62.11%] [Generator loss: 0.7903%]\n",
            "7208 [Discriminator loss: 0.6900%, acc.: 51.95%] [Generator loss: 0.7861%]\n",
            "7209 [Discriminator loss: 0.6869%, acc.: 53.91%] [Generator loss: 0.7804%]\n",
            "7210 [Discriminator loss: 0.6653%, acc.: 60.16%] [Generator loss: 0.7837%]\n",
            "7211 [Discriminator loss: 0.6929%, acc.: 55.86%] [Generator loss: 0.7683%]\n",
            "7212 [Discriminator loss: 0.6842%, acc.: 54.30%] [Generator loss: 0.7878%]\n",
            "7213 [Discriminator loss: 0.6990%, acc.: 51.56%] [Generator loss: 0.7697%]\n",
            "7214 [Discriminator loss: 0.6742%, acc.: 56.25%] [Generator loss: 0.7862%]\n",
            "7215 [Discriminator loss: 0.6642%, acc.: 64.06%] [Generator loss: 0.7760%]\n",
            "7216 [Discriminator loss: 0.6688%, acc.: 59.77%] [Generator loss: 0.7943%]\n",
            "7217 [Discriminator loss: 0.6879%, acc.: 55.47%] [Generator loss: 0.7569%]\n",
            "7218 [Discriminator loss: 0.6751%, acc.: 60.94%] [Generator loss: 0.8032%]\n",
            "7219 [Discriminator loss: 0.6790%, acc.: 56.64%] [Generator loss: 0.7740%]\n",
            "7220 [Discriminator loss: 0.6792%, acc.: 59.38%] [Generator loss: 0.7771%]\n",
            "7221 [Discriminator loss: 0.6764%, acc.: 59.38%] [Generator loss: 0.7701%]\n",
            "7222 [Discriminator loss: 0.6785%, acc.: 55.08%] [Generator loss: 0.7848%]\n",
            "7223 [Discriminator loss: 0.6906%, acc.: 48.83%] [Generator loss: 0.7765%]\n",
            "7224 [Discriminator loss: 0.6643%, acc.: 58.98%] [Generator loss: 0.7713%]\n",
            "7225 [Discriminator loss: 0.6731%, acc.: 59.77%] [Generator loss: 0.7850%]\n",
            "7226 [Discriminator loss: 0.6629%, acc.: 59.77%] [Generator loss: 0.7739%]\n",
            "7227 [Discriminator loss: 0.6788%, acc.: 58.59%] [Generator loss: 0.7843%]\n",
            "7228 [Discriminator loss: 0.6681%, acc.: 60.16%] [Generator loss: 0.7941%]\n",
            "7229 [Discriminator loss: 0.6831%, acc.: 56.64%] [Generator loss: 0.8016%]\n",
            "7230 [Discriminator loss: 0.6769%, acc.: 54.69%] [Generator loss: 0.8033%]\n",
            "7231 [Discriminator loss: 0.6847%, acc.: 51.17%] [Generator loss: 0.8024%]\n",
            "7232 [Discriminator loss: 0.6643%, acc.: 64.06%] [Generator loss: 0.8042%]\n",
            "7233 [Discriminator loss: 0.6574%, acc.: 63.67%] [Generator loss: 0.7914%]\n",
            "7234 [Discriminator loss: 0.6727%, acc.: 60.55%] [Generator loss: 0.7868%]\n",
            "7235 [Discriminator loss: 0.6868%, acc.: 55.47%] [Generator loss: 0.7856%]\n",
            "7236 [Discriminator loss: 0.6702%, acc.: 59.77%] [Generator loss: 0.7869%]\n",
            "7237 [Discriminator loss: 0.6609%, acc.: 60.16%] [Generator loss: 0.7827%]\n",
            "7238 [Discriminator loss: 0.6596%, acc.: 63.28%] [Generator loss: 0.7868%]\n",
            "7239 [Discriminator loss: 0.6662%, acc.: 64.45%] [Generator loss: 0.7974%]\n",
            "7240 [Discriminator loss: 0.6730%, acc.: 58.98%] [Generator loss: 0.7914%]\n",
            "7241 [Discriminator loss: 0.6769%, acc.: 55.08%] [Generator loss: 0.7807%]\n",
            "7242 [Discriminator loss: 0.6654%, acc.: 58.20%] [Generator loss: 0.7939%]\n",
            "7243 [Discriminator loss: 0.6904%, acc.: 52.34%] [Generator loss: 0.7522%]\n",
            "7244 [Discriminator loss: 0.6613%, acc.: 61.33%] [Generator loss: 0.7770%]\n",
            "7245 [Discriminator loss: 0.6546%, acc.: 62.50%] [Generator loss: 0.7731%]\n",
            "7246 [Discriminator loss: 0.6791%, acc.: 53.91%] [Generator loss: 0.7742%]\n",
            "7247 [Discriminator loss: 0.6581%, acc.: 63.67%] [Generator loss: 0.7846%]\n",
            "7248 [Discriminator loss: 0.6551%, acc.: 62.11%] [Generator loss: 0.8076%]\n",
            "7249 [Discriminator loss: 0.6807%, acc.: 58.20%] [Generator loss: 0.7911%]\n",
            "7250 [Discriminator loss: 0.6804%, acc.: 57.42%] [Generator loss: 0.7905%]\n",
            "7251 [Discriminator loss: 0.6749%, acc.: 57.03%] [Generator loss: 0.7948%]\n",
            "7252 [Discriminator loss: 0.6696%, acc.: 59.38%] [Generator loss: 0.7919%]\n",
            "7253 [Discriminator loss: 0.6774%, acc.: 57.81%] [Generator loss: 0.7830%]\n",
            "7254 [Discriminator loss: 0.6837%, acc.: 57.42%] [Generator loss: 0.7806%]\n",
            "7255 [Discriminator loss: 0.6693%, acc.: 60.55%] [Generator loss: 0.7937%]\n",
            "7256 [Discriminator loss: 0.6782%, acc.: 58.59%] [Generator loss: 0.7920%]\n",
            "7257 [Discriminator loss: 0.6789%, acc.: 58.98%] [Generator loss: 0.7753%]\n",
            "7258 [Discriminator loss: 0.6811%, acc.: 56.64%] [Generator loss: 0.7631%]\n",
            "7259 [Discriminator loss: 0.6546%, acc.: 64.84%] [Generator loss: 0.7648%]\n",
            "7260 [Discriminator loss: 0.6696%, acc.: 55.47%] [Generator loss: 0.7404%]\n",
            "7261 [Discriminator loss: 0.6956%, acc.: 50.78%] [Generator loss: 0.7768%]\n",
            "7262 [Discriminator loss: 0.6821%, acc.: 52.73%] [Generator loss: 0.7932%]\n",
            "7263 [Discriminator loss: 0.7052%, acc.: 46.88%] [Generator loss: 0.7720%]\n",
            "7264 [Discriminator loss: 0.6574%, acc.: 63.67%] [Generator loss: 0.7753%]\n",
            "7265 [Discriminator loss: 0.6803%, acc.: 52.73%] [Generator loss: 0.7741%]\n",
            "7266 [Discriminator loss: 0.6657%, acc.: 59.77%] [Generator loss: 0.7808%]\n",
            "7267 [Discriminator loss: 0.6792%, acc.: 58.20%] [Generator loss: 0.7818%]\n",
            "7268 [Discriminator loss: 0.6947%, acc.: 50.78%] [Generator loss: 0.7657%]\n",
            "7269 [Discriminator loss: 0.6747%, acc.: 54.69%] [Generator loss: 0.7667%]\n",
            "7270 [Discriminator loss: 0.6762%, acc.: 55.47%] [Generator loss: 0.7626%]\n",
            "7271 [Discriminator loss: 0.6662%, acc.: 59.38%] [Generator loss: 0.7802%]\n",
            "7272 [Discriminator loss: 0.6752%, acc.: 57.03%] [Generator loss: 0.7929%]\n",
            "7273 [Discriminator loss: 0.6759%, acc.: 58.59%] [Generator loss: 0.7892%]\n",
            "7274 [Discriminator loss: 0.6786%, acc.: 53.12%] [Generator loss: 0.7909%]\n",
            "7275 [Discriminator loss: 0.6773%, acc.: 59.77%] [Generator loss: 0.7854%]\n",
            "7276 [Discriminator loss: 0.6858%, acc.: 55.47%] [Generator loss: 0.7655%]\n",
            "7277 [Discriminator loss: 0.6839%, acc.: 56.25%] [Generator loss: 0.7709%]\n",
            "7278 [Discriminator loss: 0.6950%, acc.: 48.44%] [Generator loss: 0.7897%]\n",
            "7279 [Discriminator loss: 0.6735%, acc.: 58.59%] [Generator loss: 0.7721%]\n",
            "7280 [Discriminator loss: 0.6678%, acc.: 59.38%] [Generator loss: 0.7742%]\n",
            "7281 [Discriminator loss: 0.6812%, acc.: 55.47%] [Generator loss: 0.7860%]\n",
            "7282 [Discriminator loss: 0.6834%, acc.: 52.34%] [Generator loss: 0.7805%]\n",
            "7283 [Discriminator loss: 0.6766%, acc.: 55.47%] [Generator loss: 0.7898%]\n",
            "7284 [Discriminator loss: 0.6794%, acc.: 53.12%] [Generator loss: 0.7685%]\n",
            "7285 [Discriminator loss: 0.6884%, acc.: 51.56%] [Generator loss: 0.7894%]\n",
            "7286 [Discriminator loss: 0.6732%, acc.: 58.98%] [Generator loss: 0.7920%]\n",
            "7287 [Discriminator loss: 0.6751%, acc.: 60.94%] [Generator loss: 0.7737%]\n",
            "7288 [Discriminator loss: 0.6653%, acc.: 60.55%] [Generator loss: 0.7862%]\n",
            "7289 [Discriminator loss: 0.6599%, acc.: 64.45%] [Generator loss: 0.7747%]\n",
            "7290 [Discriminator loss: 0.6747%, acc.: 60.55%] [Generator loss: 0.7683%]\n",
            "7291 [Discriminator loss: 0.6691%, acc.: 61.33%] [Generator loss: 0.7507%]\n",
            "7292 [Discriminator loss: 0.6875%, acc.: 51.56%] [Generator loss: 0.7588%]\n",
            "7293 [Discriminator loss: 0.6801%, acc.: 53.52%] [Generator loss: 0.7881%]\n",
            "7294 [Discriminator loss: 0.6669%, acc.: 57.03%] [Generator loss: 0.7884%]\n",
            "7295 [Discriminator loss: 0.6845%, acc.: 53.52%] [Generator loss: 0.7651%]\n",
            "7296 [Discriminator loss: 0.6851%, acc.: 55.08%] [Generator loss: 0.7797%]\n",
            "7297 [Discriminator loss: 0.6907%, acc.: 53.52%] [Generator loss: 0.7449%]\n",
            "7298 [Discriminator loss: 0.6652%, acc.: 55.86%] [Generator loss: 0.7716%]\n",
            "7299 [Discriminator loss: 0.6791%, acc.: 52.73%] [Generator loss: 0.8267%]\n",
            "7300 [Discriminator loss: 0.6883%, acc.: 57.42%] [Generator loss: 0.7704%]\n",
            "7301 [Discriminator loss: 0.6749%, acc.: 55.08%] [Generator loss: 0.7706%]\n",
            "7302 [Discriminator loss: 0.6731%, acc.: 59.77%] [Generator loss: 0.7766%]\n",
            "7303 [Discriminator loss: 0.6851%, acc.: 53.12%] [Generator loss: 0.7818%]\n",
            "7304 [Discriminator loss: 0.6788%, acc.: 58.20%] [Generator loss: 0.7847%]\n",
            "7305 [Discriminator loss: 0.6733%, acc.: 56.64%] [Generator loss: 0.7628%]\n",
            "7306 [Discriminator loss: 0.6966%, acc.: 53.91%] [Generator loss: 0.7876%]\n",
            "7307 [Discriminator loss: 0.6601%, acc.: 61.72%] [Generator loss: 0.7795%]\n",
            "7308 [Discriminator loss: 0.6737%, acc.: 60.55%] [Generator loss: 0.7951%]\n",
            "7309 [Discriminator loss: 0.6767%, acc.: 56.25%] [Generator loss: 0.7837%]\n",
            "7310 [Discriminator loss: 0.6720%, acc.: 56.25%] [Generator loss: 0.7696%]\n",
            "7311 [Discriminator loss: 0.6790%, acc.: 55.47%] [Generator loss: 0.7658%]\n",
            "7312 [Discriminator loss: 0.6964%, acc.: 51.95%] [Generator loss: 0.7947%]\n",
            "7313 [Discriminator loss: 0.6895%, acc.: 56.25%] [Generator loss: 0.7841%]\n",
            "7314 [Discriminator loss: 0.6844%, acc.: 53.91%] [Generator loss: 0.7630%]\n",
            "7315 [Discriminator loss: 0.6831%, acc.: 57.81%] [Generator loss: 0.7690%]\n",
            "7316 [Discriminator loss: 0.6858%, acc.: 52.34%] [Generator loss: 0.7706%]\n",
            "7317 [Discriminator loss: 0.6882%, acc.: 53.12%] [Generator loss: 0.7789%]\n",
            "7318 [Discriminator loss: 0.6883%, acc.: 52.73%] [Generator loss: 0.7639%]\n",
            "7319 [Discriminator loss: 0.6756%, acc.: 57.81%] [Generator loss: 0.7771%]\n",
            "7320 [Discriminator loss: 0.6808%, acc.: 60.55%] [Generator loss: 0.7764%]\n",
            "7321 [Discriminator loss: 0.6745%, acc.: 57.81%] [Generator loss: 0.7824%]\n",
            "7322 [Discriminator loss: 0.6925%, acc.: 53.12%] [Generator loss: 0.7677%]\n",
            "7323 [Discriminator loss: 0.6779%, acc.: 55.08%] [Generator loss: 0.7715%]\n",
            "7324 [Discriminator loss: 0.6884%, acc.: 58.20%] [Generator loss: 0.8024%]\n",
            "7325 [Discriminator loss: 0.6784%, acc.: 60.94%] [Generator loss: 0.7707%]\n",
            "7326 [Discriminator loss: 0.6839%, acc.: 57.42%] [Generator loss: 0.7664%]\n",
            "7327 [Discriminator loss: 0.6905%, acc.: 53.91%] [Generator loss: 0.7906%]\n",
            "7328 [Discriminator loss: 0.6762%, acc.: 57.42%] [Generator loss: 0.7839%]\n",
            "7329 [Discriminator loss: 0.6873%, acc.: 55.86%] [Generator loss: 0.7640%]\n",
            "7330 [Discriminator loss: 0.6636%, acc.: 62.50%] [Generator loss: 0.7672%]\n",
            "7331 [Discriminator loss: 0.6746%, acc.: 56.64%] [Generator loss: 0.7528%]\n",
            "7332 [Discriminator loss: 0.6791%, acc.: 53.52%] [Generator loss: 0.7955%]\n",
            "7333 [Discriminator loss: 0.6800%, acc.: 56.25%] [Generator loss: 0.7850%]\n",
            "7334 [Discriminator loss: 0.6785%, acc.: 55.86%] [Generator loss: 0.7872%]\n",
            "7335 [Discriminator loss: 0.6627%, acc.: 62.89%] [Generator loss: 0.7796%]\n",
            "7336 [Discriminator loss: 0.6914%, acc.: 51.56%] [Generator loss: 0.7812%]\n",
            "7337 [Discriminator loss: 0.6774%, acc.: 60.94%] [Generator loss: 0.7772%]\n",
            "7338 [Discriminator loss: 0.6706%, acc.: 60.94%] [Generator loss: 0.7785%]\n",
            "7339 [Discriminator loss: 0.6965%, acc.: 50.78%] [Generator loss: 0.7815%]\n",
            "7340 [Discriminator loss: 0.6610%, acc.: 60.16%] [Generator loss: 0.7981%]\n",
            "7341 [Discriminator loss: 0.6548%, acc.: 63.67%] [Generator loss: 0.7795%]\n",
            "7342 [Discriminator loss: 0.6754%, acc.: 59.38%] [Generator loss: 0.7885%]\n",
            "7343 [Discriminator loss: 0.6735%, acc.: 59.38%] [Generator loss: 0.7799%]\n",
            "7344 [Discriminator loss: 0.6702%, acc.: 59.38%] [Generator loss: 0.7846%]\n",
            "7345 [Discriminator loss: 0.6519%, acc.: 62.89%] [Generator loss: 0.7787%]\n",
            "7346 [Discriminator loss: 0.6523%, acc.: 66.02%] [Generator loss: 0.7878%]\n",
            "7347 [Discriminator loss: 0.6648%, acc.: 61.72%] [Generator loss: 0.7729%]\n",
            "7348 [Discriminator loss: 0.6737%, acc.: 56.25%] [Generator loss: 0.7641%]\n",
            "7349 [Discriminator loss: 0.6669%, acc.: 60.55%] [Generator loss: 0.7567%]\n",
            "7350 [Discriminator loss: 0.6709%, acc.: 54.30%] [Generator loss: 0.7806%]\n",
            "7351 [Discriminator loss: 0.6717%, acc.: 59.38%] [Generator loss: 0.8071%]\n",
            "7352 [Discriminator loss: 0.6584%, acc.: 62.50%] [Generator loss: 0.7886%]\n",
            "7353 [Discriminator loss: 0.6779%, acc.: 58.20%] [Generator loss: 0.7752%]\n",
            "7354 [Discriminator loss: 0.6699%, acc.: 60.94%] [Generator loss: 0.7734%]\n",
            "7355 [Discriminator loss: 0.6699%, acc.: 62.11%] [Generator loss: 0.7838%]\n",
            "7356 [Discriminator loss: 0.6680%, acc.: 57.03%] [Generator loss: 0.7793%]\n",
            "7357 [Discriminator loss: 0.6905%, acc.: 56.64%] [Generator loss: 0.7680%]\n",
            "7358 [Discriminator loss: 0.6836%, acc.: 56.64%] [Generator loss: 0.7814%]\n",
            "7359 [Discriminator loss: 0.6810%, acc.: 57.03%] [Generator loss: 0.7724%]\n",
            "7360 [Discriminator loss: 0.6796%, acc.: 56.64%] [Generator loss: 0.7869%]\n",
            "7361 [Discriminator loss: 0.6747%, acc.: 58.98%] [Generator loss: 0.7993%]\n",
            "7362 [Discriminator loss: 0.6750%, acc.: 56.25%] [Generator loss: 0.7816%]\n",
            "7363 [Discriminator loss: 0.6871%, acc.: 52.73%] [Generator loss: 0.7831%]\n",
            "7364 [Discriminator loss: 0.6958%, acc.: 50.78%] [Generator loss: 0.7741%]\n",
            "7365 [Discriminator loss: 0.6910%, acc.: 52.34%] [Generator loss: 0.7872%]\n",
            "7366 [Discriminator loss: 0.6731%, acc.: 59.38%] [Generator loss: 0.7810%]\n",
            "7367 [Discriminator loss: 0.6745%, acc.: 58.98%] [Generator loss: 0.7845%]\n",
            "7368 [Discriminator loss: 0.6785%, acc.: 57.81%] [Generator loss: 0.7754%]\n",
            "7369 [Discriminator loss: 0.6794%, acc.: 55.08%] [Generator loss: 0.7762%]\n",
            "7370 [Discriminator loss: 0.6735%, acc.: 56.25%] [Generator loss: 0.7957%]\n",
            "7371 [Discriminator loss: 0.6603%, acc.: 62.89%] [Generator loss: 0.7788%]\n",
            "7372 [Discriminator loss: 0.6855%, acc.: 50.39%] [Generator loss: 0.7824%]\n",
            "7373 [Discriminator loss: 0.6732%, acc.: 55.86%] [Generator loss: 0.7926%]\n",
            "7374 [Discriminator loss: 0.6726%, acc.: 60.94%] [Generator loss: 0.7664%]\n",
            "7375 [Discriminator loss: 0.6687%, acc.: 57.81%] [Generator loss: 0.7950%]\n",
            "7376 [Discriminator loss: 0.6637%, acc.: 58.20%] [Generator loss: 0.7774%]\n",
            "7377 [Discriminator loss: 0.6970%, acc.: 50.78%] [Generator loss: 0.7694%]\n",
            "7378 [Discriminator loss: 0.6972%, acc.: 51.17%] [Generator loss: 0.7607%]\n",
            "7379 [Discriminator loss: 0.6847%, acc.: 55.08%] [Generator loss: 0.7534%]\n",
            "7380 [Discriminator loss: 0.6713%, acc.: 58.59%] [Generator loss: 0.7656%]\n",
            "7381 [Discriminator loss: 0.6637%, acc.: 61.72%] [Generator loss: 0.7649%]\n",
            "7382 [Discriminator loss: 0.6714%, acc.: 60.55%] [Generator loss: 0.7519%]\n",
            "7383 [Discriminator loss: 0.6755%, acc.: 53.52%] [Generator loss: 0.7788%]\n",
            "7384 [Discriminator loss: 0.6691%, acc.: 58.20%] [Generator loss: 0.7946%]\n",
            "7385 [Discriminator loss: 0.6625%, acc.: 62.50%] [Generator loss: 0.7669%]\n",
            "7386 [Discriminator loss: 0.6971%, acc.: 49.61%] [Generator loss: 0.7884%]\n",
            "7387 [Discriminator loss: 0.6682%, acc.: 57.81%] [Generator loss: 0.7879%]\n",
            "7388 [Discriminator loss: 0.6933%, acc.: 52.34%] [Generator loss: 0.7734%]\n",
            "7389 [Discriminator loss: 0.6964%, acc.: 52.34%] [Generator loss: 0.7690%]\n",
            "7390 [Discriminator loss: 0.6614%, acc.: 60.16%] [Generator loss: 0.7844%]\n",
            "7391 [Discriminator loss: 0.6664%, acc.: 60.94%] [Generator loss: 0.7570%]\n",
            "7392 [Discriminator loss: 0.6895%, acc.: 51.95%] [Generator loss: 0.7665%]\n",
            "7393 [Discriminator loss: 0.6667%, acc.: 57.42%] [Generator loss: 0.7568%]\n",
            "7394 [Discriminator loss: 0.6538%, acc.: 65.23%] [Generator loss: 0.7877%]\n",
            "7395 [Discriminator loss: 0.6573%, acc.: 64.06%] [Generator loss: 0.7667%]\n",
            "7396 [Discriminator loss: 0.6641%, acc.: 60.55%] [Generator loss: 0.7641%]\n",
            "7397 [Discriminator loss: 0.6785%, acc.: 54.69%] [Generator loss: 0.7797%]\n",
            "7398 [Discriminator loss: 0.6710%, acc.: 57.03%] [Generator loss: 0.7610%]\n",
            "7399 [Discriminator loss: 0.6475%, acc.: 65.62%] [Generator loss: 0.7752%]\n",
            "7400 [Discriminator loss: 0.6722%, acc.: 57.03%] [Generator loss: 0.7810%]\n",
            "7401 [Discriminator loss: 0.6605%, acc.: 61.33%] [Generator loss: 0.7728%]\n",
            "7402 [Discriminator loss: 0.6803%, acc.: 56.25%] [Generator loss: 0.7674%]\n",
            "7403 [Discriminator loss: 0.6837%, acc.: 55.08%] [Generator loss: 0.7970%]\n",
            "7404 [Discriminator loss: 0.6786%, acc.: 55.86%] [Generator loss: 0.8032%]\n",
            "7405 [Discriminator loss: 0.6799%, acc.: 56.25%] [Generator loss: 0.7674%]\n",
            "7406 [Discriminator loss: 0.6762%, acc.: 59.38%] [Generator loss: 0.7684%]\n",
            "7407 [Discriminator loss: 0.6693%, acc.: 62.50%] [Generator loss: 0.7847%]\n",
            "7408 [Discriminator loss: 0.6858%, acc.: 59.77%] [Generator loss: 0.7912%]\n",
            "7409 [Discriminator loss: 0.6620%, acc.: 63.67%] [Generator loss: 0.8035%]\n",
            "7410 [Discriminator loss: 0.6760%, acc.: 55.08%] [Generator loss: 0.7893%]\n",
            "7411 [Discriminator loss: 0.6653%, acc.: 58.59%] [Generator loss: 0.7952%]\n",
            "7412 [Discriminator loss: 0.6657%, acc.: 61.33%] [Generator loss: 0.8119%]\n",
            "7413 [Discriminator loss: 0.6859%, acc.: 54.30%] [Generator loss: 0.7794%]\n",
            "7414 [Discriminator loss: 0.6783%, acc.: 54.69%] [Generator loss: 0.7769%]\n",
            "7415 [Discriminator loss: 0.6684%, acc.: 60.94%] [Generator loss: 0.7649%]\n",
            "7416 [Discriminator loss: 0.6929%, acc.: 51.95%] [Generator loss: 0.7810%]\n",
            "7417 [Discriminator loss: 0.6857%, acc.: 55.08%] [Generator loss: 0.7832%]\n",
            "7418 [Discriminator loss: 0.6883%, acc.: 54.30%] [Generator loss: 0.7962%]\n",
            "7419 [Discriminator loss: 0.6784%, acc.: 56.25%] [Generator loss: 0.7975%]\n",
            "7420 [Discriminator loss: 0.6800%, acc.: 54.30%] [Generator loss: 0.7910%]\n",
            "7421 [Discriminator loss: 0.6852%, acc.: 51.56%] [Generator loss: 0.7756%]\n",
            "7422 [Discriminator loss: 0.6829%, acc.: 53.52%] [Generator loss: 0.7911%]\n",
            "7423 [Discriminator loss: 0.6747%, acc.: 58.59%] [Generator loss: 0.7873%]\n",
            "7424 [Discriminator loss: 0.6744%, acc.: 57.03%] [Generator loss: 0.7800%]\n",
            "7425 [Discriminator loss: 0.6772%, acc.: 56.64%] [Generator loss: 0.7691%]\n",
            "7426 [Discriminator loss: 0.6700%, acc.: 58.59%] [Generator loss: 0.7686%]\n",
            "7427 [Discriminator loss: 0.6699%, acc.: 58.20%] [Generator loss: 0.7509%]\n",
            "7428 [Discriminator loss: 0.6944%, acc.: 50.39%] [Generator loss: 0.7627%]\n",
            "7429 [Discriminator loss: 0.6741%, acc.: 56.25%] [Generator loss: 0.7921%]\n",
            "7430 [Discriminator loss: 0.6622%, acc.: 60.94%] [Generator loss: 0.7809%]\n",
            "7431 [Discriminator loss: 0.6835%, acc.: 55.47%] [Generator loss: 0.7852%]\n",
            "7432 [Discriminator loss: 0.6793%, acc.: 58.59%] [Generator loss: 0.7720%]\n",
            "7433 [Discriminator loss: 0.6629%, acc.: 59.38%] [Generator loss: 0.8133%]\n",
            "7434 [Discriminator loss: 0.6809%, acc.: 55.86%] [Generator loss: 0.7820%]\n",
            "7435 [Discriminator loss: 0.6871%, acc.: 57.03%] [Generator loss: 0.7806%]\n",
            "7436 [Discriminator loss: 0.6683%, acc.: 57.42%] [Generator loss: 0.7610%]\n",
            "7437 [Discriminator loss: 0.6714%, acc.: 57.03%] [Generator loss: 0.7766%]\n",
            "7438 [Discriminator loss: 0.6473%, acc.: 65.62%] [Generator loss: 0.7761%]\n",
            "7439 [Discriminator loss: 0.6836%, acc.: 56.25%] [Generator loss: 0.7747%]\n",
            "7440 [Discriminator loss: 0.6875%, acc.: 55.47%] [Generator loss: 0.7626%]\n",
            "7441 [Discriminator loss: 0.6749%, acc.: 54.69%] [Generator loss: 0.7750%]\n",
            "7442 [Discriminator loss: 0.6665%, acc.: 60.16%] [Generator loss: 0.7686%]\n",
            "7443 [Discriminator loss: 0.6888%, acc.: 52.34%] [Generator loss: 0.7714%]\n",
            "7444 [Discriminator loss: 0.6774%, acc.: 56.64%] [Generator loss: 0.7854%]\n",
            "7445 [Discriminator loss: 0.6810%, acc.: 55.47%] [Generator loss: 0.7911%]\n",
            "7446 [Discriminator loss: 0.6753%, acc.: 57.03%] [Generator loss: 0.7691%]\n",
            "7447 [Discriminator loss: 0.6855%, acc.: 55.08%] [Generator loss: 0.7802%]\n",
            "7448 [Discriminator loss: 0.6784%, acc.: 56.25%] [Generator loss: 0.7812%]\n",
            "7449 [Discriminator loss: 0.6767%, acc.: 56.25%] [Generator loss: 0.7819%]\n",
            "7450 [Discriminator loss: 0.6894%, acc.: 46.88%] [Generator loss: 0.7667%]\n",
            "7451 [Discriminator loss: 0.6949%, acc.: 54.30%] [Generator loss: 0.8000%]\n",
            "7452 [Discriminator loss: 0.6733%, acc.: 56.64%] [Generator loss: 0.7820%]\n",
            "7453 [Discriminator loss: 0.6724%, acc.: 57.81%] [Generator loss: 0.7730%]\n",
            "7454 [Discriminator loss: 0.6786%, acc.: 55.08%] [Generator loss: 0.7924%]\n",
            "7455 [Discriminator loss: 0.6760%, acc.: 54.69%] [Generator loss: 0.7874%]\n",
            "7456 [Discriminator loss: 0.6722%, acc.: 58.20%] [Generator loss: 0.7737%]\n",
            "7457 [Discriminator loss: 0.6743%, acc.: 60.94%] [Generator loss: 0.7808%]\n",
            "7458 [Discriminator loss: 0.6711%, acc.: 55.86%] [Generator loss: 0.7660%]\n",
            "7459 [Discriminator loss: 0.6627%, acc.: 60.94%] [Generator loss: 0.7862%]\n",
            "7460 [Discriminator loss: 0.6730%, acc.: 57.42%] [Generator loss: 0.7975%]\n",
            "7461 [Discriminator loss: 0.6865%, acc.: 56.25%] [Generator loss: 0.7878%]\n",
            "7462 [Discriminator loss: 0.6647%, acc.: 57.42%] [Generator loss: 0.7750%]\n",
            "7463 [Discriminator loss: 0.6805%, acc.: 57.03%] [Generator loss: 0.7914%]\n",
            "7464 [Discriminator loss: 0.6677%, acc.: 61.72%] [Generator loss: 0.7857%]\n",
            "7465 [Discriminator loss: 0.6633%, acc.: 61.33%] [Generator loss: 0.7884%]\n",
            "7466 [Discriminator loss: 0.6690%, acc.: 60.55%] [Generator loss: 0.7784%]\n",
            "7467 [Discriminator loss: 0.6787%, acc.: 56.64%] [Generator loss: 0.7624%]\n",
            "7468 [Discriminator loss: 0.6786%, acc.: 58.98%] [Generator loss: 0.7855%]\n",
            "7469 [Discriminator loss: 0.6825%, acc.: 53.91%] [Generator loss: 0.8009%]\n",
            "7470 [Discriminator loss: 0.6667%, acc.: 60.94%] [Generator loss: 0.7896%]\n",
            "7471 [Discriminator loss: 0.6570%, acc.: 61.72%] [Generator loss: 0.7798%]\n",
            "7472 [Discriminator loss: 0.6613%, acc.: 60.94%] [Generator loss: 0.7927%]\n",
            "7473 [Discriminator loss: 0.6765%, acc.: 61.72%] [Generator loss: 0.7698%]\n",
            "7474 [Discriminator loss: 0.6739%, acc.: 56.64%] [Generator loss: 0.7755%]\n",
            "7475 [Discriminator loss: 0.6747%, acc.: 54.30%] [Generator loss: 0.7864%]\n",
            "7476 [Discriminator loss: 0.6785%, acc.: 55.86%] [Generator loss: 0.7653%]\n",
            "7477 [Discriminator loss: 0.6839%, acc.: 57.03%] [Generator loss: 0.7667%]\n",
            "7478 [Discriminator loss: 0.6603%, acc.: 59.38%] [Generator loss: 0.7743%]\n",
            "7479 [Discriminator loss: 0.6660%, acc.: 60.16%] [Generator loss: 0.7714%]\n",
            "7480 [Discriminator loss: 0.6573%, acc.: 64.06%] [Generator loss: 0.7864%]\n",
            "7481 [Discriminator loss: 0.6857%, acc.: 58.20%] [Generator loss: 0.7767%]\n",
            "7482 [Discriminator loss: 0.6619%, acc.: 64.06%] [Generator loss: 0.7634%]\n",
            "7483 [Discriminator loss: 0.6655%, acc.: 58.20%] [Generator loss: 0.7820%]\n",
            "7484 [Discriminator loss: 0.6778%, acc.: 53.91%] [Generator loss: 0.7822%]\n",
            "7485 [Discriminator loss: 0.6808%, acc.: 57.81%] [Generator loss: 0.7720%]\n",
            "7486 [Discriminator loss: 0.6781%, acc.: 58.20%] [Generator loss: 0.7821%]\n",
            "7487 [Discriminator loss: 0.6676%, acc.: 57.03%] [Generator loss: 0.7826%]\n",
            "7488 [Discriminator loss: 0.6611%, acc.: 58.98%] [Generator loss: 0.8046%]\n",
            "7489 [Discriminator loss: 0.6898%, acc.: 57.03%] [Generator loss: 0.7637%]\n",
            "7490 [Discriminator loss: 0.6851%, acc.: 49.61%] [Generator loss: 0.7799%]\n",
            "7491 [Discriminator loss: 0.6551%, acc.: 63.67%] [Generator loss: 0.7805%]\n",
            "7492 [Discriminator loss: 0.6641%, acc.: 60.94%] [Generator loss: 0.7812%]\n",
            "7493 [Discriminator loss: 0.6722%, acc.: 57.81%] [Generator loss: 0.7729%]\n",
            "7494 [Discriminator loss: 0.6831%, acc.: 55.08%] [Generator loss: 0.7740%]\n",
            "7495 [Discriminator loss: 0.6936%, acc.: 50.00%] [Generator loss: 0.7505%]\n",
            "7496 [Discriminator loss: 0.6645%, acc.: 59.77%] [Generator loss: 0.7666%]\n",
            "7497 [Discriminator loss: 0.6715%, acc.: 58.20%] [Generator loss: 0.7584%]\n",
            "7498 [Discriminator loss: 0.6912%, acc.: 51.56%] [Generator loss: 0.7663%]\n",
            "7499 [Discriminator loss: 0.6913%, acc.: 50.39%] [Generator loss: 0.7606%]\n",
            "7500 [Discriminator loss: 0.6841%, acc.: 54.69%] [Generator loss: 0.7826%]\n",
            "7501 [Discriminator loss: 0.6891%, acc.: 50.39%] [Generator loss: 0.7886%]\n",
            "7502 [Discriminator loss: 0.6764%, acc.: 53.91%] [Generator loss: 0.7907%]\n",
            "7503 [Discriminator loss: 0.6659%, acc.: 59.77%] [Generator loss: 0.7802%]\n",
            "7504 [Discriminator loss: 0.6857%, acc.: 52.73%] [Generator loss: 0.7786%]\n",
            "7505 [Discriminator loss: 0.6849%, acc.: 56.25%] [Generator loss: 0.7756%]\n",
            "7506 [Discriminator loss: 0.6560%, acc.: 60.55%] [Generator loss: 0.7788%]\n",
            "7507 [Discriminator loss: 0.6842%, acc.: 53.91%] [Generator loss: 0.7658%]\n",
            "7508 [Discriminator loss: 0.6651%, acc.: 58.98%] [Generator loss: 0.7848%]\n",
            "7509 [Discriminator loss: 0.6867%, acc.: 55.08%] [Generator loss: 0.7544%]\n",
            "7510 [Discriminator loss: 0.6679%, acc.: 56.25%] [Generator loss: 0.7564%]\n",
            "7511 [Discriminator loss: 0.6564%, acc.: 65.62%] [Generator loss: 0.7606%]\n",
            "7512 [Discriminator loss: 0.6740%, acc.: 59.38%] [Generator loss: 0.7853%]\n",
            "7513 [Discriminator loss: 0.6836%, acc.: 55.47%] [Generator loss: 0.7728%]\n",
            "7514 [Discriminator loss: 0.6618%, acc.: 62.11%] [Generator loss: 0.7685%]\n",
            "7515 [Discriminator loss: 0.6888%, acc.: 53.12%] [Generator loss: 0.7571%]\n",
            "7516 [Discriminator loss: 0.6962%, acc.: 54.69%] [Generator loss: 0.7598%]\n",
            "7517 [Discriminator loss: 0.6700%, acc.: 60.55%] [Generator loss: 0.7686%]\n",
            "7518 [Discriminator loss: 0.6796%, acc.: 59.77%] [Generator loss: 0.7898%]\n",
            "7519 [Discriminator loss: 0.6675%, acc.: 60.94%] [Generator loss: 0.7710%]\n",
            "7520 [Discriminator loss: 0.6709%, acc.: 58.98%] [Generator loss: 0.7836%]\n",
            "7521 [Discriminator loss: 0.6811%, acc.: 58.59%] [Generator loss: 0.7634%]\n",
            "7522 [Discriminator loss: 0.6663%, acc.: 59.38%] [Generator loss: 0.7847%]\n",
            "7523 [Discriminator loss: 0.6586%, acc.: 64.45%] [Generator loss: 0.7993%]\n",
            "7524 [Discriminator loss: 0.6773%, acc.: 55.86%] [Generator loss: 0.7838%]\n",
            "7525 [Discriminator loss: 0.6926%, acc.: 55.47%] [Generator loss: 0.7670%]\n",
            "7526 [Discriminator loss: 0.6804%, acc.: 52.73%] [Generator loss: 0.7951%]\n",
            "7527 [Discriminator loss: 0.6890%, acc.: 53.52%] [Generator loss: 0.8006%]\n",
            "7528 [Discriminator loss: 0.6733%, acc.: 53.91%] [Generator loss: 0.7735%]\n",
            "7529 [Discriminator loss: 0.6698%, acc.: 58.20%] [Generator loss: 0.7698%]\n",
            "7530 [Discriminator loss: 0.6848%, acc.: 55.86%] [Generator loss: 0.7774%]\n",
            "7531 [Discriminator loss: 0.6807%, acc.: 58.20%] [Generator loss: 0.8030%]\n",
            "7532 [Discriminator loss: 0.6865%, acc.: 56.64%] [Generator loss: 0.7801%]\n",
            "7533 [Discriminator loss: 0.6683%, acc.: 60.94%] [Generator loss: 0.7998%]\n",
            "7534 [Discriminator loss: 0.6639%, acc.: 63.67%] [Generator loss: 0.7998%]\n",
            "7535 [Discriminator loss: 0.6795%, acc.: 55.08%] [Generator loss: 0.7801%]\n",
            "7536 [Discriminator loss: 0.6989%, acc.: 53.12%] [Generator loss: 0.7863%]\n",
            "7537 [Discriminator loss: 0.6815%, acc.: 57.03%] [Generator loss: 0.7798%]\n",
            "7538 [Discriminator loss: 0.6838%, acc.: 57.03%] [Generator loss: 0.7898%]\n",
            "7539 [Discriminator loss: 0.6923%, acc.: 55.47%] [Generator loss: 0.7655%]\n",
            "7540 [Discriminator loss: 0.6793%, acc.: 57.03%] [Generator loss: 0.7822%]\n",
            "7541 [Discriminator loss: 0.6733%, acc.: 57.03%] [Generator loss: 0.7789%]\n",
            "7542 [Discriminator loss: 0.6902%, acc.: 51.56%] [Generator loss: 0.7868%]\n",
            "7543 [Discriminator loss: 0.6770%, acc.: 56.25%] [Generator loss: 0.7732%]\n",
            "7544 [Discriminator loss: 0.6967%, acc.: 50.78%] [Generator loss: 0.7824%]\n",
            "7545 [Discriminator loss: 0.6931%, acc.: 55.86%] [Generator loss: 0.7574%]\n",
            "7546 [Discriminator loss: 0.6778%, acc.: 59.38%] [Generator loss: 0.7659%]\n",
            "7547 [Discriminator loss: 0.6903%, acc.: 55.86%] [Generator loss: 0.7603%]\n",
            "7548 [Discriminator loss: 0.6918%, acc.: 53.12%] [Generator loss: 0.7751%]\n",
            "7549 [Discriminator loss: 0.6697%, acc.: 62.50%] [Generator loss: 0.7701%]\n",
            "7550 [Discriminator loss: 0.6788%, acc.: 56.64%] [Generator loss: 0.7786%]\n",
            "7551 [Discriminator loss: 0.6804%, acc.: 57.42%] [Generator loss: 0.8059%]\n",
            "7552 [Discriminator loss: 0.6621%, acc.: 63.67%] [Generator loss: 0.8054%]\n",
            "7553 [Discriminator loss: 0.6880%, acc.: 53.52%] [Generator loss: 0.7775%]\n",
            "7554 [Discriminator loss: 0.6785%, acc.: 60.55%] [Generator loss: 0.7790%]\n",
            "7555 [Discriminator loss: 0.6560%, acc.: 61.72%] [Generator loss: 0.7713%]\n",
            "7556 [Discriminator loss: 0.6747%, acc.: 54.69%] [Generator loss: 0.7690%]\n",
            "7557 [Discriminator loss: 0.6753%, acc.: 57.81%] [Generator loss: 0.7661%]\n",
            "7558 [Discriminator loss: 0.6665%, acc.: 61.33%] [Generator loss: 0.7535%]\n",
            "7559 [Discriminator loss: 0.6805%, acc.: 57.42%] [Generator loss: 0.7691%]\n",
            "7560 [Discriminator loss: 0.6627%, acc.: 60.16%] [Generator loss: 0.7796%]\n",
            "7561 [Discriminator loss: 0.6862%, acc.: 51.56%] [Generator loss: 0.7807%]\n",
            "7562 [Discriminator loss: 0.6885%, acc.: 52.73%] [Generator loss: 0.7673%]\n",
            "7563 [Discriminator loss: 0.6657%, acc.: 56.64%] [Generator loss: 0.7672%]\n",
            "7564 [Discriminator loss: 0.6660%, acc.: 57.03%] [Generator loss: 0.7740%]\n",
            "7565 [Discriminator loss: 0.6781%, acc.: 56.25%] [Generator loss: 0.8033%]\n",
            "7566 [Discriminator loss: 0.6682%, acc.: 60.94%] [Generator loss: 0.7873%]\n",
            "7567 [Discriminator loss: 0.6821%, acc.: 58.98%] [Generator loss: 0.7873%]\n",
            "7568 [Discriminator loss: 0.6622%, acc.: 62.50%] [Generator loss: 0.7732%]\n",
            "7569 [Discriminator loss: 0.6858%, acc.: 54.30%] [Generator loss: 0.7781%]\n",
            "7570 [Discriminator loss: 0.6801%, acc.: 60.55%] [Generator loss: 0.7992%]\n",
            "7571 [Discriminator loss: 0.6798%, acc.: 56.25%] [Generator loss: 0.7714%]\n",
            "7572 [Discriminator loss: 0.6733%, acc.: 55.47%] [Generator loss: 0.8056%]\n",
            "7573 [Discriminator loss: 0.7068%, acc.: 51.95%] [Generator loss: 0.7906%]\n",
            "7574 [Discriminator loss: 0.6747%, acc.: 56.64%] [Generator loss: 0.7862%]\n",
            "7575 [Discriminator loss: 0.6590%, acc.: 58.98%] [Generator loss: 0.8105%]\n",
            "7576 [Discriminator loss: 0.6575%, acc.: 60.55%] [Generator loss: 0.7952%]\n",
            "7577 [Discriminator loss: 0.6762%, acc.: 59.38%] [Generator loss: 0.8073%]\n",
            "7578 [Discriminator loss: 0.6961%, acc.: 55.86%] [Generator loss: 0.8005%]\n",
            "7579 [Discriminator loss: 0.6669%, acc.: 59.77%] [Generator loss: 0.7865%]\n",
            "7580 [Discriminator loss: 0.6711%, acc.: 61.72%] [Generator loss: 0.7693%]\n",
            "7581 [Discriminator loss: 0.6809%, acc.: 56.64%] [Generator loss: 0.7796%]\n",
            "7582 [Discriminator loss: 0.6780%, acc.: 54.69%] [Generator loss: 0.7657%]\n",
            "7583 [Discriminator loss: 0.6810%, acc.: 53.91%] [Generator loss: 0.7936%]\n",
            "7584 [Discriminator loss: 0.6623%, acc.: 61.72%] [Generator loss: 0.7721%]\n",
            "7585 [Discriminator loss: 0.6797%, acc.: 57.81%] [Generator loss: 0.7865%]\n",
            "7586 [Discriminator loss: 0.6726%, acc.: 57.81%] [Generator loss: 0.7785%]\n",
            "7587 [Discriminator loss: 0.6773%, acc.: 53.52%] [Generator loss: 0.7801%]\n",
            "7588 [Discriminator loss: 0.6909%, acc.: 50.39%] [Generator loss: 0.7758%]\n",
            "7589 [Discriminator loss: 0.6810%, acc.: 58.98%] [Generator loss: 0.7637%]\n",
            "7590 [Discriminator loss: 0.6926%, acc.: 50.00%] [Generator loss: 0.7744%]\n",
            "7591 [Discriminator loss: 0.6693%, acc.: 60.55%] [Generator loss: 0.7873%]\n",
            "7592 [Discriminator loss: 0.6741%, acc.: 57.81%] [Generator loss: 0.7756%]\n",
            "7593 [Discriminator loss: 0.6918%, acc.: 55.47%] [Generator loss: 0.7671%]\n",
            "7594 [Discriminator loss: 0.6701%, acc.: 61.33%] [Generator loss: 0.7750%]\n",
            "7595 [Discriminator loss: 0.6559%, acc.: 65.62%] [Generator loss: 0.7662%]\n",
            "7596 [Discriminator loss: 0.6781%, acc.: 60.55%] [Generator loss: 0.7765%]\n",
            "7597 [Discriminator loss: 0.6872%, acc.: 52.73%] [Generator loss: 0.7639%]\n",
            "7598 [Discriminator loss: 0.6802%, acc.: 56.64%] [Generator loss: 0.7649%]\n",
            "7599 [Discriminator loss: 0.6838%, acc.: 54.30%] [Generator loss: 0.7720%]\n",
            "7600 [Discriminator loss: 0.6889%, acc.: 54.69%] [Generator loss: 0.7737%]\n",
            "7601 [Discriminator loss: 0.7004%, acc.: 47.66%] [Generator loss: 0.7709%]\n",
            "7602 [Discriminator loss: 0.6918%, acc.: 53.12%] [Generator loss: 0.7712%]\n",
            "7603 [Discriminator loss: 0.6781%, acc.: 56.25%] [Generator loss: 0.7545%]\n",
            "7604 [Discriminator loss: 0.6934%, acc.: 51.95%] [Generator loss: 0.7758%]\n",
            "7605 [Discriminator loss: 0.6878%, acc.: 53.91%] [Generator loss: 0.7667%]\n",
            "7606 [Discriminator loss: 0.6948%, acc.: 48.44%] [Generator loss: 0.7849%]\n",
            "7607 [Discriminator loss: 0.6834%, acc.: 51.95%] [Generator loss: 0.7674%]\n",
            "7608 [Discriminator loss: 0.6890%, acc.: 57.42%] [Generator loss: 0.7929%]\n",
            "7609 [Discriminator loss: 0.6664%, acc.: 55.86%] [Generator loss: 0.7596%]\n",
            "7610 [Discriminator loss: 0.6953%, acc.: 55.86%] [Generator loss: 0.7707%]\n",
            "7611 [Discriminator loss: 0.6818%, acc.: 58.59%] [Generator loss: 0.7697%]\n",
            "7612 [Discriminator loss: 0.6591%, acc.: 60.94%] [Generator loss: 0.8193%]\n",
            "7613 [Discriminator loss: 0.6801%, acc.: 53.12%] [Generator loss: 0.8137%]\n",
            "7614 [Discriminator loss: 0.6777%, acc.: 56.64%] [Generator loss: 0.7898%]\n",
            "7615 [Discriminator loss: 0.6727%, acc.: 57.42%] [Generator loss: 0.8163%]\n",
            "7616 [Discriminator loss: 0.6852%, acc.: 53.52%] [Generator loss: 0.7955%]\n",
            "7617 [Discriminator loss: 0.6746%, acc.: 57.81%] [Generator loss: 0.7766%]\n",
            "7618 [Discriminator loss: 0.6768%, acc.: 56.25%] [Generator loss: 0.7726%]\n",
            "7619 [Discriminator loss: 0.6679%, acc.: 60.55%] [Generator loss: 0.7839%]\n",
            "7620 [Discriminator loss: 0.6607%, acc.: 59.38%] [Generator loss: 0.7842%]\n",
            "7621 [Discriminator loss: 0.6715%, acc.: 59.38%] [Generator loss: 0.7870%]\n",
            "7622 [Discriminator loss: 0.6668%, acc.: 59.38%] [Generator loss: 0.7733%]\n",
            "7623 [Discriminator loss: 0.6782%, acc.: 53.52%] [Generator loss: 0.7697%]\n",
            "7624 [Discriminator loss: 0.6757%, acc.: 55.47%] [Generator loss: 0.7749%]\n",
            "7625 [Discriminator loss: 0.6693%, acc.: 56.25%] [Generator loss: 0.7911%]\n",
            "7626 [Discriminator loss: 0.6547%, acc.: 63.28%] [Generator loss: 0.7933%]\n",
            "7627 [Discriminator loss: 0.6817%, acc.: 55.86%] [Generator loss: 0.7741%]\n",
            "7628 [Discriminator loss: 0.6703%, acc.: 60.55%] [Generator loss: 0.7736%]\n",
            "7629 [Discriminator loss: 0.6725%, acc.: 61.72%] [Generator loss: 0.7967%]\n",
            "7630 [Discriminator loss: 0.6826%, acc.: 51.95%] [Generator loss: 0.7734%]\n",
            "7631 [Discriminator loss: 0.6641%, acc.: 62.11%] [Generator loss: 0.7726%]\n",
            "7632 [Discriminator loss: 0.6767%, acc.: 58.20%] [Generator loss: 0.7660%]\n",
            "7633 [Discriminator loss: 0.6680%, acc.: 61.72%] [Generator loss: 0.7742%]\n",
            "7634 [Discriminator loss: 0.6617%, acc.: 63.67%] [Generator loss: 0.7732%]\n",
            "7635 [Discriminator loss: 0.6711%, acc.: 60.94%] [Generator loss: 0.7763%]\n",
            "7636 [Discriminator loss: 0.6824%, acc.: 58.20%] [Generator loss: 0.7613%]\n",
            "7637 [Discriminator loss: 0.6848%, acc.: 56.64%] [Generator loss: 0.7718%]\n",
            "7638 [Discriminator loss: 0.6760%, acc.: 56.64%] [Generator loss: 0.7658%]\n",
            "7639 [Discriminator loss: 0.6655%, acc.: 62.50%] [Generator loss: 0.7745%]\n",
            "7640 [Discriminator loss: 0.6684%, acc.: 57.42%] [Generator loss: 0.7867%]\n",
            "7641 [Discriminator loss: 0.6580%, acc.: 62.89%] [Generator loss: 0.7946%]\n",
            "7642 [Discriminator loss: 0.6669%, acc.: 60.94%] [Generator loss: 0.7872%]\n",
            "7643 [Discriminator loss: 0.6622%, acc.: 65.23%] [Generator loss: 0.8001%]\n",
            "7644 [Discriminator loss: 0.6578%, acc.: 63.67%] [Generator loss: 0.7995%]\n",
            "7645 [Discriminator loss: 0.6539%, acc.: 64.06%] [Generator loss: 0.7927%]\n",
            "7646 [Discriminator loss: 0.6626%, acc.: 60.55%] [Generator loss: 0.8005%]\n",
            "7647 [Discriminator loss: 0.6684%, acc.: 60.55%] [Generator loss: 0.7831%]\n",
            "7648 [Discriminator loss: 0.6830%, acc.: 53.12%] [Generator loss: 0.7921%]\n",
            "7649 [Discriminator loss: 0.6771%, acc.: 57.81%] [Generator loss: 0.7779%]\n",
            "7650 [Discriminator loss: 0.6905%, acc.: 52.34%] [Generator loss: 0.7963%]\n",
            "7651 [Discriminator loss: 0.6663%, acc.: 61.72%] [Generator loss: 0.7599%]\n",
            "7652 [Discriminator loss: 0.6619%, acc.: 60.16%] [Generator loss: 0.7790%]\n",
            "7653 [Discriminator loss: 0.6642%, acc.: 63.28%] [Generator loss: 0.7691%]\n",
            "7654 [Discriminator loss: 0.6696%, acc.: 57.03%] [Generator loss: 0.7657%]\n",
            "7655 [Discriminator loss: 0.6537%, acc.: 60.94%] [Generator loss: 0.7683%]\n",
            "7656 [Discriminator loss: 0.6645%, acc.: 62.11%] [Generator loss: 0.7741%]\n",
            "7657 [Discriminator loss: 0.6778%, acc.: 55.08%] [Generator loss: 0.7886%]\n",
            "7658 [Discriminator loss: 0.6701%, acc.: 62.50%] [Generator loss: 0.7900%]\n",
            "7659 [Discriminator loss: 0.6688%, acc.: 60.94%] [Generator loss: 0.7741%]\n",
            "7660 [Discriminator loss: 0.6716%, acc.: 56.64%] [Generator loss: 0.7783%]\n",
            "7661 [Discriminator loss: 0.6699%, acc.: 58.20%] [Generator loss: 0.7752%]\n",
            "7662 [Discriminator loss: 0.6747%, acc.: 56.25%] [Generator loss: 0.7764%]\n",
            "7663 [Discriminator loss: 0.6883%, acc.: 55.47%] [Generator loss: 0.7652%]\n",
            "7664 [Discriminator loss: 0.6779%, acc.: 58.59%] [Generator loss: 0.7729%]\n",
            "7665 [Discriminator loss: 0.6623%, acc.: 60.55%] [Generator loss: 0.7713%]\n",
            "7666 [Discriminator loss: 0.6728%, acc.: 58.98%] [Generator loss: 0.7842%]\n",
            "7667 [Discriminator loss: 0.6919%, acc.: 52.34%] [Generator loss: 0.7792%]\n",
            "7668 [Discriminator loss: 0.6849%, acc.: 54.30%] [Generator loss: 0.7798%]\n",
            "7669 [Discriminator loss: 0.6602%, acc.: 62.11%] [Generator loss: 0.7639%]\n",
            "7670 [Discriminator loss: 0.6814%, acc.: 53.91%] [Generator loss: 0.7937%]\n",
            "7671 [Discriminator loss: 0.6764%, acc.: 53.12%] [Generator loss: 0.7658%]\n",
            "7672 [Discriminator loss: 0.6850%, acc.: 55.08%] [Generator loss: 0.7802%]\n",
            "7673 [Discriminator loss: 0.6790%, acc.: 57.42%] [Generator loss: 0.7793%]\n",
            "7674 [Discriminator loss: 0.6774%, acc.: 58.98%] [Generator loss: 0.7633%]\n",
            "7675 [Discriminator loss: 0.6820%, acc.: 58.20%] [Generator loss: 0.7651%]\n",
            "7676 [Discriminator loss: 0.6743%, acc.: 55.08%] [Generator loss: 0.7430%]\n",
            "7677 [Discriminator loss: 0.6731%, acc.: 55.86%] [Generator loss: 0.7606%]\n",
            "7678 [Discriminator loss: 0.6857%, acc.: 55.86%] [Generator loss: 0.7486%]\n",
            "7679 [Discriminator loss: 0.6827%, acc.: 58.20%] [Generator loss: 0.7881%]\n",
            "7680 [Discriminator loss: 0.6812%, acc.: 55.08%] [Generator loss: 0.7715%]\n",
            "7681 [Discriminator loss: 0.6759%, acc.: 54.69%] [Generator loss: 0.7838%]\n",
            "7682 [Discriminator loss: 0.6698%, acc.: 56.64%] [Generator loss: 0.7746%]\n",
            "7683 [Discriminator loss: 0.6706%, acc.: 60.55%] [Generator loss: 0.7964%]\n",
            "7684 [Discriminator loss: 0.6810%, acc.: 52.73%] [Generator loss: 0.7772%]\n",
            "7685 [Discriminator loss: 0.6964%, acc.: 54.69%] [Generator loss: 0.7928%]\n",
            "7686 [Discriminator loss: 0.6808%, acc.: 54.30%] [Generator loss: 0.7922%]\n",
            "7687 [Discriminator loss: 0.6535%, acc.: 63.67%] [Generator loss: 0.7973%]\n",
            "7688 [Discriminator loss: 0.6798%, acc.: 58.59%] [Generator loss: 0.7930%]\n",
            "7689 [Discriminator loss: 0.6774%, acc.: 54.30%] [Generator loss: 0.7936%]\n",
            "7690 [Discriminator loss: 0.6646%, acc.: 58.98%] [Generator loss: 0.7780%]\n",
            "7691 [Discriminator loss: 0.6889%, acc.: 54.69%] [Generator loss: 0.7670%]\n",
            "7692 [Discriminator loss: 0.6785%, acc.: 60.16%] [Generator loss: 0.7747%]\n",
            "7693 [Discriminator loss: 0.6830%, acc.: 54.30%] [Generator loss: 0.7714%]\n",
            "7694 [Discriminator loss: 0.6672%, acc.: 58.98%] [Generator loss: 0.7754%]\n",
            "7695 [Discriminator loss: 0.6754%, acc.: 55.86%] [Generator loss: 0.7654%]\n",
            "7696 [Discriminator loss: 0.6759%, acc.: 53.52%] [Generator loss: 0.8034%]\n",
            "7697 [Discriminator loss: 0.6822%, acc.: 53.91%] [Generator loss: 0.7760%]\n",
            "7698 [Discriminator loss: 0.6855%, acc.: 55.08%] [Generator loss: 0.7783%]\n",
            "7699 [Discriminator loss: 0.6774%, acc.: 57.42%] [Generator loss: 0.7666%]\n",
            "7700 [Discriminator loss: 0.6822%, acc.: 55.86%] [Generator loss: 0.7623%]\n",
            "7701 [Discriminator loss: 0.6737%, acc.: 59.77%] [Generator loss: 0.7884%]\n",
            "7702 [Discriminator loss: 0.6691%, acc.: 60.16%] [Generator loss: 0.7659%]\n",
            "7703 [Discriminator loss: 0.6936%, acc.: 48.83%] [Generator loss: 0.7828%]\n",
            "7704 [Discriminator loss: 0.6735%, acc.: 59.77%] [Generator loss: 0.7830%]\n",
            "7705 [Discriminator loss: 0.6775%, acc.: 58.98%] [Generator loss: 0.7820%]\n",
            "7706 [Discriminator loss: 0.6655%, acc.: 59.38%] [Generator loss: 0.7799%]\n",
            "7707 [Discriminator loss: 0.6727%, acc.: 55.86%] [Generator loss: 0.7763%]\n",
            "7708 [Discriminator loss: 0.6782%, acc.: 55.08%] [Generator loss: 0.7851%]\n",
            "7709 [Discriminator loss: 0.6633%, acc.: 64.06%] [Generator loss: 0.7763%]\n",
            "7710 [Discriminator loss: 0.6758%, acc.: 57.81%] [Generator loss: 0.7786%]\n",
            "7711 [Discriminator loss: 0.6768%, acc.: 57.81%] [Generator loss: 0.7803%]\n",
            "7712 [Discriminator loss: 0.6768%, acc.: 57.42%] [Generator loss: 0.7561%]\n",
            "7713 [Discriminator loss: 0.6839%, acc.: 53.91%] [Generator loss: 0.7959%]\n",
            "7714 [Discriminator loss: 0.6774%, acc.: 55.86%] [Generator loss: 0.7861%]\n",
            "7715 [Discriminator loss: 0.6795%, acc.: 57.03%] [Generator loss: 0.7906%]\n",
            "7716 [Discriminator loss: 0.6820%, acc.: 54.30%] [Generator loss: 0.7921%]\n",
            "7717 [Discriminator loss: 0.6583%, acc.: 63.67%] [Generator loss: 0.7856%]\n",
            "7718 [Discriminator loss: 0.6617%, acc.: 57.81%] [Generator loss: 0.7784%]\n",
            "7719 [Discriminator loss: 0.6793%, acc.: 54.30%] [Generator loss: 0.7898%]\n",
            "7720 [Discriminator loss: 0.6723%, acc.: 58.98%] [Generator loss: 0.7727%]\n",
            "7721 [Discriminator loss: 0.6784%, acc.: 55.86%] [Generator loss: 0.7935%]\n",
            "7722 [Discriminator loss: 0.6621%, acc.: 62.11%] [Generator loss: 0.7812%]\n",
            "7723 [Discriminator loss: 0.6720%, acc.: 55.86%] [Generator loss: 0.7653%]\n",
            "7724 [Discriminator loss: 0.6982%, acc.: 50.78%] [Generator loss: 0.7884%]\n",
            "7725 [Discriminator loss: 0.6858%, acc.: 52.73%] [Generator loss: 0.7682%]\n",
            "7726 [Discriminator loss: 0.6640%, acc.: 60.16%] [Generator loss: 0.7665%]\n",
            "7727 [Discriminator loss: 0.6827%, acc.: 58.98%] [Generator loss: 0.7805%]\n",
            "7728 [Discriminator loss: 0.6558%, acc.: 61.33%] [Generator loss: 0.7751%]\n",
            "7729 [Discriminator loss: 0.6844%, acc.: 56.25%] [Generator loss: 0.7778%]\n",
            "7730 [Discriminator loss: 0.6806%, acc.: 56.64%] [Generator loss: 0.7646%]\n",
            "7731 [Discriminator loss: 0.7011%, acc.: 47.66%] [Generator loss: 0.7635%]\n",
            "7732 [Discriminator loss: 0.6807%, acc.: 55.08%] [Generator loss: 0.7649%]\n",
            "7733 [Discriminator loss: 0.6756%, acc.: 60.55%] [Generator loss: 0.8096%]\n",
            "7734 [Discriminator loss: 0.6635%, acc.: 60.94%] [Generator loss: 0.7779%]\n",
            "7735 [Discriminator loss: 0.6625%, acc.: 59.38%] [Generator loss: 0.7896%]\n",
            "7736 [Discriminator loss: 0.6781%, acc.: 60.16%] [Generator loss: 0.7635%]\n",
            "7737 [Discriminator loss: 0.6822%, acc.: 56.64%] [Generator loss: 0.7687%]\n",
            "7738 [Discriminator loss: 0.6622%, acc.: 62.89%] [Generator loss: 0.7988%]\n",
            "7739 [Discriminator loss: 0.6876%, acc.: 52.73%] [Generator loss: 0.7670%]\n",
            "7740 [Discriminator loss: 0.6679%, acc.: 58.20%] [Generator loss: 0.7842%]\n",
            "7741 [Discriminator loss: 0.6533%, acc.: 60.16%] [Generator loss: 0.7690%]\n",
            "7742 [Discriminator loss: 0.6790%, acc.: 55.47%] [Generator loss: 0.7736%]\n",
            "7743 [Discriminator loss: 0.6934%, acc.: 50.78%] [Generator loss: 0.7660%]\n",
            "7744 [Discriminator loss: 0.6903%, acc.: 51.95%] [Generator loss: 0.7636%]\n",
            "7745 [Discriminator loss: 0.6834%, acc.: 54.30%] [Generator loss: 0.7690%]\n",
            "7746 [Discriminator loss: 0.6717%, acc.: 56.64%] [Generator loss: 0.7572%]\n",
            "7747 [Discriminator loss: 0.6788%, acc.: 57.42%] [Generator loss: 0.7651%]\n",
            "7748 [Discriminator loss: 0.6801%, acc.: 53.91%] [Generator loss: 0.7780%]\n",
            "7749 [Discriminator loss: 0.6833%, acc.: 57.42%] [Generator loss: 0.7629%]\n",
            "7750 [Discriminator loss: 0.6756%, acc.: 53.52%] [Generator loss: 0.7740%]\n",
            "7751 [Discriminator loss: 0.6676%, acc.: 58.98%] [Generator loss: 0.7856%]\n",
            "7752 [Discriminator loss: 0.6594%, acc.: 64.06%] [Generator loss: 0.7654%]\n",
            "7753 [Discriminator loss: 0.6550%, acc.: 62.89%] [Generator loss: 0.7718%]\n",
            "7754 [Discriminator loss: 0.6776%, acc.: 57.42%] [Generator loss: 0.7805%]\n",
            "7755 [Discriminator loss: 0.6684%, acc.: 62.11%] [Generator loss: 0.7846%]\n",
            "7756 [Discriminator loss: 0.6621%, acc.: 59.77%] [Generator loss: 0.7795%]\n",
            "7757 [Discriminator loss: 0.6755%, acc.: 55.47%] [Generator loss: 0.7699%]\n",
            "7758 [Discriminator loss: 0.6698%, acc.: 60.94%] [Generator loss: 0.7751%]\n",
            "7759 [Discriminator loss: 0.6756%, acc.: 58.98%] [Generator loss: 0.7683%]\n",
            "7760 [Discriminator loss: 0.6660%, acc.: 60.16%] [Generator loss: 0.7489%]\n",
            "7761 [Discriminator loss: 0.6877%, acc.: 51.56%] [Generator loss: 0.7914%]\n",
            "7762 [Discriminator loss: 0.6814%, acc.: 55.86%] [Generator loss: 0.7473%]\n",
            "7763 [Discriminator loss: 0.6644%, acc.: 58.98%] [Generator loss: 0.7661%]\n",
            "7764 [Discriminator loss: 0.6690%, acc.: 59.38%] [Generator loss: 0.7708%]\n",
            "7765 [Discriminator loss: 0.6910%, acc.: 53.91%] [Generator loss: 0.7584%]\n",
            "7766 [Discriminator loss: 0.6742%, acc.: 57.42%] [Generator loss: 0.7542%]\n",
            "7767 [Discriminator loss: 0.6846%, acc.: 55.47%] [Generator loss: 0.7880%]\n",
            "7768 [Discriminator loss: 0.6752%, acc.: 57.03%] [Generator loss: 0.7932%]\n",
            "7769 [Discriminator loss: 0.6654%, acc.: 58.98%] [Generator loss: 0.7845%]\n",
            "7770 [Discriminator loss: 0.6596%, acc.: 61.33%] [Generator loss: 0.7797%]\n",
            "7771 [Discriminator loss: 0.6759%, acc.: 58.20%] [Generator loss: 0.7880%]\n",
            "7772 [Discriminator loss: 0.6562%, acc.: 60.94%] [Generator loss: 0.7528%]\n",
            "7773 [Discriminator loss: 0.6793%, acc.: 55.86%] [Generator loss: 0.7862%]\n",
            "7774 [Discriminator loss: 0.6694%, acc.: 57.81%] [Generator loss: 0.7678%]\n",
            "7775 [Discriminator loss: 0.6848%, acc.: 53.12%] [Generator loss: 0.7722%]\n",
            "7776 [Discriminator loss: 0.6713%, acc.: 56.64%] [Generator loss: 0.7673%]\n",
            "7777 [Discriminator loss: 0.6939%, acc.: 54.69%] [Generator loss: 0.7694%]\n",
            "7778 [Discriminator loss: 0.6643%, acc.: 64.06%] [Generator loss: 0.7987%]\n",
            "7779 [Discriminator loss: 0.6685%, acc.: 58.98%] [Generator loss: 0.8020%]\n",
            "7780 [Discriminator loss: 0.6841%, acc.: 52.73%] [Generator loss: 0.7736%]\n",
            "7781 [Discriminator loss: 0.6621%, acc.: 60.94%] [Generator loss: 0.7630%]\n",
            "7782 [Discriminator loss: 0.6751%, acc.: 60.16%] [Generator loss: 0.7665%]\n",
            "7783 [Discriminator loss: 0.6634%, acc.: 62.50%] [Generator loss: 0.7709%]\n",
            "7784 [Discriminator loss: 0.6711%, acc.: 57.03%] [Generator loss: 0.7686%]\n",
            "7785 [Discriminator loss: 0.6717%, acc.: 57.81%] [Generator loss: 0.7743%]\n",
            "7786 [Discriminator loss: 0.6743%, acc.: 60.16%] [Generator loss: 0.7772%]\n",
            "7787 [Discriminator loss: 0.6670%, acc.: 59.38%] [Generator loss: 0.7908%]\n",
            "7788 [Discriminator loss: 0.6908%, acc.: 54.30%] [Generator loss: 0.7678%]\n",
            "7789 [Discriminator loss: 0.6872%, acc.: 50.00%] [Generator loss: 0.7660%]\n",
            "7790 [Discriminator loss: 0.6716%, acc.: 57.03%] [Generator loss: 0.7977%]\n",
            "7791 [Discriminator loss: 0.6743%, acc.: 60.16%] [Generator loss: 0.7627%]\n",
            "7792 [Discriminator loss: 0.6624%, acc.: 62.89%] [Generator loss: 0.7759%]\n",
            "7793 [Discriminator loss: 0.6663%, acc.: 59.77%] [Generator loss: 0.7801%]\n",
            "7794 [Discriminator loss: 0.6719%, acc.: 54.69%] [Generator loss: 0.7640%]\n",
            "7795 [Discriminator loss: 0.6707%, acc.: 58.59%] [Generator loss: 0.7558%]\n",
            "7796 [Discriminator loss: 0.6450%, acc.: 66.02%] [Generator loss: 0.7726%]\n",
            "7797 [Discriminator loss: 0.6631%, acc.: 61.72%] [Generator loss: 0.7766%]\n",
            "7798 [Discriminator loss: 0.6583%, acc.: 62.11%] [Generator loss: 0.7574%]\n",
            "7799 [Discriminator loss: 0.6744%, acc.: 60.16%] [Generator loss: 0.7639%]\n",
            "7800 [Discriminator loss: 0.6628%, acc.: 61.33%] [Generator loss: 0.7567%]\n",
            "7801 [Discriminator loss: 0.6717%, acc.: 61.33%] [Generator loss: 0.7656%]\n",
            "7802 [Discriminator loss: 0.6533%, acc.: 64.84%] [Generator loss: 0.7415%]\n",
            "7803 [Discriminator loss: 0.6676%, acc.: 60.94%] [Generator loss: 0.7671%]\n",
            "7804 [Discriminator loss: 0.6602%, acc.: 63.67%] [Generator loss: 0.7745%]\n",
            "7805 [Discriminator loss: 0.6653%, acc.: 59.77%] [Generator loss: 0.8049%]\n",
            "7806 [Discriminator loss: 0.6687%, acc.: 61.72%] [Generator loss: 0.7863%]\n",
            "7807 [Discriminator loss: 0.6773%, acc.: 58.98%] [Generator loss: 0.7941%]\n",
            "7808 [Discriminator loss: 0.6871%, acc.: 55.47%] [Generator loss: 0.7774%]\n",
            "7809 [Discriminator loss: 0.6749%, acc.: 54.30%] [Generator loss: 0.7639%]\n",
            "7810 [Discriminator loss: 0.6867%, acc.: 55.86%] [Generator loss: 0.7780%]\n",
            "7811 [Discriminator loss: 0.6642%, acc.: 60.94%] [Generator loss: 0.7681%]\n",
            "7812 [Discriminator loss: 0.6780%, acc.: 54.30%] [Generator loss: 0.7696%]\n",
            "7813 [Discriminator loss: 0.6868%, acc.: 56.25%] [Generator loss: 0.7558%]\n",
            "7814 [Discriminator loss: 0.6859%, acc.: 55.86%] [Generator loss: 0.7488%]\n",
            "7815 [Discriminator loss: 0.6665%, acc.: 58.59%] [Generator loss: 0.7510%]\n",
            "7816 [Discriminator loss: 0.6632%, acc.: 61.72%] [Generator loss: 0.7682%]\n",
            "7817 [Discriminator loss: 0.6837%, acc.: 54.30%] [Generator loss: 0.7807%]\n",
            "7818 [Discriminator loss: 0.6849%, acc.: 56.25%] [Generator loss: 0.7924%]\n",
            "7819 [Discriminator loss: 0.6789%, acc.: 57.81%] [Generator loss: 0.7447%]\n",
            "7820 [Discriminator loss: 0.6963%, acc.: 51.95%] [Generator loss: 0.7795%]\n",
            "7821 [Discriminator loss: 0.7068%, acc.: 48.83%] [Generator loss: 0.7708%]\n",
            "7822 [Discriminator loss: 0.6789%, acc.: 55.86%] [Generator loss: 0.7902%]\n",
            "7823 [Discriminator loss: 0.6617%, acc.: 61.33%] [Generator loss: 0.7712%]\n",
            "7824 [Discriminator loss: 0.7007%, acc.: 52.34%] [Generator loss: 0.7799%]\n",
            "7825 [Discriminator loss: 0.6684%, acc.: 60.55%] [Generator loss: 0.7826%]\n",
            "7826 [Discriminator loss: 0.6719%, acc.: 59.77%] [Generator loss: 0.7796%]\n",
            "7827 [Discriminator loss: 0.6887%, acc.: 51.56%] [Generator loss: 0.7879%]\n",
            "7828 [Discriminator loss: 0.6685%, acc.: 58.59%] [Generator loss: 0.7681%]\n",
            "7829 [Discriminator loss: 0.6759%, acc.: 57.42%] [Generator loss: 0.7634%]\n",
            "7830 [Discriminator loss: 0.6622%, acc.: 58.20%] [Generator loss: 0.7673%]\n",
            "7831 [Discriminator loss: 0.6606%, acc.: 60.16%] [Generator loss: 0.7799%]\n",
            "7832 [Discriminator loss: 0.6630%, acc.: 57.03%] [Generator loss: 0.7979%]\n",
            "7833 [Discriminator loss: 0.6734%, acc.: 55.08%] [Generator loss: 0.7849%]\n",
            "7834 [Discriminator loss: 0.6593%, acc.: 58.59%] [Generator loss: 0.7839%]\n",
            "7835 [Discriminator loss: 0.6721%, acc.: 57.81%] [Generator loss: 0.7814%]\n",
            "7836 [Discriminator loss: 0.6823%, acc.: 55.86%] [Generator loss: 0.7742%]\n",
            "7837 [Discriminator loss: 0.6788%, acc.: 57.81%] [Generator loss: 0.7797%]\n",
            "7838 [Discriminator loss: 0.6982%, acc.: 52.73%] [Generator loss: 0.8003%]\n",
            "7839 [Discriminator loss: 0.6752%, acc.: 56.64%] [Generator loss: 0.7947%]\n",
            "7840 [Discriminator loss: 0.6537%, acc.: 58.98%] [Generator loss: 0.7933%]\n",
            "7841 [Discriminator loss: 0.6772%, acc.: 59.77%] [Generator loss: 0.7778%]\n",
            "7842 [Discriminator loss: 0.6855%, acc.: 58.59%] [Generator loss: 0.7739%]\n",
            "7843 [Discriminator loss: 0.6594%, acc.: 58.59%] [Generator loss: 0.8201%]\n",
            "7844 [Discriminator loss: 0.6582%, acc.: 64.06%] [Generator loss: 0.8008%]\n",
            "7845 [Discriminator loss: 0.6677%, acc.: 60.16%] [Generator loss: 0.8083%]\n",
            "7846 [Discriminator loss: 0.6766%, acc.: 61.33%] [Generator loss: 0.8110%]\n",
            "7847 [Discriminator loss: 0.6730%, acc.: 58.59%] [Generator loss: 0.7745%]\n",
            "7848 [Discriminator loss: 0.6591%, acc.: 60.94%] [Generator loss: 0.8174%]\n",
            "7849 [Discriminator loss: 0.6583%, acc.: 62.11%] [Generator loss: 0.7874%]\n",
            "7850 [Discriminator loss: 0.6706%, acc.: 58.20%] [Generator loss: 0.7831%]\n",
            "7851 [Discriminator loss: 0.6853%, acc.: 58.20%] [Generator loss: 0.7747%]\n",
            "7852 [Discriminator loss: 0.6711%, acc.: 58.98%] [Generator loss: 0.7879%]\n",
            "7853 [Discriminator loss: 0.6763%, acc.: 59.38%] [Generator loss: 0.7765%]\n",
            "7854 [Discriminator loss: 0.6591%, acc.: 59.77%] [Generator loss: 0.7991%]\n",
            "7855 [Discriminator loss: 0.6708%, acc.: 58.98%] [Generator loss: 0.7626%]\n",
            "7856 [Discriminator loss: 0.6879%, acc.: 50.78%] [Generator loss: 0.8027%]\n",
            "7857 [Discriminator loss: 0.6568%, acc.: 60.55%] [Generator loss: 0.7853%]\n",
            "7858 [Discriminator loss: 0.6753%, acc.: 56.25%] [Generator loss: 0.7869%]\n",
            "7859 [Discriminator loss: 0.6781%, acc.: 55.47%] [Generator loss: 0.7921%]\n",
            "7860 [Discriminator loss: 0.6768%, acc.: 56.64%] [Generator loss: 0.7774%]\n",
            "7861 [Discriminator loss: 0.6658%, acc.: 60.16%] [Generator loss: 0.7531%]\n",
            "7862 [Discriminator loss: 0.6788%, acc.: 55.86%] [Generator loss: 0.7829%]\n",
            "7863 [Discriminator loss: 0.6750%, acc.: 58.20%] [Generator loss: 0.7812%]\n",
            "7864 [Discriminator loss: 0.6952%, acc.: 55.08%] [Generator loss: 0.7750%]\n",
            "7865 [Discriminator loss: 0.6645%, acc.: 62.89%] [Generator loss: 0.7537%]\n",
            "7866 [Discriminator loss: 0.6915%, acc.: 50.78%] [Generator loss: 0.7740%]\n",
            "7867 [Discriminator loss: 0.6611%, acc.: 63.28%] [Generator loss: 0.7823%]\n",
            "7868 [Discriminator loss: 0.6671%, acc.: 62.11%] [Generator loss: 0.7787%]\n",
            "7869 [Discriminator loss: 0.6807%, acc.: 56.64%] [Generator loss: 0.7818%]\n",
            "7870 [Discriminator loss: 0.6818%, acc.: 57.81%] [Generator loss: 0.7856%]\n",
            "7871 [Discriminator loss: 0.6906%, acc.: 53.12%] [Generator loss: 0.7835%]\n",
            "7872 [Discriminator loss: 0.6770%, acc.: 57.03%] [Generator loss: 0.7971%]\n",
            "7873 [Discriminator loss: 0.6659%, acc.: 63.28%] [Generator loss: 0.7889%]\n",
            "7874 [Discriminator loss: 0.6925%, acc.: 52.34%] [Generator loss: 0.7878%]\n",
            "7875 [Discriminator loss: 0.6746%, acc.: 56.25%] [Generator loss: 0.8006%]\n",
            "7876 [Discriminator loss: 0.6769%, acc.: 54.69%] [Generator loss: 0.7889%]\n",
            "7877 [Discriminator loss: 0.6812%, acc.: 56.25%] [Generator loss: 0.7826%]\n",
            "7878 [Discriminator loss: 0.6722%, acc.: 58.98%] [Generator loss: 0.7986%]\n",
            "7879 [Discriminator loss: 0.6812%, acc.: 55.86%] [Generator loss: 0.7945%]\n",
            "7880 [Discriminator loss: 0.6722%, acc.: 57.81%] [Generator loss: 0.8002%]\n",
            "7881 [Discriminator loss: 0.6784%, acc.: 52.73%] [Generator loss: 0.8074%]\n",
            "7882 [Discriminator loss: 0.6895%, acc.: 54.69%] [Generator loss: 0.7786%]\n",
            "7883 [Discriminator loss: 0.6757%, acc.: 57.03%] [Generator loss: 0.7710%]\n",
            "7884 [Discriminator loss: 0.6729%, acc.: 60.55%] [Generator loss: 0.7919%]\n",
            "7885 [Discriminator loss: 0.6860%, acc.: 52.73%] [Generator loss: 0.7701%]\n",
            "7886 [Discriminator loss: 0.6836%, acc.: 56.25%] [Generator loss: 0.7586%]\n",
            "7887 [Discriminator loss: 0.6824%, acc.: 52.34%] [Generator loss: 0.7618%]\n",
            "7888 [Discriminator loss: 0.6581%, acc.: 61.72%] [Generator loss: 0.7591%]\n",
            "7889 [Discriminator loss: 0.6595%, acc.: 61.72%] [Generator loss: 0.7611%]\n",
            "7890 [Discriminator loss: 0.6729%, acc.: 56.25%] [Generator loss: 0.7565%]\n",
            "7891 [Discriminator loss: 0.6806%, acc.: 57.42%] [Generator loss: 0.7546%]\n",
            "7892 [Discriminator loss: 0.6690%, acc.: 60.16%] [Generator loss: 0.7657%]\n",
            "7893 [Discriminator loss: 0.6790%, acc.: 56.25%] [Generator loss: 0.7703%]\n",
            "7894 [Discriminator loss: 0.6716%, acc.: 56.64%] [Generator loss: 0.7802%]\n",
            "7895 [Discriminator loss: 0.6797%, acc.: 54.69%] [Generator loss: 0.7852%]\n",
            "7896 [Discriminator loss: 0.6805%, acc.: 58.20%] [Generator loss: 0.7748%]\n",
            "7897 [Discriminator loss: 0.6883%, acc.: 53.12%] [Generator loss: 0.7900%]\n",
            "7898 [Discriminator loss: 0.6771%, acc.: 55.86%] [Generator loss: 0.7767%]\n",
            "7899 [Discriminator loss: 0.6621%, acc.: 59.77%] [Generator loss: 0.7969%]\n",
            "7900 [Discriminator loss: 0.6529%, acc.: 67.58%] [Generator loss: 0.7771%]\n",
            "7901 [Discriminator loss: 0.6756%, acc.: 58.59%] [Generator loss: 0.7895%]\n",
            "7902 [Discriminator loss: 0.6843%, acc.: 58.20%] [Generator loss: 0.7894%]\n",
            "7903 [Discriminator loss: 0.6757%, acc.: 55.47%] [Generator loss: 0.7473%]\n",
            "7904 [Discriminator loss: 0.6756%, acc.: 57.03%] [Generator loss: 0.7717%]\n",
            "7905 [Discriminator loss: 0.6778%, acc.: 57.42%] [Generator loss: 0.7824%]\n",
            "7906 [Discriminator loss: 0.6717%, acc.: 57.81%] [Generator loss: 0.7803%]\n",
            "7907 [Discriminator loss: 0.6733%, acc.: 54.30%] [Generator loss: 0.7703%]\n",
            "7908 [Discriminator loss: 0.6709%, acc.: 59.77%] [Generator loss: 0.7859%]\n",
            "7909 [Discriminator loss: 0.6735%, acc.: 60.16%] [Generator loss: 0.7756%]\n",
            "7910 [Discriminator loss: 0.6782%, acc.: 55.86%] [Generator loss: 0.7641%]\n",
            "7911 [Discriminator loss: 0.6708%, acc.: 58.98%] [Generator loss: 0.7772%]\n",
            "7912 [Discriminator loss: 0.6844%, acc.: 56.25%] [Generator loss: 0.8013%]\n",
            "7913 [Discriminator loss: 0.6780%, acc.: 55.86%] [Generator loss: 0.8104%]\n",
            "7914 [Discriminator loss: 0.6806%, acc.: 57.81%] [Generator loss: 0.8024%]\n",
            "7915 [Discriminator loss: 0.6655%, acc.: 63.28%] [Generator loss: 0.8027%]\n",
            "7916 [Discriminator loss: 0.6750%, acc.: 57.81%] [Generator loss: 0.7884%]\n",
            "7917 [Discriminator loss: 0.6765%, acc.: 58.59%] [Generator loss: 0.7942%]\n",
            "7918 [Discriminator loss: 0.6703%, acc.: 60.94%] [Generator loss: 0.7942%]\n",
            "7919 [Discriminator loss: 0.6696%, acc.: 58.98%] [Generator loss: 0.7912%]\n",
            "7920 [Discriminator loss: 0.6548%, acc.: 62.89%] [Generator loss: 0.7853%]\n",
            "7921 [Discriminator loss: 0.6839%, acc.: 56.64%] [Generator loss: 0.7757%]\n",
            "7922 [Discriminator loss: 0.6909%, acc.: 56.64%] [Generator loss: 0.7873%]\n",
            "7923 [Discriminator loss: 0.6744%, acc.: 58.20%] [Generator loss: 0.7798%]\n",
            "7924 [Discriminator loss: 0.6725%, acc.: 61.72%] [Generator loss: 0.7828%]\n",
            "7925 [Discriminator loss: 0.6589%, acc.: 61.72%] [Generator loss: 0.7878%]\n",
            "7926 [Discriminator loss: 0.6583%, acc.: 64.06%] [Generator loss: 0.7899%]\n",
            "7927 [Discriminator loss: 0.6948%, acc.: 53.12%] [Generator loss: 0.7646%]\n",
            "7928 [Discriminator loss: 0.6629%, acc.: 62.11%] [Generator loss: 0.7582%]\n",
            "7929 [Discriminator loss: 0.6725%, acc.: 57.42%] [Generator loss: 0.7808%]\n",
            "7930 [Discriminator loss: 0.6660%, acc.: 59.38%] [Generator loss: 0.7890%]\n",
            "7931 [Discriminator loss: 0.6596%, acc.: 62.11%] [Generator loss: 0.7797%]\n",
            "7932 [Discriminator loss: 0.6838%, acc.: 56.25%] [Generator loss: 0.7780%]\n",
            "7933 [Discriminator loss: 0.6804%, acc.: 57.03%] [Generator loss: 0.7701%]\n",
            "7934 [Discriminator loss: 0.6842%, acc.: 51.17%] [Generator loss: 0.7963%]\n",
            "7935 [Discriminator loss: 0.6689%, acc.: 61.33%] [Generator loss: 0.7820%]\n",
            "7936 [Discriminator loss: 0.6880%, acc.: 57.03%] [Generator loss: 0.7795%]\n",
            "7937 [Discriminator loss: 0.6789%, acc.: 57.03%] [Generator loss: 0.7757%]\n",
            "7938 [Discriminator loss: 0.6652%, acc.: 62.50%] [Generator loss: 0.7783%]\n",
            "7939 [Discriminator loss: 0.6569%, acc.: 61.33%] [Generator loss: 0.7884%]\n",
            "7940 [Discriminator loss: 0.6861%, acc.: 55.86%] [Generator loss: 0.7814%]\n",
            "7941 [Discriminator loss: 0.6823%, acc.: 53.52%] [Generator loss: 0.7789%]\n",
            "7942 [Discriminator loss: 0.6604%, acc.: 59.77%] [Generator loss: 0.7979%]\n",
            "7943 [Discriminator loss: 0.6780%, acc.: 58.20%] [Generator loss: 0.7640%]\n",
            "7944 [Discriminator loss: 0.6790%, acc.: 53.91%] [Generator loss: 0.7728%]\n",
            "7945 [Discriminator loss: 0.6961%, acc.: 46.88%] [Generator loss: 0.7723%]\n",
            "7946 [Discriminator loss: 0.6766%, acc.: 54.30%] [Generator loss: 0.7754%]\n",
            "7947 [Discriminator loss: 0.6878%, acc.: 54.69%] [Generator loss: 0.7870%]\n",
            "7948 [Discriminator loss: 0.6887%, acc.: 51.17%] [Generator loss: 0.7655%]\n",
            "7949 [Discriminator loss: 0.6972%, acc.: 48.83%] [Generator loss: 0.8004%]\n",
            "7950 [Discriminator loss: 0.6847%, acc.: 57.03%] [Generator loss: 0.7607%]\n",
            "7951 [Discriminator loss: 0.6842%, acc.: 57.03%] [Generator loss: 0.7699%]\n",
            "7952 [Discriminator loss: 0.6785%, acc.: 56.25%] [Generator loss: 0.7613%]\n",
            "7953 [Discriminator loss: 0.6934%, acc.: 50.78%] [Generator loss: 0.7623%]\n",
            "7954 [Discriminator loss: 0.6654%, acc.: 62.50%] [Generator loss: 0.7650%]\n",
            "7955 [Discriminator loss: 0.6859%, acc.: 55.08%] [Generator loss: 0.7738%]\n",
            "7956 [Discriminator loss: 0.6878%, acc.: 57.81%] [Generator loss: 0.7822%]\n",
            "7957 [Discriminator loss: 0.6744%, acc.: 58.20%] [Generator loss: 0.7856%]\n",
            "7958 [Discriminator loss: 0.6918%, acc.: 55.47%] [Generator loss: 0.7724%]\n",
            "7959 [Discriminator loss: 0.6750%, acc.: 52.73%] [Generator loss: 0.7764%]\n",
            "7960 [Discriminator loss: 0.6673%, acc.: 59.77%] [Generator loss: 0.7779%]\n",
            "7961 [Discriminator loss: 0.6589%, acc.: 58.98%] [Generator loss: 0.7776%]\n",
            "7962 [Discriminator loss: 0.6734%, acc.: 60.55%] [Generator loss: 0.7717%]\n",
            "7963 [Discriminator loss: 0.6623%, acc.: 63.28%] [Generator loss: 0.7905%]\n",
            "7964 [Discriminator loss: 0.6724%, acc.: 57.81%] [Generator loss: 0.7486%]\n",
            "7965 [Discriminator loss: 0.6892%, acc.: 52.34%] [Generator loss: 0.7427%]\n",
            "7966 [Discriminator loss: 0.6676%, acc.: 59.77%] [Generator loss: 0.7608%]\n",
            "7967 [Discriminator loss: 0.6786%, acc.: 59.38%] [Generator loss: 0.7836%]\n",
            "7968 [Discriminator loss: 0.6774%, acc.: 55.86%] [Generator loss: 0.7628%]\n",
            "7969 [Discriminator loss: 0.6913%, acc.: 53.91%] [Generator loss: 0.7613%]\n",
            "7970 [Discriminator loss: 0.6946%, acc.: 52.34%] [Generator loss: 0.7510%]\n",
            "7971 [Discriminator loss: 0.6890%, acc.: 51.95%] [Generator loss: 0.7529%]\n",
            "7972 [Discriminator loss: 0.6737%, acc.: 56.25%] [Generator loss: 0.7596%]\n",
            "7973 [Discriminator loss: 0.6779%, acc.: 53.52%] [Generator loss: 0.7768%]\n",
            "7974 [Discriminator loss: 0.6829%, acc.: 55.47%] [Generator loss: 0.7793%]\n",
            "7975 [Discriminator loss: 0.6536%, acc.: 63.67%] [Generator loss: 0.7791%]\n",
            "7976 [Discriminator loss: 0.6772%, acc.: 56.25%] [Generator loss: 0.7813%]\n",
            "7977 [Discriminator loss: 0.6788%, acc.: 54.69%] [Generator loss: 0.8084%]\n",
            "7978 [Discriminator loss: 0.6642%, acc.: 62.50%] [Generator loss: 0.7945%]\n",
            "7979 [Discriminator loss: 0.6855%, acc.: 55.47%] [Generator loss: 0.7930%]\n",
            "7980 [Discriminator loss: 0.6795%, acc.: 56.25%] [Generator loss: 0.7742%]\n",
            "7981 [Discriminator loss: 0.6996%, acc.: 52.73%] [Generator loss: 0.7904%]\n",
            "7982 [Discriminator loss: 0.6742%, acc.: 53.52%] [Generator loss: 0.7857%]\n",
            "7983 [Discriminator loss: 0.6766%, acc.: 56.25%] [Generator loss: 0.7674%]\n",
            "7984 [Discriminator loss: 0.6815%, acc.: 57.81%] [Generator loss: 0.7630%]\n",
            "7985 [Discriminator loss: 0.6836%, acc.: 51.95%] [Generator loss: 0.8092%]\n",
            "7986 [Discriminator loss: 0.6844%, acc.: 52.34%] [Generator loss: 0.7689%]\n",
            "7987 [Discriminator loss: 0.6697%, acc.: 61.33%] [Generator loss: 0.7859%]\n",
            "7988 [Discriminator loss: 0.6781%, acc.: 55.08%] [Generator loss: 0.7913%]\n",
            "7989 [Discriminator loss: 0.6655%, acc.: 66.41%] [Generator loss: 0.7630%]\n",
            "7990 [Discriminator loss: 0.6681%, acc.: 60.16%] [Generator loss: 0.7674%]\n",
            "7991 [Discriminator loss: 0.6847%, acc.: 53.52%] [Generator loss: 0.7678%]\n",
            "7992 [Discriminator loss: 0.6629%, acc.: 60.55%] [Generator loss: 0.7737%]\n",
            "7993 [Discriminator loss: 0.6772%, acc.: 51.56%] [Generator loss: 0.7807%]\n",
            "7994 [Discriminator loss: 0.6846%, acc.: 53.12%] [Generator loss: 0.7759%]\n",
            "7995 [Discriminator loss: 0.6678%, acc.: 59.77%] [Generator loss: 0.7499%]\n",
            "7996 [Discriminator loss: 0.6967%, acc.: 50.00%] [Generator loss: 0.7601%]\n",
            "7997 [Discriminator loss: 0.6702%, acc.: 55.86%] [Generator loss: 0.7502%]\n",
            "7998 [Discriminator loss: 0.6892%, acc.: 52.73%] [Generator loss: 0.7604%]\n",
            "7999 [Discriminator loss: 0.6738%, acc.: 59.38%] [Generator loss: 0.7751%]\n",
            "8000 [Discriminator loss: 0.6853%, acc.: 58.20%] [Generator loss: 0.7548%]\n",
            "8001 [Discriminator loss: 0.6802%, acc.: 54.30%] [Generator loss: 0.7597%]\n",
            "8002 [Discriminator loss: 0.6765%, acc.: 58.20%] [Generator loss: 0.7384%]\n",
            "8003 [Discriminator loss: 0.6618%, acc.: 63.67%] [Generator loss: 0.7691%]\n",
            "8004 [Discriminator loss: 0.6822%, acc.: 55.08%] [Generator loss: 0.7732%]\n",
            "8005 [Discriminator loss: 0.6785%, acc.: 56.64%] [Generator loss: 0.7991%]\n",
            "8006 [Discriminator loss: 0.6637%, acc.: 60.16%] [Generator loss: 0.7917%]\n",
            "8007 [Discriminator loss: 0.6805%, acc.: 55.47%] [Generator loss: 0.7958%]\n",
            "8008 [Discriminator loss: 0.6796%, acc.: 57.81%] [Generator loss: 0.7929%]\n",
            "8009 [Discriminator loss: 0.6705%, acc.: 58.98%] [Generator loss: 0.7784%]\n",
            "8010 [Discriminator loss: 0.6710%, acc.: 59.77%] [Generator loss: 0.7553%]\n",
            "8011 [Discriminator loss: 0.6826%, acc.: 57.42%] [Generator loss: 0.7601%]\n",
            "8012 [Discriminator loss: 0.6724%, acc.: 58.59%] [Generator loss: 0.7568%]\n",
            "8013 [Discriminator loss: 0.6695%, acc.: 58.98%] [Generator loss: 0.7622%]\n",
            "8014 [Discriminator loss: 0.6619%, acc.: 59.38%] [Generator loss: 0.7683%]\n",
            "8015 [Discriminator loss: 0.6679%, acc.: 56.64%] [Generator loss: 0.7695%]\n",
            "8016 [Discriminator loss: 0.6772%, acc.: 57.81%] [Generator loss: 0.7705%]\n",
            "8017 [Discriminator loss: 0.6609%, acc.: 62.11%] [Generator loss: 0.7787%]\n",
            "8018 [Discriminator loss: 0.6839%, acc.: 53.52%] [Generator loss: 0.7795%]\n",
            "8019 [Discriminator loss: 0.6773%, acc.: 57.42%] [Generator loss: 0.7656%]\n",
            "8020 [Discriminator loss: 0.6627%, acc.: 60.55%] [Generator loss: 0.7974%]\n",
            "8021 [Discriminator loss: 0.6749%, acc.: 56.64%] [Generator loss: 0.7814%]\n",
            "8022 [Discriminator loss: 0.6660%, acc.: 60.94%] [Generator loss: 0.7764%]\n",
            "8023 [Discriminator loss: 0.6677%, acc.: 60.16%] [Generator loss: 0.7937%]\n",
            "8024 [Discriminator loss: 0.6767%, acc.: 59.38%] [Generator loss: 0.7814%]\n",
            "8025 [Discriminator loss: 0.6866%, acc.: 53.52%] [Generator loss: 0.7769%]\n",
            "8026 [Discriminator loss: 0.6775%, acc.: 59.77%] [Generator loss: 0.7841%]\n",
            "8027 [Discriminator loss: 0.6742%, acc.: 58.59%] [Generator loss: 0.7862%]\n",
            "8028 [Discriminator loss: 0.6763%, acc.: 57.42%] [Generator loss: 0.7917%]\n",
            "8029 [Discriminator loss: 0.6809%, acc.: 53.91%] [Generator loss: 0.7893%]\n",
            "8030 [Discriminator loss: 0.6681%, acc.: 55.86%] [Generator loss: 0.7702%]\n",
            "8031 [Discriminator loss: 0.6840%, acc.: 54.69%] [Generator loss: 0.8133%]\n",
            "8032 [Discriminator loss: 0.6745%, acc.: 50.78%] [Generator loss: 0.7816%]\n",
            "8033 [Discriminator loss: 0.6714%, acc.: 57.03%] [Generator loss: 0.7870%]\n",
            "8034 [Discriminator loss: 0.6809%, acc.: 61.33%] [Generator loss: 0.7738%]\n",
            "8035 [Discriminator loss: 0.6782%, acc.: 58.98%] [Generator loss: 0.7676%]\n",
            "8036 [Discriminator loss: 0.6611%, acc.: 58.98%] [Generator loss: 0.7962%]\n",
            "8037 [Discriminator loss: 0.6662%, acc.: 58.98%] [Generator loss: 0.7822%]\n",
            "8038 [Discriminator loss: 0.6606%, acc.: 62.11%] [Generator loss: 0.7883%]\n",
            "8039 [Discriminator loss: 0.6815%, acc.: 57.81%] [Generator loss: 0.7790%]\n",
            "8040 [Discriminator loss: 0.6857%, acc.: 54.30%] [Generator loss: 0.7767%]\n",
            "8041 [Discriminator loss: 0.6842%, acc.: 57.42%] [Generator loss: 0.7669%]\n",
            "8042 [Discriminator loss: 0.6635%, acc.: 60.55%] [Generator loss: 0.7958%]\n",
            "8043 [Discriminator loss: 0.6655%, acc.: 57.81%] [Generator loss: 0.7780%]\n",
            "8044 [Discriminator loss: 0.6733%, acc.: 57.81%] [Generator loss: 0.7905%]\n",
            "8045 [Discriminator loss: 0.6441%, acc.: 66.41%] [Generator loss: 0.7701%]\n",
            "8046 [Discriminator loss: 0.6700%, acc.: 62.50%] [Generator loss: 0.7737%]\n",
            "8047 [Discriminator loss: 0.6552%, acc.: 62.50%] [Generator loss: 0.7838%]\n",
            "8048 [Discriminator loss: 0.6654%, acc.: 66.02%] [Generator loss: 0.7899%]\n",
            "8049 [Discriminator loss: 0.6819%, acc.: 55.08%] [Generator loss: 0.7994%]\n",
            "8050 [Discriminator loss: 0.6791%, acc.: 58.59%] [Generator loss: 0.7678%]\n",
            "8051 [Discriminator loss: 0.6518%, acc.: 64.45%] [Generator loss: 0.7897%]\n",
            "8052 [Discriminator loss: 0.6759%, acc.: 56.64%] [Generator loss: 0.7642%]\n",
            "8053 [Discriminator loss: 0.6709%, acc.: 54.69%] [Generator loss: 0.7864%]\n",
            "8054 [Discriminator loss: 0.6742%, acc.: 58.20%] [Generator loss: 0.8095%]\n",
            "8055 [Discriminator loss: 0.6669%, acc.: 57.03%] [Generator loss: 0.7850%]\n",
            "8056 [Discriminator loss: 0.6443%, acc.: 68.36%] [Generator loss: 0.7939%]\n",
            "8057 [Discriminator loss: 0.6856%, acc.: 57.03%] [Generator loss: 0.8105%]\n",
            "8058 [Discriminator loss: 0.6690%, acc.: 61.72%] [Generator loss: 0.7778%]\n",
            "8059 [Discriminator loss: 0.6859%, acc.: 52.73%] [Generator loss: 0.7709%]\n",
            "8060 [Discriminator loss: 0.6750%, acc.: 54.30%] [Generator loss: 0.7859%]\n",
            "8061 [Discriminator loss: 0.6846%, acc.: 59.38%] [Generator loss: 0.7759%]\n",
            "8062 [Discriminator loss: 0.6768%, acc.: 57.03%] [Generator loss: 0.7849%]\n",
            "8063 [Discriminator loss: 0.6684%, acc.: 57.81%] [Generator loss: 0.8063%]\n",
            "8064 [Discriminator loss: 0.6787%, acc.: 60.16%] [Generator loss: 0.7785%]\n",
            "8065 [Discriminator loss: 0.6859%, acc.: 55.08%] [Generator loss: 0.7659%]\n",
            "8066 [Discriminator loss: 0.6755%, acc.: 58.98%] [Generator loss: 0.8030%]\n",
            "8067 [Discriminator loss: 0.6761%, acc.: 59.38%] [Generator loss: 0.7895%]\n",
            "8068 [Discriminator loss: 0.6694%, acc.: 58.20%] [Generator loss: 0.7762%]\n",
            "8069 [Discriminator loss: 0.6812%, acc.: 56.25%] [Generator loss: 0.7617%]\n",
            "8070 [Discriminator loss: 0.6716%, acc.: 60.16%] [Generator loss: 0.7870%]\n",
            "8071 [Discriminator loss: 0.6872%, acc.: 52.34%] [Generator loss: 0.7936%]\n",
            "8072 [Discriminator loss: 0.6594%, acc.: 64.45%] [Generator loss: 0.7716%]\n",
            "8073 [Discriminator loss: 0.6667%, acc.: 57.03%] [Generator loss: 0.7687%]\n",
            "8074 [Discriminator loss: 0.6715%, acc.: 59.38%] [Generator loss: 0.7701%]\n",
            "8075 [Discriminator loss: 0.6880%, acc.: 54.69%] [Generator loss: 0.7752%]\n",
            "8076 [Discriminator loss: 0.6689%, acc.: 61.33%] [Generator loss: 0.7852%]\n",
            "8077 [Discriminator loss: 0.6818%, acc.: 55.86%] [Generator loss: 0.8016%]\n",
            "8078 [Discriminator loss: 0.6937%, acc.: 53.52%] [Generator loss: 0.7765%]\n",
            "8079 [Discriminator loss: 0.6673%, acc.: 63.28%] [Generator loss: 0.7799%]\n",
            "8080 [Discriminator loss: 0.6757%, acc.: 60.16%] [Generator loss: 0.8042%]\n",
            "8081 [Discriminator loss: 0.6542%, acc.: 64.45%] [Generator loss: 0.7929%]\n",
            "8082 [Discriminator loss: 0.6670%, acc.: 61.72%] [Generator loss: 0.7824%]\n",
            "8083 [Discriminator loss: 0.6762%, acc.: 53.12%] [Generator loss: 0.8042%]\n",
            "8084 [Discriminator loss: 0.6767%, acc.: 54.30%] [Generator loss: 0.8025%]\n",
            "8085 [Discriminator loss: 0.6809%, acc.: 54.30%] [Generator loss: 0.7763%]\n",
            "8086 [Discriminator loss: 0.6970%, acc.: 54.30%] [Generator loss: 0.7835%]\n",
            "8087 [Discriminator loss: 0.6760%, acc.: 59.77%] [Generator loss: 0.7824%]\n",
            "8088 [Discriminator loss: 0.6558%, acc.: 66.41%] [Generator loss: 0.7828%]\n",
            "8089 [Discriminator loss: 0.6825%, acc.: 53.91%] [Generator loss: 0.7762%]\n",
            "8090 [Discriminator loss: 0.6628%, acc.: 61.72%] [Generator loss: 0.7745%]\n",
            "8091 [Discriminator loss: 0.6798%, acc.: 57.42%] [Generator loss: 0.7565%]\n",
            "8092 [Discriminator loss: 0.6702%, acc.: 55.86%] [Generator loss: 0.7642%]\n",
            "8093 [Discriminator loss: 0.6811%, acc.: 55.86%] [Generator loss: 0.7595%]\n",
            "8094 [Discriminator loss: 0.6721%, acc.: 57.03%] [Generator loss: 0.7860%]\n",
            "8095 [Discriminator loss: 0.6771%, acc.: 58.20%] [Generator loss: 0.7788%]\n",
            "8096 [Discriminator loss: 0.6788%, acc.: 57.81%] [Generator loss: 0.7942%]\n",
            "8097 [Discriminator loss: 0.6871%, acc.: 56.25%] [Generator loss: 0.7770%]\n",
            "8098 [Discriminator loss: 0.6909%, acc.: 51.56%] [Generator loss: 0.7740%]\n",
            "8099 [Discriminator loss: 0.6727%, acc.: 57.03%] [Generator loss: 0.7678%]\n",
            "8100 [Discriminator loss: 0.6609%, acc.: 64.45%] [Generator loss: 0.7821%]\n",
            "8101 [Discriminator loss: 0.6845%, acc.: 56.25%] [Generator loss: 0.7797%]\n",
            "8102 [Discriminator loss: 0.6577%, acc.: 58.59%] [Generator loss: 0.7769%]\n",
            "8103 [Discriminator loss: 0.6713%, acc.: 58.59%] [Generator loss: 0.7940%]\n",
            "8104 [Discriminator loss: 0.6750%, acc.: 57.81%] [Generator loss: 0.7826%]\n",
            "8105 [Discriminator loss: 0.6688%, acc.: 58.98%] [Generator loss: 0.7696%]\n",
            "8106 [Discriminator loss: 0.6601%, acc.: 63.28%] [Generator loss: 0.7962%]\n",
            "8107 [Discriminator loss: 0.6633%, acc.: 62.11%] [Generator loss: 0.7720%]\n",
            "8108 [Discriminator loss: 0.6575%, acc.: 59.38%] [Generator loss: 0.7568%]\n",
            "8109 [Discriminator loss: 0.6763%, acc.: 57.03%] [Generator loss: 0.7613%]\n",
            "8110 [Discriminator loss: 0.6828%, acc.: 56.25%] [Generator loss: 0.7801%]\n",
            "8111 [Discriminator loss: 0.6611%, acc.: 62.11%] [Generator loss: 0.8172%]\n",
            "8112 [Discriminator loss: 0.6765%, acc.: 58.20%] [Generator loss: 0.7574%]\n",
            "8113 [Discriminator loss: 0.6758%, acc.: 53.52%] [Generator loss: 0.7807%]\n",
            "8114 [Discriminator loss: 0.6748%, acc.: 59.38%] [Generator loss: 0.8060%]\n",
            "8115 [Discriminator loss: 0.6779%, acc.: 61.33%] [Generator loss: 0.7992%]\n",
            "8116 [Discriminator loss: 0.6372%, acc.: 68.75%] [Generator loss: 0.7851%]\n",
            "8117 [Discriminator loss: 0.6597%, acc.: 61.72%] [Generator loss: 0.8107%]\n",
            "8118 [Discriminator loss: 0.6722%, acc.: 59.77%] [Generator loss: 0.7976%]\n",
            "8119 [Discriminator loss: 0.6632%, acc.: 61.33%] [Generator loss: 0.7860%]\n",
            "8120 [Discriminator loss: 0.6459%, acc.: 66.80%] [Generator loss: 0.7966%]\n",
            "8121 [Discriminator loss: 0.6734%, acc.: 59.77%] [Generator loss: 0.7713%]\n",
            "8122 [Discriminator loss: 0.6860%, acc.: 54.69%] [Generator loss: 0.7898%]\n",
            "8123 [Discriminator loss: 0.6655%, acc.: 57.81%] [Generator loss: 0.7947%]\n",
            "8124 [Discriminator loss: 0.6586%, acc.: 60.94%] [Generator loss: 0.7950%]\n",
            "8125 [Discriminator loss: 0.6786%, acc.: 57.03%] [Generator loss: 0.7847%]\n",
            "8126 [Discriminator loss: 0.6578%, acc.: 60.16%] [Generator loss: 0.7804%]\n",
            "8127 [Discriminator loss: 0.6652%, acc.: 62.11%] [Generator loss: 0.7878%]\n",
            "8128 [Discriminator loss: 0.6753%, acc.: 58.20%] [Generator loss: 0.7737%]\n",
            "8129 [Discriminator loss: 0.6793%, acc.: 56.64%] [Generator loss: 0.7612%]\n",
            "8130 [Discriminator loss: 0.6818%, acc.: 57.42%] [Generator loss: 0.7667%]\n",
            "8131 [Discriminator loss: 0.6701%, acc.: 62.11%] [Generator loss: 0.7631%]\n",
            "8132 [Discriminator loss: 0.6606%, acc.: 64.06%] [Generator loss: 0.7787%]\n",
            "8133 [Discriminator loss: 0.6592%, acc.: 62.89%] [Generator loss: 0.7881%]\n",
            "8134 [Discriminator loss: 0.6830%, acc.: 55.47%] [Generator loss: 0.8092%]\n",
            "8135 [Discriminator loss: 0.6770%, acc.: 59.77%] [Generator loss: 0.7779%]\n",
            "8136 [Discriminator loss: 0.6619%, acc.: 58.98%] [Generator loss: 0.7818%]\n",
            "8137 [Discriminator loss: 0.6526%, acc.: 65.23%] [Generator loss: 0.7629%]\n",
            "8138 [Discriminator loss: 0.6647%, acc.: 59.38%] [Generator loss: 0.8093%]\n",
            "8139 [Discriminator loss: 0.6584%, acc.: 65.62%] [Generator loss: 0.7869%]\n",
            "8140 [Discriminator loss: 0.6770%, acc.: 57.81%] [Generator loss: 0.7914%]\n",
            "8141 [Discriminator loss: 0.6737%, acc.: 58.98%] [Generator loss: 0.7982%]\n",
            "8142 [Discriminator loss: 0.6570%, acc.: 64.06%] [Generator loss: 0.7865%]\n",
            "8143 [Discriminator loss: 0.6658%, acc.: 60.94%] [Generator loss: 0.7752%]\n",
            "8144 [Discriminator loss: 0.6531%, acc.: 62.89%] [Generator loss: 0.7935%]\n",
            "8145 [Discriminator loss: 0.6841%, acc.: 55.08%] [Generator loss: 0.8042%]\n",
            "8146 [Discriminator loss: 0.6785%, acc.: 56.25%] [Generator loss: 0.7901%]\n",
            "8147 [Discriminator loss: 0.6757%, acc.: 57.03%] [Generator loss: 0.7998%]\n",
            "8148 [Discriminator loss: 0.6496%, acc.: 62.50%] [Generator loss: 0.7833%]\n",
            "8149 [Discriminator loss: 0.6614%, acc.: 60.55%] [Generator loss: 0.7931%]\n",
            "8150 [Discriminator loss: 0.6620%, acc.: 62.11%] [Generator loss: 0.7983%]\n",
            "8151 [Discriminator loss: 0.6866%, acc.: 49.61%] [Generator loss: 0.7998%]\n",
            "8152 [Discriminator loss: 0.6607%, acc.: 64.84%] [Generator loss: 0.7839%]\n",
            "8153 [Discriminator loss: 0.6532%, acc.: 62.11%] [Generator loss: 0.7766%]\n",
            "8154 [Discriminator loss: 0.6703%, acc.: 60.16%] [Generator loss: 0.7809%]\n",
            "8155 [Discriminator loss: 0.6708%, acc.: 60.16%] [Generator loss: 0.7942%]\n",
            "8156 [Discriminator loss: 0.6793%, acc.: 58.98%] [Generator loss: 0.7855%]\n",
            "8157 [Discriminator loss: 0.6646%, acc.: 60.55%] [Generator loss: 0.7939%]\n",
            "8158 [Discriminator loss: 0.6938%, acc.: 52.73%] [Generator loss: 0.8072%]\n",
            "8159 [Discriminator loss: 0.6899%, acc.: 54.30%] [Generator loss: 0.7905%]\n",
            "8160 [Discriminator loss: 0.6862%, acc.: 55.47%] [Generator loss: 0.7843%]\n",
            "8161 [Discriminator loss: 0.6740%, acc.: 60.94%] [Generator loss: 0.7698%]\n",
            "8162 [Discriminator loss: 0.6700%, acc.: 57.42%] [Generator loss: 0.7707%]\n",
            "8163 [Discriminator loss: 0.6704%, acc.: 59.38%] [Generator loss: 0.7704%]\n",
            "8164 [Discriminator loss: 0.6669%, acc.: 60.16%] [Generator loss: 0.7808%]\n",
            "8165 [Discriminator loss: 0.6550%, acc.: 60.94%] [Generator loss: 0.8006%]\n",
            "8166 [Discriminator loss: 0.6873%, acc.: 57.42%] [Generator loss: 0.7991%]\n",
            "8167 [Discriminator loss: 0.6544%, acc.: 63.67%] [Generator loss: 0.8086%]\n",
            "8168 [Discriminator loss: 0.6801%, acc.: 57.03%] [Generator loss: 0.7982%]\n",
            "8169 [Discriminator loss: 0.6843%, acc.: 51.56%] [Generator loss: 0.7877%]\n",
            "8170 [Discriminator loss: 0.6644%, acc.: 58.98%] [Generator loss: 0.7831%]\n",
            "8171 [Discriminator loss: 0.6607%, acc.: 62.11%] [Generator loss: 0.8167%]\n",
            "8172 [Discriminator loss: 0.6587%, acc.: 63.67%] [Generator loss: 0.7974%]\n",
            "8173 [Discriminator loss: 0.6757%, acc.: 61.33%] [Generator loss: 0.7835%]\n",
            "8174 [Discriminator loss: 0.6548%, acc.: 58.98%] [Generator loss: 0.7783%]\n",
            "8175 [Discriminator loss: 0.6671%, acc.: 59.77%] [Generator loss: 0.7799%]\n",
            "8176 [Discriminator loss: 0.6680%, acc.: 59.38%] [Generator loss: 0.7602%]\n",
            "8177 [Discriminator loss: 0.6666%, acc.: 61.33%] [Generator loss: 0.7419%]\n",
            "8178 [Discriminator loss: 0.6481%, acc.: 63.28%] [Generator loss: 0.7663%]\n",
            "8179 [Discriminator loss: 0.6868%, acc.: 51.95%] [Generator loss: 0.7657%]\n",
            "8180 [Discriminator loss: 0.6689%, acc.: 57.81%] [Generator loss: 0.7551%]\n",
            "8181 [Discriminator loss: 0.6655%, acc.: 60.94%] [Generator loss: 0.7671%]\n",
            "8182 [Discriminator loss: 0.6729%, acc.: 55.86%] [Generator loss: 0.7693%]\n",
            "8183 [Discriminator loss: 0.6713%, acc.: 57.03%] [Generator loss: 0.7748%]\n",
            "8184 [Discriminator loss: 0.6743%, acc.: 61.72%] [Generator loss: 0.7942%]\n",
            "8185 [Discriminator loss: 0.6581%, acc.: 62.11%] [Generator loss: 0.7933%]\n",
            "8186 [Discriminator loss: 0.6563%, acc.: 62.11%] [Generator loss: 0.7723%]\n",
            "8187 [Discriminator loss: 0.6782%, acc.: 57.42%] [Generator loss: 0.7760%]\n",
            "8188 [Discriminator loss: 0.6798%, acc.: 57.42%] [Generator loss: 0.7817%]\n",
            "8189 [Discriminator loss: 0.6696%, acc.: 58.98%] [Generator loss: 0.7672%]\n",
            "8190 [Discriminator loss: 0.6713%, acc.: 58.98%] [Generator loss: 0.7821%]\n",
            "8191 [Discriminator loss: 0.6636%, acc.: 59.38%] [Generator loss: 0.7832%]\n",
            "8192 [Discriminator loss: 0.6700%, acc.: 60.94%] [Generator loss: 0.8083%]\n",
            "8193 [Discriminator loss: 0.6821%, acc.: 51.56%] [Generator loss: 0.7937%]\n",
            "8194 [Discriminator loss: 0.6766%, acc.: 62.11%] [Generator loss: 0.7938%]\n",
            "8195 [Discriminator loss: 0.6827%, acc.: 57.42%] [Generator loss: 0.7986%]\n",
            "8196 [Discriminator loss: 0.6688%, acc.: 55.86%] [Generator loss: 0.7813%]\n",
            "8197 [Discriminator loss: 0.6678%, acc.: 58.59%] [Generator loss: 0.7883%]\n",
            "8198 [Discriminator loss: 0.6748%, acc.: 59.38%] [Generator loss: 0.7845%]\n",
            "8199 [Discriminator loss: 0.6937%, acc.: 56.64%] [Generator loss: 0.7801%]\n",
            "8200 [Discriminator loss: 0.6953%, acc.: 51.95%] [Generator loss: 0.7862%]\n",
            "8201 [Discriminator loss: 0.6929%, acc.: 55.08%] [Generator loss: 0.7652%]\n",
            "8202 [Discriminator loss: 0.6696%, acc.: 60.94%] [Generator loss: 0.7850%]\n",
            "8203 [Discriminator loss: 0.6996%, acc.: 53.52%] [Generator loss: 0.7741%]\n",
            "8204 [Discriminator loss: 0.6756%, acc.: 58.59%] [Generator loss: 0.7661%]\n",
            "8205 [Discriminator loss: 0.6986%, acc.: 49.61%] [Generator loss: 0.7896%]\n",
            "8206 [Discriminator loss: 0.6760%, acc.: 56.64%] [Generator loss: 0.7796%]\n",
            "8207 [Discriminator loss: 0.6762%, acc.: 58.59%] [Generator loss: 0.8051%]\n",
            "8208 [Discriminator loss: 0.6653%, acc.: 57.03%] [Generator loss: 0.7788%]\n",
            "8209 [Discriminator loss: 0.6844%, acc.: 56.64%] [Generator loss: 0.7778%]\n",
            "8210 [Discriminator loss: 0.6897%, acc.: 51.17%] [Generator loss: 0.7748%]\n",
            "8211 [Discriminator loss: 0.6831%, acc.: 53.91%] [Generator loss: 0.7833%]\n",
            "8212 [Discriminator loss: 0.6825%, acc.: 57.03%] [Generator loss: 0.7806%]\n",
            "8213 [Discriminator loss: 0.6892%, acc.: 55.08%] [Generator loss: 0.7836%]\n",
            "8214 [Discriminator loss: 0.6741%, acc.: 57.42%] [Generator loss: 0.7797%]\n",
            "8215 [Discriminator loss: 0.6803%, acc.: 53.52%] [Generator loss: 0.7822%]\n",
            "8216 [Discriminator loss: 0.6672%, acc.: 62.89%] [Generator loss: 0.8074%]\n",
            "8217 [Discriminator loss: 0.6638%, acc.: 56.64%] [Generator loss: 0.8039%]\n",
            "8218 [Discriminator loss: 0.6710%, acc.: 55.86%] [Generator loss: 0.8172%]\n",
            "8219 [Discriminator loss: 0.6759%, acc.: 56.64%] [Generator loss: 0.7971%]\n",
            "8220 [Discriminator loss: 0.6937%, acc.: 51.17%] [Generator loss: 0.7932%]\n",
            "8221 [Discriminator loss: 0.6787%, acc.: 57.42%] [Generator loss: 0.7852%]\n",
            "8222 [Discriminator loss: 0.6831%, acc.: 58.59%] [Generator loss: 0.7924%]\n",
            "8223 [Discriminator loss: 0.6819%, acc.: 56.25%] [Generator loss: 0.8167%]\n",
            "8224 [Discriminator loss: 0.6614%, acc.: 60.94%] [Generator loss: 0.7845%]\n",
            "8225 [Discriminator loss: 0.6672%, acc.: 59.38%] [Generator loss: 0.8024%]\n",
            "8226 [Discriminator loss: 0.6730%, acc.: 57.81%] [Generator loss: 0.8003%]\n",
            "8227 [Discriminator loss: 0.6745%, acc.: 59.77%] [Generator loss: 0.7770%]\n",
            "8228 [Discriminator loss: 0.6781%, acc.: 59.38%] [Generator loss: 0.7913%]\n",
            "8229 [Discriminator loss: 0.6736%, acc.: 57.81%] [Generator loss: 0.7848%]\n",
            "8230 [Discriminator loss: 0.6860%, acc.: 51.95%] [Generator loss: 0.7796%]\n",
            "8231 [Discriminator loss: 0.6816%, acc.: 53.91%] [Generator loss: 0.7779%]\n",
            "8232 [Discriminator loss: 0.6649%, acc.: 60.55%] [Generator loss: 0.8015%]\n",
            "8233 [Discriminator loss: 0.6710%, acc.: 58.98%] [Generator loss: 0.8046%]\n",
            "8234 [Discriminator loss: 0.6759%, acc.: 57.42%] [Generator loss: 0.7730%]\n",
            "8235 [Discriminator loss: 0.6737%, acc.: 57.42%] [Generator loss: 0.7758%]\n",
            "8236 [Discriminator loss: 0.6692%, acc.: 60.55%] [Generator loss: 0.7890%]\n",
            "8237 [Discriminator loss: 0.6804%, acc.: 53.52%] [Generator loss: 0.8015%]\n",
            "8238 [Discriminator loss: 0.6673%, acc.: 60.94%] [Generator loss: 0.7889%]\n",
            "8239 [Discriminator loss: 0.6590%, acc.: 62.89%] [Generator loss: 0.7812%]\n",
            "8240 [Discriminator loss: 0.6825%, acc.: 53.52%] [Generator loss: 0.7759%]\n",
            "8241 [Discriminator loss: 0.6826%, acc.: 55.86%] [Generator loss: 0.7527%]\n",
            "8242 [Discriminator loss: 0.6687%, acc.: 60.16%] [Generator loss: 0.7592%]\n",
            "8243 [Discriminator loss: 0.6742%, acc.: 59.77%] [Generator loss: 0.7648%]\n",
            "8244 [Discriminator loss: 0.6729%, acc.: 58.20%] [Generator loss: 0.7823%]\n",
            "8245 [Discriminator loss: 0.6689%, acc.: 58.59%] [Generator loss: 0.7891%]\n",
            "8246 [Discriminator loss: 0.6566%, acc.: 60.55%] [Generator loss: 0.7948%]\n",
            "8247 [Discriminator loss: 0.6647%, acc.: 58.98%] [Generator loss: 0.8070%]\n",
            "8248 [Discriminator loss: 0.6544%, acc.: 63.67%] [Generator loss: 0.7734%]\n",
            "8249 [Discriminator loss: 0.6816%, acc.: 57.81%] [Generator loss: 0.7974%]\n",
            "8250 [Discriminator loss: 0.6605%, acc.: 61.33%] [Generator loss: 0.7625%]\n",
            "8251 [Discriminator loss: 0.6772%, acc.: 50.78%] [Generator loss: 0.7937%]\n",
            "8252 [Discriminator loss: 0.6759%, acc.: 56.64%] [Generator loss: 0.8030%]\n",
            "8253 [Discriminator loss: 0.6607%, acc.: 61.33%] [Generator loss: 0.7944%]\n",
            "8254 [Discriminator loss: 0.6680%, acc.: 62.50%] [Generator loss: 0.7864%]\n",
            "8255 [Discriminator loss: 0.6583%, acc.: 62.89%] [Generator loss: 0.8124%]\n",
            "8256 [Discriminator loss: 0.6640%, acc.: 61.72%] [Generator loss: 0.7950%]\n",
            "8257 [Discriminator loss: 0.6930%, acc.: 50.78%] [Generator loss: 0.7848%]\n",
            "8258 [Discriminator loss: 0.6632%, acc.: 60.94%] [Generator loss: 0.7929%]\n",
            "8259 [Discriminator loss: 0.6612%, acc.: 62.50%] [Generator loss: 0.7933%]\n",
            "8260 [Discriminator loss: 0.6618%, acc.: 59.38%] [Generator loss: 0.8159%]\n",
            "8261 [Discriminator loss: 0.6517%, acc.: 61.33%] [Generator loss: 0.8194%]\n",
            "8262 [Discriminator loss: 0.6704%, acc.: 58.98%] [Generator loss: 0.7996%]\n",
            "8263 [Discriminator loss: 0.6792%, acc.: 57.42%] [Generator loss: 0.7744%]\n",
            "8264 [Discriminator loss: 0.6458%, acc.: 66.80%] [Generator loss: 0.7610%]\n",
            "8265 [Discriminator loss: 0.6612%, acc.: 60.94%] [Generator loss: 0.7998%]\n",
            "8266 [Discriminator loss: 0.6612%, acc.: 62.11%] [Generator loss: 0.7743%]\n",
            "8267 [Discriminator loss: 0.6913%, acc.: 53.52%] [Generator loss: 0.7683%]\n",
            "8268 [Discriminator loss: 0.6704%, acc.: 60.16%] [Generator loss: 0.7989%]\n",
            "8269 [Discriminator loss: 0.6785%, acc.: 54.30%] [Generator loss: 0.8195%]\n",
            "8270 [Discriminator loss: 0.6896%, acc.: 56.64%] [Generator loss: 0.8089%]\n",
            "8271 [Discriminator loss: 0.6960%, acc.: 56.64%] [Generator loss: 0.7743%]\n",
            "8272 [Discriminator loss: 0.6676%, acc.: 61.33%] [Generator loss: 0.7942%]\n",
            "8273 [Discriminator loss: 0.6788%, acc.: 57.42%] [Generator loss: 0.7866%]\n",
            "8274 [Discriminator loss: 0.6543%, acc.: 65.23%] [Generator loss: 0.7580%]\n",
            "8275 [Discriminator loss: 0.6713%, acc.: 58.20%] [Generator loss: 0.7977%]\n",
            "8276 [Discriminator loss: 0.6595%, acc.: 64.84%] [Generator loss: 0.7864%]\n",
            "8277 [Discriminator loss: 0.6798%, acc.: 58.59%] [Generator loss: 0.7968%]\n",
            "8278 [Discriminator loss: 0.6706%, acc.: 57.03%] [Generator loss: 0.7961%]\n",
            "8279 [Discriminator loss: 0.6636%, acc.: 64.06%] [Generator loss: 0.7925%]\n",
            "8280 [Discriminator loss: 0.6740%, acc.: 56.64%] [Generator loss: 0.7921%]\n",
            "8281 [Discriminator loss: 0.6666%, acc.: 58.98%] [Generator loss: 0.7875%]\n",
            "8282 [Discriminator loss: 0.6895%, acc.: 53.12%] [Generator loss: 0.7893%]\n",
            "8283 [Discriminator loss: 0.6560%, acc.: 64.06%] [Generator loss: 0.7947%]\n",
            "8284 [Discriminator loss: 0.6787%, acc.: 59.38%] [Generator loss: 0.7980%]\n",
            "8285 [Discriminator loss: 0.6911%, acc.: 51.17%] [Generator loss: 0.7983%]\n",
            "8286 [Discriminator loss: 0.6761%, acc.: 54.69%] [Generator loss: 0.8007%]\n",
            "8287 [Discriminator loss: 0.6733%, acc.: 63.67%] [Generator loss: 0.7888%]\n",
            "8288 [Discriminator loss: 0.6726%, acc.: 58.20%] [Generator loss: 0.8158%]\n",
            "8289 [Discriminator loss: 0.6556%, acc.: 60.55%] [Generator loss: 0.7806%]\n",
            "8290 [Discriminator loss: 0.6969%, acc.: 48.44%] [Generator loss: 0.7916%]\n",
            "8291 [Discriminator loss: 0.6514%, acc.: 63.67%] [Generator loss: 0.7854%]\n",
            "8292 [Discriminator loss: 0.6867%, acc.: 53.52%] [Generator loss: 0.7925%]\n",
            "8293 [Discriminator loss: 0.6737%, acc.: 59.77%] [Generator loss: 0.8167%]\n",
            "8294 [Discriminator loss: 0.6783%, acc.: 57.03%] [Generator loss: 0.7841%]\n",
            "8295 [Discriminator loss: 0.6831%, acc.: 55.08%] [Generator loss: 0.7947%]\n",
            "8296 [Discriminator loss: 0.6678%, acc.: 57.81%] [Generator loss: 0.8103%]\n",
            "8297 [Discriminator loss: 0.6653%, acc.: 62.11%] [Generator loss: 0.7931%]\n",
            "8298 [Discriminator loss: 0.6743%, acc.: 57.81%] [Generator loss: 0.7854%]\n",
            "8299 [Discriminator loss: 0.6638%, acc.: 61.72%] [Generator loss: 0.8148%]\n",
            "8300 [Discriminator loss: 0.6761%, acc.: 57.81%] [Generator loss: 0.8009%]\n",
            "8301 [Discriminator loss: 0.6722%, acc.: 58.20%] [Generator loss: 0.8266%]\n",
            "8302 [Discriminator loss: 0.6579%, acc.: 62.50%] [Generator loss: 0.7999%]\n",
            "8303 [Discriminator loss: 0.6768%, acc.: 57.81%] [Generator loss: 0.8051%]\n",
            "8304 [Discriminator loss: 0.6551%, acc.: 64.84%] [Generator loss: 0.7899%]\n",
            "8305 [Discriminator loss: 0.6643%, acc.: 60.55%] [Generator loss: 0.8085%]\n",
            "8306 [Discriminator loss: 0.6565%, acc.: 64.45%] [Generator loss: 0.7983%]\n",
            "8307 [Discriminator loss: 0.6782%, acc.: 58.59%] [Generator loss: 0.8037%]\n",
            "8308 [Discriminator loss: 0.6524%, acc.: 64.45%] [Generator loss: 0.8033%]\n",
            "8309 [Discriminator loss: 0.6609%, acc.: 65.23%] [Generator loss: 0.8073%]\n",
            "8310 [Discriminator loss: 0.6773%, acc.: 60.55%] [Generator loss: 0.7956%]\n",
            "8311 [Discriminator loss: 0.6639%, acc.: 62.89%] [Generator loss: 0.8255%]\n",
            "8312 [Discriminator loss: 0.6833%, acc.: 58.59%] [Generator loss: 0.7847%]\n",
            "8313 [Discriminator loss: 0.6765%, acc.: 61.72%] [Generator loss: 0.7986%]\n",
            "8314 [Discriminator loss: 0.6848%, acc.: 56.25%] [Generator loss: 0.7919%]\n",
            "8315 [Discriminator loss: 0.6573%, acc.: 63.28%] [Generator loss: 0.7917%]\n",
            "8316 [Discriminator loss: 0.6655%, acc.: 58.98%] [Generator loss: 0.7786%]\n",
            "8317 [Discriminator loss: 0.6706%, acc.: 60.16%] [Generator loss: 0.8046%]\n",
            "8318 [Discriminator loss: 0.6767%, acc.: 58.59%] [Generator loss: 0.7978%]\n",
            "8319 [Discriminator loss: 0.6726%, acc.: 60.55%] [Generator loss: 0.7926%]\n",
            "8320 [Discriminator loss: 0.6727%, acc.: 56.25%] [Generator loss: 0.7861%]\n",
            "8321 [Discriminator loss: 0.6718%, acc.: 60.16%] [Generator loss: 0.7939%]\n",
            "8322 [Discriminator loss: 0.6628%, acc.: 62.50%] [Generator loss: 0.7967%]\n",
            "8323 [Discriminator loss: 0.6740%, acc.: 61.33%] [Generator loss: 0.7879%]\n",
            "8324 [Discriminator loss: 0.6834%, acc.: 54.30%] [Generator loss: 0.7769%]\n",
            "8325 [Discriminator loss: 0.6701%, acc.: 56.64%] [Generator loss: 0.7770%]\n",
            "8326 [Discriminator loss: 0.6738%, acc.: 57.03%] [Generator loss: 0.8123%]\n",
            "8327 [Discriminator loss: 0.6700%, acc.: 56.64%] [Generator loss: 0.8251%]\n",
            "8328 [Discriminator loss: 0.6720%, acc.: 59.77%] [Generator loss: 0.7978%]\n",
            "8329 [Discriminator loss: 0.6682%, acc.: 54.69%] [Generator loss: 0.7937%]\n",
            "8330 [Discriminator loss: 0.6896%, acc.: 52.73%] [Generator loss: 0.7976%]\n",
            "8331 [Discriminator loss: 0.6641%, acc.: 59.77%] [Generator loss: 0.7785%]\n",
            "8332 [Discriminator loss: 0.6974%, acc.: 48.83%] [Generator loss: 0.7950%]\n",
            "8333 [Discriminator loss: 0.6765%, acc.: 58.20%] [Generator loss: 0.7918%]\n",
            "8334 [Discriminator loss: 0.6827%, acc.: 51.56%] [Generator loss: 0.8006%]\n",
            "8335 [Discriminator loss: 0.6662%, acc.: 63.28%] [Generator loss: 0.8041%]\n",
            "8336 [Discriminator loss: 0.6762%, acc.: 58.98%] [Generator loss: 0.7963%]\n",
            "8337 [Discriminator loss: 0.6675%, acc.: 59.38%] [Generator loss: 0.8091%]\n",
            "8338 [Discriminator loss: 0.6880%, acc.: 57.03%] [Generator loss: 0.8000%]\n",
            "8339 [Discriminator loss: 0.6937%, acc.: 54.30%] [Generator loss: 0.7944%]\n",
            "8340 [Discriminator loss: 0.6581%, acc.: 62.11%] [Generator loss: 0.7933%]\n",
            "8341 [Discriminator loss: 0.6586%, acc.: 63.28%] [Generator loss: 0.7906%]\n",
            "8342 [Discriminator loss: 0.6729%, acc.: 57.81%] [Generator loss: 0.7822%]\n",
            "8343 [Discriminator loss: 0.6981%, acc.: 51.17%] [Generator loss: 0.7895%]\n",
            "8344 [Discriminator loss: 0.6758%, acc.: 60.55%] [Generator loss: 0.7812%]\n",
            "8345 [Discriminator loss: 0.6719%, acc.: 58.59%] [Generator loss: 0.7800%]\n",
            "8346 [Discriminator loss: 0.6831%, acc.: 55.47%] [Generator loss: 0.8023%]\n",
            "8347 [Discriminator loss: 0.6824%, acc.: 56.25%] [Generator loss: 0.7752%]\n",
            "8348 [Discriminator loss: 0.6704%, acc.: 61.33%] [Generator loss: 0.7846%]\n",
            "8349 [Discriminator loss: 0.6692%, acc.: 57.81%] [Generator loss: 0.7794%]\n",
            "8350 [Discriminator loss: 0.6915%, acc.: 55.86%] [Generator loss: 0.7778%]\n",
            "8351 [Discriminator loss: 0.6889%, acc.: 52.73%] [Generator loss: 0.7713%]\n",
            "8352 [Discriminator loss: 0.6728%, acc.: 60.55%] [Generator loss: 0.7763%]\n",
            "8353 [Discriminator loss: 0.6872%, acc.: 54.30%] [Generator loss: 0.7715%]\n",
            "8354 [Discriminator loss: 0.6714%, acc.: 60.16%] [Generator loss: 0.7653%]\n",
            "8355 [Discriminator loss: 0.6555%, acc.: 61.72%] [Generator loss: 0.7720%]\n",
            "8356 [Discriminator loss: 0.6574%, acc.: 61.33%] [Generator loss: 0.7849%]\n",
            "8357 [Discriminator loss: 0.6693%, acc.: 60.94%] [Generator loss: 0.7887%]\n",
            "8358 [Discriminator loss: 0.6736%, acc.: 55.47%] [Generator loss: 0.7989%]\n",
            "8359 [Discriminator loss: 0.6806%, acc.: 55.47%] [Generator loss: 0.7929%]\n",
            "8360 [Discriminator loss: 0.6813%, acc.: 53.91%] [Generator loss: 0.7822%]\n",
            "8361 [Discriminator loss: 0.6759%, acc.: 60.55%] [Generator loss: 0.7846%]\n",
            "8362 [Discriminator loss: 0.6637%, acc.: 55.86%] [Generator loss: 0.7745%]\n",
            "8363 [Discriminator loss: 0.6722%, acc.: 64.06%] [Generator loss: 0.7847%]\n",
            "8364 [Discriminator loss: 0.6710%, acc.: 58.20%] [Generator loss: 0.8031%]\n",
            "8365 [Discriminator loss: 0.6829%, acc.: 56.64%] [Generator loss: 0.7917%]\n",
            "8366 [Discriminator loss: 0.6693%, acc.: 59.38%] [Generator loss: 0.7690%]\n",
            "8367 [Discriminator loss: 0.6678%, acc.: 58.20%] [Generator loss: 0.8105%]\n",
            "8368 [Discriminator loss: 0.6670%, acc.: 54.30%] [Generator loss: 0.7760%]\n",
            "8369 [Discriminator loss: 0.6805%, acc.: 57.42%] [Generator loss: 0.7874%]\n",
            "8370 [Discriminator loss: 0.6676%, acc.: 61.33%] [Generator loss: 0.7845%]\n",
            "8371 [Discriminator loss: 0.6718%, acc.: 57.81%] [Generator loss: 0.7788%]\n",
            "8372 [Discriminator loss: 0.6727%, acc.: 57.42%] [Generator loss: 0.7945%]\n",
            "8373 [Discriminator loss: 0.6774%, acc.: 57.42%] [Generator loss: 0.7774%]\n",
            "8374 [Discriminator loss: 0.6803%, acc.: 58.59%] [Generator loss: 0.7902%]\n",
            "8375 [Discriminator loss: 0.6796%, acc.: 62.11%] [Generator loss: 0.7987%]\n",
            "8376 [Discriminator loss: 0.6710%, acc.: 58.59%] [Generator loss: 0.7954%]\n",
            "8377 [Discriminator loss: 0.6847%, acc.: 55.08%] [Generator loss: 0.7922%]\n",
            "8378 [Discriminator loss: 0.6709%, acc.: 58.20%] [Generator loss: 0.7653%]\n",
            "8379 [Discriminator loss: 0.6839%, acc.: 54.69%] [Generator loss: 0.7521%]\n",
            "8380 [Discriminator loss: 0.6718%, acc.: 62.50%] [Generator loss: 0.7815%]\n",
            "8381 [Discriminator loss: 0.6806%, acc.: 54.30%] [Generator loss: 0.7834%]\n",
            "8382 [Discriminator loss: 0.6580%, acc.: 64.06%] [Generator loss: 0.7874%]\n",
            "8383 [Discriminator loss: 0.6852%, acc.: 53.52%] [Generator loss: 0.7675%]\n",
            "8384 [Discriminator loss: 0.6851%, acc.: 55.86%] [Generator loss: 0.7725%]\n",
            "8385 [Discriminator loss: 0.6715%, acc.: 58.59%] [Generator loss: 0.7634%]\n",
            "8386 [Discriminator loss: 0.6779%, acc.: 56.25%] [Generator loss: 0.7709%]\n",
            "8387 [Discriminator loss: 0.6720%, acc.: 54.30%] [Generator loss: 0.7677%]\n",
            "8388 [Discriminator loss: 0.6803%, acc.: 54.69%] [Generator loss: 0.7732%]\n",
            "8389 [Discriminator loss: 0.6640%, acc.: 60.55%] [Generator loss: 0.7840%]\n",
            "8390 [Discriminator loss: 0.6662%, acc.: 58.59%] [Generator loss: 0.7888%]\n",
            "8391 [Discriminator loss: 0.6899%, acc.: 55.47%] [Generator loss: 0.8073%]\n",
            "8392 [Discriminator loss: 0.6858%, acc.: 53.12%] [Generator loss: 0.7945%]\n",
            "8393 [Discriminator loss: 0.6620%, acc.: 60.16%] [Generator loss: 0.7861%]\n",
            "8394 [Discriminator loss: 0.6676%, acc.: 60.16%] [Generator loss: 0.7962%]\n",
            "8395 [Discriminator loss: 0.6813%, acc.: 60.16%] [Generator loss: 0.7566%]\n",
            "8396 [Discriminator loss: 0.6715%, acc.: 58.98%] [Generator loss: 0.7690%]\n",
            "8397 [Discriminator loss: 0.6637%, acc.: 57.81%] [Generator loss: 0.7942%]\n",
            "8398 [Discriminator loss: 0.6694%, acc.: 57.81%] [Generator loss: 0.7878%]\n",
            "8399 [Discriminator loss: 0.6448%, acc.: 64.06%] [Generator loss: 0.7825%]\n",
            "8400 [Discriminator loss: 0.6781%, acc.: 55.08%] [Generator loss: 0.7915%]\n",
            "8401 [Discriminator loss: 0.6562%, acc.: 61.72%] [Generator loss: 0.7859%]\n",
            "8402 [Discriminator loss: 0.6689%, acc.: 58.20%] [Generator loss: 0.7730%]\n",
            "8403 [Discriminator loss: 0.6720%, acc.: 59.77%] [Generator loss: 0.7805%]\n",
            "8404 [Discriminator loss: 0.6659%, acc.: 58.98%] [Generator loss: 0.7906%]\n",
            "8405 [Discriminator loss: 0.6585%, acc.: 61.33%] [Generator loss: 0.7940%]\n",
            "8406 [Discriminator loss: 0.6744%, acc.: 55.47%] [Generator loss: 0.8008%]\n",
            "8407 [Discriminator loss: 0.6780%, acc.: 55.47%] [Generator loss: 0.7810%]\n",
            "8408 [Discriminator loss: 0.6631%, acc.: 58.98%] [Generator loss: 0.7840%]\n",
            "8409 [Discriminator loss: 0.6845%, acc.: 54.69%] [Generator loss: 0.7902%]\n",
            "8410 [Discriminator loss: 0.6812%, acc.: 54.69%] [Generator loss: 0.7972%]\n",
            "8411 [Discriminator loss: 0.6862%, acc.: 57.42%] [Generator loss: 0.8054%]\n",
            "8412 [Discriminator loss: 0.6830%, acc.: 59.77%] [Generator loss: 0.7773%]\n",
            "8413 [Discriminator loss: 0.6754%, acc.: 53.91%] [Generator loss: 0.8021%]\n",
            "8414 [Discriminator loss: 0.6609%, acc.: 60.16%] [Generator loss: 0.7964%]\n",
            "8415 [Discriminator loss: 0.6887%, acc.: 55.08%] [Generator loss: 0.7809%]\n",
            "8416 [Discriminator loss: 0.6754%, acc.: 59.77%] [Generator loss: 0.7863%]\n",
            "8417 [Discriminator loss: 0.6622%, acc.: 60.94%] [Generator loss: 0.7953%]\n",
            "8418 [Discriminator loss: 0.6629%, acc.: 62.50%] [Generator loss: 0.7588%]\n",
            "8419 [Discriminator loss: 0.6720%, acc.: 55.86%] [Generator loss: 0.7709%]\n",
            "8420 [Discriminator loss: 0.6726%, acc.: 55.47%] [Generator loss: 0.7883%]\n",
            "8421 [Discriminator loss: 0.6732%, acc.: 55.47%] [Generator loss: 0.7817%]\n",
            "8422 [Discriminator loss: 0.6810%, acc.: 53.12%] [Generator loss: 0.7859%]\n",
            "8423 [Discriminator loss: 0.6556%, acc.: 65.62%] [Generator loss: 0.7911%]\n",
            "8424 [Discriminator loss: 0.6813%, acc.: 59.77%] [Generator loss: 0.7984%]\n",
            "8425 [Discriminator loss: 0.6679%, acc.: 55.86%] [Generator loss: 0.8121%]\n",
            "8426 [Discriminator loss: 0.6694%, acc.: 60.16%] [Generator loss: 0.7905%]\n",
            "8427 [Discriminator loss: 0.6824%, acc.: 55.08%] [Generator loss: 0.7985%]\n",
            "8428 [Discriminator loss: 0.6877%, acc.: 54.30%] [Generator loss: 0.7740%]\n",
            "8429 [Discriminator loss: 0.6746%, acc.: 56.64%] [Generator loss: 0.7570%]\n",
            "8430 [Discriminator loss: 0.6456%, acc.: 67.19%] [Generator loss: 0.7697%]\n",
            "8431 [Discriminator loss: 0.6612%, acc.: 60.94%] [Generator loss: 0.8039%]\n",
            "8432 [Discriminator loss: 0.6696%, acc.: 58.20%] [Generator loss: 0.7861%]\n",
            "8433 [Discriminator loss: 0.6745%, acc.: 59.38%] [Generator loss: 0.7885%]\n",
            "8434 [Discriminator loss: 0.6681%, acc.: 59.38%] [Generator loss: 0.7880%]\n",
            "8435 [Discriminator loss: 0.6663%, acc.: 60.16%] [Generator loss: 0.7824%]\n",
            "8436 [Discriminator loss: 0.6712%, acc.: 56.25%] [Generator loss: 0.7915%]\n",
            "8437 [Discriminator loss: 0.6742%, acc.: 57.03%] [Generator loss: 0.7916%]\n",
            "8438 [Discriminator loss: 0.6696%, acc.: 59.38%] [Generator loss: 0.7948%]\n",
            "8439 [Discriminator loss: 0.6793%, acc.: 57.03%] [Generator loss: 0.7874%]\n",
            "8440 [Discriminator loss: 0.6581%, acc.: 63.67%] [Generator loss: 0.7742%]\n",
            "8441 [Discriminator loss: 0.6912%, acc.: 52.34%] [Generator loss: 0.7942%]\n",
            "8442 [Discriminator loss: 0.6546%, acc.: 60.16%] [Generator loss: 0.7717%]\n",
            "8443 [Discriminator loss: 0.6791%, acc.: 55.47%] [Generator loss: 0.7719%]\n",
            "8444 [Discriminator loss: 0.6601%, acc.: 62.89%] [Generator loss: 0.7828%]\n",
            "8445 [Discriminator loss: 0.6872%, acc.: 54.69%] [Generator loss: 0.7797%]\n",
            "8446 [Discriminator loss: 0.6651%, acc.: 59.77%] [Generator loss: 0.7898%]\n",
            "8447 [Discriminator loss: 0.6753%, acc.: 58.20%] [Generator loss: 0.7649%]\n",
            "8448 [Discriminator loss: 0.6573%, acc.: 64.45%] [Generator loss: 0.7643%]\n",
            "8449 [Discriminator loss: 0.6821%, acc.: 55.47%] [Generator loss: 0.7900%]\n",
            "8450 [Discriminator loss: 0.6515%, acc.: 62.50%] [Generator loss: 0.7961%]\n",
            "8451 [Discriminator loss: 0.6630%, acc.: 60.16%] [Generator loss: 0.7708%]\n",
            "8452 [Discriminator loss: 0.6625%, acc.: 63.28%] [Generator loss: 0.8096%]\n",
            "8453 [Discriminator loss: 0.6539%, acc.: 62.89%] [Generator loss: 0.7860%]\n",
            "8454 [Discriminator loss: 0.6723%, acc.: 57.81%] [Generator loss: 0.7729%]\n",
            "8455 [Discriminator loss: 0.6600%, acc.: 62.50%] [Generator loss: 0.7757%]\n",
            "8456 [Discriminator loss: 0.6726%, acc.: 58.98%] [Generator loss: 0.7818%]\n",
            "8457 [Discriminator loss: 0.6576%, acc.: 60.16%] [Generator loss: 0.7716%]\n",
            "8458 [Discriminator loss: 0.6678%, acc.: 53.52%] [Generator loss: 0.7820%]\n",
            "8459 [Discriminator loss: 0.6598%, acc.: 61.72%] [Generator loss: 0.7939%]\n",
            "8460 [Discriminator loss: 0.6884%, acc.: 51.95%] [Generator loss: 0.7920%]\n",
            "8461 [Discriminator loss: 0.6650%, acc.: 58.20%] [Generator loss: 0.7973%]\n",
            "8462 [Discriminator loss: 0.6784%, acc.: 56.25%] [Generator loss: 0.7799%]\n",
            "8463 [Discriminator loss: 0.6826%, acc.: 53.12%] [Generator loss: 0.7856%]\n",
            "8464 [Discriminator loss: 0.6747%, acc.: 58.98%] [Generator loss: 0.7782%]\n",
            "8465 [Discriminator loss: 0.6587%, acc.: 61.72%] [Generator loss: 0.7698%]\n",
            "8466 [Discriminator loss: 0.6766%, acc.: 57.42%] [Generator loss: 0.7664%]\n",
            "8467 [Discriminator loss: 0.6675%, acc.: 61.33%] [Generator loss: 0.7821%]\n",
            "8468 [Discriminator loss: 0.6651%, acc.: 60.16%] [Generator loss: 0.7693%]\n",
            "8469 [Discriminator loss: 0.6673%, acc.: 60.94%] [Generator loss: 0.7821%]\n",
            "8470 [Discriminator loss: 0.6581%, acc.: 65.23%] [Generator loss: 0.7862%]\n",
            "8471 [Discriminator loss: 0.6630%, acc.: 63.67%] [Generator loss: 0.8061%]\n",
            "8472 [Discriminator loss: 0.6593%, acc.: 60.55%] [Generator loss: 0.7966%]\n",
            "8473 [Discriminator loss: 0.6755%, acc.: 58.98%] [Generator loss: 0.7887%]\n",
            "8474 [Discriminator loss: 0.6773%, acc.: 61.33%] [Generator loss: 0.7961%]\n",
            "8475 [Discriminator loss: 0.6768%, acc.: 54.69%] [Generator loss: 0.7871%]\n",
            "8476 [Discriminator loss: 0.6793%, acc.: 55.86%] [Generator loss: 0.8060%]\n",
            "8477 [Discriminator loss: 0.6603%, acc.: 63.67%] [Generator loss: 0.7829%]\n",
            "8478 [Discriminator loss: 0.7000%, acc.: 50.39%] [Generator loss: 0.7849%]\n",
            "8479 [Discriminator loss: 0.6600%, acc.: 62.50%] [Generator loss: 0.7963%]\n",
            "8480 [Discriminator loss: 0.6900%, acc.: 53.12%] [Generator loss: 0.7837%]\n",
            "8481 [Discriminator loss: 0.6644%, acc.: 57.81%] [Generator loss: 0.7733%]\n",
            "8482 [Discriminator loss: 0.6686%, acc.: 61.72%] [Generator loss: 0.7624%]\n",
            "8483 [Discriminator loss: 0.6779%, acc.: 59.77%] [Generator loss: 0.7725%]\n",
            "8484 [Discriminator loss: 0.6700%, acc.: 59.77%] [Generator loss: 0.7792%]\n",
            "8485 [Discriminator loss: 0.6817%, acc.: 57.03%] [Generator loss: 0.7697%]\n",
            "8486 [Discriminator loss: 0.6555%, acc.: 60.55%] [Generator loss: 0.7824%]\n",
            "8487 [Discriminator loss: 0.6587%, acc.: 60.16%] [Generator loss: 0.8164%]\n",
            "8488 [Discriminator loss: 0.6829%, acc.: 58.59%] [Generator loss: 0.7674%]\n",
            "8489 [Discriminator loss: 0.6567%, acc.: 62.89%] [Generator loss: 0.7955%]\n",
            "8490 [Discriminator loss: 0.6738%, acc.: 57.81%] [Generator loss: 0.7706%]\n",
            "8491 [Discriminator loss: 0.6573%, acc.: 59.77%] [Generator loss: 0.7771%]\n",
            "8492 [Discriminator loss: 0.6614%, acc.: 63.28%] [Generator loss: 0.7876%]\n",
            "8493 [Discriminator loss: 0.6757%, acc.: 55.86%] [Generator loss: 0.7720%]\n",
            "8494 [Discriminator loss: 0.6569%, acc.: 61.72%] [Generator loss: 0.8070%]\n",
            "8495 [Discriminator loss: 0.6713%, acc.: 58.59%] [Generator loss: 0.7732%]\n",
            "8496 [Discriminator loss: 0.6750%, acc.: 56.64%] [Generator loss: 0.7728%]\n",
            "8497 [Discriminator loss: 0.6678%, acc.: 59.77%] [Generator loss: 0.7921%]\n",
            "8498 [Discriminator loss: 0.6808%, acc.: 57.81%] [Generator loss: 0.7974%]\n",
            "8499 [Discriminator loss: 0.6712%, acc.: 57.03%] [Generator loss: 0.7919%]\n",
            "8500 [Discriminator loss: 0.6813%, acc.: 55.08%] [Generator loss: 0.8054%]\n",
            "8501 [Discriminator loss: 0.6666%, acc.: 60.55%] [Generator loss: 0.7700%]\n",
            "8502 [Discriminator loss: 0.6818%, acc.: 58.20%] [Generator loss: 0.7751%]\n",
            "8503 [Discriminator loss: 0.6759%, acc.: 56.25%] [Generator loss: 0.7872%]\n",
            "8504 [Discriminator loss: 0.6702%, acc.: 62.50%] [Generator loss: 0.7728%]\n",
            "8505 [Discriminator loss: 0.6674%, acc.: 58.98%] [Generator loss: 0.7831%]\n",
            "8506 [Discriminator loss: 0.6641%, acc.: 62.11%] [Generator loss: 0.7791%]\n",
            "8507 [Discriminator loss: 0.6821%, acc.: 57.81%] [Generator loss: 0.7889%]\n",
            "8508 [Discriminator loss: 0.6787%, acc.: 57.42%] [Generator loss: 0.7836%]\n",
            "8509 [Discriminator loss: 0.6631%, acc.: 62.89%] [Generator loss: 0.7959%]\n",
            "8510 [Discriminator loss: 0.6821%, acc.: 57.42%] [Generator loss: 0.7809%]\n",
            "8511 [Discriminator loss: 0.6866%, acc.: 53.52%] [Generator loss: 0.7752%]\n",
            "8512 [Discriminator loss: 0.6784%, acc.: 59.38%] [Generator loss: 0.7874%]\n",
            "8513 [Discriminator loss: 0.6672%, acc.: 60.94%] [Generator loss: 0.7666%]\n",
            "8514 [Discriminator loss: 0.6864%, acc.: 56.25%] [Generator loss: 0.7725%]\n",
            "8515 [Discriminator loss: 0.6724%, acc.: 57.03%] [Generator loss: 0.7773%]\n",
            "8516 [Discriminator loss: 0.6930%, acc.: 55.08%] [Generator loss: 0.7622%]\n",
            "8517 [Discriminator loss: 0.6969%, acc.: 50.39%] [Generator loss: 0.7830%]\n",
            "8518 [Discriminator loss: 0.6800%, acc.: 56.25%] [Generator loss: 0.7807%]\n",
            "8519 [Discriminator loss: 0.6635%, acc.: 62.50%] [Generator loss: 0.7639%]\n",
            "8520 [Discriminator loss: 0.6872%, acc.: 55.47%] [Generator loss: 0.7717%]\n",
            "8521 [Discriminator loss: 0.6757%, acc.: 57.03%] [Generator loss: 0.7939%]\n",
            "8522 [Discriminator loss: 0.6773%, acc.: 60.55%] [Generator loss: 0.7692%]\n",
            "8523 [Discriminator loss: 0.6728%, acc.: 57.81%] [Generator loss: 0.7970%]\n",
            "8524 [Discriminator loss: 0.6685%, acc.: 61.72%] [Generator loss: 0.7702%]\n",
            "8525 [Discriminator loss: 0.6668%, acc.: 61.33%] [Generator loss: 0.7816%]\n",
            "8526 [Discriminator loss: 0.6710%, acc.: 58.20%] [Generator loss: 0.8130%]\n",
            "8527 [Discriminator loss: 0.6791%, acc.: 56.64%] [Generator loss: 0.7831%]\n",
            "8528 [Discriminator loss: 0.6849%, acc.: 54.69%] [Generator loss: 0.7895%]\n",
            "8529 [Discriminator loss: 0.6691%, acc.: 59.38%] [Generator loss: 0.7595%]\n",
            "8530 [Discriminator loss: 0.6737%, acc.: 61.33%] [Generator loss: 0.7576%]\n",
            "8531 [Discriminator loss: 0.6797%, acc.: 52.34%] [Generator loss: 0.7731%]\n",
            "8532 [Discriminator loss: 0.6707%, acc.: 59.77%] [Generator loss: 0.7831%]\n",
            "8533 [Discriminator loss: 0.6682%, acc.: 60.16%] [Generator loss: 0.7873%]\n",
            "8534 [Discriminator loss: 0.6727%, acc.: 55.86%] [Generator loss: 0.7635%]\n",
            "8535 [Discriminator loss: 0.6664%, acc.: 62.89%] [Generator loss: 0.7657%]\n",
            "8536 [Discriminator loss: 0.6545%, acc.: 60.94%] [Generator loss: 0.7910%]\n",
            "8537 [Discriminator loss: 0.6707%, acc.: 60.55%] [Generator loss: 0.7505%]\n",
            "8538 [Discriminator loss: 0.6719%, acc.: 60.16%] [Generator loss: 0.7934%]\n",
            "8539 [Discriminator loss: 0.6695%, acc.: 59.38%] [Generator loss: 0.7974%]\n",
            "8540 [Discriminator loss: 0.6871%, acc.: 51.95%] [Generator loss: 0.7853%]\n",
            "8541 [Discriminator loss: 0.6639%, acc.: 56.64%] [Generator loss: 0.7848%]\n",
            "8542 [Discriminator loss: 0.6684%, acc.: 58.20%] [Generator loss: 0.7614%]\n",
            "8543 [Discriminator loss: 0.6711%, acc.: 58.59%] [Generator loss: 0.7666%]\n",
            "8544 [Discriminator loss: 0.6658%, acc.: 59.77%] [Generator loss: 0.7968%]\n",
            "8545 [Discriminator loss: 0.6979%, acc.: 49.61%] [Generator loss: 0.7788%]\n",
            "8546 [Discriminator loss: 0.6849%, acc.: 56.64%] [Generator loss: 0.8386%]\n",
            "8547 [Discriminator loss: 0.6788%, acc.: 57.03%] [Generator loss: 0.7967%]\n",
            "8548 [Discriminator loss: 0.6587%, acc.: 60.55%] [Generator loss: 0.8088%]\n",
            "8549 [Discriminator loss: 0.6747%, acc.: 57.03%] [Generator loss: 0.7885%]\n",
            "8550 [Discriminator loss: 0.6675%, acc.: 59.38%] [Generator loss: 0.7836%]\n",
            "8551 [Discriminator loss: 0.6859%, acc.: 57.81%] [Generator loss: 0.7834%]\n",
            "8552 [Discriminator loss: 0.6779%, acc.: 59.38%] [Generator loss: 0.7985%]\n",
            "8553 [Discriminator loss: 0.6750%, acc.: 56.64%] [Generator loss: 0.7663%]\n",
            "8554 [Discriminator loss: 0.6765%, acc.: 56.25%] [Generator loss: 0.7794%]\n",
            "8555 [Discriminator loss: 0.6840%, acc.: 56.64%] [Generator loss: 0.7842%]\n",
            "8556 [Discriminator loss: 0.6801%, acc.: 58.59%] [Generator loss: 0.7712%]\n",
            "8557 [Discriminator loss: 0.6731%, acc.: 59.77%] [Generator loss: 0.7769%]\n",
            "8558 [Discriminator loss: 0.6733%, acc.: 60.55%] [Generator loss: 0.7880%]\n",
            "8559 [Discriminator loss: 0.6743%, acc.: 57.03%] [Generator loss: 0.7725%]\n",
            "8560 [Discriminator loss: 0.6695%, acc.: 58.98%] [Generator loss: 0.7664%]\n",
            "8561 [Discriminator loss: 0.6620%, acc.: 62.89%] [Generator loss: 0.7836%]\n",
            "8562 [Discriminator loss: 0.6719%, acc.: 58.20%] [Generator loss: 0.7890%]\n",
            "8563 [Discriminator loss: 0.6669%, acc.: 61.33%] [Generator loss: 0.7750%]\n",
            "8564 [Discriminator loss: 0.6671%, acc.: 57.42%] [Generator loss: 0.8265%]\n",
            "8565 [Discriminator loss: 0.6633%, acc.: 58.20%] [Generator loss: 0.7982%]\n",
            "8566 [Discriminator loss: 0.6852%, acc.: 54.69%] [Generator loss: 0.7985%]\n",
            "8567 [Discriminator loss: 0.6632%, acc.: 58.98%] [Generator loss: 0.7913%]\n",
            "8568 [Discriminator loss: 0.6632%, acc.: 62.11%] [Generator loss: 0.7872%]\n",
            "8569 [Discriminator loss: 0.6687%, acc.: 60.94%] [Generator loss: 0.7953%]\n",
            "8570 [Discriminator loss: 0.6582%, acc.: 66.41%] [Generator loss: 0.7969%]\n",
            "8571 [Discriminator loss: 0.6783%, acc.: 58.98%] [Generator loss: 0.8178%]\n",
            "8572 [Discriminator loss: 0.6795%, acc.: 57.81%] [Generator loss: 0.8052%]\n",
            "8573 [Discriminator loss: 0.6773%, acc.: 57.81%] [Generator loss: 0.7865%]\n",
            "8574 [Discriminator loss: 0.6507%, acc.: 64.06%] [Generator loss: 0.8285%]\n",
            "8575 [Discriminator loss: 0.6634%, acc.: 64.06%] [Generator loss: 0.7881%]\n",
            "8576 [Discriminator loss: 0.6692%, acc.: 61.33%] [Generator loss: 0.7840%]\n",
            "8577 [Discriminator loss: 0.6713%, acc.: 58.98%] [Generator loss: 0.7956%]\n",
            "8578 [Discriminator loss: 0.6811%, acc.: 57.81%] [Generator loss: 0.7928%]\n",
            "8579 [Discriminator loss: 0.6486%, acc.: 63.67%] [Generator loss: 0.7838%]\n",
            "8580 [Discriminator loss: 0.6729%, acc.: 55.47%] [Generator loss: 0.8090%]\n",
            "8581 [Discriminator loss: 0.6787%, acc.: 55.86%] [Generator loss: 0.8022%]\n",
            "8582 [Discriminator loss: 0.6886%, acc.: 55.08%] [Generator loss: 0.7877%]\n",
            "8583 [Discriminator loss: 0.6808%, acc.: 55.86%] [Generator loss: 0.8200%]\n",
            "8584 [Discriminator loss: 0.6841%, acc.: 53.91%] [Generator loss: 0.7861%]\n",
            "8585 [Discriminator loss: 0.6823%, acc.: 51.95%] [Generator loss: 0.8043%]\n",
            "8586 [Discriminator loss: 0.6797%, acc.: 57.42%] [Generator loss: 0.7888%]\n",
            "8587 [Discriminator loss: 0.6657%, acc.: 62.50%] [Generator loss: 0.7598%]\n",
            "8588 [Discriminator loss: 0.6715%, acc.: 59.77%] [Generator loss: 0.7773%]\n",
            "8589 [Discriminator loss: 0.6807%, acc.: 61.72%] [Generator loss: 0.8019%]\n",
            "8590 [Discriminator loss: 0.6663%, acc.: 60.55%] [Generator loss: 0.7657%]\n",
            "8591 [Discriminator loss: 0.6474%, acc.: 66.80%] [Generator loss: 0.8083%]\n",
            "8592 [Discriminator loss: 0.6877%, acc.: 53.52%] [Generator loss: 0.8025%]\n",
            "8593 [Discriminator loss: 0.6696%, acc.: 54.30%] [Generator loss: 0.8007%]\n",
            "8594 [Discriminator loss: 0.6456%, acc.: 64.45%] [Generator loss: 0.7963%]\n",
            "8595 [Discriminator loss: 0.6716%, acc.: 56.64%] [Generator loss: 0.7868%]\n",
            "8596 [Discriminator loss: 0.6472%, acc.: 65.23%] [Generator loss: 0.8174%]\n",
            "8597 [Discriminator loss: 0.6636%, acc.: 59.38%] [Generator loss: 0.7794%]\n",
            "8598 [Discriminator loss: 0.6825%, acc.: 53.12%] [Generator loss: 0.7880%]\n",
            "8599 [Discriminator loss: 0.6596%, acc.: 62.50%] [Generator loss: 0.7752%]\n",
            "8600 [Discriminator loss: 0.6865%, acc.: 53.12%] [Generator loss: 0.7917%]\n",
            "8601 [Discriminator loss: 0.6759%, acc.: 58.59%] [Generator loss: 0.7760%]\n",
            "8602 [Discriminator loss: 0.6713%, acc.: 62.11%] [Generator loss: 0.7752%]\n",
            "8603 [Discriminator loss: 0.6765%, acc.: 53.91%] [Generator loss: 0.7633%]\n",
            "8604 [Discriminator loss: 0.6767%, acc.: 53.91%] [Generator loss: 0.7896%]\n",
            "8605 [Discriminator loss: 0.6571%, acc.: 64.06%] [Generator loss: 0.7654%]\n",
            "8606 [Discriminator loss: 0.6653%, acc.: 57.03%] [Generator loss: 0.7908%]\n",
            "8607 [Discriminator loss: 0.6721%, acc.: 54.30%] [Generator loss: 0.8045%]\n",
            "8608 [Discriminator loss: 0.6683%, acc.: 56.25%] [Generator loss: 0.7845%]\n",
            "8609 [Discriminator loss: 0.6541%, acc.: 63.67%] [Generator loss: 0.7674%]\n",
            "8610 [Discriminator loss: 0.6639%, acc.: 55.86%] [Generator loss: 0.7885%]\n",
            "8611 [Discriminator loss: 0.6449%, acc.: 58.98%] [Generator loss: 0.8067%]\n",
            "8612 [Discriminator loss: 0.6720%, acc.: 55.08%] [Generator loss: 0.8154%]\n",
            "8613 [Discriminator loss: 0.6831%, acc.: 55.47%] [Generator loss: 0.8152%]\n",
            "8614 [Discriminator loss: 0.6783%, acc.: 57.42%] [Generator loss: 0.7874%]\n",
            "8615 [Discriminator loss: 0.6604%, acc.: 60.94%] [Generator loss: 0.7941%]\n",
            "8616 [Discriminator loss: 0.6791%, acc.: 56.64%] [Generator loss: 0.8082%]\n",
            "8617 [Discriminator loss: 0.6783%, acc.: 57.03%] [Generator loss: 0.7968%]\n",
            "8618 [Discriminator loss: 0.6953%, acc.: 55.86%] [Generator loss: 0.8130%]\n",
            "8619 [Discriminator loss: 0.6796%, acc.: 56.25%] [Generator loss: 0.7838%]\n",
            "8620 [Discriminator loss: 0.6874%, acc.: 57.42%] [Generator loss: 0.7736%]\n",
            "8621 [Discriminator loss: 0.6599%, acc.: 65.62%] [Generator loss: 0.8063%]\n",
            "8622 [Discriminator loss: 0.6707%, acc.: 59.38%] [Generator loss: 0.8142%]\n",
            "8623 [Discriminator loss: 0.6795%, acc.: 56.25%] [Generator loss: 0.7957%]\n",
            "8624 [Discriminator loss: 0.6818%, acc.: 54.30%] [Generator loss: 0.7924%]\n",
            "8625 [Discriminator loss: 0.6727%, acc.: 59.38%] [Generator loss: 0.7791%]\n",
            "8626 [Discriminator loss: 0.6698%, acc.: 62.11%] [Generator loss: 0.7959%]\n",
            "8627 [Discriminator loss: 0.6658%, acc.: 59.38%] [Generator loss: 0.7895%]\n",
            "8628 [Discriminator loss: 0.6821%, acc.: 55.47%] [Generator loss: 0.7699%]\n",
            "8629 [Discriminator loss: 0.6743%, acc.: 60.94%] [Generator loss: 0.8008%]\n",
            "8630 [Discriminator loss: 0.6795%, acc.: 58.98%] [Generator loss: 0.7843%]\n",
            "8631 [Discriminator loss: 0.6533%, acc.: 66.02%] [Generator loss: 0.7747%]\n",
            "8632 [Discriminator loss: 0.6742%, acc.: 60.55%] [Generator loss: 0.7925%]\n",
            "8633 [Discriminator loss: 0.6644%, acc.: 58.59%] [Generator loss: 0.7802%]\n",
            "8634 [Discriminator loss: 0.6666%, acc.: 58.98%] [Generator loss: 0.7725%]\n",
            "8635 [Discriminator loss: 0.6814%, acc.: 56.25%] [Generator loss: 0.7860%]\n",
            "8636 [Discriminator loss: 0.6704%, acc.: 63.28%] [Generator loss: 0.7516%]\n",
            "8637 [Discriminator loss: 0.6608%, acc.: 65.23%] [Generator loss: 0.7724%]\n",
            "8638 [Discriminator loss: 0.6663%, acc.: 56.25%] [Generator loss: 0.8005%]\n",
            "8639 [Discriminator loss: 0.6658%, acc.: 66.02%] [Generator loss: 0.7800%]\n",
            "8640 [Discriminator loss: 0.6672%, acc.: 62.11%] [Generator loss: 0.8023%]\n",
            "8641 [Discriminator loss: 0.6727%, acc.: 56.64%] [Generator loss: 0.8136%]\n",
            "8642 [Discriminator loss: 0.6764%, acc.: 58.59%] [Generator loss: 0.7830%]\n",
            "8643 [Discriminator loss: 0.6737%, acc.: 57.42%] [Generator loss: 0.7841%]\n",
            "8644 [Discriminator loss: 0.6890%, acc.: 55.47%] [Generator loss: 0.8101%]\n",
            "8645 [Discriminator loss: 0.6791%, acc.: 57.03%] [Generator loss: 0.8167%]\n",
            "8646 [Discriminator loss: 0.6526%, acc.: 62.11%] [Generator loss: 0.8108%]\n",
            "8647 [Discriminator loss: 0.6552%, acc.: 61.72%] [Generator loss: 0.8103%]\n",
            "8648 [Discriminator loss: 0.6716%, acc.: 55.47%] [Generator loss: 0.7966%]\n",
            "8649 [Discriminator loss: 0.6547%, acc.: 61.33%] [Generator loss: 0.8048%]\n",
            "8650 [Discriminator loss: 0.6473%, acc.: 61.33%] [Generator loss: 0.8135%]\n",
            "8651 [Discriminator loss: 0.6675%, acc.: 59.38%] [Generator loss: 0.8055%]\n",
            "8652 [Discriminator loss: 0.6686%, acc.: 55.86%] [Generator loss: 0.7923%]\n",
            "8653 [Discriminator loss: 0.6671%, acc.: 58.59%] [Generator loss: 0.7790%]\n",
            "8654 [Discriminator loss: 0.6491%, acc.: 62.89%] [Generator loss: 0.7971%]\n",
            "8655 [Discriminator loss: 0.6445%, acc.: 65.23%] [Generator loss: 0.7824%]\n",
            "8656 [Discriminator loss: 0.6610%, acc.: 62.89%] [Generator loss: 0.7777%]\n",
            "8657 [Discriminator loss: 0.6530%, acc.: 63.67%] [Generator loss: 0.7838%]\n",
            "8658 [Discriminator loss: 0.6464%, acc.: 65.62%] [Generator loss: 0.7953%]\n",
            "8659 [Discriminator loss: 0.6570%, acc.: 62.89%] [Generator loss: 0.7861%]\n",
            "8660 [Discriminator loss: 0.6755%, acc.: 55.47%] [Generator loss: 0.7827%]\n",
            "8661 [Discriminator loss: 0.6605%, acc.: 57.42%] [Generator loss: 0.8002%]\n",
            "8662 [Discriminator loss: 0.6494%, acc.: 62.89%] [Generator loss: 0.7863%]\n",
            "8663 [Discriminator loss: 0.6662%, acc.: 59.38%] [Generator loss: 0.7693%]\n",
            "8664 [Discriminator loss: 0.6442%, acc.: 64.45%] [Generator loss: 0.7886%]\n",
            "8665 [Discriminator loss: 0.6595%, acc.: 58.98%] [Generator loss: 0.8086%]\n",
            "8666 [Discriminator loss: 0.6762%, acc.: 57.03%] [Generator loss: 0.7716%]\n",
            "8667 [Discriminator loss: 0.6667%, acc.: 61.72%] [Generator loss: 0.7662%]\n",
            "8668 [Discriminator loss: 0.6763%, acc.: 57.42%] [Generator loss: 0.8101%]\n",
            "8669 [Discriminator loss: 0.6530%, acc.: 63.28%] [Generator loss: 0.7734%]\n",
            "8670 [Discriminator loss: 0.6609%, acc.: 60.94%] [Generator loss: 0.8083%]\n",
            "8671 [Discriminator loss: 0.6489%, acc.: 61.72%] [Generator loss: 0.8070%]\n",
            "8672 [Discriminator loss: 0.6541%, acc.: 61.33%] [Generator loss: 0.7782%]\n",
            "8673 [Discriminator loss: 0.6830%, acc.: 55.86%] [Generator loss: 0.7866%]\n",
            "8674 [Discriminator loss: 0.6731%, acc.: 57.42%] [Generator loss: 0.7932%]\n",
            "8675 [Discriminator loss: 0.6577%, acc.: 60.55%] [Generator loss: 0.8064%]\n",
            "8676 [Discriminator loss: 0.6643%, acc.: 58.20%] [Generator loss: 0.7818%]\n",
            "8677 [Discriminator loss: 0.6902%, acc.: 52.73%] [Generator loss: 0.7957%]\n",
            "8678 [Discriminator loss: 0.6433%, acc.: 62.89%] [Generator loss: 0.8046%]\n",
            "8679 [Discriminator loss: 0.6657%, acc.: 60.94%] [Generator loss: 0.7732%]\n",
            "8680 [Discriminator loss: 0.6636%, acc.: 56.25%] [Generator loss: 0.7862%]\n",
            "8681 [Discriminator loss: 0.6777%, acc.: 59.38%] [Generator loss: 0.8145%]\n",
            "8682 [Discriminator loss: 0.6504%, acc.: 62.11%] [Generator loss: 0.7895%]\n",
            "8683 [Discriminator loss: 0.6759%, acc.: 57.81%] [Generator loss: 0.8123%]\n",
            "8684 [Discriminator loss: 0.6802%, acc.: 57.03%] [Generator loss: 0.8144%]\n",
            "8685 [Discriminator loss: 0.6574%, acc.: 64.06%] [Generator loss: 0.8430%]\n",
            "8686 [Discriminator loss: 0.6576%, acc.: 63.28%] [Generator loss: 0.8224%]\n",
            "8687 [Discriminator loss: 0.6663%, acc.: 58.98%] [Generator loss: 0.8167%]\n",
            "8688 [Discriminator loss: 0.6735%, acc.: 58.59%] [Generator loss: 0.8008%]\n",
            "8689 [Discriminator loss: 0.6688%, acc.: 53.91%] [Generator loss: 0.7865%]\n",
            "8690 [Discriminator loss: 0.6604%, acc.: 60.55%] [Generator loss: 0.8027%]\n",
            "8691 [Discriminator loss: 0.6889%, acc.: 56.25%] [Generator loss: 0.7780%]\n",
            "8692 [Discriminator loss: 0.6876%, acc.: 55.47%] [Generator loss: 0.7757%]\n",
            "8693 [Discriminator loss: 0.6826%, acc.: 53.12%] [Generator loss: 0.8003%]\n",
            "8694 [Discriminator loss: 0.6807%, acc.: 54.69%] [Generator loss: 0.7663%]\n",
            "8695 [Discriminator loss: 0.6696%, acc.: 58.20%] [Generator loss: 0.7768%]\n",
            "8696 [Discriminator loss: 0.6811%, acc.: 58.98%] [Generator loss: 0.7832%]\n",
            "8697 [Discriminator loss: 0.6801%, acc.: 53.52%] [Generator loss: 0.7785%]\n",
            "8698 [Discriminator loss: 0.6675%, acc.: 58.98%] [Generator loss: 0.7858%]\n",
            "8699 [Discriminator loss: 0.6706%, acc.: 58.59%] [Generator loss: 0.7626%]\n",
            "8700 [Discriminator loss: 0.6689%, acc.: 57.03%] [Generator loss: 0.7638%]\n",
            "8701 [Discriminator loss: 0.6720%, acc.: 58.20%] [Generator loss: 0.7815%]\n",
            "8702 [Discriminator loss: 0.6635%, acc.: 61.33%] [Generator loss: 0.8007%]\n",
            "8703 [Discriminator loss: 0.6744%, acc.: 57.81%] [Generator loss: 0.7651%]\n",
            "8704 [Discriminator loss: 0.6506%, acc.: 62.11%] [Generator loss: 0.7665%]\n",
            "8705 [Discriminator loss: 0.6828%, acc.: 57.81%] [Generator loss: 0.7930%]\n",
            "8706 [Discriminator loss: 0.6821%, acc.: 58.59%] [Generator loss: 0.7981%]\n",
            "8707 [Discriminator loss: 0.6575%, acc.: 63.67%] [Generator loss: 0.7829%]\n",
            "8708 [Discriminator loss: 0.6825%, acc.: 52.73%] [Generator loss: 0.8114%]\n",
            "8709 [Discriminator loss: 0.6618%, acc.: 60.16%] [Generator loss: 0.7979%]\n",
            "8710 [Discriminator loss: 0.6656%, acc.: 62.50%] [Generator loss: 0.7805%]\n",
            "8711 [Discriminator loss: 0.6696%, acc.: 58.98%] [Generator loss: 0.8048%]\n",
            "8712 [Discriminator loss: 0.6692%, acc.: 61.72%] [Generator loss: 0.7994%]\n",
            "8713 [Discriminator loss: 0.6642%, acc.: 55.47%] [Generator loss: 0.8025%]\n",
            "8714 [Discriminator loss: 0.6678%, acc.: 57.03%] [Generator loss: 0.7887%]\n",
            "8715 [Discriminator loss: 0.6631%, acc.: 60.55%] [Generator loss: 0.7603%]\n",
            "8716 [Discriminator loss: 0.6620%, acc.: 62.11%] [Generator loss: 0.7913%]\n",
            "8717 [Discriminator loss: 0.6840%, acc.: 55.86%] [Generator loss: 0.7855%]\n",
            "8718 [Discriminator loss: 0.6748%, acc.: 57.03%] [Generator loss: 0.7545%]\n",
            "8719 [Discriminator loss: 0.6726%, acc.: 59.77%] [Generator loss: 0.7597%]\n",
            "8720 [Discriminator loss: 0.6810%, acc.: 55.86%] [Generator loss: 0.7906%]\n",
            "8721 [Discriminator loss: 0.6873%, acc.: 58.20%] [Generator loss: 0.7950%]\n",
            "8722 [Discriminator loss: 0.6616%, acc.: 59.77%] [Generator loss: 0.8034%]\n",
            "8723 [Discriminator loss: 0.6811%, acc.: 58.20%] [Generator loss: 0.8037%]\n",
            "8724 [Discriminator loss: 0.6687%, acc.: 58.20%] [Generator loss: 0.7998%]\n",
            "8725 [Discriminator loss: 0.6784%, acc.: 55.47%] [Generator loss: 0.7911%]\n",
            "8726 [Discriminator loss: 0.6784%, acc.: 58.20%] [Generator loss: 0.7972%]\n",
            "8727 [Discriminator loss: 0.6722%, acc.: 56.25%] [Generator loss: 0.7975%]\n",
            "8728 [Discriminator loss: 0.6711%, acc.: 58.59%] [Generator loss: 0.8180%]\n",
            "8729 [Discriminator loss: 0.6831%, acc.: 54.69%] [Generator loss: 0.7869%]\n",
            "8730 [Discriminator loss: 0.6657%, acc.: 58.59%] [Generator loss: 0.7877%]\n",
            "8731 [Discriminator loss: 0.6707%, acc.: 58.59%] [Generator loss: 0.7772%]\n",
            "8732 [Discriminator loss: 0.6727%, acc.: 60.55%] [Generator loss: 0.7720%]\n",
            "8733 [Discriminator loss: 0.6536%, acc.: 65.23%] [Generator loss: 0.7921%]\n",
            "8734 [Discriminator loss: 0.6920%, acc.: 52.34%] [Generator loss: 0.7708%]\n",
            "8735 [Discriminator loss: 0.6807%, acc.: 56.25%] [Generator loss: 0.7719%]\n",
            "8736 [Discriminator loss: 0.6561%, acc.: 62.50%] [Generator loss: 0.7814%]\n",
            "8737 [Discriminator loss: 0.6593%, acc.: 60.16%] [Generator loss: 0.8001%]\n",
            "8738 [Discriminator loss: 0.6801%, acc.: 56.25%] [Generator loss: 0.7924%]\n",
            "8739 [Discriminator loss: 0.6825%, acc.: 57.42%] [Generator loss: 0.7809%]\n",
            "8740 [Discriminator loss: 0.6820%, acc.: 56.64%] [Generator loss: 0.7929%]\n",
            "8741 [Discriminator loss: 0.6827%, acc.: 57.81%] [Generator loss: 0.7823%]\n",
            "8742 [Discriminator loss: 0.6538%, acc.: 62.89%] [Generator loss: 0.7893%]\n",
            "8743 [Discriminator loss: 0.6796%, acc.: 56.64%] [Generator loss: 0.8120%]\n",
            "8744 [Discriminator loss: 0.6620%, acc.: 60.55%] [Generator loss: 0.8049%]\n",
            "8745 [Discriminator loss: 0.6977%, acc.: 53.91%] [Generator loss: 0.7915%]\n",
            "8746 [Discriminator loss: 0.6585%, acc.: 64.84%] [Generator loss: 0.7959%]\n",
            "8747 [Discriminator loss: 0.6789%, acc.: 58.98%] [Generator loss: 0.7855%]\n",
            "8748 [Discriminator loss: 0.6859%, acc.: 56.25%] [Generator loss: 0.7912%]\n",
            "8749 [Discriminator loss: 0.6664%, acc.: 60.55%] [Generator loss: 0.7780%]\n",
            "8750 [Discriminator loss: 0.7037%, acc.: 48.83%] [Generator loss: 0.7928%]\n",
            "8751 [Discriminator loss: 0.6602%, acc.: 60.55%] [Generator loss: 0.7925%]\n",
            "8752 [Discriminator loss: 0.6815%, acc.: 55.08%] [Generator loss: 0.7970%]\n",
            "8753 [Discriminator loss: 0.6717%, acc.: 60.16%] [Generator loss: 0.7955%]\n",
            "8754 [Discriminator loss: 0.6607%, acc.: 59.38%] [Generator loss: 0.7832%]\n",
            "8755 [Discriminator loss: 0.6724%, acc.: 55.47%] [Generator loss: 0.7956%]\n",
            "8756 [Discriminator loss: 0.6852%, acc.: 56.64%] [Generator loss: 0.7673%]\n",
            "8757 [Discriminator loss: 0.6810%, acc.: 56.25%] [Generator loss: 0.7834%]\n",
            "8758 [Discriminator loss: 0.6835%, acc.: 55.47%] [Generator loss: 0.7606%]\n",
            "8759 [Discriminator loss: 0.6624%, acc.: 59.77%] [Generator loss: 0.7646%]\n",
            "8760 [Discriminator loss: 0.6701%, acc.: 62.50%] [Generator loss: 0.7785%]\n",
            "8761 [Discriminator loss: 0.6914%, acc.: 55.08%] [Generator loss: 0.7844%]\n",
            "8762 [Discriminator loss: 0.6895%, acc.: 53.52%] [Generator loss: 0.7916%]\n",
            "8763 [Discriminator loss: 0.6616%, acc.: 63.67%] [Generator loss: 0.7892%]\n",
            "8764 [Discriminator loss: 0.6838%, acc.: 58.98%] [Generator loss: 0.7847%]\n",
            "8765 [Discriminator loss: 0.6691%, acc.: 56.25%] [Generator loss: 0.7722%]\n",
            "8766 [Discriminator loss: 0.6779%, acc.: 57.03%] [Generator loss: 0.7753%]\n",
            "8767 [Discriminator loss: 0.6895%, acc.: 55.47%] [Generator loss: 0.7902%]\n",
            "8768 [Discriminator loss: 0.6667%, acc.: 60.94%] [Generator loss: 0.7983%]\n",
            "8769 [Discriminator loss: 0.6783%, acc.: 54.69%] [Generator loss: 0.7885%]\n",
            "8770 [Discriminator loss: 0.6762%, acc.: 58.59%] [Generator loss: 0.7947%]\n",
            "8771 [Discriminator loss: 0.6801%, acc.: 56.64%] [Generator loss: 0.7707%]\n",
            "8772 [Discriminator loss: 0.6586%, acc.: 60.16%] [Generator loss: 0.7994%]\n",
            "8773 [Discriminator loss: 0.6973%, acc.: 55.86%] [Generator loss: 0.7545%]\n",
            "8774 [Discriminator loss: 0.6836%, acc.: 56.25%] [Generator loss: 0.7657%]\n",
            "8775 [Discriminator loss: 0.6795%, acc.: 58.59%] [Generator loss: 0.7675%]\n",
            "8776 [Discriminator loss: 0.6889%, acc.: 52.73%] [Generator loss: 0.7957%]\n",
            "8777 [Discriminator loss: 0.6883%, acc.: 53.12%] [Generator loss: 0.7927%]\n",
            "8778 [Discriminator loss: 0.6788%, acc.: 57.03%] [Generator loss: 0.7902%]\n",
            "8779 [Discriminator loss: 0.6693%, acc.: 60.94%] [Generator loss: 0.7870%]\n",
            "8780 [Discriminator loss: 0.6682%, acc.: 61.33%] [Generator loss: 0.7774%]\n",
            "8781 [Discriminator loss: 0.6750%, acc.: 60.55%] [Generator loss: 0.7767%]\n",
            "8782 [Discriminator loss: 0.6658%, acc.: 65.23%] [Generator loss: 0.7697%]\n",
            "8783 [Discriminator loss: 0.6765%, acc.: 57.81%] [Generator loss: 0.7773%]\n",
            "8784 [Discriminator loss: 0.6714%, acc.: 58.59%] [Generator loss: 0.7776%]\n",
            "8785 [Discriminator loss: 0.6754%, acc.: 56.64%] [Generator loss: 0.7791%]\n",
            "8786 [Discriminator loss: 0.6783%, acc.: 58.20%] [Generator loss: 0.7840%]\n",
            "8787 [Discriminator loss: 0.6715%, acc.: 57.42%] [Generator loss: 0.7708%]\n",
            "8788 [Discriminator loss: 0.6748%, acc.: 56.25%] [Generator loss: 0.7836%]\n",
            "8789 [Discriminator loss: 0.6697%, acc.: 58.98%] [Generator loss: 0.7813%]\n",
            "8790 [Discriminator loss: 0.6681%, acc.: 62.89%] [Generator loss: 0.7542%]\n",
            "8791 [Discriminator loss: 0.6680%, acc.: 59.77%] [Generator loss: 0.7809%]\n",
            "8792 [Discriminator loss: 0.6728%, acc.: 58.20%] [Generator loss: 0.8017%]\n",
            "8793 [Discriminator loss: 0.6596%, acc.: 64.06%] [Generator loss: 0.7802%]\n",
            "8794 [Discriminator loss: 0.6759%, acc.: 59.77%] [Generator loss: 0.7954%]\n",
            "8795 [Discriminator loss: 0.6699%, acc.: 60.55%] [Generator loss: 0.7871%]\n",
            "8796 [Discriminator loss: 0.6623%, acc.: 59.38%] [Generator loss: 0.7837%]\n",
            "8797 [Discriminator loss: 0.6684%, acc.: 58.98%] [Generator loss: 0.7820%]\n",
            "8798 [Discriminator loss: 0.6768%, acc.: 57.81%] [Generator loss: 0.7988%]\n",
            "8799 [Discriminator loss: 0.6628%, acc.: 60.16%] [Generator loss: 0.8068%]\n",
            "8800 [Discriminator loss: 0.6837%, acc.: 52.73%] [Generator loss: 0.7760%]\n",
            "8801 [Discriminator loss: 0.6728%, acc.: 58.20%] [Generator loss: 0.7769%]\n",
            "8802 [Discriminator loss: 0.6633%, acc.: 60.55%] [Generator loss: 0.7914%]\n",
            "8803 [Discriminator loss: 0.6589%, acc.: 59.38%] [Generator loss: 0.7983%]\n",
            "8804 [Discriminator loss: 0.6810%, acc.: 56.25%] [Generator loss: 0.7910%]\n",
            "8805 [Discriminator loss: 0.6703%, acc.: 60.55%] [Generator loss: 0.7832%]\n",
            "8806 [Discriminator loss: 0.7086%, acc.: 50.00%] [Generator loss: 0.7718%]\n",
            "8807 [Discriminator loss: 0.6567%, acc.: 64.06%] [Generator loss: 0.7725%]\n",
            "8808 [Discriminator loss: 0.6722%, acc.: 56.64%] [Generator loss: 0.7819%]\n",
            "8809 [Discriminator loss: 0.6795%, acc.: 54.30%] [Generator loss: 0.7905%]\n",
            "8810 [Discriminator loss: 0.6584%, acc.: 61.72%] [Generator loss: 0.7829%]\n",
            "8811 [Discriminator loss: 0.6690%, acc.: 58.98%] [Generator loss: 0.7920%]\n",
            "8812 [Discriminator loss: 0.6756%, acc.: 61.72%] [Generator loss: 0.7655%]\n",
            "8813 [Discriminator loss: 0.6560%, acc.: 64.06%] [Generator loss: 0.7801%]\n",
            "8814 [Discriminator loss: 0.6726%, acc.: 57.03%] [Generator loss: 0.7824%]\n",
            "8815 [Discriminator loss: 0.6755%, acc.: 55.86%] [Generator loss: 0.7643%]\n",
            "8816 [Discriminator loss: 0.6570%, acc.: 60.16%] [Generator loss: 0.8004%]\n",
            "8817 [Discriminator loss: 0.6795%, acc.: 57.42%] [Generator loss: 0.8095%]\n",
            "8818 [Discriminator loss: 0.6709%, acc.: 56.64%] [Generator loss: 0.8308%]\n",
            "8819 [Discriminator loss: 0.6768%, acc.: 56.64%] [Generator loss: 0.8024%]\n",
            "8820 [Discriminator loss: 0.6646%, acc.: 58.98%] [Generator loss: 0.8285%]\n",
            "8821 [Discriminator loss: 0.6690%, acc.: 58.59%] [Generator loss: 0.7833%]\n",
            "8822 [Discriminator loss: 0.6813%, acc.: 53.91%] [Generator loss: 0.8039%]\n",
            "8823 [Discriminator loss: 0.6653%, acc.: 61.72%] [Generator loss: 0.7957%]\n",
            "8824 [Discriminator loss: 0.6744%, acc.: 55.47%] [Generator loss: 0.7935%]\n",
            "8825 [Discriminator loss: 0.6832%, acc.: 55.47%] [Generator loss: 0.7887%]\n",
            "8826 [Discriminator loss: 0.6664%, acc.: 59.38%] [Generator loss: 0.7943%]\n",
            "8827 [Discriminator loss: 0.6564%, acc.: 58.20%] [Generator loss: 0.7775%]\n",
            "8828 [Discriminator loss: 0.6488%, acc.: 65.23%] [Generator loss: 0.7873%]\n",
            "8829 [Discriminator loss: 0.6586%, acc.: 61.72%] [Generator loss: 0.7833%]\n",
            "8830 [Discriminator loss: 0.6692%, acc.: 62.89%] [Generator loss: 0.7959%]\n",
            "8831 [Discriminator loss: 0.6847%, acc.: 56.25%] [Generator loss: 0.7831%]\n",
            "8832 [Discriminator loss: 0.6695%, acc.: 58.20%] [Generator loss: 0.7751%]\n",
            "8833 [Discriminator loss: 0.6746%, acc.: 58.59%] [Generator loss: 0.7834%]\n",
            "8834 [Discriminator loss: 0.6693%, acc.: 58.98%] [Generator loss: 0.8024%]\n",
            "8835 [Discriminator loss: 0.6821%, acc.: 55.47%] [Generator loss: 0.8053%]\n",
            "8836 [Discriminator loss: 0.6849%, acc.: 53.12%] [Generator loss: 0.7941%]\n",
            "8837 [Discriminator loss: 0.6810%, acc.: 56.25%] [Generator loss: 0.7655%]\n",
            "8838 [Discriminator loss: 0.6840%, acc.: 48.83%] [Generator loss: 0.7671%]\n",
            "8839 [Discriminator loss: 0.6787%, acc.: 57.03%] [Generator loss: 0.7838%]\n",
            "8840 [Discriminator loss: 0.6873%, acc.: 49.61%] [Generator loss: 0.7758%]\n",
            "8841 [Discriminator loss: 0.6662%, acc.: 57.81%] [Generator loss: 0.7955%]\n",
            "8842 [Discriminator loss: 0.6836%, acc.: 55.08%] [Generator loss: 0.7993%]\n",
            "8843 [Discriminator loss: 0.6770%, acc.: 59.38%] [Generator loss: 0.7743%]\n",
            "8844 [Discriminator loss: 0.6912%, acc.: 51.17%] [Generator loss: 0.7828%]\n",
            "8845 [Discriminator loss: 0.6676%, acc.: 60.94%] [Generator loss: 0.7916%]\n",
            "8846 [Discriminator loss: 0.6746%, acc.: 61.72%] [Generator loss: 0.7774%]\n",
            "8847 [Discriminator loss: 0.6727%, acc.: 60.94%] [Generator loss: 0.7735%]\n",
            "8848 [Discriminator loss: 0.6779%, acc.: 55.47%] [Generator loss: 0.7756%]\n",
            "8849 [Discriminator loss: 0.6848%, acc.: 55.86%] [Generator loss: 0.7686%]\n",
            "8850 [Discriminator loss: 0.6761%, acc.: 59.38%] [Generator loss: 0.7634%]\n",
            "8851 [Discriminator loss: 0.6905%, acc.: 53.12%] [Generator loss: 0.7811%]\n",
            "8852 [Discriminator loss: 0.6739%, acc.: 57.03%] [Generator loss: 0.7901%]\n",
            "8853 [Discriminator loss: 0.6924%, acc.: 52.73%] [Generator loss: 0.7622%]\n",
            "8854 [Discriminator loss: 0.6832%, acc.: 55.08%] [Generator loss: 0.7592%]\n",
            "8855 [Discriminator loss: 0.6579%, acc.: 63.28%] [Generator loss: 0.7722%]\n",
            "8856 [Discriminator loss: 0.6729%, acc.: 60.16%] [Generator loss: 0.7854%]\n",
            "8857 [Discriminator loss: 0.6920%, acc.: 53.12%] [Generator loss: 0.7524%]\n",
            "8858 [Discriminator loss: 0.6801%, acc.: 54.30%] [Generator loss: 0.7865%]\n",
            "8859 [Discriminator loss: 0.6756%, acc.: 58.20%] [Generator loss: 0.7792%]\n",
            "8860 [Discriminator loss: 0.6749%, acc.: 58.59%] [Generator loss: 0.7855%]\n",
            "8861 [Discriminator loss: 0.6774%, acc.: 58.59%] [Generator loss: 0.7913%]\n",
            "8862 [Discriminator loss: 0.6707%, acc.: 58.59%] [Generator loss: 0.8138%]\n",
            "8863 [Discriminator loss: 0.6707%, acc.: 57.42%] [Generator loss: 0.7959%]\n",
            "8864 [Discriminator loss: 0.6849%, acc.: 55.08%] [Generator loss: 0.8070%]\n",
            "8865 [Discriminator loss: 0.6878%, acc.: 53.52%] [Generator loss: 0.7862%]\n",
            "8866 [Discriminator loss: 0.6612%, acc.: 63.67%] [Generator loss: 0.7573%]\n",
            "8867 [Discriminator loss: 0.6927%, acc.: 52.73%] [Generator loss: 0.7792%]\n",
            "8868 [Discriminator loss: 0.6758%, acc.: 57.03%] [Generator loss: 0.7874%]\n",
            "8869 [Discriminator loss: 0.6687%, acc.: 59.77%] [Generator loss: 0.7861%]\n",
            "8870 [Discriminator loss: 0.6731%, acc.: 55.86%] [Generator loss: 0.8007%]\n",
            "8871 [Discriminator loss: 0.6851%, acc.: 55.08%] [Generator loss: 0.7923%]\n",
            "8872 [Discriminator loss: 0.6519%, acc.: 63.67%] [Generator loss: 0.7971%]\n",
            "8873 [Discriminator loss: 0.6725%, acc.: 58.98%] [Generator loss: 0.7955%]\n",
            "8874 [Discriminator loss: 0.6766%, acc.: 56.64%] [Generator loss: 0.8006%]\n",
            "8875 [Discriminator loss: 0.6884%, acc.: 57.42%] [Generator loss: 0.7701%]\n",
            "8876 [Discriminator loss: 0.6867%, acc.: 56.25%] [Generator loss: 0.7752%]\n",
            "8877 [Discriminator loss: 0.6748%, acc.: 59.77%] [Generator loss: 0.7932%]\n",
            "8878 [Discriminator loss: 0.6610%, acc.: 59.77%] [Generator loss: 0.7818%]\n",
            "8879 [Discriminator loss: 0.6696%, acc.: 58.20%] [Generator loss: 0.8001%]\n",
            "8880 [Discriminator loss: 0.6476%, acc.: 65.23%] [Generator loss: 0.8014%]\n",
            "8881 [Discriminator loss: 0.6710%, acc.: 56.64%] [Generator loss: 0.7620%]\n",
            "8882 [Discriminator loss: 0.6658%, acc.: 58.20%] [Generator loss: 0.7613%]\n",
            "8883 [Discriminator loss: 0.6654%, acc.: 57.42%] [Generator loss: 0.7817%]\n",
            "8884 [Discriminator loss: 0.6799%, acc.: 55.86%] [Generator loss: 0.7597%]\n",
            "8885 [Discriminator loss: 0.6685%, acc.: 63.28%] [Generator loss: 0.7911%]\n",
            "8886 [Discriminator loss: 0.6603%, acc.: 58.20%] [Generator loss: 0.7616%]\n",
            "8887 [Discriminator loss: 0.6677%, acc.: 58.20%] [Generator loss: 0.7976%]\n",
            "8888 [Discriminator loss: 0.6790%, acc.: 51.17%] [Generator loss: 0.7724%]\n",
            "8889 [Discriminator loss: 0.6900%, acc.: 53.91%] [Generator loss: 0.7484%]\n",
            "8890 [Discriminator loss: 0.6741%, acc.: 54.69%] [Generator loss: 0.7782%]\n",
            "8891 [Discriminator loss: 0.6784%, acc.: 55.47%] [Generator loss: 0.7844%]\n",
            "8892 [Discriminator loss: 0.6756%, acc.: 53.52%] [Generator loss: 0.7880%]\n",
            "8893 [Discriminator loss: 0.6797%, acc.: 53.91%] [Generator loss: 0.7708%]\n",
            "8894 [Discriminator loss: 0.6867%, acc.: 51.17%] [Generator loss: 0.7759%]\n",
            "8895 [Discriminator loss: 0.7036%, acc.: 50.00%] [Generator loss: 0.7706%]\n",
            "8896 [Discriminator loss: 0.6757%, acc.: 57.03%] [Generator loss: 0.7642%]\n",
            "8897 [Discriminator loss: 0.6643%, acc.: 61.33%] [Generator loss: 0.7969%]\n",
            "8898 [Discriminator loss: 0.6939%, acc.: 51.17%] [Generator loss: 0.7616%]\n",
            "8899 [Discriminator loss: 0.6754%, acc.: 58.59%] [Generator loss: 0.7890%]\n",
            "8900 [Discriminator loss: 0.6916%, acc.: 49.22%] [Generator loss: 0.7778%]\n",
            "8901 [Discriminator loss: 0.6652%, acc.: 59.77%] [Generator loss: 0.7941%]\n",
            "8902 [Discriminator loss: 0.6692%, acc.: 58.98%] [Generator loss: 0.7860%]\n",
            "8903 [Discriminator loss: 0.6825%, acc.: 57.42%] [Generator loss: 0.7820%]\n",
            "8904 [Discriminator loss: 0.6839%, acc.: 53.12%] [Generator loss: 0.7795%]\n",
            "8905 [Discriminator loss: 0.6750%, acc.: 53.91%] [Generator loss: 0.7715%]\n",
            "8906 [Discriminator loss: 0.6820%, acc.: 60.94%] [Generator loss: 0.7798%]\n",
            "8907 [Discriminator loss: 0.6728%, acc.: 58.98%] [Generator loss: 0.7750%]\n",
            "8908 [Discriminator loss: 0.6879%, acc.: 53.52%] [Generator loss: 0.7789%]\n",
            "8909 [Discriminator loss: 0.6938%, acc.: 52.73%] [Generator loss: 0.7432%]\n",
            "8910 [Discriminator loss: 0.6925%, acc.: 52.73%] [Generator loss: 0.7655%]\n",
            "8911 [Discriminator loss: 0.6621%, acc.: 58.98%] [Generator loss: 0.7557%]\n",
            "8912 [Discriminator loss: 0.6897%, acc.: 53.12%] [Generator loss: 0.7811%]\n",
            "8913 [Discriminator loss: 0.6882%, acc.: 55.08%] [Generator loss: 0.7863%]\n",
            "8914 [Discriminator loss: 0.6683%, acc.: 53.91%] [Generator loss: 0.7904%]\n",
            "8915 [Discriminator loss: 0.6686%, acc.: 60.55%] [Generator loss: 0.7852%]\n",
            "8916 [Discriminator loss: 0.6695%, acc.: 57.42%] [Generator loss: 0.7919%]\n",
            "8917 [Discriminator loss: 0.6680%, acc.: 64.06%] [Generator loss: 0.7929%]\n",
            "8918 [Discriminator loss: 0.6813%, acc.: 57.03%] [Generator loss: 0.7694%]\n",
            "8919 [Discriminator loss: 0.6632%, acc.: 64.06%] [Generator loss: 0.7771%]\n",
            "8920 [Discriminator loss: 0.6928%, acc.: 58.59%] [Generator loss: 0.7812%]\n",
            "8921 [Discriminator loss: 0.6700%, acc.: 57.03%] [Generator loss: 0.7542%]\n",
            "8922 [Discriminator loss: 0.6742%, acc.: 54.69%] [Generator loss: 0.7557%]\n",
            "8923 [Discriminator loss: 0.6815%, acc.: 58.20%] [Generator loss: 0.7628%]\n",
            "8924 [Discriminator loss: 0.6713%, acc.: 60.16%] [Generator loss: 0.7664%]\n",
            "8925 [Discriminator loss: 0.6767%, acc.: 56.25%] [Generator loss: 0.7603%]\n",
            "8926 [Discriminator loss: 0.6656%, acc.: 62.11%] [Generator loss: 0.7841%]\n",
            "8927 [Discriminator loss: 0.6674%, acc.: 62.50%] [Generator loss: 0.8038%]\n",
            "8928 [Discriminator loss: 0.6722%, acc.: 58.59%] [Generator loss: 0.7930%]\n",
            "8929 [Discriminator loss: 0.6978%, acc.: 55.86%] [Generator loss: 0.7722%]\n",
            "8930 [Discriminator loss: 0.6864%, acc.: 56.64%] [Generator loss: 0.8031%]\n",
            "8931 [Discriminator loss: 0.6807%, acc.: 55.86%] [Generator loss: 0.7906%]\n",
            "8932 [Discriminator loss: 0.6779%, acc.: 52.73%] [Generator loss: 0.7725%]\n",
            "8933 [Discriminator loss: 0.6703%, acc.: 59.77%] [Generator loss: 0.7670%]\n",
            "8934 [Discriminator loss: 0.6721%, acc.: 57.81%] [Generator loss: 0.8165%]\n",
            "8935 [Discriminator loss: 0.6668%, acc.: 57.03%] [Generator loss: 0.8187%]\n",
            "8936 [Discriminator loss: 0.6887%, acc.: 55.47%] [Generator loss: 0.7804%]\n",
            "8937 [Discriminator loss: 0.6633%, acc.: 62.50%] [Generator loss: 0.7826%]\n",
            "8938 [Discriminator loss: 0.6664%, acc.: 58.59%] [Generator loss: 0.7876%]\n",
            "8939 [Discriminator loss: 0.6824%, acc.: 58.20%] [Generator loss: 0.7675%]\n",
            "8940 [Discriminator loss: 0.6638%, acc.: 64.06%] [Generator loss: 0.7926%]\n",
            "8941 [Discriminator loss: 0.6687%, acc.: 60.94%] [Generator loss: 0.7897%]\n",
            "8942 [Discriminator loss: 0.6710%, acc.: 54.69%] [Generator loss: 0.7500%]\n",
            "8943 [Discriminator loss: 0.6839%, acc.: 57.81%] [Generator loss: 0.7783%]\n",
            "8944 [Discriminator loss: 0.6557%, acc.: 59.38%] [Generator loss: 0.7600%]\n",
            "8945 [Discriminator loss: 0.6536%, acc.: 61.72%] [Generator loss: 0.7824%]\n",
            "8946 [Discriminator loss: 0.7027%, acc.: 46.09%] [Generator loss: 0.7691%]\n",
            "8947 [Discriminator loss: 0.6751%, acc.: 55.86%] [Generator loss: 0.7849%]\n",
            "8948 [Discriminator loss: 0.6880%, acc.: 53.52%] [Generator loss: 0.7643%]\n",
            "8949 [Discriminator loss: 0.6558%, acc.: 65.23%] [Generator loss: 0.7822%]\n",
            "8950 [Discriminator loss: 0.6653%, acc.: 61.72%] [Generator loss: 0.7929%]\n",
            "8951 [Discriminator loss: 0.6792%, acc.: 53.91%] [Generator loss: 0.8002%]\n",
            "8952 [Discriminator loss: 0.6716%, acc.: 57.03%] [Generator loss: 0.7889%]\n",
            "8953 [Discriminator loss: 0.6866%, acc.: 53.91%] [Generator loss: 0.8005%]\n",
            "8954 [Discriminator loss: 0.6644%, acc.: 58.59%] [Generator loss: 0.7652%]\n",
            "8955 [Discriminator loss: 0.6798%, acc.: 55.86%] [Generator loss: 0.7862%]\n",
            "8956 [Discriminator loss: 0.6642%, acc.: 60.94%] [Generator loss: 0.7941%]\n",
            "8957 [Discriminator loss: 0.6674%, acc.: 57.81%] [Generator loss: 0.7825%]\n",
            "8958 [Discriminator loss: 0.6547%, acc.: 59.38%] [Generator loss: 0.7799%]\n",
            "8959 [Discriminator loss: 0.6715%, acc.: 59.77%] [Generator loss: 0.7802%]\n",
            "8960 [Discriminator loss: 0.6821%, acc.: 55.47%] [Generator loss: 0.7539%]\n",
            "8961 [Discriminator loss: 0.6817%, acc.: 52.73%] [Generator loss: 0.7886%]\n",
            "8962 [Discriminator loss: 0.6666%, acc.: 60.55%] [Generator loss: 0.7778%]\n",
            "8963 [Discriminator loss: 0.6747%, acc.: 56.64%] [Generator loss: 0.7711%]\n",
            "8964 [Discriminator loss: 0.6877%, acc.: 52.34%] [Generator loss: 0.7798%]\n",
            "8965 [Discriminator loss: 0.6827%, acc.: 56.64%] [Generator loss: 0.7898%]\n",
            "8966 [Discriminator loss: 0.6917%, acc.: 50.78%] [Generator loss: 0.8078%]\n",
            "8967 [Discriminator loss: 0.6733%, acc.: 57.03%] [Generator loss: 0.7960%]\n",
            "8968 [Discriminator loss: 0.6849%, acc.: 57.81%] [Generator loss: 0.7785%]\n",
            "8969 [Discriminator loss: 0.6536%, acc.: 64.84%] [Generator loss: 0.8004%]\n",
            "8970 [Discriminator loss: 0.6749%, acc.: 57.81%] [Generator loss: 0.7855%]\n",
            "8971 [Discriminator loss: 0.6655%, acc.: 61.33%] [Generator loss: 0.8162%]\n",
            "8972 [Discriminator loss: 0.6885%, acc.: 54.69%] [Generator loss: 0.8017%]\n",
            "8973 [Discriminator loss: 0.6650%, acc.: 60.55%] [Generator loss: 0.8085%]\n",
            "8974 [Discriminator loss: 0.6812%, acc.: 57.81%] [Generator loss: 0.7915%]\n",
            "8975 [Discriminator loss: 0.6684%, acc.: 58.59%] [Generator loss: 0.8077%]\n",
            "8976 [Discriminator loss: 0.6700%, acc.: 57.03%] [Generator loss: 0.7914%]\n",
            "8977 [Discriminator loss: 0.6610%, acc.: 61.72%] [Generator loss: 0.7775%]\n",
            "8978 [Discriminator loss: 0.6770%, acc.: 55.47%] [Generator loss: 0.7753%]\n",
            "8979 [Discriminator loss: 0.6712%, acc.: 61.33%] [Generator loss: 0.7881%]\n",
            "8980 [Discriminator loss: 0.6688%, acc.: 60.16%] [Generator loss: 0.7838%]\n",
            "8981 [Discriminator loss: 0.6818%, acc.: 57.03%] [Generator loss: 0.7940%]\n",
            "8982 [Discriminator loss: 0.6807%, acc.: 55.86%] [Generator loss: 0.7704%]\n",
            "8983 [Discriminator loss: 0.6655%, acc.: 60.16%] [Generator loss: 0.7730%]\n",
            "8984 [Discriminator loss: 0.6789%, acc.: 58.59%] [Generator loss: 0.7680%]\n",
            "8985 [Discriminator loss: 0.6576%, acc.: 60.16%] [Generator loss: 0.7720%]\n",
            "8986 [Discriminator loss: 0.6744%, acc.: 54.30%] [Generator loss: 0.7618%]\n",
            "8987 [Discriminator loss: 0.6672%, acc.: 57.81%] [Generator loss: 0.7499%]\n",
            "8988 [Discriminator loss: 0.6616%, acc.: 60.55%] [Generator loss: 0.7760%]\n",
            "8989 [Discriminator loss: 0.6561%, acc.: 66.41%] [Generator loss: 0.7506%]\n",
            "8990 [Discriminator loss: 0.6854%, acc.: 57.03%] [Generator loss: 0.7483%]\n",
            "8991 [Discriminator loss: 0.6742%, acc.: 56.25%] [Generator loss: 0.7940%]\n",
            "8992 [Discriminator loss: 0.6727%, acc.: 62.11%] [Generator loss: 0.7424%]\n",
            "8993 [Discriminator loss: 0.6699%, acc.: 57.03%] [Generator loss: 0.7851%]\n",
            "8994 [Discriminator loss: 0.6691%, acc.: 57.03%] [Generator loss: 0.7541%]\n",
            "8995 [Discriminator loss: 0.6841%, acc.: 53.91%] [Generator loss: 0.7719%]\n",
            "8996 [Discriminator loss: 0.6886%, acc.: 50.39%] [Generator loss: 0.8043%]\n",
            "8997 [Discriminator loss: 0.6706%, acc.: 57.03%] [Generator loss: 0.7872%]\n",
            "8998 [Discriminator loss: 0.6741%, acc.: 58.98%] [Generator loss: 0.8005%]\n",
            "8999 [Discriminator loss: 0.6950%, acc.: 52.34%] [Generator loss: 0.7761%]\n",
            "9000 [Discriminator loss: 0.6838%, acc.: 52.34%] [Generator loss: 0.7946%]\n",
            "9001 [Discriminator loss: 0.6848%, acc.: 53.91%] [Generator loss: 0.7836%]\n",
            "9002 [Discriminator loss: 0.6676%, acc.: 61.33%] [Generator loss: 0.7817%]\n",
            "9003 [Discriminator loss: 0.6886%, acc.: 55.86%] [Generator loss: 0.7718%]\n",
            "9004 [Discriminator loss: 0.6832%, acc.: 54.69%] [Generator loss: 0.7902%]\n",
            "9005 [Discriminator loss: 0.6794%, acc.: 55.86%] [Generator loss: 0.7905%]\n",
            "9006 [Discriminator loss: 0.6901%, acc.: 53.12%] [Generator loss: 0.7864%]\n",
            "9007 [Discriminator loss: 0.6642%, acc.: 62.11%] [Generator loss: 0.7693%]\n",
            "9008 [Discriminator loss: 0.6903%, acc.: 54.69%] [Generator loss: 0.7825%]\n",
            "9009 [Discriminator loss: 0.6862%, acc.: 54.69%] [Generator loss: 0.7821%]\n",
            "9010 [Discriminator loss: 0.6898%, acc.: 51.95%] [Generator loss: 0.7901%]\n",
            "9011 [Discriminator loss: 0.6710%, acc.: 54.69%] [Generator loss: 0.7760%]\n",
            "9012 [Discriminator loss: 0.6659%, acc.: 60.16%] [Generator loss: 0.7911%]\n",
            "9013 [Discriminator loss: 0.6689%, acc.: 58.98%] [Generator loss: 0.7917%]\n",
            "9014 [Discriminator loss: 0.6871%, acc.: 53.91%] [Generator loss: 0.7727%]\n",
            "9015 [Discriminator loss: 0.6778%, acc.: 58.59%] [Generator loss: 0.7747%]\n",
            "9016 [Discriminator loss: 0.6739%, acc.: 57.42%] [Generator loss: 0.7600%]\n",
            "9017 [Discriminator loss: 0.6698%, acc.: 57.03%] [Generator loss: 0.8014%]\n",
            "9018 [Discriminator loss: 0.6648%, acc.: 60.94%] [Generator loss: 0.7932%]\n",
            "9019 [Discriminator loss: 0.6568%, acc.: 60.55%] [Generator loss: 0.7832%]\n",
            "9020 [Discriminator loss: 0.6722%, acc.: 59.77%] [Generator loss: 0.7755%]\n",
            "9021 [Discriminator loss: 0.6917%, acc.: 53.91%] [Generator loss: 0.8118%]\n",
            "9022 [Discriminator loss: 0.6709%, acc.: 54.69%] [Generator loss: 0.7997%]\n",
            "9023 [Discriminator loss: 0.6835%, acc.: 54.69%] [Generator loss: 0.8163%]\n",
            "9024 [Discriminator loss: 0.6762%, acc.: 55.08%] [Generator loss: 0.7998%]\n",
            "9025 [Discriminator loss: 0.6912%, acc.: 58.98%] [Generator loss: 0.7777%]\n",
            "9026 [Discriminator loss: 0.6822%, acc.: 56.25%] [Generator loss: 0.7837%]\n",
            "9027 [Discriminator loss: 0.6764%, acc.: 56.64%] [Generator loss: 0.7707%]\n",
            "9028 [Discriminator loss: 0.6777%, acc.: 54.69%] [Generator loss: 0.7668%]\n",
            "9029 [Discriminator loss: 0.6665%, acc.: 55.47%] [Generator loss: 0.7713%]\n",
            "9030 [Discriminator loss: 0.6689%, acc.: 57.42%] [Generator loss: 0.7921%]\n",
            "9031 [Discriminator loss: 0.6646%, acc.: 61.72%] [Generator loss: 0.8080%]\n",
            "9032 [Discriminator loss: 0.6597%, acc.: 66.41%] [Generator loss: 0.7846%]\n",
            "9033 [Discriminator loss: 0.6732%, acc.: 58.20%] [Generator loss: 0.7911%]\n",
            "9034 [Discriminator loss: 0.6691%, acc.: 58.20%] [Generator loss: 0.7832%]\n",
            "9035 [Discriminator loss: 0.6605%, acc.: 61.33%] [Generator loss: 0.7930%]\n",
            "9036 [Discriminator loss: 0.6777%, acc.: 54.30%] [Generator loss: 0.7924%]\n",
            "9037 [Discriminator loss: 0.6716%, acc.: 60.94%] [Generator loss: 0.8023%]\n",
            "9038 [Discriminator loss: 0.6648%, acc.: 60.16%] [Generator loss: 0.8199%]\n",
            "9039 [Discriminator loss: 0.6791%, acc.: 56.25%] [Generator loss: 0.7815%]\n",
            "9040 [Discriminator loss: 0.6816%, acc.: 52.73%] [Generator loss: 0.8187%]\n",
            "9041 [Discriminator loss: 0.6852%, acc.: 53.12%] [Generator loss: 0.7728%]\n",
            "9042 [Discriminator loss: 0.6652%, acc.: 65.62%] [Generator loss: 0.7941%]\n",
            "9043 [Discriminator loss: 0.6887%, acc.: 54.30%] [Generator loss: 0.7925%]\n",
            "9044 [Discriminator loss: 0.6728%, acc.: 57.03%] [Generator loss: 0.7918%]\n",
            "9045 [Discriminator loss: 0.6792%, acc.: 55.08%] [Generator loss: 0.7750%]\n",
            "9046 [Discriminator loss: 0.6779%, acc.: 58.98%] [Generator loss: 0.7746%]\n",
            "9047 [Discriminator loss: 0.6632%, acc.: 60.16%] [Generator loss: 0.7673%]\n",
            "9048 [Discriminator loss: 0.6773%, acc.: 55.47%] [Generator loss: 0.7696%]\n",
            "9049 [Discriminator loss: 0.6613%, acc.: 60.94%] [Generator loss: 0.8050%]\n",
            "9050 [Discriminator loss: 0.6745%, acc.: 60.16%] [Generator loss: 0.7817%]\n",
            "9051 [Discriminator loss: 0.6716%, acc.: 53.91%] [Generator loss: 0.7997%]\n",
            "9052 [Discriminator loss: 0.6645%, acc.: 55.08%] [Generator loss: 0.8117%]\n",
            "9053 [Discriminator loss: 0.6762%, acc.: 55.08%] [Generator loss: 0.7828%]\n",
            "9054 [Discriminator loss: 0.6672%, acc.: 58.98%] [Generator loss: 0.7734%]\n",
            "9055 [Discriminator loss: 0.6672%, acc.: 58.20%] [Generator loss: 0.8012%]\n",
            "9056 [Discriminator loss: 0.6676%, acc.: 57.42%] [Generator loss: 0.7799%]\n",
            "9057 [Discriminator loss: 0.6585%, acc.: 63.28%] [Generator loss: 0.8053%]\n",
            "9058 [Discriminator loss: 0.6878%, acc.: 54.30%] [Generator loss: 0.8029%]\n",
            "9059 [Discriminator loss: 0.6522%, acc.: 65.23%] [Generator loss: 0.8014%]\n",
            "9060 [Discriminator loss: 0.6580%, acc.: 58.59%] [Generator loss: 0.7551%]\n",
            "9061 [Discriminator loss: 0.6615%, acc.: 60.94%] [Generator loss: 0.7609%]\n",
            "9062 [Discriminator loss: 0.6630%, acc.: 60.55%] [Generator loss: 0.7794%]\n",
            "9063 [Discriminator loss: 0.6880%, acc.: 57.03%] [Generator loss: 0.7820%]\n",
            "9064 [Discriminator loss: 0.6852%, acc.: 53.12%] [Generator loss: 0.7838%]\n",
            "9065 [Discriminator loss: 0.6582%, acc.: 62.89%] [Generator loss: 0.8255%]\n",
            "9066 [Discriminator loss: 0.6628%, acc.: 59.38%] [Generator loss: 0.8132%]\n",
            "9067 [Discriminator loss: 0.6735%, acc.: 58.98%] [Generator loss: 0.8073%]\n",
            "9068 [Discriminator loss: 0.6804%, acc.: 57.81%] [Generator loss: 0.8012%]\n",
            "9069 [Discriminator loss: 0.6750%, acc.: 54.30%] [Generator loss: 0.7896%]\n",
            "9070 [Discriminator loss: 0.6638%, acc.: 59.38%] [Generator loss: 0.7650%]\n",
            "9071 [Discriminator loss: 0.6846%, acc.: 56.64%] [Generator loss: 0.7976%]\n",
            "9072 [Discriminator loss: 0.6660%, acc.: 59.77%] [Generator loss: 0.7628%]\n",
            "9073 [Discriminator loss: 0.6556%, acc.: 62.50%] [Generator loss: 0.7950%]\n",
            "9074 [Discriminator loss: 0.6609%, acc.: 61.33%] [Generator loss: 0.7837%]\n",
            "9075 [Discriminator loss: 0.6679%, acc.: 59.38%] [Generator loss: 0.7831%]\n",
            "9076 [Discriminator loss: 0.6751%, acc.: 58.59%] [Generator loss: 0.7943%]\n",
            "9077 [Discriminator loss: 0.6808%, acc.: 53.91%] [Generator loss: 0.7830%]\n",
            "9078 [Discriminator loss: 0.6699%, acc.: 60.55%] [Generator loss: 0.8015%]\n",
            "9079 [Discriminator loss: 0.6877%, acc.: 51.56%] [Generator loss: 0.7685%]\n",
            "9080 [Discriminator loss: 0.6814%, acc.: 56.64%] [Generator loss: 0.7663%]\n",
            "9081 [Discriminator loss: 0.6800%, acc.: 59.38%] [Generator loss: 0.7966%]\n",
            "9082 [Discriminator loss: 0.6552%, acc.: 64.45%] [Generator loss: 0.7868%]\n",
            "9083 [Discriminator loss: 0.6667%, acc.: 61.72%] [Generator loss: 0.7961%]\n",
            "9084 [Discriminator loss: 0.6747%, acc.: 58.98%] [Generator loss: 0.7819%]\n",
            "9085 [Discriminator loss: 0.6661%, acc.: 57.81%] [Generator loss: 0.7892%]\n",
            "9086 [Discriminator loss: 0.6729%, acc.: 58.98%] [Generator loss: 0.7824%]\n",
            "9087 [Discriminator loss: 0.6673%, acc.: 58.98%] [Generator loss: 0.7934%]\n",
            "9088 [Discriminator loss: 0.6878%, acc.: 53.91%] [Generator loss: 0.7621%]\n",
            "9089 [Discriminator loss: 0.6767%, acc.: 54.30%] [Generator loss: 0.7521%]\n",
            "9090 [Discriminator loss: 0.6810%, acc.: 57.42%] [Generator loss: 0.7693%]\n",
            "9091 [Discriminator loss: 0.6671%, acc.: 60.16%] [Generator loss: 0.7816%]\n",
            "9092 [Discriminator loss: 0.6991%, acc.: 50.78%] [Generator loss: 0.7625%]\n",
            "9093 [Discriminator loss: 0.6782%, acc.: 58.59%] [Generator loss: 0.7681%]\n",
            "9094 [Discriminator loss: 0.6538%, acc.: 62.89%] [Generator loss: 0.7764%]\n",
            "9095 [Discriminator loss: 0.6627%, acc.: 63.28%] [Generator loss: 0.7679%]\n",
            "9096 [Discriminator loss: 0.6818%, acc.: 57.03%] [Generator loss: 0.7814%]\n",
            "9097 [Discriminator loss: 0.6924%, acc.: 51.95%] [Generator loss: 0.7812%]\n",
            "9098 [Discriminator loss: 0.6938%, acc.: 54.69%] [Generator loss: 0.7918%]\n",
            "9099 [Discriminator loss: 0.6828%, acc.: 54.30%] [Generator loss: 0.7833%]\n",
            "9100 [Discriminator loss: 0.6898%, acc.: 55.08%] [Generator loss: 0.7823%]\n",
            "9101 [Discriminator loss: 0.6774%, acc.: 56.25%] [Generator loss: 0.7927%]\n",
            "9102 [Discriminator loss: 0.6795%, acc.: 58.98%] [Generator loss: 0.7801%]\n",
            "9103 [Discriminator loss: 0.6829%, acc.: 58.59%] [Generator loss: 0.7766%]\n",
            "9104 [Discriminator loss: 0.6787%, acc.: 54.30%] [Generator loss: 0.7932%]\n",
            "9105 [Discriminator loss: 0.6668%, acc.: 64.06%] [Generator loss: 0.7867%]\n",
            "9106 [Discriminator loss: 0.6716%, acc.: 57.81%] [Generator loss: 0.7840%]\n",
            "9107 [Discriminator loss: 0.6749%, acc.: 58.98%] [Generator loss: 0.7832%]\n",
            "9108 [Discriminator loss: 0.6845%, acc.: 55.86%] [Generator loss: 0.7496%]\n",
            "9109 [Discriminator loss: 0.6688%, acc.: 59.38%] [Generator loss: 0.8000%]\n",
            "9110 [Discriminator loss: 0.6673%, acc.: 61.72%] [Generator loss: 0.7979%]\n",
            "9111 [Discriminator loss: 0.6545%, acc.: 63.67%] [Generator loss: 0.7902%]\n",
            "9112 [Discriminator loss: 0.6603%, acc.: 63.67%] [Generator loss: 0.7912%]\n",
            "9113 [Discriminator loss: 0.6762%, acc.: 61.33%] [Generator loss: 0.7645%]\n",
            "9114 [Discriminator loss: 0.6642%, acc.: 61.72%] [Generator loss: 0.7703%]\n",
            "9115 [Discriminator loss: 0.6775%, acc.: 55.08%] [Generator loss: 0.7808%]\n",
            "9116 [Discriminator loss: 0.6642%, acc.: 62.89%] [Generator loss: 0.7608%]\n",
            "9117 [Discriminator loss: 0.6565%, acc.: 64.45%] [Generator loss: 0.7832%]\n",
            "9118 [Discriminator loss: 0.6616%, acc.: 62.50%] [Generator loss: 0.7593%]\n",
            "9119 [Discriminator loss: 0.6765%, acc.: 51.95%] [Generator loss: 0.7611%]\n",
            "9120 [Discriminator loss: 0.6877%, acc.: 56.25%] [Generator loss: 0.7819%]\n",
            "9121 [Discriminator loss: 0.6727%, acc.: 58.20%] [Generator loss: 0.7642%]\n",
            "9122 [Discriminator loss: 0.6711%, acc.: 57.03%] [Generator loss: 0.7501%]\n",
            "9123 [Discriminator loss: 0.6753%, acc.: 60.16%] [Generator loss: 0.7716%]\n",
            "9124 [Discriminator loss: 0.6806%, acc.: 57.03%] [Generator loss: 0.7681%]\n",
            "9125 [Discriminator loss: 0.6694%, acc.: 59.38%] [Generator loss: 0.7954%]\n",
            "9126 [Discriminator loss: 0.6854%, acc.: 53.52%] [Generator loss: 0.7952%]\n",
            "9127 [Discriminator loss: 0.6817%, acc.: 51.95%] [Generator loss: 0.7793%]\n",
            "9128 [Discriminator loss: 0.6654%, acc.: 66.80%] [Generator loss: 0.7782%]\n",
            "9129 [Discriminator loss: 0.6759%, acc.: 57.03%] [Generator loss: 0.7716%]\n",
            "9130 [Discriminator loss: 0.6756%, acc.: 58.59%] [Generator loss: 0.7886%]\n",
            "9131 [Discriminator loss: 0.6656%, acc.: 59.77%] [Generator loss: 0.8001%]\n",
            "9132 [Discriminator loss: 0.6698%, acc.: 59.77%] [Generator loss: 0.7979%]\n",
            "9133 [Discriminator loss: 0.6761%, acc.: 55.47%] [Generator loss: 0.7978%]\n",
            "9134 [Discriminator loss: 0.6758%, acc.: 56.64%] [Generator loss: 0.7839%]\n",
            "9135 [Discriminator loss: 0.6614%, acc.: 64.84%] [Generator loss: 0.7632%]\n",
            "9136 [Discriminator loss: 0.6717%, acc.: 59.77%] [Generator loss: 0.8079%]\n",
            "9137 [Discriminator loss: 0.6623%, acc.: 61.72%] [Generator loss: 0.7959%]\n",
            "9138 [Discriminator loss: 0.6790%, acc.: 55.08%] [Generator loss: 0.7845%]\n",
            "9139 [Discriminator loss: 0.6895%, acc.: 55.08%] [Generator loss: 0.7712%]\n",
            "9140 [Discriminator loss: 0.6862%, acc.: 52.73%] [Generator loss: 0.7862%]\n",
            "9141 [Discriminator loss: 0.6622%, acc.: 59.77%] [Generator loss: 0.7549%]\n",
            "9142 [Discriminator loss: 0.6766%, acc.: 58.59%] [Generator loss: 0.7707%]\n",
            "9143 [Discriminator loss: 0.6815%, acc.: 56.25%] [Generator loss: 0.7856%]\n",
            "9144 [Discriminator loss: 0.6724%, acc.: 58.98%] [Generator loss: 0.7920%]\n",
            "9145 [Discriminator loss: 0.6746%, acc.: 57.03%] [Generator loss: 0.8033%]\n",
            "9146 [Discriminator loss: 0.6719%, acc.: 55.86%] [Generator loss: 0.7748%]\n",
            "9147 [Discriminator loss: 0.6915%, acc.: 54.30%] [Generator loss: 0.7648%]\n",
            "9148 [Discriminator loss: 0.6678%, acc.: 60.94%] [Generator loss: 0.7686%]\n",
            "9149 [Discriminator loss: 0.6714%, acc.: 58.59%] [Generator loss: 0.7849%]\n",
            "9150 [Discriminator loss: 0.6856%, acc.: 54.30%] [Generator loss: 0.7888%]\n",
            "9151 [Discriminator loss: 0.6790%, acc.: 56.25%] [Generator loss: 0.7903%]\n",
            "9152 [Discriminator loss: 0.6794%, acc.: 56.25%] [Generator loss: 0.7935%]\n",
            "9153 [Discriminator loss: 0.6913%, acc.: 56.25%] [Generator loss: 0.7924%]\n",
            "9154 [Discriminator loss: 0.6830%, acc.: 55.47%] [Generator loss: 0.7688%]\n",
            "9155 [Discriminator loss: 0.6836%, acc.: 57.81%] [Generator loss: 0.7676%]\n",
            "9156 [Discriminator loss: 0.6833%, acc.: 56.64%] [Generator loss: 0.7725%]\n",
            "9157 [Discriminator loss: 0.6813%, acc.: 59.38%] [Generator loss: 0.7772%]\n",
            "9158 [Discriminator loss: 0.6739%, acc.: 58.20%] [Generator loss: 0.7522%]\n",
            "9159 [Discriminator loss: 0.6840%, acc.: 52.73%] [Generator loss: 0.7601%]\n",
            "9160 [Discriminator loss: 0.6643%, acc.: 58.98%] [Generator loss: 0.7627%]\n",
            "9161 [Discriminator loss: 0.6642%, acc.: 56.64%] [Generator loss: 0.7763%]\n",
            "9162 [Discriminator loss: 0.6709%, acc.: 58.98%] [Generator loss: 0.7792%]\n",
            "9163 [Discriminator loss: 0.6846%, acc.: 53.52%] [Generator loss: 0.7831%]\n",
            "9164 [Discriminator loss: 0.6685%, acc.: 57.81%] [Generator loss: 0.8007%]\n",
            "9165 [Discriminator loss: 0.6904%, acc.: 54.69%] [Generator loss: 0.7739%]\n",
            "9166 [Discriminator loss: 0.6706%, acc.: 57.42%] [Generator loss: 0.7623%]\n",
            "9167 [Discriminator loss: 0.7037%, acc.: 48.83%] [Generator loss: 0.7870%]\n",
            "9168 [Discriminator loss: 0.6787%, acc.: 57.03%] [Generator loss: 0.8021%]\n",
            "9169 [Discriminator loss: 0.6943%, acc.: 52.73%] [Generator loss: 0.8043%]\n",
            "9170 [Discriminator loss: 0.6914%, acc.: 50.39%] [Generator loss: 0.8247%]\n",
            "9171 [Discriminator loss: 0.6708%, acc.: 59.77%] [Generator loss: 0.7799%]\n",
            "9172 [Discriminator loss: 0.6889%, acc.: 53.52%] [Generator loss: 0.7694%]\n",
            "9173 [Discriminator loss: 0.6939%, acc.: 52.73%] [Generator loss: 0.7945%]\n",
            "9174 [Discriminator loss: 0.6661%, acc.: 59.77%] [Generator loss: 0.7764%]\n",
            "9175 [Discriminator loss: 0.6733%, acc.: 57.42%] [Generator loss: 0.7744%]\n",
            "9176 [Discriminator loss: 0.6788%, acc.: 58.20%] [Generator loss: 0.7795%]\n",
            "9177 [Discriminator loss: 0.6645%, acc.: 58.20%] [Generator loss: 0.7817%]\n",
            "9178 [Discriminator loss: 0.6743%, acc.: 58.20%] [Generator loss: 0.7818%]\n",
            "9179 [Discriminator loss: 0.6671%, acc.: 60.94%] [Generator loss: 0.7776%]\n",
            "9180 [Discriminator loss: 0.6715%, acc.: 59.77%] [Generator loss: 0.7759%]\n",
            "9181 [Discriminator loss: 0.6673%, acc.: 61.72%] [Generator loss: 0.7893%]\n",
            "9182 [Discriminator loss: 0.6586%, acc.: 64.45%] [Generator loss: 0.7831%]\n",
            "9183 [Discriminator loss: 0.6705%, acc.: 60.94%] [Generator loss: 0.7847%]\n",
            "9184 [Discriminator loss: 0.6825%, acc.: 58.59%] [Generator loss: 0.7832%]\n",
            "9185 [Discriminator loss: 0.6809%, acc.: 57.42%] [Generator loss: 0.7917%]\n",
            "9186 [Discriminator loss: 0.6664%, acc.: 59.77%] [Generator loss: 0.8015%]\n",
            "9187 [Discriminator loss: 0.6738%, acc.: 62.89%] [Generator loss: 0.7776%]\n",
            "9188 [Discriminator loss: 0.6655%, acc.: 61.33%] [Generator loss: 0.7667%]\n",
            "9189 [Discriminator loss: 0.6819%, acc.: 58.98%] [Generator loss: 0.7575%]\n",
            "9190 [Discriminator loss: 0.6795%, acc.: 57.81%] [Generator loss: 0.7886%]\n",
            "9191 [Discriminator loss: 0.6596%, acc.: 60.16%] [Generator loss: 0.7742%]\n",
            "9192 [Discriminator loss: 0.6766%, acc.: 57.42%] [Generator loss: 0.7908%]\n",
            "9193 [Discriminator loss: 0.6705%, acc.: 56.25%] [Generator loss: 0.7705%]\n",
            "9194 [Discriminator loss: 0.6747%, acc.: 54.69%] [Generator loss: 0.7610%]\n",
            "9195 [Discriminator loss: 0.6964%, acc.: 54.30%] [Generator loss: 0.7584%]\n",
            "9196 [Discriminator loss: 0.6650%, acc.: 62.11%] [Generator loss: 0.7507%]\n",
            "9197 [Discriminator loss: 0.6706%, acc.: 57.81%] [Generator loss: 0.7764%]\n",
            "9198 [Discriminator loss: 0.6610%, acc.: 60.94%] [Generator loss: 0.7819%]\n",
            "9199 [Discriminator loss: 0.6575%, acc.: 60.55%] [Generator loss: 0.7781%]\n",
            "9200 [Discriminator loss: 0.6559%, acc.: 62.89%] [Generator loss: 0.7760%]\n",
            "9201 [Discriminator loss: 0.6658%, acc.: 60.16%] [Generator loss: 0.7616%]\n",
            "9202 [Discriminator loss: 0.6741%, acc.: 58.20%] [Generator loss: 0.7599%]\n",
            "9203 [Discriminator loss: 0.6791%, acc.: 55.86%] [Generator loss: 0.7779%]\n",
            "9204 [Discriminator loss: 0.6683%, acc.: 62.11%] [Generator loss: 0.7924%]\n",
            "9205 [Discriminator loss: 0.6796%, acc.: 56.64%] [Generator loss: 0.7593%]\n",
            "9206 [Discriminator loss: 0.6681%, acc.: 58.20%] [Generator loss: 0.7853%]\n",
            "9207 [Discriminator loss: 0.6773%, acc.: 60.16%] [Generator loss: 0.7694%]\n",
            "9208 [Discriminator loss: 0.6675%, acc.: 58.20%] [Generator loss: 0.7681%]\n",
            "9209 [Discriminator loss: 0.6750%, acc.: 57.81%] [Generator loss: 0.7569%]\n",
            "9210 [Discriminator loss: 0.6622%, acc.: 57.42%] [Generator loss: 0.7765%]\n",
            "9211 [Discriminator loss: 0.6874%, acc.: 51.56%] [Generator loss: 0.7586%]\n",
            "9212 [Discriminator loss: 0.6756%, acc.: 55.47%] [Generator loss: 0.7858%]\n",
            "9213 [Discriminator loss: 0.6772%, acc.: 58.98%] [Generator loss: 0.8210%]\n",
            "9214 [Discriminator loss: 0.6747%, acc.: 58.98%] [Generator loss: 0.8124%]\n",
            "9215 [Discriminator loss: 0.6718%, acc.: 57.03%] [Generator loss: 0.7850%]\n",
            "9216 [Discriminator loss: 0.6723%, acc.: 58.20%] [Generator loss: 0.7900%]\n",
            "9217 [Discriminator loss: 0.6798%, acc.: 57.03%] [Generator loss: 0.7685%]\n",
            "9218 [Discriminator loss: 0.6595%, acc.: 59.38%] [Generator loss: 0.7818%]\n",
            "9219 [Discriminator loss: 0.6622%, acc.: 57.42%] [Generator loss: 0.7733%]\n",
            "9220 [Discriminator loss: 0.6660%, acc.: 60.16%] [Generator loss: 0.7795%]\n",
            "9221 [Discriminator loss: 0.6625%, acc.: 60.94%] [Generator loss: 0.7901%]\n",
            "9222 [Discriminator loss: 0.6560%, acc.: 61.33%] [Generator loss: 0.7730%]\n",
            "9223 [Discriminator loss: 0.6759%, acc.: 58.59%] [Generator loss: 0.7850%]\n",
            "9224 [Discriminator loss: 0.6891%, acc.: 55.08%] [Generator loss: 0.7784%]\n",
            "9225 [Discriminator loss: 0.6762%, acc.: 57.03%] [Generator loss: 0.7808%]\n",
            "9226 [Discriminator loss: 0.6791%, acc.: 60.55%] [Generator loss: 0.7691%]\n",
            "9227 [Discriminator loss: 0.6593%, acc.: 61.72%] [Generator loss: 0.7950%]\n",
            "9228 [Discriminator loss: 0.6645%, acc.: 57.81%] [Generator loss: 0.7867%]\n",
            "9229 [Discriminator loss: 0.6666%, acc.: 61.33%] [Generator loss: 0.7965%]\n",
            "9230 [Discriminator loss: 0.6805%, acc.: 52.34%] [Generator loss: 0.7905%]\n",
            "9231 [Discriminator loss: 0.6821%, acc.: 53.91%] [Generator loss: 0.7608%]\n",
            "9232 [Discriminator loss: 0.6681%, acc.: 57.81%] [Generator loss: 0.7908%]\n",
            "9233 [Discriminator loss: 0.6677%, acc.: 58.20%] [Generator loss: 0.7803%]\n",
            "9234 [Discriminator loss: 0.6570%, acc.: 63.28%] [Generator loss: 0.7907%]\n",
            "9235 [Discriminator loss: 0.6755%, acc.: 55.08%] [Generator loss: 0.7797%]\n",
            "9236 [Discriminator loss: 0.6870%, acc.: 53.91%] [Generator loss: 0.7835%]\n",
            "9237 [Discriminator loss: 0.6821%, acc.: 51.17%] [Generator loss: 0.7874%]\n",
            "9238 [Discriminator loss: 0.6795%, acc.: 54.69%] [Generator loss: 0.7715%]\n",
            "9239 [Discriminator loss: 0.6690%, acc.: 58.59%] [Generator loss: 0.7674%]\n",
            "9240 [Discriminator loss: 0.6657%, acc.: 58.59%] [Generator loss: 0.7637%]\n",
            "9241 [Discriminator loss: 0.6621%, acc.: 60.16%] [Generator loss: 0.7844%]\n",
            "9242 [Discriminator loss: 0.6734%, acc.: 55.08%] [Generator loss: 0.7728%]\n",
            "9243 [Discriminator loss: 0.6729%, acc.: 54.69%] [Generator loss: 0.8042%]\n",
            "9244 [Discriminator loss: 0.6710%, acc.: 55.47%] [Generator loss: 0.7717%]\n",
            "9245 [Discriminator loss: 0.6695%, acc.: 60.94%] [Generator loss: 0.7763%]\n",
            "9246 [Discriminator loss: 0.6565%, acc.: 61.72%] [Generator loss: 0.7670%]\n",
            "9247 [Discriminator loss: 0.6784%, acc.: 53.12%] [Generator loss: 0.7647%]\n",
            "9248 [Discriminator loss: 0.6729%, acc.: 57.03%] [Generator loss: 0.7750%]\n",
            "9249 [Discriminator loss: 0.6706%, acc.: 61.72%] [Generator loss: 0.7650%]\n",
            "9250 [Discriminator loss: 0.6901%, acc.: 51.56%] [Generator loss: 0.7542%]\n",
            "9251 [Discriminator loss: 0.6731%, acc.: 59.77%] [Generator loss: 0.8058%]\n",
            "9252 [Discriminator loss: 0.6640%, acc.: 60.55%] [Generator loss: 0.7954%]\n",
            "9253 [Discriminator loss: 0.6950%, acc.: 55.08%] [Generator loss: 0.7721%]\n",
            "9254 [Discriminator loss: 0.6760%, acc.: 57.81%] [Generator loss: 0.7990%]\n",
            "9255 [Discriminator loss: 0.6584%, acc.: 62.89%] [Generator loss: 0.7838%]\n",
            "9256 [Discriminator loss: 0.6784%, acc.: 58.20%] [Generator loss: 0.7811%]\n",
            "9257 [Discriminator loss: 0.6845%, acc.: 57.42%] [Generator loss: 0.7620%]\n",
            "9258 [Discriminator loss: 0.6837%, acc.: 54.30%] [Generator loss: 0.7713%]\n",
            "9259 [Discriminator loss: 0.6818%, acc.: 57.42%] [Generator loss: 0.7724%]\n",
            "9260 [Discriminator loss: 0.6781%, acc.: 59.38%] [Generator loss: 0.7576%]\n",
            "9261 [Discriminator loss: 0.6707%, acc.: 57.03%] [Generator loss: 0.7838%]\n",
            "9262 [Discriminator loss: 0.6664%, acc.: 60.16%] [Generator loss: 0.7766%]\n",
            "9263 [Discriminator loss: 0.6802%, acc.: 56.25%] [Generator loss: 0.7678%]\n",
            "9264 [Discriminator loss: 0.6885%, acc.: 52.34%] [Generator loss: 0.7523%]\n",
            "9265 [Discriminator loss: 0.6730%, acc.: 53.91%] [Generator loss: 0.7820%]\n",
            "9266 [Discriminator loss: 0.6762%, acc.: 56.64%] [Generator loss: 0.7961%]\n",
            "9267 [Discriminator loss: 0.6848%, acc.: 57.42%] [Generator loss: 0.7926%]\n",
            "9268 [Discriminator loss: 0.6672%, acc.: 61.33%] [Generator loss: 0.7593%]\n",
            "9269 [Discriminator loss: 0.6626%, acc.: 57.03%] [Generator loss: 0.7791%]\n",
            "9270 [Discriminator loss: 0.6898%, acc.: 52.34%] [Generator loss: 0.7820%]\n",
            "9271 [Discriminator loss: 0.6730%, acc.: 55.08%] [Generator loss: 0.7677%]\n",
            "9272 [Discriminator loss: 0.6760%, acc.: 58.59%] [Generator loss: 0.7853%]\n",
            "9273 [Discriminator loss: 0.6739%, acc.: 57.42%] [Generator loss: 0.7923%]\n",
            "9274 [Discriminator loss: 0.6713%, acc.: 58.59%] [Generator loss: 0.7624%]\n",
            "9275 [Discriminator loss: 0.6888%, acc.: 56.64%] [Generator loss: 0.7400%]\n",
            "9276 [Discriminator loss: 0.6540%, acc.: 64.06%] [Generator loss: 0.7874%]\n",
            "9277 [Discriminator loss: 0.6697%, acc.: 57.42%] [Generator loss: 0.7540%]\n",
            "9278 [Discriminator loss: 0.6533%, acc.: 63.28%] [Generator loss: 0.7555%]\n",
            "9279 [Discriminator loss: 0.6673%, acc.: 58.98%] [Generator loss: 0.7551%]\n",
            "9280 [Discriminator loss: 0.6668%, acc.: 61.33%] [Generator loss: 0.7739%]\n",
            "9281 [Discriminator loss: 0.6674%, acc.: 62.89%] [Generator loss: 0.7801%]\n",
            "9282 [Discriminator loss: 0.6774%, acc.: 57.03%] [Generator loss: 0.8140%]\n",
            "9283 [Discriminator loss: 0.6832%, acc.: 55.47%] [Generator loss: 0.7863%]\n",
            "9284 [Discriminator loss: 0.6811%, acc.: 55.08%] [Generator loss: 0.7755%]\n",
            "9285 [Discriminator loss: 0.6596%, acc.: 62.11%] [Generator loss: 0.7775%]\n",
            "9286 [Discriminator loss: 0.6671%, acc.: 59.77%] [Generator loss: 0.7834%]\n",
            "9287 [Discriminator loss: 0.6676%, acc.: 60.94%] [Generator loss: 0.7788%]\n",
            "9288 [Discriminator loss: 0.6749%, acc.: 54.69%] [Generator loss: 0.7681%]\n",
            "9289 [Discriminator loss: 0.6670%, acc.: 57.03%] [Generator loss: 0.7707%]\n",
            "9290 [Discriminator loss: 0.6519%, acc.: 61.33%] [Generator loss: 0.7894%]\n",
            "9291 [Discriminator loss: 0.6773%, acc.: 55.08%] [Generator loss: 0.7844%]\n",
            "9292 [Discriminator loss: 0.6671%, acc.: 59.77%] [Generator loss: 0.7994%]\n",
            "9293 [Discriminator loss: 0.6647%, acc.: 58.59%] [Generator loss: 0.7684%]\n",
            "9294 [Discriminator loss: 0.6870%, acc.: 56.64%] [Generator loss: 0.7618%]\n",
            "9295 [Discriminator loss: 0.6744%, acc.: 59.77%] [Generator loss: 0.7768%]\n",
            "9296 [Discriminator loss: 0.6769%, acc.: 57.03%] [Generator loss: 0.7893%]\n",
            "9297 [Discriminator loss: 0.6616%, acc.: 63.67%] [Generator loss: 0.8004%]\n",
            "9298 [Discriminator loss: 0.6839%, acc.: 53.91%] [Generator loss: 0.7843%]\n",
            "9299 [Discriminator loss: 0.6833%, acc.: 51.17%] [Generator loss: 0.8040%]\n",
            "9300 [Discriminator loss: 0.6791%, acc.: 56.25%] [Generator loss: 0.7684%]\n",
            "9301 [Discriminator loss: 0.6625%, acc.: 66.80%] [Generator loss: 0.7739%]\n",
            "9302 [Discriminator loss: 0.6697%, acc.: 57.42%] [Generator loss: 0.7824%]\n",
            "9303 [Discriminator loss: 0.6816%, acc.: 60.16%] [Generator loss: 0.7949%]\n",
            "9304 [Discriminator loss: 0.6656%, acc.: 59.77%] [Generator loss: 0.7950%]\n",
            "9305 [Discriminator loss: 0.6765%, acc.: 60.94%] [Generator loss: 0.8014%]\n",
            "9306 [Discriminator loss: 0.6768%, acc.: 58.20%] [Generator loss: 0.7938%]\n",
            "9307 [Discriminator loss: 0.6570%, acc.: 64.45%] [Generator loss: 0.7947%]\n",
            "9308 [Discriminator loss: 0.6519%, acc.: 64.06%] [Generator loss: 0.7709%]\n",
            "9309 [Discriminator loss: 0.6755%, acc.: 55.08%] [Generator loss: 0.8050%]\n",
            "9310 [Discriminator loss: 0.6708%, acc.: 59.38%] [Generator loss: 0.7794%]\n",
            "9311 [Discriminator loss: 0.6845%, acc.: 53.52%] [Generator loss: 0.7818%]\n",
            "9312 [Discriminator loss: 0.6618%, acc.: 60.55%] [Generator loss: 0.7379%]\n",
            "9313 [Discriminator loss: 0.6739%, acc.: 57.42%] [Generator loss: 0.7786%]\n",
            "9314 [Discriminator loss: 0.6670%, acc.: 56.64%] [Generator loss: 0.7888%]\n",
            "9315 [Discriminator loss: 0.6714%, acc.: 60.16%] [Generator loss: 0.7692%]\n",
            "9316 [Discriminator loss: 0.6622%, acc.: 59.77%] [Generator loss: 0.7665%]\n",
            "9317 [Discriminator loss: 0.6777%, acc.: 56.64%] [Generator loss: 0.7745%]\n",
            "9318 [Discriminator loss: 0.6797%, acc.: 57.42%] [Generator loss: 0.7889%]\n",
            "9319 [Discriminator loss: 0.6745%, acc.: 57.81%] [Generator loss: 0.7697%]\n",
            "9320 [Discriminator loss: 0.6725%, acc.: 60.16%] [Generator loss: 0.7925%]\n",
            "9321 [Discriminator loss: 0.6703%, acc.: 58.20%] [Generator loss: 0.7714%]\n",
            "9322 [Discriminator loss: 0.6862%, acc.: 55.08%] [Generator loss: 0.7686%]\n",
            "9323 [Discriminator loss: 0.6648%, acc.: 60.94%] [Generator loss: 0.7589%]\n",
            "9324 [Discriminator loss: 0.6568%, acc.: 58.59%] [Generator loss: 0.7613%]\n",
            "9325 [Discriminator loss: 0.6589%, acc.: 60.16%] [Generator loss: 0.7940%]\n",
            "9326 [Discriminator loss: 0.6898%, acc.: 50.39%] [Generator loss: 0.7732%]\n",
            "9327 [Discriminator loss: 0.6877%, acc.: 54.30%] [Generator loss: 0.7769%]\n",
            "9328 [Discriminator loss: 0.6669%, acc.: 61.72%] [Generator loss: 0.7965%]\n",
            "9329 [Discriminator loss: 0.6689%, acc.: 58.59%] [Generator loss: 0.8091%]\n",
            "9330 [Discriminator loss: 0.6785%, acc.: 58.59%] [Generator loss: 0.7864%]\n",
            "9331 [Discriminator loss: 0.6632%, acc.: 60.55%] [Generator loss: 0.7987%]\n",
            "9332 [Discriminator loss: 0.6465%, acc.: 67.58%] [Generator loss: 0.7792%]\n",
            "9333 [Discriminator loss: 0.6693%, acc.: 57.42%] [Generator loss: 0.7655%]\n",
            "9334 [Discriminator loss: 0.6692%, acc.: 59.38%] [Generator loss: 0.7910%]\n",
            "9335 [Discriminator loss: 0.6622%, acc.: 62.50%] [Generator loss: 0.7939%]\n",
            "9336 [Discriminator loss: 0.6825%, acc.: 55.08%] [Generator loss: 0.7696%]\n",
            "9337 [Discriminator loss: 0.6636%, acc.: 62.50%] [Generator loss: 0.7938%]\n",
            "9338 [Discriminator loss: 0.6682%, acc.: 61.33%] [Generator loss: 0.7962%]\n",
            "9339 [Discriminator loss: 0.6684%, acc.: 60.94%] [Generator loss: 0.7887%]\n",
            "9340 [Discriminator loss: 0.6736%, acc.: 59.38%] [Generator loss: 0.7805%]\n",
            "9341 [Discriminator loss: 0.6718%, acc.: 58.20%] [Generator loss: 0.7671%]\n",
            "9342 [Discriminator loss: 0.6806%, acc.: 60.55%] [Generator loss: 0.8021%]\n",
            "9343 [Discriminator loss: 0.6689%, acc.: 61.33%] [Generator loss: 0.7969%]\n",
            "9344 [Discriminator loss: 0.6872%, acc.: 54.69%] [Generator loss: 0.7925%]\n",
            "9345 [Discriminator loss: 0.6858%, acc.: 53.12%] [Generator loss: 0.7975%]\n",
            "9346 [Discriminator loss: 0.6741%, acc.: 58.59%] [Generator loss: 0.7935%]\n",
            "9347 [Discriminator loss: 0.6829%, acc.: 56.25%] [Generator loss: 0.7830%]\n",
            "9348 [Discriminator loss: 0.6725%, acc.: 57.03%] [Generator loss: 0.7643%]\n",
            "9349 [Discriminator loss: 0.6725%, acc.: 57.03%] [Generator loss: 0.7730%]\n",
            "9350 [Discriminator loss: 0.6597%, acc.: 62.50%] [Generator loss: 0.7732%]\n",
            "9351 [Discriminator loss: 0.6755%, acc.: 58.98%] [Generator loss: 0.7813%]\n",
            "9352 [Discriminator loss: 0.6887%, acc.: 52.34%] [Generator loss: 0.7949%]\n",
            "9353 [Discriminator loss: 0.6707%, acc.: 57.42%] [Generator loss: 0.7547%]\n",
            "9354 [Discriminator loss: 0.6798%, acc.: 56.64%] [Generator loss: 0.7629%]\n",
            "9355 [Discriminator loss: 0.6754%, acc.: 56.64%] [Generator loss: 0.7687%]\n",
            "9356 [Discriminator loss: 0.6752%, acc.: 54.30%] [Generator loss: 0.7666%]\n",
            "9357 [Discriminator loss: 0.6809%, acc.: 57.03%] [Generator loss: 0.7841%]\n",
            "9358 [Discriminator loss: 0.6670%, acc.: 62.89%] [Generator loss: 0.7936%]\n",
            "9359 [Discriminator loss: 0.6810%, acc.: 55.08%] [Generator loss: 0.7675%]\n",
            "9360 [Discriminator loss: 0.6554%, acc.: 60.55%] [Generator loss: 0.7853%]\n",
            "9361 [Discriminator loss: 0.6583%, acc.: 60.94%] [Generator loss: 0.7713%]\n",
            "9362 [Discriminator loss: 0.6632%, acc.: 57.81%] [Generator loss: 0.7926%]\n",
            "9363 [Discriminator loss: 0.6576%, acc.: 60.16%] [Generator loss: 0.7722%]\n",
            "9364 [Discriminator loss: 0.6695%, acc.: 58.59%] [Generator loss: 0.8026%]\n",
            "9365 [Discriminator loss: 0.6713%, acc.: 55.47%] [Generator loss: 0.7683%]\n",
            "9366 [Discriminator loss: 0.6660%, acc.: 58.20%] [Generator loss: 0.7758%]\n",
            "9367 [Discriminator loss: 0.6697%, acc.: 59.38%] [Generator loss: 0.8028%]\n",
            "9368 [Discriminator loss: 0.6696%, acc.: 58.59%] [Generator loss: 0.7945%]\n",
            "9369 [Discriminator loss: 0.6787%, acc.: 57.42%] [Generator loss: 0.7872%]\n",
            "9370 [Discriminator loss: 0.6681%, acc.: 57.81%] [Generator loss: 0.7791%]\n",
            "9371 [Discriminator loss: 0.6937%, acc.: 54.30%] [Generator loss: 0.7981%]\n",
            "9372 [Discriminator loss: 0.6799%, acc.: 58.59%] [Generator loss: 0.7943%]\n",
            "9373 [Discriminator loss: 0.6674%, acc.: 56.64%] [Generator loss: 0.7787%]\n",
            "9374 [Discriminator loss: 0.6751%, acc.: 58.98%] [Generator loss: 0.7710%]\n",
            "9375 [Discriminator loss: 0.6764%, acc.: 53.52%] [Generator loss: 0.7790%]\n",
            "9376 [Discriminator loss: 0.6685%, acc.: 60.16%] [Generator loss: 0.7899%]\n",
            "9377 [Discriminator loss: 0.6773%, acc.: 57.42%] [Generator loss: 0.8053%]\n",
            "9378 [Discriminator loss: 0.6557%, acc.: 61.33%] [Generator loss: 0.7909%]\n",
            "9379 [Discriminator loss: 0.6644%, acc.: 64.45%] [Generator loss: 0.7802%]\n",
            "9380 [Discriminator loss: 0.6870%, acc.: 58.98%] [Generator loss: 0.7731%]\n",
            "9381 [Discriminator loss: 0.6819%, acc.: 58.59%] [Generator loss: 0.7893%]\n",
            "9382 [Discriminator loss: 0.6697%, acc.: 60.55%] [Generator loss: 0.7844%]\n",
            "9383 [Discriminator loss: 0.6732%, acc.: 60.55%] [Generator loss: 0.7774%]\n",
            "9384 [Discriminator loss: 0.6616%, acc.: 58.59%] [Generator loss: 0.8084%]\n",
            "9385 [Discriminator loss: 0.6803%, acc.: 55.08%] [Generator loss: 0.7732%]\n",
            "9386 [Discriminator loss: 0.6739%, acc.: 57.81%] [Generator loss: 0.8093%]\n",
            "9387 [Discriminator loss: 0.6855%, acc.: 53.91%] [Generator loss: 0.8076%]\n",
            "9388 [Discriminator loss: 0.6660%, acc.: 59.77%] [Generator loss: 0.8115%]\n",
            "9389 [Discriminator loss: 0.6884%, acc.: 55.86%] [Generator loss: 0.7944%]\n",
            "9390 [Discriminator loss: 0.6640%, acc.: 62.11%] [Generator loss: 0.7955%]\n",
            "9391 [Discriminator loss: 0.6722%, acc.: 57.42%] [Generator loss: 0.7688%]\n",
            "9392 [Discriminator loss: 0.6748%, acc.: 56.64%] [Generator loss: 0.7899%]\n",
            "9393 [Discriminator loss: 0.6916%, acc.: 54.30%] [Generator loss: 0.7925%]\n",
            "9394 [Discriminator loss: 0.6917%, acc.: 54.30%] [Generator loss: 0.7807%]\n",
            "9395 [Discriminator loss: 0.6726%, acc.: 59.77%] [Generator loss: 0.7866%]\n",
            "9396 [Discriminator loss: 0.6818%, acc.: 55.86%] [Generator loss: 0.7538%]\n",
            "9397 [Discriminator loss: 0.6900%, acc.: 53.52%] [Generator loss: 0.7690%]\n",
            "9398 [Discriminator loss: 0.6693%, acc.: 62.89%] [Generator loss: 0.7666%]\n",
            "9399 [Discriminator loss: 0.6804%, acc.: 55.86%] [Generator loss: 0.7673%]\n",
            "9400 [Discriminator loss: 0.6816%, acc.: 58.59%] [Generator loss: 0.7532%]\n",
            "9401 [Discriminator loss: 0.6685%, acc.: 60.16%] [Generator loss: 0.7600%]\n",
            "9402 [Discriminator loss: 0.6915%, acc.: 54.30%] [Generator loss: 0.7438%]\n",
            "9403 [Discriminator loss: 0.6776%, acc.: 55.47%] [Generator loss: 0.7667%]\n",
            "9404 [Discriminator loss: 0.6625%, acc.: 60.55%] [Generator loss: 0.7670%]\n",
            "9405 [Discriminator loss: 0.6729%, acc.: 58.98%] [Generator loss: 0.7711%]\n",
            "9406 [Discriminator loss: 0.6801%, acc.: 58.59%] [Generator loss: 0.7517%]\n",
            "9407 [Discriminator loss: 0.6760%, acc.: 55.47%] [Generator loss: 0.7688%]\n",
            "9408 [Discriminator loss: 0.6731%, acc.: 57.03%] [Generator loss: 0.7480%]\n",
            "9409 [Discriminator loss: 0.6848%, acc.: 58.98%] [Generator loss: 0.7558%]\n",
            "9410 [Discriminator loss: 0.6799%, acc.: 55.86%] [Generator loss: 0.7556%]\n",
            "9411 [Discriminator loss: 0.6782%, acc.: 57.03%] [Generator loss: 0.7807%]\n",
            "9412 [Discriminator loss: 0.6705%, acc.: 59.77%] [Generator loss: 0.7897%]\n",
            "9413 [Discriminator loss: 0.6828%, acc.: 57.03%] [Generator loss: 0.7778%]\n",
            "9414 [Discriminator loss: 0.6966%, acc.: 53.91%] [Generator loss: 0.7716%]\n",
            "9415 [Discriminator loss: 0.6895%, acc.: 53.12%] [Generator loss: 0.7663%]\n",
            "9416 [Discriminator loss: 0.6790%, acc.: 53.52%] [Generator loss: 0.7808%]\n",
            "9417 [Discriminator loss: 0.6681%, acc.: 59.77%] [Generator loss: 0.7784%]\n",
            "9418 [Discriminator loss: 0.6704%, acc.: 60.16%] [Generator loss: 0.7776%]\n",
            "9419 [Discriminator loss: 0.6884%, acc.: 51.17%] [Generator loss: 0.7874%]\n",
            "9420 [Discriminator loss: 0.6658%, acc.: 60.16%] [Generator loss: 0.7957%]\n",
            "9421 [Discriminator loss: 0.6595%, acc.: 61.72%] [Generator loss: 0.7922%]\n",
            "9422 [Discriminator loss: 0.6762%, acc.: 58.20%] [Generator loss: 0.7889%]\n",
            "9423 [Discriminator loss: 0.6785%, acc.: 57.42%] [Generator loss: 0.7839%]\n",
            "9424 [Discriminator loss: 0.6695%, acc.: 60.55%] [Generator loss: 0.7841%]\n",
            "9425 [Discriminator loss: 0.6759%, acc.: 57.03%] [Generator loss: 0.7716%]\n",
            "9426 [Discriminator loss: 0.6688%, acc.: 59.77%] [Generator loss: 0.7847%]\n",
            "9427 [Discriminator loss: 0.6767%, acc.: 59.77%] [Generator loss: 0.7672%]\n",
            "9428 [Discriminator loss: 0.6772%, acc.: 56.25%] [Generator loss: 0.7535%]\n",
            "9429 [Discriminator loss: 0.6720%, acc.: 57.81%] [Generator loss: 0.7848%]\n",
            "9430 [Discriminator loss: 0.6928%, acc.: 55.86%] [Generator loss: 0.7849%]\n",
            "9431 [Discriminator loss: 0.6785%, acc.: 55.47%] [Generator loss: 0.7612%]\n",
            "9432 [Discriminator loss: 0.6717%, acc.: 57.03%] [Generator loss: 0.7572%]\n",
            "9433 [Discriminator loss: 0.6774%, acc.: 60.94%] [Generator loss: 0.7870%]\n",
            "9434 [Discriminator loss: 0.6674%, acc.: 57.81%] [Generator loss: 0.7710%]\n",
            "9435 [Discriminator loss: 0.6783%, acc.: 55.86%] [Generator loss: 0.7894%]\n",
            "9436 [Discriminator loss: 0.6754%, acc.: 57.81%] [Generator loss: 0.8039%]\n",
            "9437 [Discriminator loss: 0.6794%, acc.: 57.42%] [Generator loss: 0.7863%]\n",
            "9438 [Discriminator loss: 0.6730%, acc.: 56.25%] [Generator loss: 0.8066%]\n",
            "9439 [Discriminator loss: 0.6810%, acc.: 56.64%] [Generator loss: 0.7959%]\n",
            "9440 [Discriminator loss: 0.6740%, acc.: 55.08%] [Generator loss: 0.7743%]\n",
            "9441 [Discriminator loss: 0.6661%, acc.: 55.47%] [Generator loss: 0.7963%]\n",
            "9442 [Discriminator loss: 0.6704%, acc.: 60.94%] [Generator loss: 0.7986%]\n",
            "9443 [Discriminator loss: 0.6718%, acc.: 54.69%] [Generator loss: 0.7807%]\n",
            "9444 [Discriminator loss: 0.6808%, acc.: 54.30%] [Generator loss: 0.7842%]\n",
            "9445 [Discriminator loss: 0.6615%, acc.: 59.77%] [Generator loss: 0.7767%]\n",
            "9446 [Discriminator loss: 0.6915%, acc.: 54.30%] [Generator loss: 0.7707%]\n",
            "9447 [Discriminator loss: 0.6722%, acc.: 59.77%] [Generator loss: 0.7815%]\n",
            "9448 [Discriminator loss: 0.6948%, acc.: 48.44%] [Generator loss: 0.7805%]\n",
            "9449 [Discriminator loss: 0.6487%, acc.: 63.67%] [Generator loss: 0.7950%]\n",
            "9450 [Discriminator loss: 0.6840%, acc.: 55.86%] [Generator loss: 0.7705%]\n",
            "9451 [Discriminator loss: 0.6804%, acc.: 57.42%] [Generator loss: 0.7961%]\n",
            "9452 [Discriminator loss: 0.6631%, acc.: 60.16%] [Generator loss: 0.7902%]\n",
            "9453 [Discriminator loss: 0.6807%, acc.: 55.08%] [Generator loss: 0.7765%]\n",
            "9454 [Discriminator loss: 0.6788%, acc.: 56.25%] [Generator loss: 0.7758%]\n",
            "9455 [Discriminator loss: 0.6546%, acc.: 59.38%] [Generator loss: 0.7794%]\n",
            "9456 [Discriminator loss: 0.6768%, acc.: 58.20%] [Generator loss: 0.7796%]\n",
            "9457 [Discriminator loss: 0.6590%, acc.: 63.28%] [Generator loss: 0.7720%]\n",
            "9458 [Discriminator loss: 0.6721%, acc.: 58.98%] [Generator loss: 0.8032%]\n",
            "9459 [Discriminator loss: 0.6712%, acc.: 59.77%] [Generator loss: 0.7880%]\n",
            "9460 [Discriminator loss: 0.6818%, acc.: 55.86%] [Generator loss: 0.7720%]\n",
            "9461 [Discriminator loss: 0.6701%, acc.: 58.98%] [Generator loss: 0.7799%]\n",
            "9462 [Discriminator loss: 0.6775%, acc.: 56.25%] [Generator loss: 0.7857%]\n",
            "9463 [Discriminator loss: 0.6584%, acc.: 60.16%] [Generator loss: 0.8043%]\n",
            "9464 [Discriminator loss: 0.6577%, acc.: 66.02%] [Generator loss: 0.7922%]\n",
            "9465 [Discriminator loss: 0.6872%, acc.: 54.30%] [Generator loss: 0.7732%]\n",
            "9466 [Discriminator loss: 0.6791%, acc.: 57.03%] [Generator loss: 0.7717%]\n",
            "9467 [Discriminator loss: 0.6584%, acc.: 61.72%] [Generator loss: 0.7846%]\n",
            "9468 [Discriminator loss: 0.6678%, acc.: 58.59%] [Generator loss: 0.8038%]\n",
            "9469 [Discriminator loss: 0.6689%, acc.: 60.16%] [Generator loss: 0.7654%]\n",
            "9470 [Discriminator loss: 0.6741%, acc.: 58.59%] [Generator loss: 0.7657%]\n",
            "9471 [Discriminator loss: 0.6553%, acc.: 59.77%] [Generator loss: 0.7571%]\n",
            "9472 [Discriminator loss: 0.6830%, acc.: 55.86%] [Generator loss: 0.7692%]\n",
            "9473 [Discriminator loss: 0.6690%, acc.: 57.42%] [Generator loss: 0.7590%]\n",
            "9474 [Discriminator loss: 0.6913%, acc.: 54.69%] [Generator loss: 0.7632%]\n",
            "9475 [Discriminator loss: 0.6654%, acc.: 61.33%] [Generator loss: 0.7755%]\n",
            "9476 [Discriminator loss: 0.6683%, acc.: 58.98%] [Generator loss: 0.7851%]\n",
            "9477 [Discriminator loss: 0.6775%, acc.: 58.20%] [Generator loss: 0.7712%]\n",
            "9478 [Discriminator loss: 0.6745%, acc.: 58.59%] [Generator loss: 0.8007%]\n",
            "9479 [Discriminator loss: 0.6803%, acc.: 52.34%] [Generator loss: 0.7823%]\n",
            "9480 [Discriminator loss: 0.6515%, acc.: 64.84%] [Generator loss: 0.7850%]\n",
            "9481 [Discriminator loss: 0.6636%, acc.: 58.59%] [Generator loss: 0.7714%]\n",
            "9482 [Discriminator loss: 0.6598%, acc.: 60.94%] [Generator loss: 0.7785%]\n",
            "9483 [Discriminator loss: 0.6718%, acc.: 59.38%] [Generator loss: 0.7864%]\n",
            "9484 [Discriminator loss: 0.6731%, acc.: 59.38%] [Generator loss: 0.7909%]\n",
            "9485 [Discriminator loss: 0.6844%, acc.: 53.52%] [Generator loss: 0.8024%]\n",
            "9486 [Discriminator loss: 0.6782%, acc.: 57.42%] [Generator loss: 0.7948%]\n",
            "9487 [Discriminator loss: 0.6803%, acc.: 60.16%] [Generator loss: 0.7857%]\n",
            "9488 [Discriminator loss: 0.6759%, acc.: 57.03%] [Generator loss: 0.7809%]\n",
            "9489 [Discriminator loss: 0.6575%, acc.: 64.45%] [Generator loss: 0.7738%]\n",
            "9490 [Discriminator loss: 0.6631%, acc.: 60.94%] [Generator loss: 0.7911%]\n",
            "9491 [Discriminator loss: 0.6829%, acc.: 53.91%] [Generator loss: 0.7922%]\n",
            "9492 [Discriminator loss: 0.6758%, acc.: 62.11%] [Generator loss: 0.8062%]\n",
            "9493 [Discriminator loss: 0.6852%, acc.: 52.34%] [Generator loss: 0.7832%]\n",
            "9494 [Discriminator loss: 0.6790%, acc.: 57.42%] [Generator loss: 0.7821%]\n",
            "9495 [Discriminator loss: 0.6631%, acc.: 59.38%] [Generator loss: 0.7719%]\n",
            "9496 [Discriminator loss: 0.6849%, acc.: 55.86%] [Generator loss: 0.7762%]\n",
            "9497 [Discriminator loss: 0.6649%, acc.: 60.55%] [Generator loss: 0.7990%]\n",
            "9498 [Discriminator loss: 0.6868%, acc.: 56.25%] [Generator loss: 0.7858%]\n",
            "9499 [Discriminator loss: 0.6413%, acc.: 65.23%] [Generator loss: 0.7617%]\n",
            "9500 [Discriminator loss: 0.6775%, acc.: 56.64%] [Generator loss: 0.7909%]\n",
            "9501 [Discriminator loss: 0.6796%, acc.: 53.91%] [Generator loss: 0.7675%]\n",
            "9502 [Discriminator loss: 0.6768%, acc.: 57.03%] [Generator loss: 0.7809%]\n",
            "9503 [Discriminator loss: 0.6687%, acc.: 61.33%] [Generator loss: 0.7736%]\n",
            "9504 [Discriminator loss: 0.6793%, acc.: 57.03%] [Generator loss: 0.8195%]\n",
            "9505 [Discriminator loss: 0.6784%, acc.: 57.42%] [Generator loss: 0.8077%]\n",
            "9506 [Discriminator loss: 0.6587%, acc.: 62.50%] [Generator loss: 0.7932%]\n",
            "9507 [Discriminator loss: 0.6724%, acc.: 60.16%] [Generator loss: 0.7920%]\n",
            "9508 [Discriminator loss: 0.6768%, acc.: 58.59%] [Generator loss: 0.8087%]\n",
            "9509 [Discriminator loss: 0.6708%, acc.: 56.25%] [Generator loss: 0.7931%]\n",
            "9510 [Discriminator loss: 0.6809%, acc.: 52.34%] [Generator loss: 0.8019%]\n",
            "9511 [Discriminator loss: 0.6713%, acc.: 59.77%] [Generator loss: 0.7734%]\n",
            "9512 [Discriminator loss: 0.6981%, acc.: 51.56%] [Generator loss: 0.7536%]\n",
            "9513 [Discriminator loss: 0.6836%, acc.: 54.30%] [Generator loss: 0.7824%]\n",
            "9514 [Discriminator loss: 0.6860%, acc.: 54.69%] [Generator loss: 0.7976%]\n",
            "9515 [Discriminator loss: 0.6860%, acc.: 53.12%] [Generator loss: 0.7916%]\n",
            "9516 [Discriminator loss: 0.6539%, acc.: 67.19%] [Generator loss: 0.7694%]\n",
            "9517 [Discriminator loss: 0.6703%, acc.: 57.42%] [Generator loss: 0.7706%]\n",
            "9518 [Discriminator loss: 0.6613%, acc.: 59.38%] [Generator loss: 0.7542%]\n",
            "9519 [Discriminator loss: 0.6736%, acc.: 57.42%] [Generator loss: 0.7671%]\n",
            "9520 [Discriminator loss: 0.6995%, acc.: 51.17%] [Generator loss: 0.7782%]\n",
            "9521 [Discriminator loss: 0.6795%, acc.: 55.86%] [Generator loss: 0.7863%]\n",
            "9522 [Discriminator loss: 0.6672%, acc.: 59.77%] [Generator loss: 0.7865%]\n",
            "9523 [Discriminator loss: 0.6730%, acc.: 54.30%] [Generator loss: 0.7897%]\n",
            "9524 [Discriminator loss: 0.6660%, acc.: 60.55%] [Generator loss: 0.7998%]\n",
            "9525 [Discriminator loss: 0.6572%, acc.: 59.77%] [Generator loss: 0.7660%]\n",
            "9526 [Discriminator loss: 0.6852%, acc.: 53.52%] [Generator loss: 0.7641%]\n",
            "9527 [Discriminator loss: 0.6959%, acc.: 53.12%] [Generator loss: 0.7781%]\n",
            "9528 [Discriminator loss: 0.6807%, acc.: 53.52%] [Generator loss: 0.7588%]\n",
            "9529 [Discriminator loss: 0.6716%, acc.: 61.33%] [Generator loss: 0.7885%]\n",
            "9530 [Discriminator loss: 0.6724%, acc.: 53.91%] [Generator loss: 0.7783%]\n",
            "9531 [Discriminator loss: 0.6796%, acc.: 58.20%] [Generator loss: 0.8004%]\n",
            "9532 [Discriminator loss: 0.6659%, acc.: 63.67%] [Generator loss: 0.7869%]\n",
            "9533 [Discriminator loss: 0.6720%, acc.: 58.59%] [Generator loss: 0.8026%]\n",
            "9534 [Discriminator loss: 0.6833%, acc.: 56.64%] [Generator loss: 0.7825%]\n",
            "9535 [Discriminator loss: 0.6867%, acc.: 53.91%] [Generator loss: 0.7889%]\n",
            "9536 [Discriminator loss: 0.6782%, acc.: 57.03%] [Generator loss: 0.7768%]\n",
            "9537 [Discriminator loss: 0.6823%, acc.: 52.73%] [Generator loss: 0.7823%]\n",
            "9538 [Discriminator loss: 0.6851%, acc.: 56.25%] [Generator loss: 0.7882%]\n",
            "9539 [Discriminator loss: 0.6689%, acc.: 55.86%] [Generator loss: 0.7690%]\n",
            "9540 [Discriminator loss: 0.6798%, acc.: 59.38%] [Generator loss: 0.7715%]\n",
            "9541 [Discriminator loss: 0.6643%, acc.: 59.38%] [Generator loss: 0.7837%]\n",
            "9542 [Discriminator loss: 0.6937%, acc.: 53.91%] [Generator loss: 0.7724%]\n",
            "9543 [Discriminator loss: 0.6820%, acc.: 54.30%] [Generator loss: 0.7847%]\n",
            "9544 [Discriminator loss: 0.6665%, acc.: 61.72%] [Generator loss: 0.7773%]\n",
            "9545 [Discriminator loss: 0.6739%, acc.: 58.20%] [Generator loss: 0.7633%]\n",
            "9546 [Discriminator loss: 0.6775%, acc.: 57.03%] [Generator loss: 0.7934%]\n",
            "9547 [Discriminator loss: 0.6713%, acc.: 58.59%] [Generator loss: 0.7549%]\n",
            "9548 [Discriminator loss: 0.6751%, acc.: 53.91%] [Generator loss: 0.7533%]\n",
            "9549 [Discriminator loss: 0.6761%, acc.: 57.42%] [Generator loss: 0.7866%]\n",
            "9550 [Discriminator loss: 0.6799%, acc.: 52.73%] [Generator loss: 0.7896%]\n",
            "9551 [Discriminator loss: 0.6681%, acc.: 59.38%] [Generator loss: 0.7757%]\n",
            "9552 [Discriminator loss: 0.6697%, acc.: 60.94%] [Generator loss: 0.7735%]\n",
            "9553 [Discriminator loss: 0.6660%, acc.: 59.77%] [Generator loss: 0.7721%]\n",
            "9554 [Discriminator loss: 0.6695%, acc.: 58.20%] [Generator loss: 0.8055%]\n",
            "9555 [Discriminator loss: 0.6727%, acc.: 55.86%] [Generator loss: 0.7843%]\n",
            "9556 [Discriminator loss: 0.6798%, acc.: 57.81%] [Generator loss: 0.7730%]\n",
            "9557 [Discriminator loss: 0.6692%, acc.: 60.94%] [Generator loss: 0.7758%]\n",
            "9558 [Discriminator loss: 0.6766%, acc.: 58.59%] [Generator loss: 0.7827%]\n",
            "9559 [Discriminator loss: 0.6844%, acc.: 53.52%] [Generator loss: 0.7904%]\n",
            "9560 [Discriminator loss: 0.6794%, acc.: 54.69%] [Generator loss: 0.7720%]\n",
            "9561 [Discriminator loss: 0.6772%, acc.: 55.08%] [Generator loss: 0.7875%]\n",
            "9562 [Discriminator loss: 0.6775%, acc.: 57.81%] [Generator loss: 0.7809%]\n",
            "9563 [Discriminator loss: 0.6771%, acc.: 57.81%] [Generator loss: 0.7816%]\n",
            "9564 [Discriminator loss: 0.6775%, acc.: 54.69%] [Generator loss: 0.7677%]\n",
            "9565 [Discriminator loss: 0.6754%, acc.: 57.42%] [Generator loss: 0.7804%]\n",
            "9566 [Discriminator loss: 0.6599%, acc.: 60.16%] [Generator loss: 0.7500%]\n",
            "9567 [Discriminator loss: 0.6874%, acc.: 55.47%] [Generator loss: 0.7601%]\n",
            "9568 [Discriminator loss: 0.6634%, acc.: 62.11%] [Generator loss: 0.7657%]\n",
            "9569 [Discriminator loss: 0.6864%, acc.: 57.42%] [Generator loss: 0.7797%]\n",
            "9570 [Discriminator loss: 0.6719%, acc.: 56.25%] [Generator loss: 0.7693%]\n",
            "9571 [Discriminator loss: 0.6743%, acc.: 58.59%] [Generator loss: 0.7849%]\n",
            "9572 [Discriminator loss: 0.6830%, acc.: 57.42%] [Generator loss: 0.7640%]\n",
            "9573 [Discriminator loss: 0.6807%, acc.: 59.38%] [Generator loss: 0.7930%]\n",
            "9574 [Discriminator loss: 0.6657%, acc.: 58.20%] [Generator loss: 0.7707%]\n",
            "9575 [Discriminator loss: 0.6813%, acc.: 58.20%] [Generator loss: 0.7794%]\n",
            "9576 [Discriminator loss: 0.6686%, acc.: 60.94%] [Generator loss: 0.7814%]\n",
            "9577 [Discriminator loss: 0.6743%, acc.: 60.16%] [Generator loss: 0.7730%]\n",
            "9578 [Discriminator loss: 0.6728%, acc.: 57.81%] [Generator loss: 0.7804%]\n",
            "9579 [Discriminator loss: 0.6675%, acc.: 62.50%] [Generator loss: 0.7762%]\n",
            "9580 [Discriminator loss: 0.6912%, acc.: 55.86%] [Generator loss: 0.7834%]\n",
            "9581 [Discriminator loss: 0.6669%, acc.: 61.72%] [Generator loss: 0.8118%]\n",
            "9582 [Discriminator loss: 0.6802%, acc.: 58.59%] [Generator loss: 0.8033%]\n",
            "9583 [Discriminator loss: 0.6786%, acc.: 55.47%] [Generator loss: 0.7828%]\n",
            "9584 [Discriminator loss: 0.6804%, acc.: 53.52%] [Generator loss: 0.7984%]\n",
            "9585 [Discriminator loss: 0.6892%, acc.: 53.12%] [Generator loss: 0.8038%]\n",
            "9586 [Discriminator loss: 0.6774%, acc.: 60.16%] [Generator loss: 0.8096%]\n",
            "9587 [Discriminator loss: 0.6806%, acc.: 55.86%] [Generator loss: 0.8037%]\n",
            "9588 [Discriminator loss: 0.6772%, acc.: 56.64%] [Generator loss: 0.7981%]\n",
            "9589 [Discriminator loss: 0.6725%, acc.: 57.03%] [Generator loss: 0.7871%]\n",
            "9590 [Discriminator loss: 0.6688%, acc.: 59.77%] [Generator loss: 0.8052%]\n",
            "9591 [Discriminator loss: 0.6755%, acc.: 55.86%] [Generator loss: 0.7878%]\n",
            "9592 [Discriminator loss: 0.6543%, acc.: 61.72%] [Generator loss: 0.7846%]\n",
            "9593 [Discriminator loss: 0.6846%, acc.: 53.52%] [Generator loss: 0.7844%]\n",
            "9594 [Discriminator loss: 0.6756%, acc.: 55.86%] [Generator loss: 0.7754%]\n",
            "9595 [Discriminator loss: 0.6606%, acc.: 59.77%] [Generator loss: 0.7719%]\n",
            "9596 [Discriminator loss: 0.6729%, acc.: 57.03%] [Generator loss: 0.7699%]\n",
            "9597 [Discriminator loss: 0.6798%, acc.: 55.47%] [Generator loss: 0.7814%]\n",
            "9598 [Discriminator loss: 0.6751%, acc.: 55.08%] [Generator loss: 0.7800%]\n",
            "9599 [Discriminator loss: 0.6533%, acc.: 64.84%] [Generator loss: 0.7979%]\n",
            "9600 [Discriminator loss: 0.6835%, acc.: 55.86%] [Generator loss: 0.7998%]\n",
            "9601 [Discriminator loss: 0.6830%, acc.: 55.08%] [Generator loss: 0.7592%]\n",
            "9602 [Discriminator loss: 0.6961%, acc.: 51.17%] [Generator loss: 0.7719%]\n",
            "9603 [Discriminator loss: 0.6801%, acc.: 55.86%] [Generator loss: 0.7746%]\n",
            "9604 [Discriminator loss: 0.6811%, acc.: 57.81%] [Generator loss: 0.7801%]\n",
            "9605 [Discriminator loss: 0.6663%, acc.: 60.55%] [Generator loss: 0.7544%]\n",
            "9606 [Discriminator loss: 0.6722%, acc.: 58.20%] [Generator loss: 0.7786%]\n",
            "9607 [Discriminator loss: 0.6917%, acc.: 57.81%] [Generator loss: 0.7693%]\n",
            "9608 [Discriminator loss: 0.6836%, acc.: 57.42%] [Generator loss: 0.7945%]\n",
            "9609 [Discriminator loss: 0.6743%, acc.: 58.59%] [Generator loss: 0.7913%]\n",
            "9610 [Discriminator loss: 0.6633%, acc.: 59.38%] [Generator loss: 0.7733%]\n",
            "9611 [Discriminator loss: 0.6775%, acc.: 58.98%] [Generator loss: 0.7686%]\n",
            "9612 [Discriminator loss: 0.6734%, acc.: 55.47%] [Generator loss: 0.8017%]\n",
            "9613 [Discriminator loss: 0.6888%, acc.: 55.08%] [Generator loss: 0.8266%]\n",
            "9614 [Discriminator loss: 0.6835%, acc.: 54.30%] [Generator loss: 0.8126%]\n",
            "9615 [Discriminator loss: 0.6645%, acc.: 58.59%] [Generator loss: 0.8004%]\n",
            "9616 [Discriminator loss: 0.6766%, acc.: 57.03%] [Generator loss: 0.7799%]\n",
            "9617 [Discriminator loss: 0.6729%, acc.: 55.08%] [Generator loss: 0.8042%]\n",
            "9618 [Discriminator loss: 0.6897%, acc.: 51.17%] [Generator loss: 0.7624%]\n",
            "9619 [Discriminator loss: 0.6562%, acc.: 64.06%] [Generator loss: 0.7918%]\n",
            "9620 [Discriminator loss: 0.6801%, acc.: 53.52%] [Generator loss: 0.7935%]\n",
            "9621 [Discriminator loss: 0.6846%, acc.: 51.95%] [Generator loss: 0.7889%]\n",
            "9622 [Discriminator loss: 0.6911%, acc.: 54.30%] [Generator loss: 0.7767%]\n",
            "9623 [Discriminator loss: 0.6866%, acc.: 53.52%] [Generator loss: 0.7491%]\n",
            "9624 [Discriminator loss: 0.6786%, acc.: 55.86%] [Generator loss: 0.7610%]\n",
            "9625 [Discriminator loss: 0.6770%, acc.: 56.64%] [Generator loss: 0.7941%]\n",
            "9626 [Discriminator loss: 0.6666%, acc.: 60.94%] [Generator loss: 0.7986%]\n",
            "9627 [Discriminator loss: 0.6857%, acc.: 54.69%] [Generator loss: 0.7960%]\n",
            "9628 [Discriminator loss: 0.6694%, acc.: 60.55%] [Generator loss: 0.7738%]\n",
            "9629 [Discriminator loss: 0.6890%, acc.: 53.52%] [Generator loss: 0.7605%]\n",
            "9630 [Discriminator loss: 0.6839%, acc.: 52.34%] [Generator loss: 0.7587%]\n",
            "9631 [Discriminator loss: 0.6708%, acc.: 57.81%] [Generator loss: 0.7811%]\n",
            "9632 [Discriminator loss: 0.6636%, acc.: 63.28%] [Generator loss: 0.7916%]\n",
            "9633 [Discriminator loss: 0.6585%, acc.: 58.98%] [Generator loss: 0.8023%]\n",
            "9634 [Discriminator loss: 0.6740%, acc.: 51.95%] [Generator loss: 0.7961%]\n",
            "9635 [Discriminator loss: 0.6765%, acc.: 57.81%] [Generator loss: 0.7875%]\n",
            "9636 [Discriminator loss: 0.6618%, acc.: 60.55%] [Generator loss: 0.8003%]\n",
            "9637 [Discriminator loss: 0.6767%, acc.: 54.30%] [Generator loss: 0.7705%]\n",
            "9638 [Discriminator loss: 0.6751%, acc.: 57.81%] [Generator loss: 0.7943%]\n",
            "9639 [Discriminator loss: 0.6872%, acc.: 51.56%] [Generator loss: 0.7768%]\n",
            "9640 [Discriminator loss: 0.6785%, acc.: 55.08%] [Generator loss: 0.7720%]\n",
            "9641 [Discriminator loss: 0.6751%, acc.: 55.86%] [Generator loss: 0.7723%]\n",
            "9642 [Discriminator loss: 0.6743%, acc.: 62.89%] [Generator loss: 0.7966%]\n",
            "9643 [Discriminator loss: 0.6754%, acc.: 56.64%] [Generator loss: 0.7870%]\n",
            "9644 [Discriminator loss: 0.6562%, acc.: 63.28%] [Generator loss: 0.7751%]\n",
            "9645 [Discriminator loss: 0.6656%, acc.: 60.16%] [Generator loss: 0.7830%]\n",
            "9646 [Discriminator loss: 0.6877%, acc.: 57.42%] [Generator loss: 0.7971%]\n",
            "9647 [Discriminator loss: 0.6760%, acc.: 60.94%] [Generator loss: 0.7954%]\n",
            "9648 [Discriminator loss: 0.6580%, acc.: 60.94%] [Generator loss: 0.7760%]\n",
            "9649 [Discriminator loss: 0.6774%, acc.: 55.86%] [Generator loss: 0.7528%]\n",
            "9650 [Discriminator loss: 0.6812%, acc.: 55.08%] [Generator loss: 0.7774%]\n",
            "9651 [Discriminator loss: 0.6976%, acc.: 49.22%] [Generator loss: 0.7789%]\n",
            "9652 [Discriminator loss: 0.6878%, acc.: 53.52%] [Generator loss: 0.7924%]\n",
            "9653 [Discriminator loss: 0.6798%, acc.: 53.91%] [Generator loss: 0.7803%]\n",
            "9654 [Discriminator loss: 0.6751%, acc.: 57.42%] [Generator loss: 0.7897%]\n",
            "9655 [Discriminator loss: 0.6721%, acc.: 59.38%] [Generator loss: 0.7838%]\n",
            "9656 [Discriminator loss: 0.6781%, acc.: 54.30%] [Generator loss: 0.7685%]\n",
            "9657 [Discriminator loss: 0.6814%, acc.: 54.69%] [Generator loss: 0.7718%]\n",
            "9658 [Discriminator loss: 0.6923%, acc.: 53.12%] [Generator loss: 0.7880%]\n",
            "9659 [Discriminator loss: 0.6623%, acc.: 58.20%] [Generator loss: 0.7799%]\n",
            "9660 [Discriminator loss: 0.6807%, acc.: 55.86%] [Generator loss: 0.7881%]\n",
            "9661 [Discriminator loss: 0.6731%, acc.: 56.25%] [Generator loss: 0.7735%]\n",
            "9662 [Discriminator loss: 0.6693%, acc.: 62.11%] [Generator loss: 0.7704%]\n",
            "9663 [Discriminator loss: 0.6713%, acc.: 58.59%] [Generator loss: 0.7927%]\n",
            "9664 [Discriminator loss: 0.6856%, acc.: 58.98%] [Generator loss: 0.7763%]\n",
            "9665 [Discriminator loss: 0.6685%, acc.: 62.89%] [Generator loss: 0.7670%]\n",
            "9666 [Discriminator loss: 0.6909%, acc.: 52.34%] [Generator loss: 0.7663%]\n",
            "9667 [Discriminator loss: 0.6615%, acc.: 60.55%] [Generator loss: 0.7810%]\n",
            "9668 [Discriminator loss: 0.6842%, acc.: 51.17%] [Generator loss: 0.7453%]\n",
            "9669 [Discriminator loss: 0.6862%, acc.: 57.42%] [Generator loss: 0.7538%]\n",
            "9670 [Discriminator loss: 0.6657%, acc.: 61.33%] [Generator loss: 0.7772%]\n",
            "9671 [Discriminator loss: 0.6738%, acc.: 60.94%] [Generator loss: 0.7522%]\n",
            "9672 [Discriminator loss: 0.6834%, acc.: 56.25%] [Generator loss: 0.7777%]\n",
            "9673 [Discriminator loss: 0.6775%, acc.: 55.86%] [Generator loss: 0.7738%]\n",
            "9674 [Discriminator loss: 0.6726%, acc.: 58.20%] [Generator loss: 0.7614%]\n",
            "9675 [Discriminator loss: 0.6798%, acc.: 54.30%] [Generator loss: 0.7701%]\n",
            "9676 [Discriminator loss: 0.6699%, acc.: 58.98%] [Generator loss: 0.7535%]\n",
            "9677 [Discriminator loss: 0.6738%, acc.: 53.12%] [Generator loss: 0.8024%]\n",
            "9678 [Discriminator loss: 0.6652%, acc.: 58.20%] [Generator loss: 0.7592%]\n",
            "9679 [Discriminator loss: 0.6641%, acc.: 60.94%] [Generator loss: 0.7908%]\n",
            "9680 [Discriminator loss: 0.6813%, acc.: 59.38%] [Generator loss: 0.7675%]\n",
            "9681 [Discriminator loss: 0.6700%, acc.: 60.55%] [Generator loss: 0.7719%]\n",
            "9682 [Discriminator loss: 0.6596%, acc.: 64.45%] [Generator loss: 0.7806%]\n",
            "9683 [Discriminator loss: 0.6838%, acc.: 53.52%] [Generator loss: 0.7703%]\n",
            "9684 [Discriminator loss: 0.6646%, acc.: 58.98%] [Generator loss: 0.7776%]\n",
            "9685 [Discriminator loss: 0.6844%, acc.: 57.81%] [Generator loss: 0.7826%]\n",
            "9686 [Discriminator loss: 0.6794%, acc.: 58.98%] [Generator loss: 0.7737%]\n",
            "9687 [Discriminator loss: 0.6803%, acc.: 58.59%] [Generator loss: 0.7887%]\n",
            "9688 [Discriminator loss: 0.6849%, acc.: 53.12%] [Generator loss: 0.7901%]\n",
            "9689 [Discriminator loss: 0.6938%, acc.: 55.47%] [Generator loss: 0.7500%]\n",
            "9690 [Discriminator loss: 0.6754%, acc.: 60.55%] [Generator loss: 0.7902%]\n",
            "9691 [Discriminator loss: 0.6757%, acc.: 60.16%] [Generator loss: 0.7790%]\n",
            "9692 [Discriminator loss: 0.6868%, acc.: 53.52%] [Generator loss: 0.7890%]\n",
            "9693 [Discriminator loss: 0.6579%, acc.: 63.28%] [Generator loss: 0.7721%]\n",
            "9694 [Discriminator loss: 0.6680%, acc.: 60.55%] [Generator loss: 0.7667%]\n",
            "9695 [Discriminator loss: 0.6783%, acc.: 57.42%] [Generator loss: 0.7515%]\n",
            "9696 [Discriminator loss: 0.6818%, acc.: 58.98%] [Generator loss: 0.7739%]\n",
            "9697 [Discriminator loss: 0.6618%, acc.: 60.16%] [Generator loss: 0.7970%]\n",
            "9698 [Discriminator loss: 0.6484%, acc.: 66.41%] [Generator loss: 0.7639%]\n",
            "9699 [Discriminator loss: 0.6917%, acc.: 52.34%] [Generator loss: 0.7596%]\n",
            "9700 [Discriminator loss: 0.6742%, acc.: 56.64%] [Generator loss: 0.7910%]\n",
            "9701 [Discriminator loss: 0.6622%, acc.: 59.77%] [Generator loss: 0.7775%]\n",
            "9702 [Discriminator loss: 0.6686%, acc.: 59.77%] [Generator loss: 0.7778%]\n",
            "9703 [Discriminator loss: 0.6854%, acc.: 54.30%] [Generator loss: 0.7887%]\n",
            "9704 [Discriminator loss: 0.6691%, acc.: 58.20%] [Generator loss: 0.7943%]\n",
            "9705 [Discriminator loss: 0.6802%, acc.: 57.81%] [Generator loss: 0.7745%]\n",
            "9706 [Discriminator loss: 0.6799%, acc.: 59.77%] [Generator loss: 0.7855%]\n",
            "9707 [Discriminator loss: 0.6720%, acc.: 59.38%] [Generator loss: 0.7932%]\n",
            "9708 [Discriminator loss: 0.6684%, acc.: 58.59%] [Generator loss: 0.8131%]\n",
            "9709 [Discriminator loss: 0.6955%, acc.: 53.91%] [Generator loss: 0.7852%]\n",
            "9710 [Discriminator loss: 0.6977%, acc.: 53.12%] [Generator loss: 0.8064%]\n",
            "9711 [Discriminator loss: 0.6546%, acc.: 62.11%] [Generator loss: 0.7931%]\n",
            "9712 [Discriminator loss: 0.6957%, acc.: 51.56%] [Generator loss: 0.8006%]\n",
            "9713 [Discriminator loss: 0.6853%, acc.: 57.03%] [Generator loss: 0.7910%]\n",
            "9714 [Discriminator loss: 0.6730%, acc.: 55.47%] [Generator loss: 0.7794%]\n",
            "9715 [Discriminator loss: 0.6765%, acc.: 57.81%] [Generator loss: 0.7899%]\n",
            "9716 [Discriminator loss: 0.6502%, acc.: 63.28%] [Generator loss: 0.7752%]\n",
            "9717 [Discriminator loss: 0.6890%, acc.: 53.52%] [Generator loss: 0.7660%]\n",
            "9718 [Discriminator loss: 0.6702%, acc.: 60.55%] [Generator loss: 0.7668%]\n",
            "9719 [Discriminator loss: 0.6738%, acc.: 52.73%] [Generator loss: 0.7752%]\n",
            "9720 [Discriminator loss: 0.6696%, acc.: 57.42%] [Generator loss: 0.7499%]\n",
            "9721 [Discriminator loss: 0.6755%, acc.: 53.52%] [Generator loss: 0.7810%]\n",
            "9722 [Discriminator loss: 0.6746%, acc.: 57.81%] [Generator loss: 0.7790%]\n",
            "9723 [Discriminator loss: 0.6757%, acc.: 59.38%] [Generator loss: 0.7725%]\n",
            "9724 [Discriminator loss: 0.6927%, acc.: 51.17%] [Generator loss: 0.7837%]\n",
            "9725 [Discriminator loss: 0.6701%, acc.: 58.98%] [Generator loss: 0.7762%]\n",
            "9726 [Discriminator loss: 0.6712%, acc.: 57.81%] [Generator loss: 0.7704%]\n",
            "9727 [Discriminator loss: 0.6792%, acc.: 52.34%] [Generator loss: 0.7662%]\n",
            "9728 [Discriminator loss: 0.6757%, acc.: 60.55%] [Generator loss: 0.7674%]\n",
            "9729 [Discriminator loss: 0.6796%, acc.: 57.42%] [Generator loss: 0.7887%]\n",
            "9730 [Discriminator loss: 0.6849%, acc.: 57.42%] [Generator loss: 0.7908%]\n",
            "9731 [Discriminator loss: 0.6788%, acc.: 60.16%] [Generator loss: 0.7673%]\n",
            "9732 [Discriminator loss: 0.6648%, acc.: 60.55%] [Generator loss: 0.7657%]\n",
            "9733 [Discriminator loss: 0.6802%, acc.: 56.64%] [Generator loss: 0.8006%]\n",
            "9734 [Discriminator loss: 0.6740%, acc.: 53.91%] [Generator loss: 0.7802%]\n",
            "9735 [Discriminator loss: 0.6646%, acc.: 61.72%] [Generator loss: 0.7874%]\n",
            "9736 [Discriminator loss: 0.6725%, acc.: 59.38%] [Generator loss: 0.7790%]\n",
            "9737 [Discriminator loss: 0.6620%, acc.: 60.94%] [Generator loss: 0.7708%]\n",
            "9738 [Discriminator loss: 0.6974%, acc.: 54.69%] [Generator loss: 0.7667%]\n",
            "9739 [Discriminator loss: 0.6794%, acc.: 58.59%] [Generator loss: 0.7705%]\n",
            "9740 [Discriminator loss: 0.6752%, acc.: 59.77%] [Generator loss: 0.7655%]\n",
            "9741 [Discriminator loss: 0.6719%, acc.: 59.38%] [Generator loss: 0.7915%]\n",
            "9742 [Discriminator loss: 0.6804%, acc.: 54.69%] [Generator loss: 0.7714%]\n",
            "9743 [Discriminator loss: 0.6849%, acc.: 52.73%] [Generator loss: 0.7653%]\n",
            "9744 [Discriminator loss: 0.6756%, acc.: 58.20%] [Generator loss: 0.7667%]\n",
            "9745 [Discriminator loss: 0.6771%, acc.: 59.77%] [Generator loss: 0.7524%]\n",
            "9746 [Discriminator loss: 0.6811%, acc.: 54.30%] [Generator loss: 0.7816%]\n",
            "9747 [Discriminator loss: 0.6547%, acc.: 64.06%] [Generator loss: 0.7783%]\n",
            "9748 [Discriminator loss: 0.6718%, acc.: 60.94%] [Generator loss: 0.7667%]\n",
            "9749 [Discriminator loss: 0.6796%, acc.: 55.08%] [Generator loss: 0.7776%]\n",
            "9750 [Discriminator loss: 0.6842%, acc.: 53.52%] [Generator loss: 0.7685%]\n",
            "9751 [Discriminator loss: 0.6723%, acc.: 60.16%] [Generator loss: 0.7774%]\n",
            "9752 [Discriminator loss: 0.6650%, acc.: 59.77%] [Generator loss: 0.8019%]\n",
            "9753 [Discriminator loss: 0.6854%, acc.: 54.69%] [Generator loss: 0.7621%]\n",
            "9754 [Discriminator loss: 0.6567%, acc.: 64.45%] [Generator loss: 0.7791%]\n",
            "9755 [Discriminator loss: 0.6799%, acc.: 55.47%] [Generator loss: 0.7795%]\n",
            "9756 [Discriminator loss: 0.6748%, acc.: 58.20%] [Generator loss: 0.7761%]\n",
            "9757 [Discriminator loss: 0.6767%, acc.: 56.25%] [Generator loss: 0.7685%]\n",
            "9758 [Discriminator loss: 0.6882%, acc.: 54.69%] [Generator loss: 0.7716%]\n",
            "9759 [Discriminator loss: 0.6717%, acc.: 58.98%] [Generator loss: 0.7558%]\n",
            "9760 [Discriminator loss: 0.6750%, acc.: 59.38%] [Generator loss: 0.7783%]\n",
            "9761 [Discriminator loss: 0.6822%, acc.: 58.98%] [Generator loss: 0.7718%]\n",
            "9762 [Discriminator loss: 0.6599%, acc.: 60.94%] [Generator loss: 0.7769%]\n",
            "9763 [Discriminator loss: 0.6755%, acc.: 58.59%] [Generator loss: 0.7770%]\n",
            "9764 [Discriminator loss: 0.6886%, acc.: 55.08%] [Generator loss: 0.7725%]\n",
            "9765 [Discriminator loss: 0.6817%, acc.: 53.12%] [Generator loss: 0.7765%]\n",
            "9766 [Discriminator loss: 0.6627%, acc.: 63.67%] [Generator loss: 0.7449%]\n",
            "9767 [Discriminator loss: 0.6629%, acc.: 60.94%] [Generator loss: 0.7687%]\n",
            "9768 [Discriminator loss: 0.6888%, acc.: 60.55%] [Generator loss: 0.7858%]\n",
            "9769 [Discriminator loss: 0.6953%, acc.: 55.47%] [Generator loss: 0.7728%]\n",
            "9770 [Discriminator loss: 0.6745%, acc.: 58.98%] [Generator loss: 0.7636%]\n",
            "9771 [Discriminator loss: 0.6778%, acc.: 54.30%] [Generator loss: 0.7555%]\n",
            "9772 [Discriminator loss: 0.6592%, acc.: 60.94%] [Generator loss: 0.7618%]\n",
            "9773 [Discriminator loss: 0.6604%, acc.: 64.45%] [Generator loss: 0.7870%]\n",
            "9774 [Discriminator loss: 0.6902%, acc.: 51.95%] [Generator loss: 0.7869%]\n",
            "9775 [Discriminator loss: 0.6722%, acc.: 60.94%] [Generator loss: 0.7983%]\n",
            "9776 [Discriminator loss: 0.6775%, acc.: 56.64%] [Generator loss: 0.7942%]\n",
            "9777 [Discriminator loss: 0.6945%, acc.: 54.69%] [Generator loss: 0.7702%]\n",
            "9778 [Discriminator loss: 0.6806%, acc.: 59.38%] [Generator loss: 0.7660%]\n",
            "9779 [Discriminator loss: 0.6670%, acc.: 61.33%] [Generator loss: 0.7603%]\n",
            "9780 [Discriminator loss: 0.6652%, acc.: 60.16%] [Generator loss: 0.8017%]\n",
            "9781 [Discriminator loss: 0.6683%, acc.: 60.55%] [Generator loss: 0.7757%]\n",
            "9782 [Discriminator loss: 0.6710%, acc.: 60.94%] [Generator loss: 0.7686%]\n",
            "9783 [Discriminator loss: 0.6931%, acc.: 54.30%] [Generator loss: 0.7759%]\n",
            "9784 [Discriminator loss: 0.6750%, acc.: 61.33%] [Generator loss: 0.7824%]\n",
            "9785 [Discriminator loss: 0.6722%, acc.: 54.69%] [Generator loss: 0.7872%]\n",
            "9786 [Discriminator loss: 0.6796%, acc.: 57.03%] [Generator loss: 0.7881%]\n",
            "9787 [Discriminator loss: 0.6664%, acc.: 62.50%] [Generator loss: 0.7723%]\n",
            "9788 [Discriminator loss: 0.6544%, acc.: 61.33%] [Generator loss: 0.7738%]\n",
            "9789 [Discriminator loss: 0.6742%, acc.: 60.55%] [Generator loss: 0.7973%]\n",
            "9790 [Discriminator loss: 0.6755%, acc.: 58.59%] [Generator loss: 0.7708%]\n",
            "9791 [Discriminator loss: 0.6669%, acc.: 64.06%] [Generator loss: 0.8112%]\n",
            "9792 [Discriminator loss: 0.6962%, acc.: 55.86%] [Generator loss: 0.7906%]\n",
            "9793 [Discriminator loss: 0.6703%, acc.: 56.64%] [Generator loss: 0.7852%]\n",
            "9794 [Discriminator loss: 0.6906%, acc.: 51.95%] [Generator loss: 0.7844%]\n",
            "9795 [Discriminator loss: 0.6475%, acc.: 64.45%] [Generator loss: 0.7830%]\n",
            "9796 [Discriminator loss: 0.6854%, acc.: 54.69%] [Generator loss: 0.7795%]\n",
            "9797 [Discriminator loss: 0.6604%, acc.: 58.98%] [Generator loss: 0.7759%]\n",
            "9798 [Discriminator loss: 0.6660%, acc.: 57.42%] [Generator loss: 0.7807%]\n",
            "9799 [Discriminator loss: 0.6842%, acc.: 55.86%] [Generator loss: 0.7789%]\n",
            "9800 [Discriminator loss: 0.6680%, acc.: 60.16%] [Generator loss: 0.7841%]\n",
            "9801 [Discriminator loss: 0.6541%, acc.: 63.67%] [Generator loss: 0.8087%]\n",
            "9802 [Discriminator loss: 0.6675%, acc.: 56.64%] [Generator loss: 0.7509%]\n",
            "9803 [Discriminator loss: 0.6619%, acc.: 62.11%] [Generator loss: 0.7992%]\n",
            "9804 [Discriminator loss: 0.6744%, acc.: 56.25%] [Generator loss: 0.8033%]\n",
            "9805 [Discriminator loss: 0.6886%, acc.: 52.73%] [Generator loss: 0.7907%]\n",
            "9806 [Discriminator loss: 0.6849%, acc.: 53.91%] [Generator loss: 0.7701%]\n",
            "9807 [Discriminator loss: 0.6731%, acc.: 53.91%] [Generator loss: 0.8024%]\n",
            "9808 [Discriminator loss: 0.6851%, acc.: 53.12%] [Generator loss: 0.7734%]\n",
            "9809 [Discriminator loss: 0.6838%, acc.: 58.20%] [Generator loss: 0.7693%]\n",
            "9810 [Discriminator loss: 0.6690%, acc.: 60.94%] [Generator loss: 0.7634%]\n",
            "9811 [Discriminator loss: 0.6581%, acc.: 62.89%] [Generator loss: 0.7840%]\n",
            "9812 [Discriminator loss: 0.6943%, acc.: 54.30%] [Generator loss: 0.7889%]\n",
            "9813 [Discriminator loss: 0.6856%, acc.: 53.91%] [Generator loss: 0.7813%]\n",
            "9814 [Discriminator loss: 0.6741%, acc.: 57.03%] [Generator loss: 0.7937%]\n",
            "9815 [Discriminator loss: 0.6649%, acc.: 58.20%] [Generator loss: 0.7779%]\n",
            "9816 [Discriminator loss: 0.6785%, acc.: 58.98%] [Generator loss: 0.7993%]\n",
            "9817 [Discriminator loss: 0.6667%, acc.: 59.77%] [Generator loss: 0.7774%]\n",
            "9818 [Discriminator loss: 0.6746%, acc.: 54.30%] [Generator loss: 0.7841%]\n",
            "9819 [Discriminator loss: 0.6613%, acc.: 62.50%] [Generator loss: 0.7996%]\n",
            "9820 [Discriminator loss: 0.6755%, acc.: 60.16%] [Generator loss: 0.7752%]\n",
            "9821 [Discriminator loss: 0.7055%, acc.: 52.34%] [Generator loss: 0.7981%]\n",
            "9822 [Discriminator loss: 0.6887%, acc.: 53.91%] [Generator loss: 0.7734%]\n",
            "9823 [Discriminator loss: 0.6861%, acc.: 54.30%] [Generator loss: 0.7790%]\n",
            "9824 [Discriminator loss: 0.6890%, acc.: 50.00%] [Generator loss: 0.7732%]\n",
            "9825 [Discriminator loss: 0.6671%, acc.: 64.06%] [Generator loss: 0.7820%]\n",
            "9826 [Discriminator loss: 0.6971%, acc.: 52.73%] [Generator loss: 0.7902%]\n",
            "9827 [Discriminator loss: 0.6665%, acc.: 57.03%] [Generator loss: 0.7969%]\n",
            "9828 [Discriminator loss: 0.6744%, acc.: 57.42%] [Generator loss: 0.8091%]\n",
            "9829 [Discriminator loss: 0.6761%, acc.: 56.25%] [Generator loss: 0.7986%]\n",
            "9830 [Discriminator loss: 0.6751%, acc.: 58.59%] [Generator loss: 0.7869%]\n",
            "9831 [Discriminator loss: 0.6659%, acc.: 58.59%] [Generator loss: 0.7521%]\n",
            "9832 [Discriminator loss: 0.6638%, acc.: 61.33%] [Generator loss: 0.7662%]\n",
            "9833 [Discriminator loss: 0.6586%, acc.: 62.11%] [Generator loss: 0.7803%]\n",
            "9834 [Discriminator loss: 0.6604%, acc.: 62.50%] [Generator loss: 0.7679%]\n",
            "9835 [Discriminator loss: 0.6608%, acc.: 60.55%] [Generator loss: 0.7656%]\n",
            "9836 [Discriminator loss: 0.6808%, acc.: 53.52%] [Generator loss: 0.7732%]\n",
            "9837 [Discriminator loss: 0.6830%, acc.: 56.64%] [Generator loss: 0.7762%]\n",
            "9838 [Discriminator loss: 0.6666%, acc.: 61.33%] [Generator loss: 0.7847%]\n",
            "9839 [Discriminator loss: 0.6765%, acc.: 58.59%] [Generator loss: 0.7763%]\n",
            "9840 [Discriminator loss: 0.6711%, acc.: 63.28%] [Generator loss: 0.8125%]\n",
            "9841 [Discriminator loss: 0.6930%, acc.: 48.83%] [Generator loss: 0.7586%]\n",
            "9842 [Discriminator loss: 0.6615%, acc.: 62.89%] [Generator loss: 0.7737%]\n",
            "9843 [Discriminator loss: 0.6731%, acc.: 57.03%] [Generator loss: 0.7919%]\n",
            "9844 [Discriminator loss: 0.6732%, acc.: 57.42%] [Generator loss: 0.7922%]\n",
            "9845 [Discriminator loss: 0.6873%, acc.: 55.08%] [Generator loss: 0.7957%]\n",
            "9846 [Discriminator loss: 0.6694%, acc.: 56.64%] [Generator loss: 0.7799%]\n",
            "9847 [Discriminator loss: 0.6763%, acc.: 51.95%] [Generator loss: 0.7708%]\n",
            "9848 [Discriminator loss: 0.6845%, acc.: 57.03%] [Generator loss: 0.7948%]\n",
            "9849 [Discriminator loss: 0.6912%, acc.: 53.52%] [Generator loss: 0.8028%]\n",
            "9850 [Discriminator loss: 0.6832%, acc.: 55.86%] [Generator loss: 0.8105%]\n",
            "9851 [Discriminator loss: 0.6600%, acc.: 63.67%] [Generator loss: 0.8026%]\n",
            "9852 [Discriminator loss: 0.6801%, acc.: 54.69%] [Generator loss: 0.7898%]\n",
            "9853 [Discriminator loss: 0.6721%, acc.: 58.20%] [Generator loss: 0.7888%]\n",
            "9854 [Discriminator loss: 0.6793%, acc.: 58.98%] [Generator loss: 0.7787%]\n",
            "9855 [Discriminator loss: 0.6726%, acc.: 60.94%] [Generator loss: 0.7917%]\n",
            "9856 [Discriminator loss: 0.6758%, acc.: 60.55%] [Generator loss: 0.7794%]\n",
            "9857 [Discriminator loss: 0.6562%, acc.: 62.11%] [Generator loss: 0.8034%]\n",
            "9858 [Discriminator loss: 0.6761%, acc.: 58.20%] [Generator loss: 0.7996%]\n",
            "9859 [Discriminator loss: 0.6658%, acc.: 63.28%] [Generator loss: 0.7739%]\n",
            "9860 [Discriminator loss: 0.6824%, acc.: 53.12%] [Generator loss: 0.7680%]\n",
            "9861 [Discriminator loss: 0.6736%, acc.: 57.42%] [Generator loss: 0.7795%]\n",
            "9862 [Discriminator loss: 0.6584%, acc.: 60.94%] [Generator loss: 0.7818%]\n",
            "9863 [Discriminator loss: 0.6632%, acc.: 56.25%] [Generator loss: 0.7952%]\n",
            "9864 [Discriminator loss: 0.6694%, acc.: 58.98%] [Generator loss: 0.7838%]\n",
            "9865 [Discriminator loss: 0.6524%, acc.: 62.11%] [Generator loss: 0.7891%]\n",
            "9866 [Discriminator loss: 0.6692%, acc.: 59.38%] [Generator loss: 0.7832%]\n",
            "9867 [Discriminator loss: 0.6726%, acc.: 55.47%] [Generator loss: 0.7850%]\n",
            "9868 [Discriminator loss: 0.6678%, acc.: 57.81%] [Generator loss: 0.7829%]\n",
            "9869 [Discriminator loss: 0.6767%, acc.: 57.81%] [Generator loss: 0.7972%]\n",
            "9870 [Discriminator loss: 0.6756%, acc.: 61.33%] [Generator loss: 0.7931%]\n",
            "9871 [Discriminator loss: 0.6620%, acc.: 62.89%] [Generator loss: 0.7714%]\n",
            "9872 [Discriminator loss: 0.6721%, acc.: 59.38%] [Generator loss: 0.7970%]\n",
            "9873 [Discriminator loss: 0.6669%, acc.: 57.81%] [Generator loss: 0.7836%]\n",
            "9874 [Discriminator loss: 0.6684%, acc.: 58.98%] [Generator loss: 0.8007%]\n",
            "9875 [Discriminator loss: 0.6759%, acc.: 55.08%] [Generator loss: 0.7763%]\n",
            "9876 [Discriminator loss: 0.6714%, acc.: 58.20%] [Generator loss: 0.7960%]\n",
            "9877 [Discriminator loss: 0.6702%, acc.: 60.55%] [Generator loss: 0.7706%]\n",
            "9878 [Discriminator loss: 0.6690%, acc.: 58.98%] [Generator loss: 0.8057%]\n",
            "9879 [Discriminator loss: 0.6828%, acc.: 57.42%] [Generator loss: 0.7874%]\n",
            "9880 [Discriminator loss: 0.6663%, acc.: 58.98%] [Generator loss: 0.7838%]\n",
            "9881 [Discriminator loss: 0.6796%, acc.: 55.86%] [Generator loss: 0.7626%]\n",
            "9882 [Discriminator loss: 0.6727%, acc.: 57.03%] [Generator loss: 0.7977%]\n",
            "9883 [Discriminator loss: 0.6637%, acc.: 61.72%] [Generator loss: 0.7658%]\n",
            "9884 [Discriminator loss: 0.6775%, acc.: 59.77%] [Generator loss: 0.8037%]\n",
            "9885 [Discriminator loss: 0.6697%, acc.: 58.20%] [Generator loss: 0.7770%]\n",
            "9886 [Discriminator loss: 0.6771%, acc.: 59.77%] [Generator loss: 0.7940%]\n",
            "9887 [Discriminator loss: 0.6696%, acc.: 60.16%] [Generator loss: 0.7846%]\n",
            "9888 [Discriminator loss: 0.6791%, acc.: 55.08%] [Generator loss: 0.7734%]\n",
            "9889 [Discriminator loss: 0.6684%, acc.: 58.59%] [Generator loss: 0.7936%]\n",
            "9890 [Discriminator loss: 0.6793%, acc.: 59.38%] [Generator loss: 0.7759%]\n",
            "9891 [Discriminator loss: 0.6487%, acc.: 61.72%] [Generator loss: 0.8033%]\n",
            "9892 [Discriminator loss: 0.6746%, acc.: 55.47%] [Generator loss: 0.7683%]\n",
            "9893 [Discriminator loss: 0.6597%, acc.: 60.16%] [Generator loss: 0.8010%]\n",
            "9894 [Discriminator loss: 0.6773%, acc.: 55.86%] [Generator loss: 0.8207%]\n",
            "9895 [Discriminator loss: 0.6896%, acc.: 53.52%] [Generator loss: 0.7837%]\n",
            "9896 [Discriminator loss: 0.6801%, acc.: 57.03%] [Generator loss: 0.8249%]\n",
            "9897 [Discriminator loss: 0.6951%, acc.: 54.30%] [Generator loss: 0.7787%]\n",
            "9898 [Discriminator loss: 0.6748%, acc.: 57.81%] [Generator loss: 0.7761%]\n",
            "9899 [Discriminator loss: 0.6822%, acc.: 53.52%] [Generator loss: 0.7600%]\n",
            "9900 [Discriminator loss: 0.6754%, acc.: 55.08%] [Generator loss: 0.7802%]\n",
            "9901 [Discriminator loss: 0.6602%, acc.: 61.33%] [Generator loss: 0.7928%]\n",
            "9902 [Discriminator loss: 0.6819%, acc.: 55.08%] [Generator loss: 0.8056%]\n",
            "9903 [Discriminator loss: 0.6802%, acc.: 57.81%] [Generator loss: 0.7831%]\n",
            "9904 [Discriminator loss: 0.6761%, acc.: 56.25%] [Generator loss: 0.7632%]\n",
            "9905 [Discriminator loss: 0.6808%, acc.: 58.20%] [Generator loss: 0.7800%]\n",
            "9906 [Discriminator loss: 0.6721%, acc.: 57.03%] [Generator loss: 0.7784%]\n",
            "9907 [Discriminator loss: 0.6887%, acc.: 58.98%] [Generator loss: 0.7909%]\n",
            "9908 [Discriminator loss: 0.6874%, acc.: 53.52%] [Generator loss: 0.7976%]\n",
            "9909 [Discriminator loss: 0.6633%, acc.: 62.50%] [Generator loss: 0.7640%]\n",
            "9910 [Discriminator loss: 0.6720%, acc.: 58.98%] [Generator loss: 0.7901%]\n",
            "9911 [Discriminator loss: 0.6936%, acc.: 51.95%] [Generator loss: 0.7856%]\n",
            "9912 [Discriminator loss: 0.6868%, acc.: 53.52%] [Generator loss: 0.7935%]\n",
            "9913 [Discriminator loss: 0.6627%, acc.: 61.72%] [Generator loss: 0.7827%]\n",
            "9914 [Discriminator loss: 0.6578%, acc.: 60.16%] [Generator loss: 0.7895%]\n",
            "9915 [Discriminator loss: 0.6781%, acc.: 57.81%] [Generator loss: 0.7905%]\n",
            "9916 [Discriminator loss: 0.6579%, acc.: 62.11%] [Generator loss: 0.7965%]\n",
            "9917 [Discriminator loss: 0.6671%, acc.: 60.55%] [Generator loss: 0.7903%]\n",
            "9918 [Discriminator loss: 0.6864%, acc.: 55.86%] [Generator loss: 0.7900%]\n",
            "9919 [Discriminator loss: 0.6693%, acc.: 57.42%] [Generator loss: 0.7744%]\n",
            "9920 [Discriminator loss: 0.6860%, acc.: 55.47%] [Generator loss: 0.7958%]\n",
            "9921 [Discriminator loss: 0.6693%, acc.: 59.38%] [Generator loss: 0.7508%]\n",
            "9922 [Discriminator loss: 0.6568%, acc.: 60.94%] [Generator loss: 0.7683%]\n",
            "9923 [Discriminator loss: 0.6997%, acc.: 51.17%] [Generator loss: 0.7796%]\n",
            "9924 [Discriminator loss: 0.6662%, acc.: 58.20%] [Generator loss: 0.7693%]\n",
            "9925 [Discriminator loss: 0.6713%, acc.: 55.86%] [Generator loss: 0.7699%]\n",
            "9926 [Discriminator loss: 0.6806%, acc.: 57.81%] [Generator loss: 0.7646%]\n",
            "9927 [Discriminator loss: 0.6989%, acc.: 53.91%] [Generator loss: 0.7677%]\n",
            "9928 [Discriminator loss: 0.6652%, acc.: 59.38%] [Generator loss: 0.7822%]\n",
            "9929 [Discriminator loss: 0.6805%, acc.: 57.81%] [Generator loss: 0.7814%]\n",
            "9930 [Discriminator loss: 0.6804%, acc.: 55.47%] [Generator loss: 0.7992%]\n",
            "9931 [Discriminator loss: 0.6821%, acc.: 57.42%] [Generator loss: 0.7807%]\n",
            "9932 [Discriminator loss: 0.6805%, acc.: 55.08%] [Generator loss: 0.7864%]\n",
            "9933 [Discriminator loss: 0.6702%, acc.: 58.98%] [Generator loss: 0.7828%]\n",
            "9934 [Discriminator loss: 0.6633%, acc.: 59.38%] [Generator loss: 0.7792%]\n",
            "9935 [Discriminator loss: 0.6852%, acc.: 53.91%] [Generator loss: 0.7720%]\n",
            "9936 [Discriminator loss: 0.6897%, acc.: 52.34%] [Generator loss: 0.7649%]\n",
            "9937 [Discriminator loss: 0.6787%, acc.: 58.59%] [Generator loss: 0.7664%]\n",
            "9938 [Discriminator loss: 0.6761%, acc.: 54.30%] [Generator loss: 0.7861%]\n",
            "9939 [Discriminator loss: 0.6758%, acc.: 58.20%] [Generator loss: 0.7937%]\n",
            "9940 [Discriminator loss: 0.6747%, acc.: 58.98%] [Generator loss: 0.7537%]\n",
            "9941 [Discriminator loss: 0.6741%, acc.: 57.03%] [Generator loss: 0.7648%]\n",
            "9942 [Discriminator loss: 0.6600%, acc.: 57.42%] [Generator loss: 0.7640%]\n",
            "9943 [Discriminator loss: 0.6738%, acc.: 56.25%] [Generator loss: 0.7853%]\n",
            "9944 [Discriminator loss: 0.6713%, acc.: 60.55%] [Generator loss: 0.7892%]\n",
            "9945 [Discriminator loss: 0.6760%, acc.: 58.59%] [Generator loss: 0.7884%]\n",
            "9946 [Discriminator loss: 0.6805%, acc.: 60.55%] [Generator loss: 0.8012%]\n",
            "9947 [Discriminator loss: 0.6875%, acc.: 54.69%] [Generator loss: 0.8014%]\n",
            "9948 [Discriminator loss: 0.6775%, acc.: 56.25%] [Generator loss: 0.7871%]\n",
            "9949 [Discriminator loss: 0.6747%, acc.: 56.25%] [Generator loss: 0.7849%]\n",
            "9950 [Discriminator loss: 0.6609%, acc.: 64.06%] [Generator loss: 0.7920%]\n",
            "9951 [Discriminator loss: 0.6881%, acc.: 55.08%] [Generator loss: 0.8037%]\n",
            "9952 [Discriminator loss: 0.6624%, acc.: 60.94%] [Generator loss: 0.7812%]\n",
            "9953 [Discriminator loss: 0.6775%, acc.: 55.86%] [Generator loss: 0.7700%]\n",
            "9954 [Discriminator loss: 0.6622%, acc.: 63.28%] [Generator loss: 0.7703%]\n",
            "9955 [Discriminator loss: 0.6571%, acc.: 63.28%] [Generator loss: 0.7751%]\n",
            "9956 [Discriminator loss: 0.6924%, acc.: 51.95%] [Generator loss: 0.7684%]\n",
            "9957 [Discriminator loss: 0.6802%, acc.: 54.30%] [Generator loss: 0.7695%]\n",
            "9958 [Discriminator loss: 0.6931%, acc.: 51.56%] [Generator loss: 0.7714%]\n",
            "9959 [Discriminator loss: 0.6657%, acc.: 57.42%] [Generator loss: 0.7667%]\n",
            "9960 [Discriminator loss: 0.6871%, acc.: 55.86%] [Generator loss: 0.7988%]\n",
            "9961 [Discriminator loss: 0.6937%, acc.: 51.56%] [Generator loss: 0.7880%]\n",
            "9962 [Discriminator loss: 0.6720%, acc.: 58.98%] [Generator loss: 0.7891%]\n",
            "9963 [Discriminator loss: 0.6892%, acc.: 53.91%] [Generator loss: 0.7835%]\n",
            "9964 [Discriminator loss: 0.6586%, acc.: 58.98%] [Generator loss: 0.7966%]\n",
            "9965 [Discriminator loss: 0.6741%, acc.: 56.25%] [Generator loss: 0.7562%]\n",
            "9966 [Discriminator loss: 0.6817%, acc.: 55.08%] [Generator loss: 0.7657%]\n",
            "9967 [Discriminator loss: 0.6771%, acc.: 57.03%] [Generator loss: 0.7612%]\n",
            "9968 [Discriminator loss: 0.6688%, acc.: 58.98%] [Generator loss: 0.7725%]\n",
            "9969 [Discriminator loss: 0.6716%, acc.: 55.47%] [Generator loss: 0.7781%]\n",
            "9970 [Discriminator loss: 0.6754%, acc.: 59.38%] [Generator loss: 0.7795%]\n",
            "9971 [Discriminator loss: 0.6674%, acc.: 60.94%] [Generator loss: 0.7905%]\n",
            "9972 [Discriminator loss: 0.6952%, acc.: 54.30%] [Generator loss: 0.7754%]\n",
            "9973 [Discriminator loss: 0.6788%, acc.: 57.81%] [Generator loss: 0.7577%]\n",
            "9974 [Discriminator loss: 0.6980%, acc.: 51.17%] [Generator loss: 0.7834%]\n",
            "9975 [Discriminator loss: 0.6914%, acc.: 52.34%] [Generator loss: 0.7530%]\n",
            "9976 [Discriminator loss: 0.6758%, acc.: 58.20%] [Generator loss: 0.7760%]\n",
            "9977 [Discriminator loss: 0.6840%, acc.: 56.64%] [Generator loss: 0.7587%]\n",
            "9978 [Discriminator loss: 0.6592%, acc.: 60.94%] [Generator loss: 0.7701%]\n",
            "9979 [Discriminator loss: 0.6791%, acc.: 55.08%] [Generator loss: 0.7693%]\n",
            "9980 [Discriminator loss: 0.6815%, acc.: 53.91%] [Generator loss: 0.7799%]\n",
            "9981 [Discriminator loss: 0.6761%, acc.: 55.86%] [Generator loss: 0.7878%]\n",
            "9982 [Discriminator loss: 0.6667%, acc.: 58.20%] [Generator loss: 0.7799%]\n",
            "9983 [Discriminator loss: 0.6929%, acc.: 51.95%] [Generator loss: 0.7825%]\n",
            "9984 [Discriminator loss: 0.6723%, acc.: 60.16%] [Generator loss: 0.7986%]\n",
            "9985 [Discriminator loss: 0.6714%, acc.: 54.69%] [Generator loss: 0.7665%]\n",
            "9986 [Discriminator loss: 0.6828%, acc.: 56.64%] [Generator loss: 0.7892%]\n",
            "9987 [Discriminator loss: 0.6617%, acc.: 64.84%] [Generator loss: 0.7889%]\n",
            "9988 [Discriminator loss: 0.6760%, acc.: 55.47%] [Generator loss: 0.7700%]\n",
            "9989 [Discriminator loss: 0.6815%, acc.: 59.38%] [Generator loss: 0.7958%]\n",
            "9990 [Discriminator loss: 0.6758%, acc.: 56.25%] [Generator loss: 0.7701%]\n",
            "9991 [Discriminator loss: 0.6803%, acc.: 53.12%] [Generator loss: 0.8085%]\n",
            "9992 [Discriminator loss: 0.6663%, acc.: 58.20%] [Generator loss: 0.7946%]\n",
            "9993 [Discriminator loss: 0.6889%, acc.: 53.91%] [Generator loss: 0.7923%]\n",
            "9994 [Discriminator loss: 0.6752%, acc.: 57.03%] [Generator loss: 0.8124%]\n",
            "9995 [Discriminator loss: 0.6628%, acc.: 57.81%] [Generator loss: 0.7925%]\n",
            "9996 [Discriminator loss: 0.6669%, acc.: 56.64%] [Generator loss: 0.7866%]\n",
            "9997 [Discriminator loss: 0.6759%, acc.: 58.20%] [Generator loss: 0.7938%]\n",
            "9998 [Discriminator loss: 0.6831%, acc.: 58.98%] [Generator loss: 0.7778%]\n",
            "9999 [Discriminator loss: 0.6734%, acc.: 58.59%] [Generator loss: 0.7809%]\n",
            "10000 [Discriminator loss: 0.6588%, acc.: 62.89%] [Generator loss: 0.7819%]\n",
            "10001 [Discriminator loss: 0.6713%, acc.: 57.42%] [Generator loss: 0.7627%]\n",
            "10002 [Discriminator loss: 0.6581%, acc.: 58.98%] [Generator loss: 0.7775%]\n",
            "10003 [Discriminator loss: 0.6849%, acc.: 55.08%] [Generator loss: 0.7678%]\n",
            "10004 [Discriminator loss: 0.6702%, acc.: 56.25%] [Generator loss: 0.7737%]\n",
            "10005 [Discriminator loss: 0.6815%, acc.: 53.52%] [Generator loss: 0.7554%]\n",
            "10006 [Discriminator loss: 0.6564%, acc.: 64.06%] [Generator loss: 0.7713%]\n",
            "10007 [Discriminator loss: 0.6591%, acc.: 62.11%] [Generator loss: 0.7741%]\n",
            "10008 [Discriminator loss: 0.6766%, acc.: 57.42%] [Generator loss: 0.7813%]\n",
            "10009 [Discriminator loss: 0.6752%, acc.: 56.64%] [Generator loss: 0.7817%]\n",
            "10010 [Discriminator loss: 0.6771%, acc.: 55.86%] [Generator loss: 0.7875%]\n",
            "10011 [Discriminator loss: 0.6827%, acc.: 58.59%] [Generator loss: 0.7792%]\n",
            "10012 [Discriminator loss: 0.6762%, acc.: 53.52%] [Generator loss: 0.7921%]\n",
            "10013 [Discriminator loss: 0.6793%, acc.: 57.81%] [Generator loss: 0.7994%]\n",
            "10014 [Discriminator loss: 0.6740%, acc.: 61.33%] [Generator loss: 0.8076%]\n",
            "10015 [Discriminator loss: 0.6730%, acc.: 57.81%] [Generator loss: 0.7768%]\n",
            "10016 [Discriminator loss: 0.6752%, acc.: 60.16%] [Generator loss: 0.7800%]\n",
            "10017 [Discriminator loss: 0.6735%, acc.: 58.59%] [Generator loss: 0.7789%]\n",
            "10018 [Discriminator loss: 0.6860%, acc.: 56.25%] [Generator loss: 0.7697%]\n",
            "10019 [Discriminator loss: 0.6756%, acc.: 53.52%] [Generator loss: 0.7702%]\n",
            "10020 [Discriminator loss: 0.6645%, acc.: 59.38%] [Generator loss: 0.7757%]\n",
            "10021 [Discriminator loss: 0.6919%, acc.: 53.91%] [Generator loss: 0.7775%]\n",
            "10022 [Discriminator loss: 0.6709%, acc.: 59.77%] [Generator loss: 0.7706%]\n",
            "10023 [Discriminator loss: 0.6641%, acc.: 56.25%] [Generator loss: 0.7921%]\n",
            "10024 [Discriminator loss: 0.6522%, acc.: 64.06%] [Generator loss: 0.8179%]\n",
            "10025 [Discriminator loss: 0.6778%, acc.: 58.20%] [Generator loss: 0.8158%]\n",
            "10026 [Discriminator loss: 0.6780%, acc.: 56.64%] [Generator loss: 0.7869%]\n",
            "10027 [Discriminator loss: 0.6650%, acc.: 62.89%] [Generator loss: 0.7766%]\n",
            "10028 [Discriminator loss: 0.6721%, acc.: 60.16%] [Generator loss: 0.8002%]\n",
            "10029 [Discriminator loss: 0.6843%, acc.: 51.17%] [Generator loss: 0.8045%]\n",
            "10030 [Discriminator loss: 0.6819%, acc.: 56.64%] [Generator loss: 0.8137%]\n",
            "10031 [Discriminator loss: 0.6637%, acc.: 64.06%] [Generator loss: 0.8107%]\n",
            "10032 [Discriminator loss: 0.7002%, acc.: 50.78%] [Generator loss: 0.7848%]\n",
            "10033 [Discriminator loss: 0.6796%, acc.: 58.59%] [Generator loss: 0.7902%]\n",
            "10034 [Discriminator loss: 0.6812%, acc.: 58.59%] [Generator loss: 0.7715%]\n",
            "10035 [Discriminator loss: 0.6640%, acc.: 64.06%] [Generator loss: 0.7753%]\n",
            "10036 [Discriminator loss: 0.6780%, acc.: 59.38%] [Generator loss: 0.7968%]\n",
            "10037 [Discriminator loss: 0.6722%, acc.: 58.98%] [Generator loss: 0.7816%]\n",
            "10038 [Discriminator loss: 0.6827%, acc.: 56.64%] [Generator loss: 0.7765%]\n",
            "10039 [Discriminator loss: 0.6689%, acc.: 60.16%] [Generator loss: 0.7703%]\n",
            "10040 [Discriminator loss: 0.6737%, acc.: 54.30%] [Generator loss: 0.7764%]\n",
            "10041 [Discriminator loss: 0.6719%, acc.: 59.77%] [Generator loss: 0.7830%]\n",
            "10042 [Discriminator loss: 0.6614%, acc.: 61.72%] [Generator loss: 0.7789%]\n",
            "10043 [Discriminator loss: 0.6771%, acc.: 61.33%] [Generator loss: 0.7794%]\n",
            "10044 [Discriminator loss: 0.6727%, acc.: 57.81%] [Generator loss: 0.7685%]\n",
            "10045 [Discriminator loss: 0.6534%, acc.: 62.11%] [Generator loss: 0.7924%]\n",
            "10046 [Discriminator loss: 0.6713%, acc.: 56.64%] [Generator loss: 0.8138%]\n",
            "10047 [Discriminator loss: 0.6674%, acc.: 58.59%] [Generator loss: 0.8038%]\n",
            "10048 [Discriminator loss: 0.6806%, acc.: 57.42%] [Generator loss: 0.7701%]\n",
            "10049 [Discriminator loss: 0.6632%, acc.: 61.72%] [Generator loss: 0.7901%]\n",
            "10050 [Discriminator loss: 0.6642%, acc.: 58.98%] [Generator loss: 0.7897%]\n",
            "10051 [Discriminator loss: 0.6830%, acc.: 57.81%] [Generator loss: 0.7999%]\n",
            "10052 [Discriminator loss: 0.6624%, acc.: 63.67%] [Generator loss: 0.7902%]\n",
            "10053 [Discriminator loss: 0.6592%, acc.: 59.38%] [Generator loss: 0.7896%]\n",
            "10054 [Discriminator loss: 0.6704%, acc.: 56.25%] [Generator loss: 0.7976%]\n",
            "10055 [Discriminator loss: 0.6727%, acc.: 57.42%] [Generator loss: 0.7825%]\n",
            "10056 [Discriminator loss: 0.6825%, acc.: 57.03%] [Generator loss: 0.7896%]\n",
            "10057 [Discriminator loss: 0.6973%, acc.: 50.00%] [Generator loss: 0.7702%]\n",
            "10058 [Discriminator loss: 0.6622%, acc.: 57.03%] [Generator loss: 0.8043%]\n",
            "10059 [Discriminator loss: 0.7090%, acc.: 49.61%] [Generator loss: 0.8130%]\n",
            "10060 [Discriminator loss: 0.6674%, acc.: 62.11%] [Generator loss: 0.8124%]\n",
            "10061 [Discriminator loss: 0.6666%, acc.: 58.20%] [Generator loss: 0.8095%]\n",
            "10062 [Discriminator loss: 0.6688%, acc.: 58.98%] [Generator loss: 0.7947%]\n",
            "10063 [Discriminator loss: 0.6746%, acc.: 61.72%] [Generator loss: 0.7679%]\n",
            "10064 [Discriminator loss: 0.6734%, acc.: 57.81%] [Generator loss: 0.7755%]\n",
            "10065 [Discriminator loss: 0.6635%, acc.: 55.86%] [Generator loss: 0.7756%]\n",
            "10066 [Discriminator loss: 0.6699%, acc.: 56.64%] [Generator loss: 0.8030%]\n",
            "10067 [Discriminator loss: 0.6592%, acc.: 65.23%] [Generator loss: 0.7723%]\n",
            "10068 [Discriminator loss: 0.6760%, acc.: 57.03%] [Generator loss: 0.7904%]\n",
            "10069 [Discriminator loss: 0.6632%, acc.: 57.03%] [Generator loss: 0.7991%]\n",
            "10070 [Discriminator loss: 0.6758%, acc.: 56.25%] [Generator loss: 0.7898%]\n",
            "10071 [Discriminator loss: 0.6884%, acc.: 52.73%] [Generator loss: 0.7945%]\n",
            "10072 [Discriminator loss: 0.6830%, acc.: 57.81%] [Generator loss: 0.8003%]\n",
            "10073 [Discriminator loss: 0.6643%, acc.: 61.33%] [Generator loss: 0.8160%]\n",
            "10074 [Discriminator loss: 0.6608%, acc.: 62.89%] [Generator loss: 0.7953%]\n",
            "10075 [Discriminator loss: 0.6604%, acc.: 61.33%] [Generator loss: 0.8129%]\n",
            "10076 [Discriminator loss: 0.6628%, acc.: 61.33%] [Generator loss: 0.7815%]\n",
            "10077 [Discriminator loss: 0.6667%, acc.: 58.59%] [Generator loss: 0.7831%]\n",
            "10078 [Discriminator loss: 0.6849%, acc.: 54.69%] [Generator loss: 0.8026%]\n",
            "10079 [Discriminator loss: 0.6667%, acc.: 61.72%] [Generator loss: 0.8018%]\n",
            "10080 [Discriminator loss: 0.6922%, acc.: 51.95%] [Generator loss: 0.7650%]\n",
            "10081 [Discriminator loss: 0.6807%, acc.: 55.08%] [Generator loss: 0.7922%]\n",
            "10082 [Discriminator loss: 0.6697%, acc.: 58.20%] [Generator loss: 0.7920%]\n",
            "10083 [Discriminator loss: 0.6771%, acc.: 56.64%] [Generator loss: 0.7807%]\n",
            "10084 [Discriminator loss: 0.6573%, acc.: 60.55%] [Generator loss: 0.7746%]\n",
            "10085 [Discriminator loss: 0.6809%, acc.: 57.81%] [Generator loss: 0.7855%]\n",
            "10086 [Discriminator loss: 0.6762%, acc.: 58.20%] [Generator loss: 0.7666%]\n",
            "10087 [Discriminator loss: 0.6806%, acc.: 53.52%] [Generator loss: 0.7969%]\n",
            "10088 [Discriminator loss: 0.6840%, acc.: 52.73%] [Generator loss: 0.7681%]\n",
            "10089 [Discriminator loss: 0.6748%, acc.: 58.20%] [Generator loss: 0.7664%]\n",
            "10090 [Discriminator loss: 0.6750%, acc.: 58.20%] [Generator loss: 0.7558%]\n",
            "10091 [Discriminator loss: 0.6726%, acc.: 55.47%] [Generator loss: 0.7801%]\n",
            "10092 [Discriminator loss: 0.6956%, acc.: 51.17%] [Generator loss: 0.7555%]\n",
            "10093 [Discriminator loss: 0.6856%, acc.: 56.64%] [Generator loss: 0.7589%]\n",
            "10094 [Discriminator loss: 0.6736%, acc.: 56.64%] [Generator loss: 0.7909%]\n",
            "10095 [Discriminator loss: 0.6718%, acc.: 59.77%] [Generator loss: 0.7689%]\n",
            "10096 [Discriminator loss: 0.6711%, acc.: 58.20%] [Generator loss: 0.7789%]\n",
            "10097 [Discriminator loss: 0.6787%, acc.: 57.81%] [Generator loss: 0.7778%]\n",
            "10098 [Discriminator loss: 0.6907%, acc.: 54.30%] [Generator loss: 0.7590%]\n",
            "10099 [Discriminator loss: 0.6618%, acc.: 65.62%] [Generator loss: 0.8064%]\n",
            "10100 [Discriminator loss: 0.6928%, acc.: 55.86%] [Generator loss: 0.7656%]\n",
            "10101 [Discriminator loss: 0.6728%, acc.: 55.47%] [Generator loss: 0.7800%]\n",
            "10102 [Discriminator loss: 0.6750%, acc.: 57.03%] [Generator loss: 0.7778%]\n",
            "10103 [Discriminator loss: 0.6725%, acc.: 54.30%] [Generator loss: 0.7858%]\n",
            "10104 [Discriminator loss: 0.6735%, acc.: 57.42%] [Generator loss: 0.7705%]\n",
            "10105 [Discriminator loss: 0.6772%, acc.: 58.20%] [Generator loss: 0.7682%]\n",
            "10106 [Discriminator loss: 0.6846%, acc.: 56.64%] [Generator loss: 0.7776%]\n",
            "10107 [Discriminator loss: 0.6560%, acc.: 62.89%] [Generator loss: 0.8021%]\n",
            "10108 [Discriminator loss: 0.6705%, acc.: 56.25%] [Generator loss: 0.8035%]\n",
            "10109 [Discriminator loss: 0.6627%, acc.: 60.16%] [Generator loss: 0.8087%]\n",
            "10110 [Discriminator loss: 0.6838%, acc.: 57.03%] [Generator loss: 0.7910%]\n",
            "10111 [Discriminator loss: 0.6742%, acc.: 57.42%] [Generator loss: 0.7886%]\n",
            "10112 [Discriminator loss: 0.6623%, acc.: 59.77%] [Generator loss: 0.7990%]\n",
            "10113 [Discriminator loss: 0.6652%, acc.: 58.98%] [Generator loss: 0.7800%]\n",
            "10114 [Discriminator loss: 0.6653%, acc.: 61.33%] [Generator loss: 0.7833%]\n",
            "10115 [Discriminator loss: 0.6723%, acc.: 58.98%] [Generator loss: 0.7654%]\n",
            "10116 [Discriminator loss: 0.6581%, acc.: 62.89%] [Generator loss: 0.7774%]\n",
            "10117 [Discriminator loss: 0.6802%, acc.: 58.59%] [Generator loss: 0.7947%]\n",
            "10118 [Discriminator loss: 0.6799%, acc.: 57.42%] [Generator loss: 0.7954%]\n",
            "10119 [Discriminator loss: 0.6754%, acc.: 57.81%] [Generator loss: 0.8133%]\n",
            "10120 [Discriminator loss: 0.6849%, acc.: 55.47%] [Generator loss: 0.7793%]\n",
            "10121 [Discriminator loss: 0.6891%, acc.: 54.69%] [Generator loss: 0.7692%]\n",
            "10122 [Discriminator loss: 0.6696%, acc.: 57.81%] [Generator loss: 0.8012%]\n",
            "10123 [Discriminator loss: 0.6933%, acc.: 52.34%] [Generator loss: 0.7907%]\n",
            "10124 [Discriminator loss: 0.6652%, acc.: 58.20%] [Generator loss: 0.8161%]\n",
            "10125 [Discriminator loss: 0.6777%, acc.: 60.16%] [Generator loss: 0.7800%]\n",
            "10126 [Discriminator loss: 0.6650%, acc.: 62.50%] [Generator loss: 0.7762%]\n",
            "10127 [Discriminator loss: 0.6716%, acc.: 55.47%] [Generator loss: 0.7677%]\n",
            "10128 [Discriminator loss: 0.6722%, acc.: 59.77%] [Generator loss: 0.8128%]\n",
            "10129 [Discriminator loss: 0.6645%, acc.: 57.81%] [Generator loss: 0.7634%]\n",
            "10130 [Discriminator loss: 0.6900%, acc.: 53.91%] [Generator loss: 0.7965%]\n",
            "10131 [Discriminator loss: 0.6620%, acc.: 58.98%] [Generator loss: 0.7904%]\n",
            "10132 [Discriminator loss: 0.6742%, acc.: 59.38%] [Generator loss: 0.7833%]\n",
            "10133 [Discriminator loss: 0.6925%, acc.: 53.12%] [Generator loss: 0.8046%]\n",
            "10134 [Discriminator loss: 0.6682%, acc.: 60.16%] [Generator loss: 0.7974%]\n",
            "10135 [Discriminator loss: 0.6759%, acc.: 57.03%] [Generator loss: 0.7778%]\n",
            "10136 [Discriminator loss: 0.6760%, acc.: 55.08%] [Generator loss: 0.7638%]\n",
            "10137 [Discriminator loss: 0.6624%, acc.: 60.55%] [Generator loss: 0.7919%]\n",
            "10138 [Discriminator loss: 0.6612%, acc.: 59.77%] [Generator loss: 0.7641%]\n",
            "10139 [Discriminator loss: 0.6695%, acc.: 62.89%] [Generator loss: 0.7846%]\n",
            "10140 [Discriminator loss: 0.6838%, acc.: 56.64%] [Generator loss: 0.7471%]\n",
            "10141 [Discriminator loss: 0.6791%, acc.: 56.25%] [Generator loss: 0.7652%]\n",
            "10142 [Discriminator loss: 0.6894%, acc.: 52.73%] [Generator loss: 0.7420%]\n",
            "10143 [Discriminator loss: 0.6706%, acc.: 61.72%] [Generator loss: 0.7684%]\n",
            "10144 [Discriminator loss: 0.6783%, acc.: 55.86%] [Generator loss: 0.7844%]\n",
            "10145 [Discriminator loss: 0.6766%, acc.: 59.77%] [Generator loss: 0.7582%]\n",
            "10146 [Discriminator loss: 0.6787%, acc.: 56.25%] [Generator loss: 0.7803%]\n",
            "10147 [Discriminator loss: 0.6705%, acc.: 57.81%] [Generator loss: 0.7768%]\n",
            "10148 [Discriminator loss: 0.6642%, acc.: 60.16%] [Generator loss: 0.7732%]\n",
            "10149 [Discriminator loss: 0.6552%, acc.: 61.33%] [Generator loss: 0.7764%]\n",
            "10150 [Discriminator loss: 0.6765%, acc.: 58.59%] [Generator loss: 0.7709%]\n",
            "10151 [Discriminator loss: 0.6827%, acc.: 55.47%] [Generator loss: 0.7789%]\n",
            "10152 [Discriminator loss: 0.6656%, acc.: 59.38%] [Generator loss: 0.7798%]\n",
            "10153 [Discriminator loss: 0.6718%, acc.: 60.16%] [Generator loss: 0.7814%]\n",
            "10154 [Discriminator loss: 0.6875%, acc.: 53.52%] [Generator loss: 0.7917%]\n",
            "10155 [Discriminator loss: 0.6718%, acc.: 58.20%] [Generator loss: 0.7739%]\n",
            "10156 [Discriminator loss: 0.6798%, acc.: 58.20%] [Generator loss: 0.7865%]\n",
            "10157 [Discriminator loss: 0.6692%, acc.: 57.03%] [Generator loss: 0.7830%]\n",
            "10158 [Discriminator loss: 0.6759%, acc.: 57.81%] [Generator loss: 0.7634%]\n",
            "10159 [Discriminator loss: 0.6761%, acc.: 53.91%] [Generator loss: 0.7854%]\n",
            "10160 [Discriminator loss: 0.6872%, acc.: 53.12%] [Generator loss: 0.7915%]\n",
            "10161 [Discriminator loss: 0.6559%, acc.: 61.33%] [Generator loss: 0.8099%]\n",
            "10162 [Discriminator loss: 0.6727%, acc.: 59.38%] [Generator loss: 0.7906%]\n",
            "10163 [Discriminator loss: 0.6598%, acc.: 60.55%] [Generator loss: 0.7896%]\n",
            "10164 [Discriminator loss: 0.6723%, acc.: 60.55%] [Generator loss: 0.7772%]\n",
            "10165 [Discriminator loss: 0.6825%, acc.: 56.64%] [Generator loss: 0.7810%]\n",
            "10166 [Discriminator loss: 0.6695%, acc.: 59.77%] [Generator loss: 0.7824%]\n",
            "10167 [Discriminator loss: 0.6602%, acc.: 63.28%] [Generator loss: 0.7893%]\n",
            "10168 [Discriminator loss: 0.6731%, acc.: 57.42%] [Generator loss: 0.7666%]\n",
            "10169 [Discriminator loss: 0.7008%, acc.: 49.22%] [Generator loss: 0.7599%]\n",
            "10170 [Discriminator loss: 0.6750%, acc.: 55.86%] [Generator loss: 0.7815%]\n",
            "10171 [Discriminator loss: 0.6813%, acc.: 54.30%] [Generator loss: 0.7821%]\n",
            "10172 [Discriminator loss: 0.6799%, acc.: 57.03%] [Generator loss: 0.7844%]\n",
            "10173 [Discriminator loss: 0.6763%, acc.: 58.20%] [Generator loss: 0.8048%]\n",
            "10174 [Discriminator loss: 0.7068%, acc.: 50.00%] [Generator loss: 0.7950%]\n",
            "10175 [Discriminator loss: 0.6661%, acc.: 58.98%] [Generator loss: 0.7963%]\n",
            "10176 [Discriminator loss: 0.6841%, acc.: 55.86%] [Generator loss: 0.7796%]\n",
            "10177 [Discriminator loss: 0.6647%, acc.: 59.77%] [Generator loss: 0.7589%]\n",
            "10178 [Discriminator loss: 0.6666%, acc.: 60.55%] [Generator loss: 0.7621%]\n",
            "10179 [Discriminator loss: 0.6813%, acc.: 53.91%] [Generator loss: 0.7582%]\n",
            "10180 [Discriminator loss: 0.6846%, acc.: 56.64%] [Generator loss: 0.7752%]\n",
            "10181 [Discriminator loss: 0.6796%, acc.: 58.59%] [Generator loss: 0.7851%]\n",
            "10182 [Discriminator loss: 0.6876%, acc.: 55.08%] [Generator loss: 0.7782%]\n",
            "10183 [Discriminator loss: 0.6689%, acc.: 58.20%] [Generator loss: 0.7799%]\n",
            "10184 [Discriminator loss: 0.6695%, acc.: 61.33%] [Generator loss: 0.7896%]\n",
            "10185 [Discriminator loss: 0.6567%, acc.: 65.23%] [Generator loss: 0.7786%]\n",
            "10186 [Discriminator loss: 0.6699%, acc.: 63.67%] [Generator loss: 0.7635%]\n",
            "10187 [Discriminator loss: 0.6635%, acc.: 59.77%] [Generator loss: 0.8039%]\n",
            "10188 [Discriminator loss: 0.7086%, acc.: 51.56%] [Generator loss: 0.7661%]\n",
            "10189 [Discriminator loss: 0.6573%, acc.: 63.28%] [Generator loss: 0.7543%]\n",
            "10190 [Discriminator loss: 0.6690%, acc.: 58.59%] [Generator loss: 0.7589%]\n",
            "10191 [Discriminator loss: 0.6858%, acc.: 56.64%] [Generator loss: 0.7737%]\n",
            "10192 [Discriminator loss: 0.6783%, acc.: 57.81%] [Generator loss: 0.8076%]\n",
            "10193 [Discriminator loss: 0.6908%, acc.: 56.64%] [Generator loss: 0.7634%]\n",
            "10194 [Discriminator loss: 0.6940%, acc.: 51.17%] [Generator loss: 0.7806%]\n",
            "10195 [Discriminator loss: 0.6665%, acc.: 62.50%] [Generator loss: 0.7592%]\n",
            "10196 [Discriminator loss: 0.6760%, acc.: 57.03%] [Generator loss: 0.7606%]\n",
            "10197 [Discriminator loss: 0.6621%, acc.: 61.33%] [Generator loss: 0.7863%]\n",
            "10198 [Discriminator loss: 0.6823%, acc.: 55.47%] [Generator loss: 0.7863%]\n",
            "10199 [Discriminator loss: 0.6699%, acc.: 57.42%] [Generator loss: 0.7844%]\n",
            "10200 [Discriminator loss: 0.6805%, acc.: 55.47%] [Generator loss: 0.7752%]\n",
            "10201 [Discriminator loss: 0.6812%, acc.: 52.34%] [Generator loss: 0.7550%]\n",
            "10202 [Discriminator loss: 0.6760%, acc.: 57.42%] [Generator loss: 0.7800%]\n",
            "10203 [Discriminator loss: 0.6846%, acc.: 50.39%] [Generator loss: 0.7901%]\n",
            "10204 [Discriminator loss: 0.6860%, acc.: 56.64%] [Generator loss: 0.7764%]\n",
            "10205 [Discriminator loss: 0.6798%, acc.: 55.47%] [Generator loss: 0.7808%]\n",
            "10206 [Discriminator loss: 0.6808%, acc.: 55.86%] [Generator loss: 0.7892%]\n",
            "10207 [Discriminator loss: 0.6670%, acc.: 59.38%] [Generator loss: 0.7678%]\n",
            "10208 [Discriminator loss: 0.6831%, acc.: 58.98%] [Generator loss: 0.7585%]\n",
            "10209 [Discriminator loss: 0.6620%, acc.: 62.11%] [Generator loss: 0.7716%]\n",
            "10210 [Discriminator loss: 0.6890%, acc.: 55.08%] [Generator loss: 0.7967%]\n",
            "10211 [Discriminator loss: 0.6766%, acc.: 57.42%] [Generator loss: 0.7801%]\n",
            "10212 [Discriminator loss: 0.6918%, acc.: 51.95%] [Generator loss: 0.8036%]\n",
            "10213 [Discriminator loss: 0.6647%, acc.: 60.16%] [Generator loss: 0.7769%]\n",
            "10214 [Discriminator loss: 0.6782%, acc.: 54.30%] [Generator loss: 0.7865%]\n",
            "10215 [Discriminator loss: 0.6829%, acc.: 55.08%] [Generator loss: 0.7830%]\n",
            "10216 [Discriminator loss: 0.6664%, acc.: 60.94%] [Generator loss: 0.7830%]\n",
            "10217 [Discriminator loss: 0.6668%, acc.: 58.59%] [Generator loss: 0.7764%]\n",
            "10218 [Discriminator loss: 0.6636%, acc.: 62.50%] [Generator loss: 0.7520%]\n",
            "10219 [Discriminator loss: 0.6827%, acc.: 55.47%] [Generator loss: 0.7613%]\n",
            "10220 [Discriminator loss: 0.6733%, acc.: 55.47%] [Generator loss: 0.7643%]\n",
            "10221 [Discriminator loss: 0.6758%, acc.: 55.08%] [Generator loss: 0.7898%]\n",
            "10222 [Discriminator loss: 0.6864%, acc.: 52.73%] [Generator loss: 0.7884%]\n",
            "10223 [Discriminator loss: 0.6662%, acc.: 62.50%] [Generator loss: 0.7844%]\n",
            "10224 [Discriminator loss: 0.6814%, acc.: 58.20%] [Generator loss: 0.7784%]\n",
            "10225 [Discriminator loss: 0.6663%, acc.: 63.28%] [Generator loss: 0.7720%]\n",
            "10226 [Discriminator loss: 0.6727%, acc.: 58.59%] [Generator loss: 0.7700%]\n",
            "10227 [Discriminator loss: 0.6836%, acc.: 56.64%] [Generator loss: 0.7693%]\n",
            "10228 [Discriminator loss: 0.6729%, acc.: 61.33%] [Generator loss: 0.7820%]\n",
            "10229 [Discriminator loss: 0.6685%, acc.: 56.64%] [Generator loss: 0.7767%]\n",
            "10230 [Discriminator loss: 0.6797%, acc.: 55.47%] [Generator loss: 0.7724%]\n",
            "10231 [Discriminator loss: 0.6631%, acc.: 60.55%] [Generator loss: 0.7792%]\n",
            "10232 [Discriminator loss: 0.6780%, acc.: 61.72%] [Generator loss: 0.7822%]\n",
            "10233 [Discriminator loss: 0.6852%, acc.: 55.08%] [Generator loss: 0.7886%]\n",
            "10234 [Discriminator loss: 0.6830%, acc.: 55.86%] [Generator loss: 0.7810%]\n",
            "10235 [Discriminator loss: 0.6790%, acc.: 58.59%] [Generator loss: 0.7869%]\n",
            "10236 [Discriminator loss: 0.6876%, acc.: 58.20%] [Generator loss: 0.7905%]\n",
            "10237 [Discriminator loss: 0.6845%, acc.: 57.81%] [Generator loss: 0.7966%]\n",
            "10238 [Discriminator loss: 0.6817%, acc.: 55.08%] [Generator loss: 0.7457%]\n",
            "10239 [Discriminator loss: 0.6838%, acc.: 55.47%] [Generator loss: 0.7852%]\n",
            "10240 [Discriminator loss: 0.6706%, acc.: 62.11%] [Generator loss: 0.7639%]\n",
            "10241 [Discriminator loss: 0.6707%, acc.: 56.25%] [Generator loss: 0.7937%]\n",
            "10242 [Discriminator loss: 0.6798%, acc.: 57.81%] [Generator loss: 0.7773%]\n",
            "10243 [Discriminator loss: 0.6672%, acc.: 57.42%] [Generator loss: 0.7809%]\n",
            "10244 [Discriminator loss: 0.6719%, acc.: 57.03%] [Generator loss: 0.7811%]\n",
            "10245 [Discriminator loss: 0.6799%, acc.: 55.47%] [Generator loss: 0.7735%]\n",
            "10246 [Discriminator loss: 0.6880%, acc.: 48.05%] [Generator loss: 0.7728%]\n",
            "10247 [Discriminator loss: 0.6544%, acc.: 65.23%] [Generator loss: 0.7445%]\n",
            "10248 [Discriminator loss: 0.6772%, acc.: 57.81%] [Generator loss: 0.7825%]\n",
            "10249 [Discriminator loss: 0.6697%, acc.: 60.55%] [Generator loss: 0.7840%]\n",
            "10250 [Discriminator loss: 0.6833%, acc.: 55.86%] [Generator loss: 0.7917%]\n",
            "10251 [Discriminator loss: 0.6775%, acc.: 59.77%] [Generator loss: 0.8013%]\n",
            "10252 [Discriminator loss: 0.6579%, acc.: 62.50%] [Generator loss: 0.7717%]\n",
            "10253 [Discriminator loss: 0.6607%, acc.: 59.38%] [Generator loss: 0.7990%]\n",
            "10254 [Discriminator loss: 0.6740%, acc.: 56.25%] [Generator loss: 0.7765%]\n",
            "10255 [Discriminator loss: 0.6720%, acc.: 59.77%] [Generator loss: 0.7800%]\n",
            "10256 [Discriminator loss: 0.6672%, acc.: 62.50%] [Generator loss: 0.7681%]\n",
            "10257 [Discriminator loss: 0.6811%, acc.: 57.03%] [Generator loss: 0.7455%]\n",
            "10258 [Discriminator loss: 0.6869%, acc.: 57.42%] [Generator loss: 0.7703%]\n",
            "10259 [Discriminator loss: 0.6621%, acc.: 57.42%] [Generator loss: 0.7925%]\n",
            "10260 [Discriminator loss: 0.6717%, acc.: 57.81%] [Generator loss: 0.7701%]\n",
            "10261 [Discriminator loss: 0.6736%, acc.: 57.03%] [Generator loss: 0.7989%]\n",
            "10262 [Discriminator loss: 0.6444%, acc.: 64.45%] [Generator loss: 0.7782%]\n",
            "10263 [Discriminator loss: 0.6713%, acc.: 59.38%] [Generator loss: 0.7845%]\n",
            "10264 [Discriminator loss: 0.6796%, acc.: 51.56%] [Generator loss: 0.7698%]\n",
            "10265 [Discriminator loss: 0.6588%, acc.: 60.16%] [Generator loss: 0.7797%]\n",
            "10266 [Discriminator loss: 0.6543%, acc.: 62.50%] [Generator loss: 0.8030%]\n",
            "10267 [Discriminator loss: 0.6807%, acc.: 55.08%] [Generator loss: 0.7913%]\n",
            "10268 [Discriminator loss: 0.6895%, acc.: 55.08%] [Generator loss: 0.7787%]\n",
            "10269 [Discriminator loss: 0.6877%, acc.: 55.47%] [Generator loss: 0.7810%]\n",
            "10270 [Discriminator loss: 0.6918%, acc.: 52.73%] [Generator loss: 0.7919%]\n",
            "10271 [Discriminator loss: 0.6708%, acc.: 58.98%] [Generator loss: 0.7980%]\n",
            "10272 [Discriminator loss: 0.6633%, acc.: 58.98%] [Generator loss: 0.7774%]\n",
            "10273 [Discriminator loss: 0.6850%, acc.: 56.64%] [Generator loss: 0.7592%]\n",
            "10274 [Discriminator loss: 0.6870%, acc.: 55.08%] [Generator loss: 0.7898%]\n",
            "10275 [Discriminator loss: 0.6852%, acc.: 56.25%] [Generator loss: 0.7776%]\n",
            "10276 [Discriminator loss: 0.6647%, acc.: 63.28%] [Generator loss: 0.7917%]\n",
            "10277 [Discriminator loss: 0.6598%, acc.: 60.16%] [Generator loss: 0.7883%]\n",
            "10278 [Discriminator loss: 0.6627%, acc.: 60.55%] [Generator loss: 0.7867%]\n",
            "10279 [Discriminator loss: 0.6672%, acc.: 62.11%] [Generator loss: 0.7739%]\n",
            "10280 [Discriminator loss: 0.6822%, acc.: 54.30%] [Generator loss: 0.7852%]\n",
            "10281 [Discriminator loss: 0.6626%, acc.: 61.33%] [Generator loss: 0.7988%]\n",
            "10282 [Discriminator loss: 0.6742%, acc.: 58.20%] [Generator loss: 0.8064%]\n",
            "10283 [Discriminator loss: 0.6716%, acc.: 60.55%] [Generator loss: 0.7853%]\n",
            "10284 [Discriminator loss: 0.6725%, acc.: 56.64%] [Generator loss: 0.7827%]\n",
            "10285 [Discriminator loss: 0.6738%, acc.: 56.64%] [Generator loss: 0.7794%]\n",
            "10286 [Discriminator loss: 0.6811%, acc.: 55.86%] [Generator loss: 0.7911%]\n",
            "10287 [Discriminator loss: 0.6955%, acc.: 51.95%] [Generator loss: 0.7783%]\n",
            "10288 [Discriminator loss: 0.6805%, acc.: 57.81%] [Generator loss: 0.7792%]\n",
            "10289 [Discriminator loss: 0.6731%, acc.: 57.42%] [Generator loss: 0.7873%]\n",
            "10290 [Discriminator loss: 0.6636%, acc.: 61.72%] [Generator loss: 0.7633%]\n",
            "10291 [Discriminator loss: 0.6773%, acc.: 56.25%] [Generator loss: 0.7623%]\n",
            "10292 [Discriminator loss: 0.6675%, acc.: 58.98%] [Generator loss: 0.7688%]\n",
            "10293 [Discriminator loss: 0.6838%, acc.: 56.64%] [Generator loss: 0.7853%]\n",
            "10294 [Discriminator loss: 0.6674%, acc.: 62.11%] [Generator loss: 0.7783%]\n",
            "10295 [Discriminator loss: 0.6508%, acc.: 64.84%] [Generator loss: 0.7986%]\n",
            "10296 [Discriminator loss: 0.6715%, acc.: 58.59%] [Generator loss: 0.7712%]\n",
            "10297 [Discriminator loss: 0.6762%, acc.: 58.59%] [Generator loss: 0.7766%]\n",
            "10298 [Discriminator loss: 0.6659%, acc.: 62.50%] [Generator loss: 0.7872%]\n",
            "10299 [Discriminator loss: 0.6912%, acc.: 54.30%] [Generator loss: 0.7680%]\n",
            "10300 [Discriminator loss: 0.6848%, acc.: 54.69%] [Generator loss: 0.8032%]\n",
            "10301 [Discriminator loss: 0.6679%, acc.: 59.77%] [Generator loss: 0.7907%]\n",
            "10302 [Discriminator loss: 0.6705%, acc.: 58.59%] [Generator loss: 0.7965%]\n",
            "10303 [Discriminator loss: 0.6813%, acc.: 52.34%] [Generator loss: 0.7648%]\n",
            "10304 [Discriminator loss: 0.6826%, acc.: 52.73%] [Generator loss: 0.7805%]\n",
            "10305 [Discriminator loss: 0.6830%, acc.: 55.86%] [Generator loss: 0.7937%]\n",
            "10306 [Discriminator loss: 0.6695%, acc.: 57.03%] [Generator loss: 0.7815%]\n",
            "10307 [Discriminator loss: 0.6722%, acc.: 56.25%] [Generator loss: 0.7820%]\n",
            "10308 [Discriminator loss: 0.6716%, acc.: 57.42%] [Generator loss: 0.7950%]\n",
            "10309 [Discriminator loss: 0.6663%, acc.: 60.55%] [Generator loss: 0.7778%]\n",
            "10310 [Discriminator loss: 0.6748%, acc.: 58.20%] [Generator loss: 0.7525%]\n",
            "10311 [Discriminator loss: 0.6599%, acc.: 62.89%] [Generator loss: 0.7546%]\n",
            "10312 [Discriminator loss: 0.6634%, acc.: 57.81%] [Generator loss: 0.7721%]\n",
            "10313 [Discriminator loss: 0.6717%, acc.: 61.33%] [Generator loss: 0.7677%]\n",
            "10314 [Discriminator loss: 0.6839%, acc.: 56.25%] [Generator loss: 0.7649%]\n",
            "10315 [Discriminator loss: 0.6620%, acc.: 62.50%] [Generator loss: 0.7694%]\n",
            "10316 [Discriminator loss: 0.6546%, acc.: 60.16%] [Generator loss: 0.7863%]\n",
            "10317 [Discriminator loss: 0.6823%, acc.: 57.81%] [Generator loss: 0.7795%]\n",
            "10318 [Discriminator loss: 0.6734%, acc.: 58.20%] [Generator loss: 0.7781%]\n",
            "10319 [Discriminator loss: 0.6848%, acc.: 55.08%] [Generator loss: 0.7944%]\n",
            "10320 [Discriminator loss: 0.6643%, acc.: 64.06%] [Generator loss: 0.7912%]\n",
            "10321 [Discriminator loss: 0.6807%, acc.: 58.98%] [Generator loss: 0.8028%]\n",
            "10322 [Discriminator loss: 0.6918%, acc.: 51.95%] [Generator loss: 0.7604%]\n",
            "10323 [Discriminator loss: 0.6854%, acc.: 55.86%] [Generator loss: 0.7894%]\n",
            "10324 [Discriminator loss: 0.6668%, acc.: 62.11%] [Generator loss: 0.7683%]\n",
            "10325 [Discriminator loss: 0.6871%, acc.: 57.81%] [Generator loss: 0.7784%]\n",
            "10326 [Discriminator loss: 0.6617%, acc.: 62.89%] [Generator loss: 0.7722%]\n",
            "10327 [Discriminator loss: 0.6388%, acc.: 70.70%] [Generator loss: 0.8086%]\n",
            "10328 [Discriminator loss: 0.6879%, acc.: 55.86%] [Generator loss: 0.7779%]\n",
            "10329 [Discriminator loss: 0.6791%, acc.: 60.94%] [Generator loss: 0.7764%]\n",
            "10330 [Discriminator loss: 0.6702%, acc.: 58.98%] [Generator loss: 0.7856%]\n",
            "10331 [Discriminator loss: 0.6615%, acc.: 64.45%] [Generator loss: 0.7897%]\n",
            "10332 [Discriminator loss: 0.6591%, acc.: 61.72%] [Generator loss: 0.7989%]\n",
            "10333 [Discriminator loss: 0.6546%, acc.: 63.28%] [Generator loss: 0.7976%]\n",
            "10334 [Discriminator loss: 0.6701%, acc.: 58.59%] [Generator loss: 0.8064%]\n",
            "10335 [Discriminator loss: 0.6804%, acc.: 57.42%] [Generator loss: 0.7764%]\n",
            "10336 [Discriminator loss: 0.6634%, acc.: 63.28%] [Generator loss: 0.7798%]\n",
            "10337 [Discriminator loss: 0.6803%, acc.: 58.59%] [Generator loss: 0.7751%]\n",
            "10338 [Discriminator loss: 0.6563%, acc.: 60.55%] [Generator loss: 0.7776%]\n",
            "10339 [Discriminator loss: 0.6763%, acc.: 55.86%] [Generator loss: 0.7629%]\n",
            "10340 [Discriminator loss: 0.6878%, acc.: 51.56%] [Generator loss: 0.7576%]\n",
            "10341 [Discriminator loss: 0.6600%, acc.: 60.94%] [Generator loss: 0.7805%]\n",
            "10342 [Discriminator loss: 0.6660%, acc.: 58.98%] [Generator loss: 0.7880%]\n",
            "10343 [Discriminator loss: 0.6708%, acc.: 60.55%] [Generator loss: 0.7936%]\n",
            "10344 [Discriminator loss: 0.6693%, acc.: 57.42%] [Generator loss: 0.7990%]\n",
            "10345 [Discriminator loss: 0.6863%, acc.: 53.12%] [Generator loss: 0.8017%]\n",
            "10346 [Discriminator loss: 0.6758%, acc.: 60.55%] [Generator loss: 0.7910%]\n",
            "10347 [Discriminator loss: 0.6706%, acc.: 63.67%] [Generator loss: 0.8094%]\n",
            "10348 [Discriminator loss: 0.6507%, acc.: 64.45%] [Generator loss: 0.7839%]\n",
            "10349 [Discriminator loss: 0.6663%, acc.: 58.59%] [Generator loss: 0.8305%]\n",
            "10350 [Discriminator loss: 0.6862%, acc.: 52.34%] [Generator loss: 0.8036%]\n",
            "10351 [Discriminator loss: 0.6637%, acc.: 60.16%] [Generator loss: 0.7727%]\n",
            "10352 [Discriminator loss: 0.6786%, acc.: 57.03%] [Generator loss: 0.7733%]\n",
            "10353 [Discriminator loss: 0.6718%, acc.: 57.42%] [Generator loss: 0.7860%]\n",
            "10354 [Discriminator loss: 0.6602%, acc.: 62.50%] [Generator loss: 0.7592%]\n",
            "10355 [Discriminator loss: 0.6635%, acc.: 62.11%] [Generator loss: 0.7758%]\n",
            "10356 [Discriminator loss: 0.6735%, acc.: 61.72%] [Generator loss: 0.8001%]\n",
            "10357 [Discriminator loss: 0.6732%, acc.: 57.03%] [Generator loss: 0.7742%]\n",
            "10358 [Discriminator loss: 0.6689%, acc.: 53.91%] [Generator loss: 0.7927%]\n",
            "10359 [Discriminator loss: 0.6746%, acc.: 56.64%] [Generator loss: 0.7760%]\n",
            "10360 [Discriminator loss: 0.6366%, acc.: 63.67%] [Generator loss: 0.7514%]\n",
            "10361 [Discriminator loss: 0.6648%, acc.: 57.81%] [Generator loss: 0.7568%]\n",
            "10362 [Discriminator loss: 0.6848%, acc.: 55.08%] [Generator loss: 0.7509%]\n",
            "10363 [Discriminator loss: 0.6726%, acc.: 56.25%] [Generator loss: 0.7710%]\n",
            "10364 [Discriminator loss: 0.6644%, acc.: 61.33%] [Generator loss: 0.7885%]\n",
            "10365 [Discriminator loss: 0.6738%, acc.: 58.59%] [Generator loss: 0.7829%]\n",
            "10366 [Discriminator loss: 0.6714%, acc.: 58.59%] [Generator loss: 0.7804%]\n",
            "10367 [Discriminator loss: 0.6629%, acc.: 60.16%] [Generator loss: 0.7634%]\n",
            "10368 [Discriminator loss: 0.6507%, acc.: 65.23%] [Generator loss: 0.7879%]\n",
            "10369 [Discriminator loss: 0.6500%, acc.: 64.45%] [Generator loss: 0.7836%]\n",
            "10370 [Discriminator loss: 0.6682%, acc.: 55.08%] [Generator loss: 0.7758%]\n",
            "10371 [Discriminator loss: 0.6773%, acc.: 58.20%] [Generator loss: 0.7974%]\n",
            "10372 [Discriminator loss: 0.6754%, acc.: 61.33%] [Generator loss: 0.7854%]\n",
            "10373 [Discriminator loss: 0.6661%, acc.: 59.77%] [Generator loss: 0.7853%]\n",
            "10374 [Discriminator loss: 0.6855%, acc.: 56.64%] [Generator loss: 0.7690%]\n",
            "10375 [Discriminator loss: 0.6811%, acc.: 55.47%] [Generator loss: 0.7757%]\n",
            "10376 [Discriminator loss: 0.6484%, acc.: 63.28%] [Generator loss: 0.7777%]\n",
            "10377 [Discriminator loss: 0.6606%, acc.: 57.42%] [Generator loss: 0.7998%]\n",
            "10378 [Discriminator loss: 0.6820%, acc.: 53.12%] [Generator loss: 0.7879%]\n",
            "10379 [Discriminator loss: 0.6620%, acc.: 60.94%] [Generator loss: 0.7710%]\n",
            "10380 [Discriminator loss: 0.6683%, acc.: 60.16%] [Generator loss: 0.7824%]\n",
            "10381 [Discriminator loss: 0.6701%, acc.: 62.50%] [Generator loss: 0.7622%]\n",
            "10382 [Discriminator loss: 0.6815%, acc.: 56.25%] [Generator loss: 0.7741%]\n",
            "10383 [Discriminator loss: 0.6768%, acc.: 56.64%] [Generator loss: 0.7663%]\n",
            "10384 [Discriminator loss: 0.6802%, acc.: 56.25%] [Generator loss: 0.7790%]\n",
            "10385 [Discriminator loss: 0.6897%, acc.: 52.34%] [Generator loss: 0.7791%]\n",
            "10386 [Discriminator loss: 0.6631%, acc.: 62.50%] [Generator loss: 0.7553%]\n",
            "10387 [Discriminator loss: 0.6703%, acc.: 56.25%] [Generator loss: 0.7427%]\n",
            "10388 [Discriminator loss: 0.6589%, acc.: 62.89%] [Generator loss: 0.7762%]\n",
            "10389 [Discriminator loss: 0.6607%, acc.: 60.16%] [Generator loss: 0.7950%]\n",
            "10390 [Discriminator loss: 0.6725%, acc.: 57.42%] [Generator loss: 0.7667%]\n",
            "10391 [Discriminator loss: 0.6573%, acc.: 60.94%] [Generator loss: 0.7937%]\n",
            "10392 [Discriminator loss: 0.6572%, acc.: 58.59%] [Generator loss: 0.7785%]\n",
            "10393 [Discriminator loss: 0.6789%, acc.: 57.03%] [Generator loss: 0.7649%]\n",
            "10394 [Discriminator loss: 0.6641%, acc.: 61.72%] [Generator loss: 0.7714%]\n",
            "10395 [Discriminator loss: 0.6745%, acc.: 55.86%] [Generator loss: 0.7909%]\n",
            "10396 [Discriminator loss: 0.6983%, acc.: 50.00%] [Generator loss: 0.7860%]\n",
            "10397 [Discriminator loss: 0.6685%, acc.: 60.55%] [Generator loss: 0.7937%]\n",
            "10398 [Discriminator loss: 0.6730%, acc.: 60.55%] [Generator loss: 0.7800%]\n",
            "10399 [Discriminator loss: 0.6654%, acc.: 62.11%] [Generator loss: 0.7763%]\n",
            "10400 [Discriminator loss: 0.6647%, acc.: 62.50%] [Generator loss: 0.7761%]\n",
            "10401 [Discriminator loss: 0.6453%, acc.: 65.62%] [Generator loss: 0.7963%]\n",
            "10402 [Discriminator loss: 0.6966%, acc.: 53.12%] [Generator loss: 0.7938%]\n",
            "10403 [Discriminator loss: 0.6849%, acc.: 54.69%] [Generator loss: 0.7725%]\n",
            "10404 [Discriminator loss: 0.6673%, acc.: 60.55%] [Generator loss: 0.8064%]\n",
            "10405 [Discriminator loss: 0.6675%, acc.: 59.38%] [Generator loss: 0.7877%]\n",
            "10406 [Discriminator loss: 0.6708%, acc.: 57.03%] [Generator loss: 0.8004%]\n",
            "10407 [Discriminator loss: 0.6748%, acc.: 59.38%] [Generator loss: 0.7842%]\n",
            "10408 [Discriminator loss: 0.6683%, acc.: 55.86%] [Generator loss: 0.7850%]\n",
            "10409 [Discriminator loss: 0.6699%, acc.: 59.38%] [Generator loss: 0.7904%]\n",
            "10410 [Discriminator loss: 0.6797%, acc.: 57.81%] [Generator loss: 0.8018%]\n",
            "10411 [Discriminator loss: 0.6909%, acc.: 51.95%] [Generator loss: 0.7884%]\n",
            "10412 [Discriminator loss: 0.6704%, acc.: 60.94%] [Generator loss: 0.8135%]\n",
            "10413 [Discriminator loss: 0.6843%, acc.: 51.95%] [Generator loss: 0.7803%]\n",
            "10414 [Discriminator loss: 0.6658%, acc.: 60.16%] [Generator loss: 0.7856%]\n",
            "10415 [Discriminator loss: 0.6864%, acc.: 53.91%] [Generator loss: 0.7872%]\n",
            "10416 [Discriminator loss: 0.6848%, acc.: 55.47%] [Generator loss: 0.7750%]\n",
            "10417 [Discriminator loss: 0.6685%, acc.: 57.81%] [Generator loss: 0.7745%]\n",
            "10418 [Discriminator loss: 0.6702%, acc.: 60.55%] [Generator loss: 0.7918%]\n",
            "10419 [Discriminator loss: 0.6726%, acc.: 58.59%] [Generator loss: 0.7820%]\n",
            "10420 [Discriminator loss: 0.6680%, acc.: 55.86%] [Generator loss: 0.7736%]\n",
            "10421 [Discriminator loss: 0.6809%, acc.: 56.25%] [Generator loss: 0.7910%]\n",
            "10422 [Discriminator loss: 0.6700%, acc.: 60.55%] [Generator loss: 0.7825%]\n",
            "10423 [Discriminator loss: 0.6783%, acc.: 57.03%] [Generator loss: 0.7814%]\n",
            "10424 [Discriminator loss: 0.6589%, acc.: 60.55%] [Generator loss: 0.7850%]\n",
            "10425 [Discriminator loss: 0.6816%, acc.: 57.03%] [Generator loss: 0.7919%]\n",
            "10426 [Discriminator loss: 0.6820%, acc.: 54.69%] [Generator loss: 0.7859%]\n",
            "10427 [Discriminator loss: 0.6841%, acc.: 56.64%] [Generator loss: 0.7758%]\n",
            "10428 [Discriminator loss: 0.6829%, acc.: 54.30%] [Generator loss: 0.7719%]\n",
            "10429 [Discriminator loss: 0.6698%, acc.: 59.77%] [Generator loss: 0.7863%]\n",
            "10430 [Discriminator loss: 0.6785%, acc.: 57.81%] [Generator loss: 0.7846%]\n",
            "10431 [Discriminator loss: 0.6775%, acc.: 60.16%] [Generator loss: 0.7895%]\n",
            "10432 [Discriminator loss: 0.6892%, acc.: 50.78%] [Generator loss: 0.7815%]\n",
            "10433 [Discriminator loss: 0.6736%, acc.: 59.77%] [Generator loss: 0.8131%]\n",
            "10434 [Discriminator loss: 0.6514%, acc.: 65.23%] [Generator loss: 0.7829%]\n",
            "10435 [Discriminator loss: 0.6672%, acc.: 60.94%] [Generator loss: 0.7827%]\n",
            "10436 [Discriminator loss: 0.6602%, acc.: 61.33%] [Generator loss: 0.8123%]\n",
            "10437 [Discriminator loss: 0.6892%, acc.: 55.47%] [Generator loss: 0.8046%]\n",
            "10438 [Discriminator loss: 0.6646%, acc.: 61.33%] [Generator loss: 0.7868%]\n",
            "10439 [Discriminator loss: 0.6769%, acc.: 58.20%] [Generator loss: 0.7557%]\n",
            "10440 [Discriminator loss: 0.6550%, acc.: 62.50%] [Generator loss: 0.7579%]\n",
            "10441 [Discriminator loss: 0.6732%, acc.: 57.03%] [Generator loss: 0.7935%]\n",
            "10442 [Discriminator loss: 0.6723%, acc.: 58.59%] [Generator loss: 0.7861%]\n",
            "10443 [Discriminator loss: 0.6705%, acc.: 60.16%] [Generator loss: 0.7753%]\n",
            "10444 [Discriminator loss: 0.6619%, acc.: 64.84%] [Generator loss: 0.7686%]\n",
            "10445 [Discriminator loss: 0.6805%, acc.: 54.30%] [Generator loss: 0.7658%]\n",
            "10446 [Discriminator loss: 0.6711%, acc.: 57.42%] [Generator loss: 0.7715%]\n",
            "10447 [Discriminator loss: 0.6859%, acc.: 53.12%] [Generator loss: 0.7750%]\n",
            "10448 [Discriminator loss: 0.6777%, acc.: 58.59%] [Generator loss: 0.7590%]\n",
            "10449 [Discriminator loss: 0.6800%, acc.: 55.47%] [Generator loss: 0.7862%]\n",
            "10450 [Discriminator loss: 0.6875%, acc.: 55.08%] [Generator loss: 0.7978%]\n",
            "10451 [Discriminator loss: 0.6618%, acc.: 61.33%] [Generator loss: 0.7809%]\n",
            "10452 [Discriminator loss: 0.6794%, acc.: 55.86%] [Generator loss: 0.7743%]\n",
            "10453 [Discriminator loss: 0.6812%, acc.: 54.69%] [Generator loss: 0.7389%]\n",
            "10454 [Discriminator loss: 0.6665%, acc.: 62.50%] [Generator loss: 0.7757%]\n",
            "10455 [Discriminator loss: 0.6865%, acc.: 54.30%] [Generator loss: 0.7814%]\n",
            "10456 [Discriminator loss: 0.6648%, acc.: 60.55%] [Generator loss: 0.7572%]\n",
            "10457 [Discriminator loss: 0.6683%, acc.: 60.16%] [Generator loss: 0.7732%]\n",
            "10458 [Discriminator loss: 0.6622%, acc.: 57.81%] [Generator loss: 0.7664%]\n",
            "10459 [Discriminator loss: 0.6721%, acc.: 57.81%] [Generator loss: 0.7947%]\n",
            "10460 [Discriminator loss: 0.6761%, acc.: 57.81%] [Generator loss: 0.8008%]\n",
            "10461 [Discriminator loss: 0.6771%, acc.: 56.64%] [Generator loss: 0.7764%]\n",
            "10462 [Discriminator loss: 0.6677%, acc.: 58.20%] [Generator loss: 0.7860%]\n",
            "10463 [Discriminator loss: 0.6525%, acc.: 65.62%] [Generator loss: 0.7841%]\n",
            "10464 [Discriminator loss: 0.6809%, acc.: 55.08%] [Generator loss: 0.7912%]\n",
            "10465 [Discriminator loss: 0.6813%, acc.: 52.34%] [Generator loss: 0.7630%]\n",
            "10466 [Discriminator loss: 0.6642%, acc.: 54.30%] [Generator loss: 0.7730%]\n",
            "10467 [Discriminator loss: 0.6642%, acc.: 61.72%] [Generator loss: 0.7680%]\n",
            "10468 [Discriminator loss: 0.6858%, acc.: 55.86%] [Generator loss: 0.7989%]\n",
            "10469 [Discriminator loss: 0.6735%, acc.: 58.20%] [Generator loss: 0.7962%]\n",
            "10470 [Discriminator loss: 0.6748%, acc.: 58.59%] [Generator loss: 0.7951%]\n",
            "10471 [Discriminator loss: 0.6934%, acc.: 51.95%] [Generator loss: 0.8160%]\n",
            "10472 [Discriminator loss: 0.6714%, acc.: 56.64%] [Generator loss: 0.7920%]\n",
            "10473 [Discriminator loss: 0.6631%, acc.: 59.38%] [Generator loss: 0.7968%]\n",
            "10474 [Discriminator loss: 0.6701%, acc.: 59.77%] [Generator loss: 0.7845%]\n",
            "10475 [Discriminator loss: 0.6802%, acc.: 58.98%] [Generator loss: 0.7928%]\n",
            "10476 [Discriminator loss: 0.6801%, acc.: 52.34%] [Generator loss: 0.7799%]\n",
            "10477 [Discriminator loss: 0.6709%, acc.: 55.08%] [Generator loss: 0.7850%]\n",
            "10478 [Discriminator loss: 0.6754%, acc.: 58.98%] [Generator loss: 0.7682%]\n",
            "10479 [Discriminator loss: 0.6744%, acc.: 58.20%] [Generator loss: 0.7687%]\n",
            "10480 [Discriminator loss: 0.6728%, acc.: 57.03%] [Generator loss: 0.7829%]\n",
            "10481 [Discriminator loss: 0.6863%, acc.: 52.34%] [Generator loss: 0.8110%]\n",
            "10482 [Discriminator loss: 0.6726%, acc.: 59.77%] [Generator loss: 0.7797%]\n",
            "10483 [Discriminator loss: 0.6813%, acc.: 55.08%] [Generator loss: 0.7817%]\n",
            "10484 [Discriminator loss: 0.6767%, acc.: 56.25%] [Generator loss: 0.7616%]\n",
            "10485 [Discriminator loss: 0.6523%, acc.: 62.89%] [Generator loss: 0.7711%]\n",
            "10486 [Discriminator loss: 0.6758%, acc.: 59.38%] [Generator loss: 0.7864%]\n",
            "10487 [Discriminator loss: 0.6678%, acc.: 59.38%] [Generator loss: 0.7769%]\n",
            "10488 [Discriminator loss: 0.6722%, acc.: 58.98%] [Generator loss: 0.7767%]\n",
            "10489 [Discriminator loss: 0.6906%, acc.: 58.59%] [Generator loss: 0.7716%]\n",
            "10490 [Discriminator loss: 0.6793%, acc.: 59.38%] [Generator loss: 0.8025%]\n",
            "10491 [Discriminator loss: 0.6789%, acc.: 51.56%] [Generator loss: 0.7840%]\n",
            "10492 [Discriminator loss: 0.6722%, acc.: 57.81%] [Generator loss: 0.8139%]\n",
            "10493 [Discriminator loss: 0.6896%, acc.: 53.12%] [Generator loss: 0.7946%]\n",
            "10494 [Discriminator loss: 0.6701%, acc.: 57.03%] [Generator loss: 0.8150%]\n",
            "10495 [Discriminator loss: 0.6756%, acc.: 58.98%] [Generator loss: 0.7908%]\n",
            "10496 [Discriminator loss: 0.6655%, acc.: 58.20%] [Generator loss: 0.7995%]\n",
            "10497 [Discriminator loss: 0.6762%, acc.: 57.42%] [Generator loss: 0.7949%]\n",
            "10498 [Discriminator loss: 0.6796%, acc.: 57.81%] [Generator loss: 0.7868%]\n",
            "10499 [Discriminator loss: 0.6935%, acc.: 53.91%] [Generator loss: 0.7828%]\n",
            "10500 [Discriminator loss: 0.6716%, acc.: 60.55%] [Generator loss: 0.7923%]\n",
            "10501 [Discriminator loss: 0.6841%, acc.: 54.30%] [Generator loss: 0.7984%]\n",
            "10502 [Discriminator loss: 0.6724%, acc.: 58.98%] [Generator loss: 0.7958%]\n",
            "10503 [Discriminator loss: 0.6808%, acc.: 55.08%] [Generator loss: 0.7943%]\n",
            "10504 [Discriminator loss: 0.6640%, acc.: 60.55%] [Generator loss: 0.7897%]\n",
            "10505 [Discriminator loss: 0.6820%, acc.: 57.42%] [Generator loss: 0.7783%]\n",
            "10506 [Discriminator loss: 0.6721%, acc.: 62.11%] [Generator loss: 0.7767%]\n",
            "10507 [Discriminator loss: 0.6802%, acc.: 57.42%] [Generator loss: 0.7329%]\n",
            "10508 [Discriminator loss: 0.6699%, acc.: 57.81%] [Generator loss: 0.7780%]\n",
            "10509 [Discriminator loss: 0.6817%, acc.: 55.08%] [Generator loss: 0.7612%]\n",
            "10510 [Discriminator loss: 0.6753%, acc.: 56.64%] [Generator loss: 0.7778%]\n",
            "10511 [Discriminator loss: 0.6697%, acc.: 59.77%] [Generator loss: 0.7806%]\n",
            "10512 [Discriminator loss: 0.6664%, acc.: 60.94%] [Generator loss: 0.7995%]\n",
            "10513 [Discriminator loss: 0.6684%, acc.: 57.81%] [Generator loss: 0.7830%]\n",
            "10514 [Discriminator loss: 0.6716%, acc.: 57.81%] [Generator loss: 0.7770%]\n",
            "10515 [Discriminator loss: 0.6695%, acc.: 57.42%] [Generator loss: 0.7907%]\n",
            "10516 [Discriminator loss: 0.6631%, acc.: 60.94%] [Generator loss: 0.7987%]\n",
            "10517 [Discriminator loss: 0.6799%, acc.: 59.77%] [Generator loss: 0.7901%]\n",
            "10518 [Discriminator loss: 0.6888%, acc.: 53.52%] [Generator loss: 0.8071%]\n",
            "10519 [Discriminator loss: 0.6852%, acc.: 56.64%] [Generator loss: 0.7738%]\n",
            "10520 [Discriminator loss: 0.6687%, acc.: 60.16%] [Generator loss: 0.7792%]\n",
            "10521 [Discriminator loss: 0.6655%, acc.: 57.03%] [Generator loss: 0.7816%]\n",
            "10522 [Discriminator loss: 0.6980%, acc.: 54.69%] [Generator loss: 0.7747%]\n",
            "10523 [Discriminator loss: 0.6644%, acc.: 60.94%] [Generator loss: 0.7731%]\n",
            "10524 [Discriminator loss: 0.6755%, acc.: 58.98%] [Generator loss: 0.7768%]\n",
            "10525 [Discriminator loss: 0.6856%, acc.: 55.08%] [Generator loss: 0.7964%]\n",
            "10526 [Discriminator loss: 0.6725%, acc.: 59.38%] [Generator loss: 0.7960%]\n",
            "10527 [Discriminator loss: 0.6785%, acc.: 60.55%] [Generator loss: 0.7893%]\n",
            "10528 [Discriminator loss: 0.6717%, acc.: 56.64%] [Generator loss: 0.7714%]\n",
            "10529 [Discriminator loss: 0.6797%, acc.: 59.38%] [Generator loss: 0.7671%]\n",
            "10530 [Discriminator loss: 0.6704%, acc.: 53.52%] [Generator loss: 0.7961%]\n",
            "10531 [Discriminator loss: 0.6667%, acc.: 61.72%] [Generator loss: 0.8021%]\n",
            "10532 [Discriminator loss: 0.6614%, acc.: 61.72%] [Generator loss: 0.7879%]\n",
            "10533 [Discriminator loss: 0.6733%, acc.: 59.38%] [Generator loss: 0.7858%]\n",
            "10534 [Discriminator loss: 0.6947%, acc.: 50.78%] [Generator loss: 0.7672%]\n",
            "10535 [Discriminator loss: 0.6864%, acc.: 55.47%] [Generator loss: 0.7941%]\n",
            "10536 [Discriminator loss: 0.6738%, acc.: 58.98%] [Generator loss: 0.7975%]\n",
            "10537 [Discriminator loss: 0.6663%, acc.: 58.20%] [Generator loss: 0.7768%]\n",
            "10538 [Discriminator loss: 0.6776%, acc.: 57.03%] [Generator loss: 0.7866%]\n",
            "10539 [Discriminator loss: 0.6692%, acc.: 57.42%] [Generator loss: 0.7738%]\n",
            "10540 [Discriminator loss: 0.6749%, acc.: 58.98%] [Generator loss: 0.7942%]\n",
            "10541 [Discriminator loss: 0.6573%, acc.: 67.97%] [Generator loss: 0.7907%]\n",
            "10542 [Discriminator loss: 0.6624%, acc.: 61.33%] [Generator loss: 0.8088%]\n",
            "10543 [Discriminator loss: 0.6676%, acc.: 60.16%] [Generator loss: 0.8028%]\n",
            "10544 [Discriminator loss: 0.6885%, acc.: 56.25%] [Generator loss: 0.8047%]\n",
            "10545 [Discriminator loss: 0.6715%, acc.: 56.64%] [Generator loss: 0.7796%]\n",
            "10546 [Discriminator loss: 0.6796%, acc.: 58.20%] [Generator loss: 0.7881%]\n",
            "10547 [Discriminator loss: 0.6679%, acc.: 57.03%] [Generator loss: 0.7959%]\n",
            "10548 [Discriminator loss: 0.6832%, acc.: 54.30%] [Generator loss: 0.7852%]\n",
            "10549 [Discriminator loss: 0.6769%, acc.: 54.69%] [Generator loss: 0.7726%]\n",
            "10550 [Discriminator loss: 0.6652%, acc.: 58.98%] [Generator loss: 0.7663%]\n",
            "10551 [Discriminator loss: 0.6748%, acc.: 55.47%] [Generator loss: 0.7663%]\n",
            "10552 [Discriminator loss: 0.6703%, acc.: 59.77%] [Generator loss: 0.8016%]\n",
            "10553 [Discriminator loss: 0.6777%, acc.: 54.69%] [Generator loss: 0.7867%]\n",
            "10554 [Discriminator loss: 0.6810%, acc.: 56.64%] [Generator loss: 0.7974%]\n",
            "10555 [Discriminator loss: 0.6782%, acc.: 56.64%] [Generator loss: 0.7524%]\n",
            "10556 [Discriminator loss: 0.6783%, acc.: 57.81%] [Generator loss: 0.7810%]\n",
            "10557 [Discriminator loss: 0.6771%, acc.: 55.86%] [Generator loss: 0.7867%]\n",
            "10558 [Discriminator loss: 0.6918%, acc.: 55.47%] [Generator loss: 0.7729%]\n",
            "10559 [Discriminator loss: 0.6644%, acc.: 59.77%] [Generator loss: 0.7723%]\n",
            "10560 [Discriminator loss: 0.6990%, acc.: 51.17%] [Generator loss: 0.7801%]\n",
            "10561 [Discriminator loss: 0.6910%, acc.: 50.39%] [Generator loss: 0.7761%]\n",
            "10562 [Discriminator loss: 0.6735%, acc.: 57.42%] [Generator loss: 0.7713%]\n",
            "10563 [Discriminator loss: 0.6854%, acc.: 53.52%] [Generator loss: 0.7815%]\n",
            "10564 [Discriminator loss: 0.6554%, acc.: 62.11%] [Generator loss: 0.8016%]\n",
            "10565 [Discriminator loss: 0.6710%, acc.: 60.94%] [Generator loss: 0.7903%]\n",
            "10566 [Discriminator loss: 0.6736%, acc.: 57.81%] [Generator loss: 0.8009%]\n",
            "10567 [Discriminator loss: 0.6781%, acc.: 58.98%] [Generator loss: 0.8040%]\n",
            "10568 [Discriminator loss: 0.6777%, acc.: 58.59%] [Generator loss: 0.7850%]\n",
            "10569 [Discriminator loss: 0.6726%, acc.: 61.33%] [Generator loss: 0.7910%]\n",
            "10570 [Discriminator loss: 0.6728%, acc.: 56.25%] [Generator loss: 0.7869%]\n",
            "10571 [Discriminator loss: 0.6870%, acc.: 55.86%] [Generator loss: 0.7998%]\n",
            "10572 [Discriminator loss: 0.6704%, acc.: 60.94%] [Generator loss: 0.7970%]\n",
            "10573 [Discriminator loss: 0.6556%, acc.: 62.11%] [Generator loss: 0.7715%]\n",
            "10574 [Discriminator loss: 0.6762%, acc.: 55.47%] [Generator loss: 0.7774%]\n",
            "10575 [Discriminator loss: 0.6806%, acc.: 59.38%] [Generator loss: 0.7838%]\n",
            "10576 [Discriminator loss: 0.6785%, acc.: 53.52%] [Generator loss: 0.7924%]\n",
            "10577 [Discriminator loss: 0.6693%, acc.: 54.69%] [Generator loss: 0.7777%]\n",
            "10578 [Discriminator loss: 0.6715%, acc.: 58.20%] [Generator loss: 0.7530%]\n",
            "10579 [Discriminator loss: 0.6777%, acc.: 55.08%] [Generator loss: 0.7818%]\n",
            "10580 [Discriminator loss: 0.6794%, acc.: 57.03%] [Generator loss: 0.7798%]\n",
            "10581 [Discriminator loss: 0.6750%, acc.: 57.03%] [Generator loss: 0.7705%]\n",
            "10582 [Discriminator loss: 0.6728%, acc.: 58.98%] [Generator loss: 0.7959%]\n",
            "10583 [Discriminator loss: 0.6691%, acc.: 58.59%] [Generator loss: 0.7839%]\n",
            "10584 [Discriminator loss: 0.6616%, acc.: 60.55%] [Generator loss: 0.7825%]\n",
            "10585 [Discriminator loss: 0.6545%, acc.: 60.55%] [Generator loss: 0.8002%]\n",
            "10586 [Discriminator loss: 0.6735%, acc.: 60.55%] [Generator loss: 0.7895%]\n",
            "10587 [Discriminator loss: 0.6619%, acc.: 61.72%] [Generator loss: 0.7851%]\n",
            "10588 [Discriminator loss: 0.6725%, acc.: 56.64%] [Generator loss: 0.7876%]\n",
            "10589 [Discriminator loss: 0.6835%, acc.: 54.30%] [Generator loss: 0.7934%]\n",
            "10590 [Discriminator loss: 0.6845%, acc.: 54.30%] [Generator loss: 0.7800%]\n",
            "10591 [Discriminator loss: 0.6681%, acc.: 58.98%] [Generator loss: 0.7706%]\n",
            "10592 [Discriminator loss: 0.6715%, acc.: 58.98%] [Generator loss: 0.7765%]\n",
            "10593 [Discriminator loss: 0.6781%, acc.: 56.25%] [Generator loss: 0.7913%]\n",
            "10594 [Discriminator loss: 0.6737%, acc.: 59.38%] [Generator loss: 0.7758%]\n",
            "10595 [Discriminator loss: 0.6791%, acc.: 57.03%] [Generator loss: 0.7877%]\n",
            "10596 [Discriminator loss: 0.6657%, acc.: 60.55%] [Generator loss: 0.7827%]\n",
            "10597 [Discriminator loss: 0.6513%, acc.: 63.67%] [Generator loss: 0.7760%]\n",
            "10598 [Discriminator loss: 0.6922%, acc.: 51.56%] [Generator loss: 0.7558%]\n",
            "10599 [Discriminator loss: 0.6760%, acc.: 57.42%] [Generator loss: 0.7682%]\n",
            "10600 [Discriminator loss: 0.6925%, acc.: 56.64%] [Generator loss: 0.7994%]\n",
            "10601 [Discriminator loss: 0.6600%, acc.: 64.06%] [Generator loss: 0.7863%]\n",
            "10602 [Discriminator loss: 0.6759%, acc.: 57.03%] [Generator loss: 0.7789%]\n",
            "10603 [Discriminator loss: 0.6815%, acc.: 60.16%] [Generator loss: 0.7821%]\n",
            "10604 [Discriminator loss: 0.6843%, acc.: 55.08%] [Generator loss: 0.7670%]\n",
            "10605 [Discriminator loss: 0.6661%, acc.: 59.38%] [Generator loss: 0.7754%]\n",
            "10606 [Discriminator loss: 0.6727%, acc.: 57.42%] [Generator loss: 0.7557%]\n",
            "10607 [Discriminator loss: 0.6764%, acc.: 59.77%] [Generator loss: 0.7943%]\n",
            "10608 [Discriminator loss: 0.6676%, acc.: 55.86%] [Generator loss: 0.7879%]\n",
            "10609 [Discriminator loss: 0.6715%, acc.: 58.59%] [Generator loss: 0.7556%]\n",
            "10610 [Discriminator loss: 0.6716%, acc.: 58.59%] [Generator loss: 0.7794%]\n",
            "10611 [Discriminator loss: 0.6942%, acc.: 51.56%] [Generator loss: 0.7862%]\n",
            "10612 [Discriminator loss: 0.6562%, acc.: 62.11%] [Generator loss: 0.7926%]\n",
            "10613 [Discriminator loss: 0.6893%, acc.: 53.52%] [Generator loss: 0.7941%]\n",
            "10614 [Discriminator loss: 0.6750%, acc.: 57.03%] [Generator loss: 0.7835%]\n",
            "10615 [Discriminator loss: 0.6834%, acc.: 56.64%] [Generator loss: 0.7694%]\n",
            "10616 [Discriminator loss: 0.6589%, acc.: 60.16%] [Generator loss: 0.8038%]\n",
            "10617 [Discriminator loss: 0.6768%, acc.: 55.08%] [Generator loss: 0.7911%]\n",
            "10618 [Discriminator loss: 0.6631%, acc.: 60.94%] [Generator loss: 0.7702%]\n",
            "10619 [Discriminator loss: 0.6605%, acc.: 61.33%] [Generator loss: 0.7835%]\n",
            "10620 [Discriminator loss: 0.6476%, acc.: 62.89%] [Generator loss: 0.7708%]\n",
            "10621 [Discriminator loss: 0.6857%, acc.: 53.52%] [Generator loss: 0.7743%]\n",
            "10622 [Discriminator loss: 0.6821%, acc.: 57.81%] [Generator loss: 0.7710%]\n",
            "10623 [Discriminator loss: 0.6770%, acc.: 58.98%] [Generator loss: 0.7743%]\n",
            "10624 [Discriminator loss: 0.6838%, acc.: 57.42%] [Generator loss: 0.7734%]\n",
            "10625 [Discriminator loss: 0.6802%, acc.: 57.42%] [Generator loss: 0.7929%]\n",
            "10626 [Discriminator loss: 0.6593%, acc.: 60.55%] [Generator loss: 0.7907%]\n",
            "10627 [Discriminator loss: 0.6711%, acc.: 60.16%] [Generator loss: 0.7970%]\n",
            "10628 [Discriminator loss: 0.6662%, acc.: 59.38%] [Generator loss: 0.7600%]\n",
            "10629 [Discriminator loss: 0.6870%, acc.: 53.91%] [Generator loss: 0.7742%]\n",
            "10630 [Discriminator loss: 0.6768%, acc.: 58.59%] [Generator loss: 0.8042%]\n",
            "10631 [Discriminator loss: 0.6643%, acc.: 57.81%] [Generator loss: 0.7777%]\n",
            "10632 [Discriminator loss: 0.6780%, acc.: 57.42%] [Generator loss: 0.8013%]\n",
            "10633 [Discriminator loss: 0.6590%, acc.: 62.50%] [Generator loss: 0.8159%]\n",
            "10634 [Discriminator loss: 0.6718%, acc.: 56.64%] [Generator loss: 0.7916%]\n",
            "10635 [Discriminator loss: 0.6731%, acc.: 57.03%] [Generator loss: 0.7762%]\n",
            "10636 [Discriminator loss: 0.6803%, acc.: 57.42%] [Generator loss: 0.8013%]\n",
            "10637 [Discriminator loss: 0.6632%, acc.: 64.84%] [Generator loss: 0.8152%]\n",
            "10638 [Discriminator loss: 0.6854%, acc.: 57.03%] [Generator loss: 0.8036%]\n",
            "10639 [Discriminator loss: 0.6688%, acc.: 63.28%] [Generator loss: 0.7858%]\n",
            "10640 [Discriminator loss: 0.6865%, acc.: 55.86%] [Generator loss: 0.7729%]\n",
            "10641 [Discriminator loss: 0.6608%, acc.: 61.33%] [Generator loss: 0.7966%]\n",
            "10642 [Discriminator loss: 0.6753%, acc.: 54.69%] [Generator loss: 0.7728%]\n",
            "10643 [Discriminator loss: 0.6482%, acc.: 67.19%] [Generator loss: 0.8093%]\n",
            "10644 [Discriminator loss: 0.6811%, acc.: 56.25%] [Generator loss: 0.8180%]\n",
            "10645 [Discriminator loss: 0.6661%, acc.: 60.55%] [Generator loss: 0.7796%]\n",
            "10646 [Discriminator loss: 0.6728%, acc.: 56.25%] [Generator loss: 0.7842%]\n",
            "10647 [Discriminator loss: 0.6625%, acc.: 64.45%] [Generator loss: 0.7752%]\n",
            "10648 [Discriminator loss: 0.6562%, acc.: 61.72%] [Generator loss: 0.7797%]\n",
            "10649 [Discriminator loss: 0.6766%, acc.: 57.81%] [Generator loss: 0.7763%]\n",
            "10650 [Discriminator loss: 0.6832%, acc.: 58.98%] [Generator loss: 0.7770%]\n",
            "10651 [Discriminator loss: 0.6703%, acc.: 60.16%] [Generator loss: 0.7748%]\n",
            "10652 [Discriminator loss: 0.6772%, acc.: 57.81%] [Generator loss: 0.7623%]\n",
            "10653 [Discriminator loss: 0.6654%, acc.: 59.38%] [Generator loss: 0.7749%]\n",
            "10654 [Discriminator loss: 0.6831%, acc.: 52.34%] [Generator loss: 0.7758%]\n",
            "10655 [Discriminator loss: 0.6765%, acc.: 57.03%] [Generator loss: 0.7970%]\n",
            "10656 [Discriminator loss: 0.6803%, acc.: 57.03%] [Generator loss: 0.8084%]\n",
            "10657 [Discriminator loss: 0.6695%, acc.: 59.38%] [Generator loss: 0.7981%]\n",
            "10658 [Discriminator loss: 0.6880%, acc.: 52.73%] [Generator loss: 0.8045%]\n",
            "10659 [Discriminator loss: 0.6637%, acc.: 56.25%] [Generator loss: 0.7896%]\n",
            "10660 [Discriminator loss: 0.6667%, acc.: 58.59%] [Generator loss: 0.8004%]\n",
            "10661 [Discriminator loss: 0.6777%, acc.: 58.20%] [Generator loss: 0.8226%]\n",
            "10662 [Discriminator loss: 0.6576%, acc.: 62.11%] [Generator loss: 0.7671%]\n",
            "10663 [Discriminator loss: 0.6896%, acc.: 55.08%] [Generator loss: 0.7596%]\n",
            "10664 [Discriminator loss: 0.6928%, acc.: 52.34%] [Generator loss: 0.7804%]\n",
            "10665 [Discriminator loss: 0.6773%, acc.: 55.86%] [Generator loss: 0.7792%]\n",
            "10666 [Discriminator loss: 0.6673%, acc.: 56.25%] [Generator loss: 0.7632%]\n",
            "10667 [Discriminator loss: 0.6613%, acc.: 59.77%] [Generator loss: 0.7925%]\n",
            "10668 [Discriminator loss: 0.6763%, acc.: 55.08%] [Generator loss: 0.7950%]\n",
            "10669 [Discriminator loss: 0.6648%, acc.: 62.50%] [Generator loss: 0.7451%]\n",
            "10670 [Discriminator loss: 0.6801%, acc.: 52.34%] [Generator loss: 0.7881%]\n",
            "10671 [Discriminator loss: 0.6711%, acc.: 55.86%] [Generator loss: 0.7962%]\n",
            "10672 [Discriminator loss: 0.6751%, acc.: 55.47%] [Generator loss: 0.7866%]\n",
            "10673 [Discriminator loss: 0.6678%, acc.: 59.77%] [Generator loss: 0.7783%]\n",
            "10674 [Discriminator loss: 0.6775%, acc.: 58.59%] [Generator loss: 0.8012%]\n",
            "10675 [Discriminator loss: 0.6897%, acc.: 51.95%] [Generator loss: 0.7540%]\n",
            "10676 [Discriminator loss: 0.6863%, acc.: 57.42%] [Generator loss: 0.7887%]\n",
            "10677 [Discriminator loss: 0.6817%, acc.: 55.08%] [Generator loss: 0.7781%]\n",
            "10678 [Discriminator loss: 0.6735%, acc.: 55.86%] [Generator loss: 0.7637%]\n",
            "10679 [Discriminator loss: 0.6801%, acc.: 57.42%] [Generator loss: 0.7639%]\n",
            "10680 [Discriminator loss: 0.6843%, acc.: 55.47%] [Generator loss: 0.7744%]\n",
            "10681 [Discriminator loss: 0.6757%, acc.: 58.98%] [Generator loss: 0.7680%]\n",
            "10682 [Discriminator loss: 0.6732%, acc.: 55.08%] [Generator loss: 0.7858%]\n",
            "10683 [Discriminator loss: 0.6793%, acc.: 59.77%] [Generator loss: 0.7765%]\n",
            "10684 [Discriminator loss: 0.6784%, acc.: 55.86%] [Generator loss: 0.7649%]\n",
            "10685 [Discriminator loss: 0.6635%, acc.: 61.72%] [Generator loss: 0.7793%]\n",
            "10686 [Discriminator loss: 0.6665%, acc.: 59.38%] [Generator loss: 0.7970%]\n",
            "10687 [Discriminator loss: 0.6794%, acc.: 57.42%] [Generator loss: 0.7920%]\n",
            "10688 [Discriminator loss: 0.6837%, acc.: 56.25%] [Generator loss: 0.7754%]\n",
            "10689 [Discriminator loss: 0.6861%, acc.: 53.91%] [Generator loss: 0.7973%]\n",
            "10690 [Discriminator loss: 0.6948%, acc.: 51.56%] [Generator loss: 0.7829%]\n",
            "10691 [Discriminator loss: 0.6523%, acc.: 62.50%] [Generator loss: 0.7841%]\n",
            "10692 [Discriminator loss: 0.6824%, acc.: 53.91%] [Generator loss: 0.7789%]\n",
            "10693 [Discriminator loss: 0.6803%, acc.: 58.20%] [Generator loss: 0.8044%]\n",
            "10694 [Discriminator loss: 0.6494%, acc.: 65.62%] [Generator loss: 0.7831%]\n",
            "10695 [Discriminator loss: 0.6797%, acc.: 57.42%] [Generator loss: 0.7674%]\n",
            "10696 [Discriminator loss: 0.6660%, acc.: 57.81%] [Generator loss: 0.7447%]\n",
            "10697 [Discriminator loss: 0.6703%, acc.: 57.81%] [Generator loss: 0.7555%]\n",
            "10698 [Discriminator loss: 0.6915%, acc.: 54.30%] [Generator loss: 0.7774%]\n",
            "10699 [Discriminator loss: 0.6802%, acc.: 55.86%] [Generator loss: 0.7828%]\n",
            "10700 [Discriminator loss: 0.6685%, acc.: 56.64%] [Generator loss: 0.7618%]\n",
            "10701 [Discriminator loss: 0.6886%, acc.: 54.69%] [Generator loss: 0.7815%]\n",
            "10702 [Discriminator loss: 0.6664%, acc.: 61.33%] [Generator loss: 0.7747%]\n",
            "10703 [Discriminator loss: 0.6681%, acc.: 58.59%] [Generator loss: 0.7789%]\n",
            "10704 [Discriminator loss: 0.6633%, acc.: 59.38%] [Generator loss: 0.7729%]\n",
            "10705 [Discriminator loss: 0.6670%, acc.: 58.98%] [Generator loss: 0.7677%]\n",
            "10706 [Discriminator loss: 0.6754%, acc.: 59.38%] [Generator loss: 0.7634%]\n",
            "10707 [Discriminator loss: 0.6931%, acc.: 50.78%] [Generator loss: 0.7837%]\n",
            "10708 [Discriminator loss: 0.6812%, acc.: 57.42%] [Generator loss: 0.7766%]\n",
            "10709 [Discriminator loss: 0.6767%, acc.: 59.38%] [Generator loss: 0.7890%]\n",
            "10710 [Discriminator loss: 0.6725%, acc.: 57.42%] [Generator loss: 0.7833%]\n",
            "10711 [Discriminator loss: 0.6778%, acc.: 57.81%] [Generator loss: 0.8086%]\n",
            "10712 [Discriminator loss: 0.6781%, acc.: 58.98%] [Generator loss: 0.7620%]\n",
            "10713 [Discriminator loss: 0.6715%, acc.: 60.16%] [Generator loss: 0.7645%]\n",
            "10714 [Discriminator loss: 0.6874%, acc.: 57.81%] [Generator loss: 0.7600%]\n",
            "10715 [Discriminator loss: 0.6774%, acc.: 57.81%] [Generator loss: 0.7664%]\n",
            "10716 [Discriminator loss: 0.6897%, acc.: 58.98%] [Generator loss: 0.7687%]\n",
            "10717 [Discriminator loss: 0.7009%, acc.: 50.78%] [Generator loss: 0.7771%]\n",
            "10718 [Discriminator loss: 0.6599%, acc.: 60.55%] [Generator loss: 0.7548%]\n",
            "10719 [Discriminator loss: 0.6755%, acc.: 59.38%] [Generator loss: 0.7811%]\n",
            "10720 [Discriminator loss: 0.6833%, acc.: 57.42%] [Generator loss: 0.7614%]\n",
            "10721 [Discriminator loss: 0.6485%, acc.: 63.28%] [Generator loss: 0.7567%]\n",
            "10722 [Discriminator loss: 0.6572%, acc.: 60.55%] [Generator loss: 0.7938%]\n",
            "10723 [Discriminator loss: 0.6911%, acc.: 51.56%] [Generator loss: 0.7642%]\n",
            "10724 [Discriminator loss: 0.6722%, acc.: 59.38%] [Generator loss: 0.7656%]\n",
            "10725 [Discriminator loss: 0.6584%, acc.: 57.42%] [Generator loss: 0.7838%]\n",
            "10726 [Discriminator loss: 0.6573%, acc.: 62.89%] [Generator loss: 0.7658%]\n",
            "10727 [Discriminator loss: 0.6776%, acc.: 53.91%] [Generator loss: 0.7899%]\n",
            "10728 [Discriminator loss: 0.6788%, acc.: 55.08%] [Generator loss: 0.7810%]\n",
            "10729 [Discriminator loss: 0.6693%, acc.: 57.42%] [Generator loss: 0.7766%]\n",
            "10730 [Discriminator loss: 0.6739%, acc.: 58.59%] [Generator loss: 0.8039%]\n",
            "10731 [Discriminator loss: 0.6662%, acc.: 60.55%] [Generator loss: 0.7887%]\n",
            "10732 [Discriminator loss: 0.6827%, acc.: 54.30%] [Generator loss: 0.7770%]\n",
            "10733 [Discriminator loss: 0.6710%, acc.: 58.59%] [Generator loss: 0.7929%]\n",
            "10734 [Discriminator loss: 0.6791%, acc.: 57.42%] [Generator loss: 0.7988%]\n",
            "10735 [Discriminator loss: 0.6681%, acc.: 55.86%] [Generator loss: 0.7834%]\n",
            "10736 [Discriminator loss: 0.6783%, acc.: 57.03%] [Generator loss: 0.7910%]\n",
            "10737 [Discriminator loss: 0.6766%, acc.: 57.42%] [Generator loss: 0.7795%]\n",
            "10738 [Discriminator loss: 0.6730%, acc.: 57.81%] [Generator loss: 0.7940%]\n",
            "10739 [Discriminator loss: 0.6811%, acc.: 56.64%] [Generator loss: 0.7936%]\n",
            "10740 [Discriminator loss: 0.6674%, acc.: 58.20%] [Generator loss: 0.7965%]\n",
            "10741 [Discriminator loss: 0.6764%, acc.: 58.20%] [Generator loss: 0.7776%]\n",
            "10742 [Discriminator loss: 0.6758%, acc.: 54.69%] [Generator loss: 0.7750%]\n",
            "10743 [Discriminator loss: 0.6856%, acc.: 56.25%] [Generator loss: 0.7776%]\n",
            "10744 [Discriminator loss: 0.6678%, acc.: 60.55%] [Generator loss: 0.7896%]\n",
            "10745 [Discriminator loss: 0.6808%, acc.: 54.30%] [Generator loss: 0.8019%]\n",
            "10746 [Discriminator loss: 0.6713%, acc.: 61.72%] [Generator loss: 0.8034%]\n",
            "10747 [Discriminator loss: 0.6808%, acc.: 53.52%] [Generator loss: 0.7991%]\n",
            "10748 [Discriminator loss: 0.6688%, acc.: 57.42%] [Generator loss: 0.7817%]\n",
            "10749 [Discriminator loss: 0.6574%, acc.: 59.77%] [Generator loss: 0.7477%]\n",
            "10750 [Discriminator loss: 0.6896%, acc.: 55.08%] [Generator loss: 0.7695%]\n",
            "10751 [Discriminator loss: 0.6711%, acc.: 58.98%] [Generator loss: 0.7777%]\n",
            "10752 [Discriminator loss: 0.6836%, acc.: 55.47%] [Generator loss: 0.7854%]\n",
            "10753 [Discriminator loss: 0.6861%, acc.: 51.95%] [Generator loss: 0.7841%]\n",
            "10754 [Discriminator loss: 0.6666%, acc.: 55.86%] [Generator loss: 0.7953%]\n",
            "10755 [Discriminator loss: 0.6851%, acc.: 53.52%] [Generator loss: 0.7781%]\n",
            "10756 [Discriminator loss: 0.6714%, acc.: 58.20%] [Generator loss: 0.7719%]\n",
            "10757 [Discriminator loss: 0.6774%, acc.: 53.91%] [Generator loss: 0.7614%]\n",
            "10758 [Discriminator loss: 0.6879%, acc.: 53.91%] [Generator loss: 0.7966%]\n",
            "10759 [Discriminator loss: 0.6580%, acc.: 57.81%] [Generator loss: 0.8009%]\n",
            "10760 [Discriminator loss: 0.6760%, acc.: 57.81%] [Generator loss: 0.7495%]\n",
            "10761 [Discriminator loss: 0.6855%, acc.: 50.78%] [Generator loss: 0.7858%]\n",
            "10762 [Discriminator loss: 0.6775%, acc.: 56.64%] [Generator loss: 0.7938%]\n",
            "10763 [Discriminator loss: 0.6650%, acc.: 60.16%] [Generator loss: 0.7651%]\n",
            "10764 [Discriminator loss: 0.6765%, acc.: 56.25%] [Generator loss: 0.7963%]\n",
            "10765 [Discriminator loss: 0.6670%, acc.: 59.38%] [Generator loss: 0.8014%]\n",
            "10766 [Discriminator loss: 0.6765%, acc.: 61.33%] [Generator loss: 0.7679%]\n",
            "10767 [Discriminator loss: 0.6781%, acc.: 57.42%] [Generator loss: 0.7831%]\n",
            "10768 [Discriminator loss: 0.6813%, acc.: 52.73%] [Generator loss: 0.7990%]\n",
            "10769 [Discriminator loss: 0.6876%, acc.: 56.25%] [Generator loss: 0.7587%]\n",
            "10770 [Discriminator loss: 0.6765%, acc.: 57.81%] [Generator loss: 0.7913%]\n",
            "10771 [Discriminator loss: 0.6678%, acc.: 62.50%] [Generator loss: 0.7881%]\n",
            "10772 [Discriminator loss: 0.6817%, acc.: 56.25%] [Generator loss: 0.7859%]\n",
            "10773 [Discriminator loss: 0.6643%, acc.: 55.47%] [Generator loss: 0.8087%]\n",
            "10774 [Discriminator loss: 0.6803%, acc.: 57.81%] [Generator loss: 0.7713%]\n",
            "10775 [Discriminator loss: 0.6874%, acc.: 54.69%] [Generator loss: 0.7887%]\n",
            "10776 [Discriminator loss: 0.6894%, acc.: 53.91%] [Generator loss: 0.7961%]\n",
            "10777 [Discriminator loss: 0.6739%, acc.: 59.77%] [Generator loss: 0.8114%]\n",
            "10778 [Discriminator loss: 0.6706%, acc.: 60.16%] [Generator loss: 0.7868%]\n",
            "10779 [Discriminator loss: 0.6805%, acc.: 53.12%] [Generator loss: 0.8107%]\n",
            "10780 [Discriminator loss: 0.6808%, acc.: 56.64%] [Generator loss: 0.7914%]\n",
            "10781 [Discriminator loss: 0.6817%, acc.: 58.98%] [Generator loss: 0.7887%]\n",
            "10782 [Discriminator loss: 0.6767%, acc.: 57.03%] [Generator loss: 0.7708%]\n",
            "10783 [Discriminator loss: 0.6588%, acc.: 60.55%] [Generator loss: 0.7791%]\n",
            "10784 [Discriminator loss: 0.6623%, acc.: 63.67%] [Generator loss: 0.7839%]\n",
            "10785 [Discriminator loss: 0.6638%, acc.: 62.50%] [Generator loss: 0.7581%]\n",
            "10786 [Discriminator loss: 0.6794%, acc.: 52.73%] [Generator loss: 0.7856%]\n",
            "10787 [Discriminator loss: 0.6740%, acc.: 58.59%] [Generator loss: 0.8008%]\n",
            "10788 [Discriminator loss: 0.6732%, acc.: 62.50%] [Generator loss: 0.7846%]\n",
            "10789 [Discriminator loss: 0.6698%, acc.: 58.98%] [Generator loss: 0.8236%]\n",
            "10790 [Discriminator loss: 0.6804%, acc.: 57.03%] [Generator loss: 0.7851%]\n",
            "10791 [Discriminator loss: 0.6624%, acc.: 62.11%] [Generator loss: 0.7571%]\n",
            "10792 [Discriminator loss: 0.6849%, acc.: 55.86%] [Generator loss: 0.7428%]\n",
            "10793 [Discriminator loss: 0.6843%, acc.: 53.52%] [Generator loss: 0.7686%]\n",
            "10794 [Discriminator loss: 0.6844%, acc.: 54.69%] [Generator loss: 0.7754%]\n",
            "10795 [Discriminator loss: 0.6681%, acc.: 60.94%] [Generator loss: 0.7935%]\n",
            "10796 [Discriminator loss: 0.6811%, acc.: 56.25%] [Generator loss: 0.8205%]\n",
            "10797 [Discriminator loss: 0.6832%, acc.: 54.69%] [Generator loss: 0.7820%]\n",
            "10798 [Discriminator loss: 0.6672%, acc.: 61.33%] [Generator loss: 0.7987%]\n",
            "10799 [Discriminator loss: 0.6784%, acc.: 57.81%] [Generator loss: 0.7992%]\n",
            "10800 [Discriminator loss: 0.6532%, acc.: 61.33%] [Generator loss: 0.7901%]\n",
            "10801 [Discriminator loss: 0.6622%, acc.: 63.67%] [Generator loss: 0.8319%]\n",
            "10802 [Discriminator loss: 0.6503%, acc.: 62.11%] [Generator loss: 0.7907%]\n",
            "10803 [Discriminator loss: 0.6788%, acc.: 58.20%] [Generator loss: 0.7876%]\n",
            "10804 [Discriminator loss: 0.6792%, acc.: 56.25%] [Generator loss: 0.7826%]\n",
            "10805 [Discriminator loss: 0.6913%, acc.: 56.25%] [Generator loss: 0.7526%]\n",
            "10806 [Discriminator loss: 0.6683%, acc.: 60.55%] [Generator loss: 0.7492%]\n",
            "10807 [Discriminator loss: 0.6805%, acc.: 57.42%] [Generator loss: 0.7685%]\n",
            "10808 [Discriminator loss: 0.6759%, acc.: 57.42%] [Generator loss: 0.7927%]\n",
            "10809 [Discriminator loss: 0.6597%, acc.: 63.28%] [Generator loss: 0.7831%]\n",
            "10810 [Discriminator loss: 0.6563%, acc.: 60.94%] [Generator loss: 0.7617%]\n",
            "10811 [Discriminator loss: 0.6660%, acc.: 58.59%] [Generator loss: 0.7983%]\n",
            "10812 [Discriminator loss: 0.6774%, acc.: 59.77%] [Generator loss: 0.7799%]\n",
            "10813 [Discriminator loss: 0.6848%, acc.: 58.20%] [Generator loss: 0.8001%]\n",
            "10814 [Discriminator loss: 0.6689%, acc.: 61.33%] [Generator loss: 0.7924%]\n",
            "10815 [Discriminator loss: 0.6831%, acc.: 57.03%] [Generator loss: 0.7815%]\n",
            "10816 [Discriminator loss: 0.6747%, acc.: 59.38%] [Generator loss: 0.7912%]\n",
            "10817 [Discriminator loss: 0.6651%, acc.: 62.89%] [Generator loss: 0.7937%]\n",
            "10818 [Discriminator loss: 0.6665%, acc.: 57.42%] [Generator loss: 0.7818%]\n",
            "10819 [Discriminator loss: 0.6755%, acc.: 57.03%] [Generator loss: 0.7777%]\n",
            "10820 [Discriminator loss: 0.6821%, acc.: 53.52%] [Generator loss: 0.7859%]\n",
            "10821 [Discriminator loss: 0.6795%, acc.: 58.98%] [Generator loss: 0.7981%]\n",
            "10822 [Discriminator loss: 0.6618%, acc.: 63.67%] [Generator loss: 0.7870%]\n",
            "10823 [Discriminator loss: 0.6607%, acc.: 60.94%] [Generator loss: 0.7930%]\n",
            "10824 [Discriminator loss: 0.6738%, acc.: 58.59%] [Generator loss: 0.7831%]\n",
            "10825 [Discriminator loss: 0.6722%, acc.: 61.33%] [Generator loss: 0.8094%]\n",
            "10826 [Discriminator loss: 0.6793%, acc.: 57.42%] [Generator loss: 0.7818%]\n",
            "10827 [Discriminator loss: 0.6776%, acc.: 60.94%] [Generator loss: 0.7898%]\n",
            "10828 [Discriminator loss: 0.6684%, acc.: 60.55%] [Generator loss: 0.7503%]\n",
            "10829 [Discriminator loss: 0.6886%, acc.: 54.69%] [Generator loss: 0.7628%]\n",
            "10830 [Discriminator loss: 0.6701%, acc.: 56.25%] [Generator loss: 0.7875%]\n",
            "10831 [Discriminator loss: 0.6737%, acc.: 58.59%] [Generator loss: 0.8012%]\n",
            "10832 [Discriminator loss: 0.6699%, acc.: 56.25%] [Generator loss: 0.7725%]\n",
            "10833 [Discriminator loss: 0.6838%, acc.: 56.25%] [Generator loss: 0.7699%]\n",
            "10834 [Discriminator loss: 0.6689%, acc.: 58.59%] [Generator loss: 0.7568%]\n",
            "10835 [Discriminator loss: 0.6949%, acc.: 53.52%] [Generator loss: 0.7777%]\n",
            "10836 [Discriminator loss: 0.6909%, acc.: 50.39%] [Generator loss: 0.7783%]\n",
            "10837 [Discriminator loss: 0.6834%, acc.: 53.91%] [Generator loss: 0.7797%]\n",
            "10838 [Discriminator loss: 0.6582%, acc.: 62.11%] [Generator loss: 0.8037%]\n",
            "10839 [Discriminator loss: 0.6637%, acc.: 59.77%] [Generator loss: 0.8131%]\n",
            "10840 [Discriminator loss: 0.6719%, acc.: 52.73%] [Generator loss: 0.7982%]\n",
            "10841 [Discriminator loss: 0.6763%, acc.: 53.91%] [Generator loss: 0.7774%]\n",
            "10842 [Discriminator loss: 0.6684%, acc.: 62.11%] [Generator loss: 0.7787%]\n",
            "10843 [Discriminator loss: 0.6711%, acc.: 58.59%] [Generator loss: 0.8104%]\n",
            "10844 [Discriminator loss: 0.6619%, acc.: 60.16%] [Generator loss: 0.7920%]\n",
            "10845 [Discriminator loss: 0.6635%, acc.: 61.72%] [Generator loss: 0.7960%]\n",
            "10846 [Discriminator loss: 0.6591%, acc.: 60.94%] [Generator loss: 0.7931%]\n",
            "10847 [Discriminator loss: 0.6817%, acc.: 58.20%] [Generator loss: 0.7947%]\n",
            "10848 [Discriminator loss: 0.6857%, acc.: 53.91%] [Generator loss: 0.7578%]\n",
            "10849 [Discriminator loss: 0.6774%, acc.: 56.64%] [Generator loss: 0.7856%]\n",
            "10850 [Discriminator loss: 0.6807%, acc.: 54.30%] [Generator loss: 0.7579%]\n",
            "10851 [Discriminator loss: 0.6706%, acc.: 55.47%] [Generator loss: 0.7764%]\n",
            "10852 [Discriminator loss: 0.6676%, acc.: 58.98%] [Generator loss: 0.7790%]\n",
            "10853 [Discriminator loss: 0.6664%, acc.: 60.16%] [Generator loss: 0.7765%]\n",
            "10854 [Discriminator loss: 0.6502%, acc.: 62.89%] [Generator loss: 0.7646%]\n",
            "10855 [Discriminator loss: 0.6743%, acc.: 59.77%] [Generator loss: 0.7453%]\n",
            "10856 [Discriminator loss: 0.6827%, acc.: 54.30%] [Generator loss: 0.7866%]\n",
            "10857 [Discriminator loss: 0.6904%, acc.: 53.52%] [Generator loss: 0.7797%]\n",
            "10858 [Discriminator loss: 0.6618%, acc.: 66.80%] [Generator loss: 0.7600%]\n",
            "10859 [Discriminator loss: 0.6785%, acc.: 51.56%] [Generator loss: 0.7881%]\n",
            "10860 [Discriminator loss: 0.6798%, acc.: 55.86%] [Generator loss: 0.7693%]\n",
            "10861 [Discriminator loss: 0.6733%, acc.: 57.03%] [Generator loss: 0.8124%]\n",
            "10862 [Discriminator loss: 0.6635%, acc.: 59.38%] [Generator loss: 0.7913%]\n",
            "10863 [Discriminator loss: 0.6608%, acc.: 60.55%] [Generator loss: 0.7988%]\n",
            "10864 [Discriminator loss: 0.6511%, acc.: 64.84%] [Generator loss: 0.7635%]\n",
            "10865 [Discriminator loss: 0.6767%, acc.: 56.64%] [Generator loss: 0.7688%]\n",
            "10866 [Discriminator loss: 0.6677%, acc.: 60.16%] [Generator loss: 0.7857%]\n",
            "10867 [Discriminator loss: 0.6790%, acc.: 57.03%] [Generator loss: 0.7608%]\n",
            "10868 [Discriminator loss: 0.6666%, acc.: 60.16%] [Generator loss: 0.7716%]\n",
            "10869 [Discriminator loss: 0.6764%, acc.: 55.47%] [Generator loss: 0.7779%]\n",
            "10870 [Discriminator loss: 0.6670%, acc.: 58.59%] [Generator loss: 0.7704%]\n",
            "10871 [Discriminator loss: 0.6784%, acc.: 59.77%] [Generator loss: 0.8089%]\n",
            "10872 [Discriminator loss: 0.6897%, acc.: 55.47%] [Generator loss: 0.7850%]\n",
            "10873 [Discriminator loss: 0.6826%, acc.: 57.03%] [Generator loss: 0.7861%]\n",
            "10874 [Discriminator loss: 0.6771%, acc.: 57.03%] [Generator loss: 0.7721%]\n",
            "10875 [Discriminator loss: 0.6774%, acc.: 56.64%] [Generator loss: 0.7855%]\n",
            "10876 [Discriminator loss: 0.6829%, acc.: 55.47%] [Generator loss: 0.7678%]\n",
            "10877 [Discriminator loss: 0.6790%, acc.: 56.64%] [Generator loss: 0.7743%]\n",
            "10878 [Discriminator loss: 0.6596%, acc.: 58.98%] [Generator loss: 0.8366%]\n",
            "10879 [Discriminator loss: 0.6707%, acc.: 59.77%] [Generator loss: 0.8014%]\n",
            "10880 [Discriminator loss: 0.6792%, acc.: 60.94%] [Generator loss: 0.7584%]\n",
            "10881 [Discriminator loss: 0.6681%, acc.: 60.55%] [Generator loss: 0.7537%]\n",
            "10882 [Discriminator loss: 0.6910%, acc.: 55.86%] [Generator loss: 0.7708%]\n",
            "10883 [Discriminator loss: 0.6877%, acc.: 55.47%] [Generator loss: 0.7569%]\n",
            "10884 [Discriminator loss: 0.6829%, acc.: 56.64%] [Generator loss: 0.8007%]\n",
            "10885 [Discriminator loss: 0.6819%, acc.: 52.34%] [Generator loss: 0.7859%]\n",
            "10886 [Discriminator loss: 0.6660%, acc.: 63.28%] [Generator loss: 0.7930%]\n",
            "10887 [Discriminator loss: 0.6881%, acc.: 52.73%] [Generator loss: 0.8249%]\n",
            "10888 [Discriminator loss: 0.6643%, acc.: 55.86%] [Generator loss: 0.8040%]\n",
            "10889 [Discriminator loss: 0.6880%, acc.: 55.08%] [Generator loss: 0.8015%]\n",
            "10890 [Discriminator loss: 0.6862%, acc.: 56.64%] [Generator loss: 0.8016%]\n",
            "10891 [Discriminator loss: 0.6860%, acc.: 54.30%] [Generator loss: 0.7830%]\n",
            "10892 [Discriminator loss: 0.6761%, acc.: 57.81%] [Generator loss: 0.7778%]\n",
            "10893 [Discriminator loss: 0.6745%, acc.: 59.77%] [Generator loss: 0.7908%]\n",
            "10894 [Discriminator loss: 0.6637%, acc.: 63.67%] [Generator loss: 0.7696%]\n",
            "10895 [Discriminator loss: 0.6557%, acc.: 62.50%] [Generator loss: 0.7995%]\n",
            "10896 [Discriminator loss: 0.6639%, acc.: 66.41%] [Generator loss: 0.8117%]\n",
            "10897 [Discriminator loss: 0.6667%, acc.: 58.59%] [Generator loss: 0.7800%]\n",
            "10898 [Discriminator loss: 0.6578%, acc.: 64.06%] [Generator loss: 0.7903%]\n",
            "10899 [Discriminator loss: 0.6615%, acc.: 58.20%] [Generator loss: 0.8015%]\n",
            "10900 [Discriminator loss: 0.6718%, acc.: 60.16%] [Generator loss: 0.7974%]\n",
            "10901 [Discriminator loss: 0.6615%, acc.: 60.94%] [Generator loss: 0.7843%]\n",
            "10902 [Discriminator loss: 0.6622%, acc.: 60.55%] [Generator loss: 0.7935%]\n",
            "10903 [Discriminator loss: 0.6844%, acc.: 55.47%] [Generator loss: 0.7961%]\n",
            "10904 [Discriminator loss: 0.6609%, acc.: 62.11%] [Generator loss: 0.7813%]\n",
            "10905 [Discriminator loss: 0.6575%, acc.: 59.77%] [Generator loss: 0.7823%]\n",
            "10906 [Discriminator loss: 0.6728%, acc.: 57.03%] [Generator loss: 0.7802%]\n",
            "10907 [Discriminator loss: 0.6626%, acc.: 58.59%] [Generator loss: 0.7826%]\n",
            "10908 [Discriminator loss: 0.6668%, acc.: 59.38%] [Generator loss: 0.8049%]\n",
            "10909 [Discriminator loss: 0.6654%, acc.: 57.42%] [Generator loss: 0.8093%]\n",
            "10910 [Discriminator loss: 0.6627%, acc.: 58.20%] [Generator loss: 0.7997%]\n",
            "10911 [Discriminator loss: 0.6905%, acc.: 53.52%] [Generator loss: 0.7921%]\n",
            "10912 [Discriminator loss: 0.6701%, acc.: 58.98%] [Generator loss: 0.7876%]\n",
            "10913 [Discriminator loss: 0.6688%, acc.: 57.81%] [Generator loss: 0.7664%]\n",
            "10914 [Discriminator loss: 0.6702%, acc.: 60.16%] [Generator loss: 0.7739%]\n",
            "10915 [Discriminator loss: 0.6721%, acc.: 58.59%] [Generator loss: 0.7761%]\n",
            "10916 [Discriminator loss: 0.6946%, acc.: 51.56%] [Generator loss: 0.7941%]\n",
            "10917 [Discriminator loss: 0.6983%, acc.: 53.12%] [Generator loss: 0.8066%]\n",
            "10918 [Discriminator loss: 0.6670%, acc.: 58.98%] [Generator loss: 0.7817%]\n",
            "10919 [Discriminator loss: 0.6760%, acc.: 55.08%] [Generator loss: 0.7862%]\n",
            "10920 [Discriminator loss: 0.6609%, acc.: 61.33%] [Generator loss: 0.7720%]\n",
            "10921 [Discriminator loss: 0.6618%, acc.: 59.38%] [Generator loss: 0.7968%]\n",
            "10922 [Discriminator loss: 0.6831%, acc.: 54.69%] [Generator loss: 0.7829%]\n",
            "10923 [Discriminator loss: 0.6622%, acc.: 58.20%] [Generator loss: 0.7710%]\n",
            "10924 [Discriminator loss: 0.6608%, acc.: 60.55%] [Generator loss: 0.7810%]\n",
            "10925 [Discriminator loss: 0.6645%, acc.: 60.55%] [Generator loss: 0.7579%]\n",
            "10926 [Discriminator loss: 0.6716%, acc.: 55.08%] [Generator loss: 0.7962%]\n",
            "10927 [Discriminator loss: 0.6691%, acc.: 62.11%] [Generator loss: 0.7727%]\n",
            "10928 [Discriminator loss: 0.6757%, acc.: 58.98%] [Generator loss: 0.7634%]\n",
            "10929 [Discriminator loss: 0.6776%, acc.: 56.25%] [Generator loss: 0.7759%]\n",
            "10930 [Discriminator loss: 0.6687%, acc.: 58.98%] [Generator loss: 0.7936%]\n",
            "10931 [Discriminator loss: 0.6675%, acc.: 55.86%] [Generator loss: 0.7827%]\n",
            "10932 [Discriminator loss: 0.6622%, acc.: 62.11%] [Generator loss: 0.7929%]\n",
            "10933 [Discriminator loss: 0.6539%, acc.: 64.84%] [Generator loss: 0.7721%]\n",
            "10934 [Discriminator loss: 0.6828%, acc.: 53.52%] [Generator loss: 0.7783%]\n",
            "10935 [Discriminator loss: 0.6582%, acc.: 61.33%] [Generator loss: 0.7769%]\n",
            "10936 [Discriminator loss: 0.6834%, acc.: 54.30%] [Generator loss: 0.8129%]\n",
            "10937 [Discriminator loss: 0.6808%, acc.: 56.64%] [Generator loss: 0.7865%]\n",
            "10938 [Discriminator loss: 0.6774%, acc.: 57.03%] [Generator loss: 0.7862%]\n",
            "10939 [Discriminator loss: 0.6692%, acc.: 59.77%] [Generator loss: 0.7814%]\n",
            "10940 [Discriminator loss: 0.6751%, acc.: 58.59%] [Generator loss: 0.7608%]\n",
            "10941 [Discriminator loss: 0.6860%, acc.: 55.08%] [Generator loss: 0.8041%]\n",
            "10942 [Discriminator loss: 0.6504%, acc.: 65.62%] [Generator loss: 0.8011%]\n",
            "10943 [Discriminator loss: 0.6705%, acc.: 57.81%] [Generator loss: 0.7916%]\n",
            "10944 [Discriminator loss: 0.6600%, acc.: 61.33%] [Generator loss: 0.8149%]\n",
            "10945 [Discriminator loss: 0.6643%, acc.: 62.89%] [Generator loss: 0.8054%]\n",
            "10946 [Discriminator loss: 0.6651%, acc.: 62.50%] [Generator loss: 0.7970%]\n",
            "10947 [Discriminator loss: 0.6675%, acc.: 63.28%] [Generator loss: 0.8177%]\n",
            "10948 [Discriminator loss: 0.6676%, acc.: 59.77%] [Generator loss: 0.8056%]\n",
            "10949 [Discriminator loss: 0.6628%, acc.: 58.59%] [Generator loss: 0.7968%]\n",
            "10950 [Discriminator loss: 0.6829%, acc.: 55.08%] [Generator loss: 0.7768%]\n",
            "10951 [Discriminator loss: 0.6828%, acc.: 56.64%] [Generator loss: 0.7690%]\n",
            "10952 [Discriminator loss: 0.6732%, acc.: 57.03%] [Generator loss: 0.7568%]\n",
            "10953 [Discriminator loss: 0.6637%, acc.: 60.55%] [Generator loss: 0.8030%]\n",
            "10954 [Discriminator loss: 0.6716%, acc.: 62.50%] [Generator loss: 0.8093%]\n",
            "10955 [Discriminator loss: 0.6662%, acc.: 58.59%] [Generator loss: 0.7884%]\n",
            "10956 [Discriminator loss: 0.6846%, acc.: 54.30%] [Generator loss: 0.7611%]\n",
            "10957 [Discriminator loss: 0.6719%, acc.: 58.59%] [Generator loss: 0.7625%]\n",
            "10958 [Discriminator loss: 0.6584%, acc.: 60.16%] [Generator loss: 0.7955%]\n",
            "10959 [Discriminator loss: 0.6633%, acc.: 57.42%] [Generator loss: 0.8065%]\n",
            "10960 [Discriminator loss: 0.6862%, acc.: 55.86%] [Generator loss: 0.7760%]\n",
            "10961 [Discriminator loss: 0.6666%, acc.: 59.38%] [Generator loss: 0.7663%]\n",
            "10962 [Discriminator loss: 0.6861%, acc.: 58.20%] [Generator loss: 0.7913%]\n",
            "10963 [Discriminator loss: 0.6855%, acc.: 55.86%] [Generator loss: 0.7739%]\n",
            "10964 [Discriminator loss: 0.6794%, acc.: 56.25%] [Generator loss: 0.7810%]\n",
            "10965 [Discriminator loss: 0.6777%, acc.: 58.20%] [Generator loss: 0.7986%]\n",
            "10966 [Discriminator loss: 0.6933%, acc.: 54.30%] [Generator loss: 0.7993%]\n",
            "10967 [Discriminator loss: 0.6768%, acc.: 57.03%] [Generator loss: 0.7898%]\n",
            "10968 [Discriminator loss: 0.6767%, acc.: 58.20%] [Generator loss: 0.7765%]\n",
            "10969 [Discriminator loss: 0.6572%, acc.: 63.28%] [Generator loss: 0.7807%]\n",
            "10970 [Discriminator loss: 0.6683%, acc.: 62.89%] [Generator loss: 0.7715%]\n",
            "10971 [Discriminator loss: 0.6619%, acc.: 61.33%] [Generator loss: 0.7648%]\n",
            "10972 [Discriminator loss: 0.6777%, acc.: 53.91%] [Generator loss: 0.7723%]\n",
            "10973 [Discriminator loss: 0.6723%, acc.: 58.98%] [Generator loss: 0.7922%]\n",
            "10974 [Discriminator loss: 0.6776%, acc.: 56.25%] [Generator loss: 0.7842%]\n",
            "10975 [Discriminator loss: 0.6546%, acc.: 66.02%] [Generator loss: 0.7817%]\n",
            "10976 [Discriminator loss: 0.6747%, acc.: 55.86%] [Generator loss: 0.7742%]\n",
            "10977 [Discriminator loss: 0.6779%, acc.: 55.08%] [Generator loss: 0.7956%]\n",
            "10978 [Discriminator loss: 0.6625%, acc.: 60.16%] [Generator loss: 0.7734%]\n",
            "10979 [Discriminator loss: 0.6567%, acc.: 61.33%] [Generator loss: 0.7729%]\n",
            "10980 [Discriminator loss: 0.6906%, acc.: 51.17%] [Generator loss: 0.7969%]\n",
            "10981 [Discriminator loss: 0.6908%, acc.: 53.52%] [Generator loss: 0.7566%]\n",
            "10982 [Discriminator loss: 0.6857%, acc.: 54.69%] [Generator loss: 0.7856%]\n",
            "10983 [Discriminator loss: 0.6702%, acc.: 57.81%] [Generator loss: 0.7663%]\n",
            "10984 [Discriminator loss: 0.6946%, acc.: 51.95%] [Generator loss: 0.7833%]\n",
            "10985 [Discriminator loss: 0.6886%, acc.: 56.64%] [Generator loss: 0.8014%]\n",
            "10986 [Discriminator loss: 0.6804%, acc.: 56.25%] [Generator loss: 0.7752%]\n",
            "10987 [Discriminator loss: 0.6771%, acc.: 57.81%] [Generator loss: 0.8089%]\n",
            "10988 [Discriminator loss: 0.6722%, acc.: 55.86%] [Generator loss: 0.8004%]\n",
            "10989 [Discriminator loss: 0.6817%, acc.: 55.86%] [Generator loss: 0.7784%]\n",
            "10990 [Discriminator loss: 0.6789%, acc.: 55.47%] [Generator loss: 0.7861%]\n",
            "10991 [Discriminator loss: 0.6673%, acc.: 61.33%] [Generator loss: 0.7759%]\n",
            "10992 [Discriminator loss: 0.6868%, acc.: 52.34%] [Generator loss: 0.8154%]\n",
            "10993 [Discriminator loss: 0.6585%, acc.: 65.62%] [Generator loss: 0.7881%]\n",
            "10994 [Discriminator loss: 0.6807%, acc.: 53.91%] [Generator loss: 0.7858%]\n",
            "10995 [Discriminator loss: 0.6703%, acc.: 60.55%] [Generator loss: 0.7666%]\n",
            "10996 [Discriminator loss: 0.6837%, acc.: 56.25%] [Generator loss: 0.7928%]\n",
            "10997 [Discriminator loss: 0.6758%, acc.: 57.03%] [Generator loss: 0.7834%]\n",
            "10998 [Discriminator loss: 0.6816%, acc.: 56.64%] [Generator loss: 0.8083%]\n",
            "10999 [Discriminator loss: 0.6607%, acc.: 61.33%] [Generator loss: 0.7716%]\n",
            "11000 [Discriminator loss: 0.6920%, acc.: 52.34%] [Generator loss: 0.7838%]\n",
            "11001 [Discriminator loss: 0.6641%, acc.: 58.98%] [Generator loss: 0.7728%]\n",
            "11002 [Discriminator loss: 0.6694%, acc.: 59.38%] [Generator loss: 0.7971%]\n",
            "11003 [Discriminator loss: 0.6691%, acc.: 57.42%] [Generator loss: 0.7998%]\n",
            "11004 [Discriminator loss: 0.6602%, acc.: 58.98%] [Generator loss: 0.7853%]\n",
            "11005 [Discriminator loss: 0.6679%, acc.: 58.20%] [Generator loss: 0.7867%]\n",
            "11006 [Discriminator loss: 0.6752%, acc.: 57.42%] [Generator loss: 0.7793%]\n",
            "11007 [Discriminator loss: 0.6670%, acc.: 58.98%] [Generator loss: 0.7930%]\n",
            "11008 [Discriminator loss: 0.6852%, acc.: 56.64%] [Generator loss: 0.7848%]\n",
            "11009 [Discriminator loss: 0.6569%, acc.: 61.33%] [Generator loss: 0.7793%]\n",
            "11010 [Discriminator loss: 0.6762%, acc.: 57.03%] [Generator loss: 0.7917%]\n",
            "11011 [Discriminator loss: 0.6809%, acc.: 50.39%] [Generator loss: 0.7974%]\n",
            "11012 [Discriminator loss: 0.6711%, acc.: 59.77%] [Generator loss: 0.7964%]\n",
            "11013 [Discriminator loss: 0.6899%, acc.: 54.69%] [Generator loss: 0.7912%]\n",
            "11014 [Discriminator loss: 0.6761%, acc.: 59.77%] [Generator loss: 0.7988%]\n",
            "11015 [Discriminator loss: 0.6795%, acc.: 57.42%] [Generator loss: 0.7640%]\n",
            "11016 [Discriminator loss: 0.6734%, acc.: 57.81%] [Generator loss: 0.7999%]\n",
            "11017 [Discriminator loss: 0.6696%, acc.: 59.77%] [Generator loss: 0.7840%]\n",
            "11018 [Discriminator loss: 0.6773%, acc.: 58.20%] [Generator loss: 0.8096%]\n",
            "11019 [Discriminator loss: 0.6709%, acc.: 58.20%] [Generator loss: 0.7785%]\n",
            "11020 [Discriminator loss: 0.6549%, acc.: 59.38%] [Generator loss: 0.7497%]\n",
            "11021 [Discriminator loss: 0.6734%, acc.: 57.81%] [Generator loss: 0.7950%]\n",
            "11022 [Discriminator loss: 0.6724%, acc.: 61.33%] [Generator loss: 0.7985%]\n",
            "11023 [Discriminator loss: 0.6699%, acc.: 57.42%] [Generator loss: 0.7923%]\n",
            "11024 [Discriminator loss: 0.6676%, acc.: 60.16%] [Generator loss: 0.7754%]\n",
            "11025 [Discriminator loss: 0.6613%, acc.: 63.67%] [Generator loss: 0.7814%]\n",
            "11026 [Discriminator loss: 0.6828%, acc.: 59.38%] [Generator loss: 0.7992%]\n",
            "11027 [Discriminator loss: 0.6676%, acc.: 58.20%] [Generator loss: 0.7935%]\n",
            "11028 [Discriminator loss: 0.6599%, acc.: 61.72%] [Generator loss: 0.8165%]\n",
            "11029 [Discriminator loss: 0.6773%, acc.: 60.16%] [Generator loss: 0.7849%]\n",
            "11030 [Discriminator loss: 0.6535%, acc.: 62.50%] [Generator loss: 0.7677%]\n",
            "11031 [Discriminator loss: 0.6740%, acc.: 55.47%] [Generator loss: 0.8014%]\n",
            "11032 [Discriminator loss: 0.6665%, acc.: 55.86%] [Generator loss: 0.7637%]\n",
            "11033 [Discriminator loss: 0.6703%, acc.: 57.03%] [Generator loss: 0.7739%]\n",
            "11034 [Discriminator loss: 0.6772%, acc.: 55.47%] [Generator loss: 0.7643%]\n",
            "11035 [Discriminator loss: 0.6749%, acc.: 53.12%] [Generator loss: 0.7832%]\n",
            "11036 [Discriminator loss: 0.6610%, acc.: 58.20%] [Generator loss: 0.7780%]\n",
            "11037 [Discriminator loss: 0.6687%, acc.: 60.16%] [Generator loss: 0.7750%]\n",
            "11038 [Discriminator loss: 0.6781%, acc.: 58.98%] [Generator loss: 0.7849%]\n",
            "11039 [Discriminator loss: 0.6831%, acc.: 55.08%] [Generator loss: 0.7687%]\n",
            "11040 [Discriminator loss: 0.6653%, acc.: 58.98%] [Generator loss: 0.7938%]\n",
            "11041 [Discriminator loss: 0.6662%, acc.: 62.11%] [Generator loss: 0.7756%]\n",
            "11042 [Discriminator loss: 0.6683%, acc.: 62.50%] [Generator loss: 0.7709%]\n",
            "11043 [Discriminator loss: 0.6692%, acc.: 57.42%] [Generator loss: 0.7745%]\n",
            "11044 [Discriminator loss: 0.6606%, acc.: 64.45%] [Generator loss: 0.7782%]\n",
            "11045 [Discriminator loss: 0.6581%, acc.: 59.38%] [Generator loss: 0.7630%]\n",
            "11046 [Discriminator loss: 0.6617%, acc.: 60.94%] [Generator loss: 0.7743%]\n",
            "11047 [Discriminator loss: 0.6623%, acc.: 60.55%] [Generator loss: 0.7838%]\n",
            "11048 [Discriminator loss: 0.6748%, acc.: 56.25%] [Generator loss: 0.7882%]\n",
            "11049 [Discriminator loss: 0.6831%, acc.: 57.42%] [Generator loss: 0.7817%]\n",
            "11050 [Discriminator loss: 0.6770%, acc.: 56.25%] [Generator loss: 0.7966%]\n",
            "11051 [Discriminator loss: 0.6678%, acc.: 58.20%] [Generator loss: 0.7884%]\n",
            "11052 [Discriminator loss: 0.6558%, acc.: 62.89%] [Generator loss: 0.8021%]\n",
            "11053 [Discriminator loss: 0.6696%, acc.: 57.42%] [Generator loss: 0.8005%]\n",
            "11054 [Discriminator loss: 0.6662%, acc.: 57.81%] [Generator loss: 0.8119%]\n",
            "11055 [Discriminator loss: 0.6657%, acc.: 61.33%] [Generator loss: 0.7890%]\n",
            "11056 [Discriminator loss: 0.6754%, acc.: 57.81%] [Generator loss: 0.7766%]\n",
            "11057 [Discriminator loss: 0.6638%, acc.: 58.59%] [Generator loss: 0.7928%]\n",
            "11058 [Discriminator loss: 0.6801%, acc.: 56.64%] [Generator loss: 0.7892%]\n",
            "11059 [Discriminator loss: 0.6636%, acc.: 60.94%] [Generator loss: 0.7851%]\n",
            "11060 [Discriminator loss: 0.6544%, acc.: 64.06%] [Generator loss: 0.7859%]\n",
            "11061 [Discriminator loss: 0.6687%, acc.: 61.72%] [Generator loss: 0.7824%]\n",
            "11062 [Discriminator loss: 0.6807%, acc.: 53.12%] [Generator loss: 0.7752%]\n",
            "11063 [Discriminator loss: 0.6626%, acc.: 59.77%] [Generator loss: 0.7823%]\n",
            "11064 [Discriminator loss: 0.6867%, acc.: 53.91%] [Generator loss: 0.7733%]\n",
            "11065 [Discriminator loss: 0.6940%, acc.: 53.12%] [Generator loss: 0.7706%]\n",
            "11066 [Discriminator loss: 0.6648%, acc.: 59.77%] [Generator loss: 0.7754%]\n",
            "11067 [Discriminator loss: 0.6687%, acc.: 56.64%] [Generator loss: 0.7796%]\n",
            "11068 [Discriminator loss: 0.6701%, acc.: 58.59%] [Generator loss: 0.7888%]\n",
            "11069 [Discriminator loss: 0.6643%, acc.: 58.59%] [Generator loss: 0.7962%]\n",
            "11070 [Discriminator loss: 0.6690%, acc.: 58.59%] [Generator loss: 0.7986%]\n",
            "11071 [Discriminator loss: 0.6598%, acc.: 63.67%] [Generator loss: 0.7853%]\n",
            "11072 [Discriminator loss: 0.6729%, acc.: 59.77%] [Generator loss: 0.7850%]\n",
            "11073 [Discriminator loss: 0.6619%, acc.: 62.89%] [Generator loss: 0.7869%]\n",
            "11074 [Discriminator loss: 0.6847%, acc.: 57.81%] [Generator loss: 0.7659%]\n",
            "11075 [Discriminator loss: 0.6814%, acc.: 56.25%] [Generator loss: 0.8111%]\n",
            "11076 [Discriminator loss: 0.6701%, acc.: 58.20%] [Generator loss: 0.7737%]\n",
            "11077 [Discriminator loss: 0.6745%, acc.: 56.25%] [Generator loss: 0.7774%]\n",
            "11078 [Discriminator loss: 0.6719%, acc.: 60.55%] [Generator loss: 0.7761%]\n",
            "11079 [Discriminator loss: 0.6511%, acc.: 65.23%] [Generator loss: 0.7759%]\n",
            "11080 [Discriminator loss: 0.6695%, acc.: 55.47%] [Generator loss: 0.7739%]\n",
            "11081 [Discriminator loss: 0.6853%, acc.: 50.78%] [Generator loss: 0.7861%]\n",
            "11082 [Discriminator loss: 0.6584%, acc.: 58.20%] [Generator loss: 0.7867%]\n",
            "11083 [Discriminator loss: 0.6738%, acc.: 60.16%] [Generator loss: 0.7941%]\n",
            "11084 [Discriminator loss: 0.6509%, acc.: 67.19%] [Generator loss: 0.7664%]\n",
            "11085 [Discriminator loss: 0.6706%, acc.: 55.86%] [Generator loss: 0.7961%]\n",
            "11086 [Discriminator loss: 0.6614%, acc.: 62.11%] [Generator loss: 0.7752%]\n",
            "11087 [Discriminator loss: 0.6614%, acc.: 60.55%] [Generator loss: 0.7782%]\n",
            "11088 [Discriminator loss: 0.6813%, acc.: 57.42%] [Generator loss: 0.7848%]\n",
            "11089 [Discriminator loss: 0.6706%, acc.: 58.59%] [Generator loss: 0.8149%]\n",
            "11090 [Discriminator loss: 0.6784%, acc.: 57.03%] [Generator loss: 0.7997%]\n",
            "11091 [Discriminator loss: 0.6700%, acc.: 58.59%] [Generator loss: 0.7978%]\n",
            "11092 [Discriminator loss: 0.6583%, acc.: 61.72%] [Generator loss: 0.7890%]\n",
            "11093 [Discriminator loss: 0.6585%, acc.: 57.81%] [Generator loss: 0.7779%]\n",
            "11094 [Discriminator loss: 0.6795%, acc.: 52.73%] [Generator loss: 0.7960%]\n",
            "11095 [Discriminator loss: 0.6607%, acc.: 59.77%] [Generator loss: 0.7923%]\n",
            "11096 [Discriminator loss: 0.6642%, acc.: 64.84%] [Generator loss: 0.8127%]\n",
            "11097 [Discriminator loss: 0.6673%, acc.: 56.64%] [Generator loss: 0.7799%]\n",
            "11098 [Discriminator loss: 0.6871%, acc.: 55.08%] [Generator loss: 0.7786%]\n",
            "11099 [Discriminator loss: 0.7002%, acc.: 53.91%] [Generator loss: 0.7496%]\n",
            "11100 [Discriminator loss: 0.6870%, acc.: 55.08%] [Generator loss: 0.7942%]\n",
            "11101 [Discriminator loss: 0.6676%, acc.: 60.94%] [Generator loss: 0.7667%]\n",
            "11102 [Discriminator loss: 0.6731%, acc.: 58.20%] [Generator loss: 0.7656%]\n",
            "11103 [Discriminator loss: 0.6813%, acc.: 54.30%] [Generator loss: 0.7719%]\n",
            "11104 [Discriminator loss: 0.6595%, acc.: 62.89%] [Generator loss: 0.7739%]\n",
            "11105 [Discriminator loss: 0.6936%, acc.: 50.39%] [Generator loss: 0.7772%]\n",
            "11106 [Discriminator loss: 0.6887%, acc.: 54.30%] [Generator loss: 0.7677%]\n",
            "11107 [Discriminator loss: 0.6747%, acc.: 60.16%] [Generator loss: 0.7941%]\n",
            "11108 [Discriminator loss: 0.6770%, acc.: 59.38%] [Generator loss: 0.7576%]\n",
            "11109 [Discriminator loss: 0.6776%, acc.: 54.69%] [Generator loss: 0.8095%]\n",
            "11110 [Discriminator loss: 0.6792%, acc.: 56.64%] [Generator loss: 0.8168%]\n",
            "11111 [Discriminator loss: 0.6719%, acc.: 56.25%] [Generator loss: 0.8015%]\n",
            "11112 [Discriminator loss: 0.6740%, acc.: 53.52%] [Generator loss: 0.7929%]\n",
            "11113 [Discriminator loss: 0.6963%, acc.: 52.34%] [Generator loss: 0.8087%]\n",
            "11114 [Discriminator loss: 0.6627%, acc.: 60.94%] [Generator loss: 0.7719%]\n",
            "11115 [Discriminator loss: 0.6608%, acc.: 60.55%] [Generator loss: 0.8074%]\n",
            "11116 [Discriminator loss: 0.6725%, acc.: 55.47%] [Generator loss: 0.7943%]\n",
            "11117 [Discriminator loss: 0.6697%, acc.: 64.06%] [Generator loss: 0.7912%]\n",
            "11118 [Discriminator loss: 0.6562%, acc.: 58.59%] [Generator loss: 0.7586%]\n",
            "11119 [Discriminator loss: 0.6575%, acc.: 63.67%] [Generator loss: 0.8010%]\n",
            "11120 [Discriminator loss: 0.6846%, acc.: 56.25%] [Generator loss: 0.7849%]\n",
            "11121 [Discriminator loss: 0.6677%, acc.: 57.42%] [Generator loss: 0.7856%]\n",
            "11122 [Discriminator loss: 0.6687%, acc.: 59.77%] [Generator loss: 0.8004%]\n",
            "11123 [Discriminator loss: 0.6561%, acc.: 58.20%] [Generator loss: 0.7907%]\n",
            "11124 [Discriminator loss: 0.6849%, acc.: 56.25%] [Generator loss: 0.8121%]\n",
            "11125 [Discriminator loss: 0.6645%, acc.: 60.16%] [Generator loss: 0.7994%]\n",
            "11126 [Discriminator loss: 0.6757%, acc.: 55.86%] [Generator loss: 0.7875%]\n",
            "11127 [Discriminator loss: 0.6478%, acc.: 69.14%] [Generator loss: 0.7990%]\n",
            "11128 [Discriminator loss: 0.6731%, acc.: 58.98%] [Generator loss: 0.7904%]\n",
            "11129 [Discriminator loss: 0.6897%, acc.: 54.69%] [Generator loss: 0.7740%]\n",
            "11130 [Discriminator loss: 0.6765%, acc.: 55.08%] [Generator loss: 0.8018%]\n",
            "11131 [Discriminator loss: 0.6797%, acc.: 55.08%] [Generator loss: 0.7828%]\n",
            "11132 [Discriminator loss: 0.6610%, acc.: 60.94%] [Generator loss: 0.7508%]\n",
            "11133 [Discriminator loss: 0.6666%, acc.: 60.55%] [Generator loss: 0.7622%]\n",
            "11134 [Discriminator loss: 0.6634%, acc.: 57.42%] [Generator loss: 0.7985%]\n",
            "11135 [Discriminator loss: 0.6814%, acc.: 53.52%] [Generator loss: 0.7465%]\n",
            "11136 [Discriminator loss: 0.6626%, acc.: 60.94%] [Generator loss: 0.7740%]\n",
            "11137 [Discriminator loss: 0.6806%, acc.: 56.25%] [Generator loss: 0.7694%]\n",
            "11138 [Discriminator loss: 0.6714%, acc.: 60.94%] [Generator loss: 0.7832%]\n",
            "11139 [Discriminator loss: 0.6744%, acc.: 58.98%] [Generator loss: 0.7850%]\n",
            "11140 [Discriminator loss: 0.6806%, acc.: 59.77%] [Generator loss: 0.7797%]\n",
            "11141 [Discriminator loss: 0.6552%, acc.: 63.28%] [Generator loss: 0.7885%]\n",
            "11142 [Discriminator loss: 0.6675%, acc.: 58.98%] [Generator loss: 0.7637%]\n",
            "11143 [Discriminator loss: 0.6704%, acc.: 57.42%] [Generator loss: 0.8009%]\n",
            "11144 [Discriminator loss: 0.6813%, acc.: 57.81%] [Generator loss: 0.8008%]\n",
            "11145 [Discriminator loss: 0.6622%, acc.: 61.72%] [Generator loss: 0.8127%]\n",
            "11146 [Discriminator loss: 0.6674%, acc.: 60.94%] [Generator loss: 0.7978%]\n",
            "11147 [Discriminator loss: 0.6889%, acc.: 51.56%] [Generator loss: 0.8033%]\n",
            "11148 [Discriminator loss: 0.6851%, acc.: 55.08%] [Generator loss: 0.7721%]\n",
            "11149 [Discriminator loss: 0.6880%, acc.: 55.47%] [Generator loss: 0.7787%]\n",
            "11150 [Discriminator loss: 0.6824%, acc.: 54.69%] [Generator loss: 0.7767%]\n",
            "11151 [Discriminator loss: 0.6724%, acc.: 58.98%] [Generator loss: 0.8150%]\n",
            "11152 [Discriminator loss: 0.6695%, acc.: 59.77%] [Generator loss: 0.7886%]\n",
            "11153 [Discriminator loss: 0.6703%, acc.: 60.55%] [Generator loss: 0.7775%]\n",
            "11154 [Discriminator loss: 0.6667%, acc.: 56.64%] [Generator loss: 0.7738%]\n",
            "11155 [Discriminator loss: 0.6783%, acc.: 53.12%] [Generator loss: 0.7928%]\n",
            "11156 [Discriminator loss: 0.6615%, acc.: 61.33%] [Generator loss: 0.7840%]\n",
            "11157 [Discriminator loss: 0.6732%, acc.: 59.38%] [Generator loss: 0.7755%]\n",
            "11158 [Discriminator loss: 0.6749%, acc.: 60.16%] [Generator loss: 0.8237%]\n",
            "11159 [Discriminator loss: 0.6549%, acc.: 59.38%] [Generator loss: 0.8049%]\n",
            "11160 [Discriminator loss: 0.6491%, acc.: 63.67%] [Generator loss: 0.7605%]\n",
            "11161 [Discriminator loss: 0.6714%, acc.: 58.98%] [Generator loss: 0.7882%]\n",
            "11162 [Discriminator loss: 0.6851%, acc.: 54.30%] [Generator loss: 0.7778%]\n",
            "11163 [Discriminator loss: 0.6859%, acc.: 53.52%] [Generator loss: 0.8036%]\n",
            "11164 [Discriminator loss: 0.6544%, acc.: 63.28%] [Generator loss: 0.7813%]\n",
            "11165 [Discriminator loss: 0.6604%, acc.: 59.77%] [Generator loss: 0.7791%]\n",
            "11166 [Discriminator loss: 0.6571%, acc.: 61.33%] [Generator loss: 0.7856%]\n",
            "11167 [Discriminator loss: 0.6640%, acc.: 58.98%] [Generator loss: 0.7965%]\n",
            "11168 [Discriminator loss: 0.6711%, acc.: 60.16%] [Generator loss: 0.7914%]\n",
            "11169 [Discriminator loss: 0.6616%, acc.: 62.50%] [Generator loss: 0.7595%]\n",
            "11170 [Discriminator loss: 0.6592%, acc.: 61.33%] [Generator loss: 0.7737%]\n",
            "11171 [Discriminator loss: 0.6780%, acc.: 58.98%] [Generator loss: 0.7625%]\n",
            "11172 [Discriminator loss: 0.6942%, acc.: 55.08%] [Generator loss: 0.7837%]\n",
            "11173 [Discriminator loss: 0.6631%, acc.: 62.89%] [Generator loss: 0.7895%]\n",
            "11174 [Discriminator loss: 0.6653%, acc.: 62.11%] [Generator loss: 0.7773%]\n",
            "11175 [Discriminator loss: 0.6671%, acc.: 59.77%] [Generator loss: 0.7663%]\n",
            "11176 [Discriminator loss: 0.6911%, acc.: 54.30%] [Generator loss: 0.7833%]\n",
            "11177 [Discriminator loss: 0.6568%, acc.: 64.45%] [Generator loss: 0.7822%]\n",
            "11178 [Discriminator loss: 0.6660%, acc.: 62.11%] [Generator loss: 0.7901%]\n",
            "11179 [Discriminator loss: 0.6666%, acc.: 61.33%] [Generator loss: 0.8273%]\n",
            "11180 [Discriminator loss: 0.6676%, acc.: 60.94%] [Generator loss: 0.7870%]\n",
            "11181 [Discriminator loss: 0.6730%, acc.: 56.25%] [Generator loss: 0.7892%]\n",
            "11182 [Discriminator loss: 0.6811%, acc.: 53.12%] [Generator loss: 0.7847%]\n",
            "11183 [Discriminator loss: 0.6641%, acc.: 61.72%] [Generator loss: 0.7844%]\n",
            "11184 [Discriminator loss: 0.6720%, acc.: 58.98%] [Generator loss: 0.8125%]\n",
            "11185 [Discriminator loss: 0.6857%, acc.: 55.86%] [Generator loss: 0.8096%]\n",
            "11186 [Discriminator loss: 0.6582%, acc.: 61.33%] [Generator loss: 0.7915%]\n",
            "11187 [Discriminator loss: 0.6610%, acc.: 62.11%] [Generator loss: 0.7730%]\n",
            "11188 [Discriminator loss: 0.6614%, acc.: 62.11%] [Generator loss: 0.7790%]\n",
            "11189 [Discriminator loss: 0.6694%, acc.: 59.38%] [Generator loss: 0.7778%]\n",
            "11190 [Discriminator loss: 0.6603%, acc.: 59.77%] [Generator loss: 0.7902%]\n",
            "11191 [Discriminator loss: 0.6685%, acc.: 57.42%] [Generator loss: 0.7641%]\n",
            "11192 [Discriminator loss: 0.6603%, acc.: 62.11%] [Generator loss: 0.7892%]\n",
            "11193 [Discriminator loss: 0.6755%, acc.: 61.33%] [Generator loss: 0.7769%]\n",
            "11194 [Discriminator loss: 0.6687%, acc.: 58.59%] [Generator loss: 0.7635%]\n",
            "11195 [Discriminator loss: 0.6617%, acc.: 56.64%] [Generator loss: 0.7800%]\n",
            "11196 [Discriminator loss: 0.6627%, acc.: 63.67%] [Generator loss: 0.7797%]\n",
            "11197 [Discriminator loss: 0.6678%, acc.: 59.38%] [Generator loss: 0.7667%]\n",
            "11198 [Discriminator loss: 0.6666%, acc.: 58.20%] [Generator loss: 0.7641%]\n",
            "11199 [Discriminator loss: 0.6868%, acc.: 54.69%] [Generator loss: 0.7744%]\n",
            "11200 [Discriminator loss: 0.6919%, acc.: 53.12%] [Generator loss: 0.7939%]\n",
            "11201 [Discriminator loss: 0.6873%, acc.: 56.25%] [Generator loss: 0.7854%]\n",
            "11202 [Discriminator loss: 0.6656%, acc.: 61.72%] [Generator loss: 0.7789%]\n",
            "11203 [Discriminator loss: 0.6824%, acc.: 53.91%] [Generator loss: 0.7824%]\n",
            "11204 [Discriminator loss: 0.6630%, acc.: 60.94%] [Generator loss: 0.7775%]\n",
            "11205 [Discriminator loss: 0.6641%, acc.: 62.11%] [Generator loss: 0.7712%]\n",
            "11206 [Discriminator loss: 0.6856%, acc.: 55.86%] [Generator loss: 0.8029%]\n",
            "11207 [Discriminator loss: 0.6668%, acc.: 63.67%] [Generator loss: 0.7784%]\n",
            "11208 [Discriminator loss: 0.6614%, acc.: 60.55%] [Generator loss: 0.8021%]\n",
            "11209 [Discriminator loss: 0.6785%, acc.: 57.81%] [Generator loss: 0.7830%]\n",
            "11210 [Discriminator loss: 0.6717%, acc.: 61.72%] [Generator loss: 0.7833%]\n",
            "11211 [Discriminator loss: 0.6714%, acc.: 58.98%] [Generator loss: 0.7724%]\n",
            "11212 [Discriminator loss: 0.6663%, acc.: 57.81%] [Generator loss: 0.7551%]\n",
            "11213 [Discriminator loss: 0.6567%, acc.: 60.94%] [Generator loss: 0.7709%]\n",
            "11214 [Discriminator loss: 0.6604%, acc.: 58.20%] [Generator loss: 0.7703%]\n",
            "11215 [Discriminator loss: 0.6673%, acc.: 58.20%] [Generator loss: 0.7743%]\n",
            "11216 [Discriminator loss: 0.6662%, acc.: 54.30%] [Generator loss: 0.7993%]\n",
            "11217 [Discriminator loss: 0.6498%, acc.: 59.38%] [Generator loss: 0.7758%]\n",
            "11218 [Discriminator loss: 0.6723%, acc.: 58.20%] [Generator loss: 0.7882%]\n",
            "11219 [Discriminator loss: 0.6834%, acc.: 54.30%] [Generator loss: 0.7632%]\n",
            "11220 [Discriminator loss: 0.6667%, acc.: 57.81%] [Generator loss: 0.7878%]\n",
            "11221 [Discriminator loss: 0.6688%, acc.: 59.77%] [Generator loss: 0.8041%]\n",
            "11222 [Discriminator loss: 0.6876%, acc.: 53.91%] [Generator loss: 0.7800%]\n",
            "11223 [Discriminator loss: 0.6777%, acc.: 58.20%] [Generator loss: 0.7711%]\n",
            "11224 [Discriminator loss: 0.6581%, acc.: 61.72%] [Generator loss: 0.8006%]\n",
            "11225 [Discriminator loss: 0.6787%, acc.: 55.86%] [Generator loss: 0.8134%]\n",
            "11226 [Discriminator loss: 0.6694%, acc.: 58.59%] [Generator loss: 0.7917%]\n",
            "11227 [Discriminator loss: 0.6647%, acc.: 56.64%] [Generator loss: 0.8175%]\n",
            "11228 [Discriminator loss: 0.6778%, acc.: 58.59%] [Generator loss: 0.7868%]\n",
            "11229 [Discriminator loss: 0.6736%, acc.: 56.64%] [Generator loss: 0.7909%]\n",
            "11230 [Discriminator loss: 0.6763%, acc.: 55.86%] [Generator loss: 0.7945%]\n",
            "11231 [Discriminator loss: 0.6815%, acc.: 57.03%] [Generator loss: 0.7988%]\n",
            "11232 [Discriminator loss: 0.6421%, acc.: 66.80%] [Generator loss: 0.7713%]\n",
            "11233 [Discriminator loss: 0.6880%, acc.: 55.47%] [Generator loss: 0.7739%]\n",
            "11234 [Discriminator loss: 0.6773%, acc.: 56.25%] [Generator loss: 0.7787%]\n",
            "11235 [Discriminator loss: 0.6621%, acc.: 60.55%] [Generator loss: 0.7994%]\n",
            "11236 [Discriminator loss: 0.6507%, acc.: 58.59%] [Generator loss: 0.7937%]\n",
            "11237 [Discriminator loss: 0.6628%, acc.: 58.98%] [Generator loss: 0.8038%]\n",
            "11238 [Discriminator loss: 0.6860%, acc.: 53.52%] [Generator loss: 0.7697%]\n",
            "11239 [Discriminator loss: 0.6778%, acc.: 57.03%] [Generator loss: 0.8125%]\n",
            "11240 [Discriminator loss: 0.6617%, acc.: 58.98%] [Generator loss: 0.7748%]\n",
            "11241 [Discriminator loss: 0.6690%, acc.: 59.38%] [Generator loss: 0.7621%]\n",
            "11242 [Discriminator loss: 0.6789%, acc.: 55.47%] [Generator loss: 0.8064%]\n",
            "11243 [Discriminator loss: 0.6873%, acc.: 51.56%] [Generator loss: 0.7693%]\n",
            "11244 [Discriminator loss: 0.6574%, acc.: 61.72%] [Generator loss: 0.7761%]\n",
            "11245 [Discriminator loss: 0.6661%, acc.: 58.59%] [Generator loss: 0.7798%]\n",
            "11246 [Discriminator loss: 0.6705%, acc.: 63.28%] [Generator loss: 0.7640%]\n",
            "11247 [Discriminator loss: 0.6699%, acc.: 58.59%] [Generator loss: 0.7741%]\n",
            "11248 [Discriminator loss: 0.6627%, acc.: 62.89%] [Generator loss: 0.7956%]\n",
            "11249 [Discriminator loss: 0.6649%, acc.: 61.72%] [Generator loss: 0.8100%]\n",
            "11250 [Discriminator loss: 0.6661%, acc.: 60.16%] [Generator loss: 0.7990%]\n",
            "11251 [Discriminator loss: 0.6707%, acc.: 55.86%] [Generator loss: 0.8005%]\n",
            "11252 [Discriminator loss: 0.6535%, acc.: 61.33%] [Generator loss: 0.7986%]\n",
            "11253 [Discriminator loss: 0.6741%, acc.: 55.86%] [Generator loss: 0.7897%]\n",
            "11254 [Discriminator loss: 0.6825%, acc.: 55.86%] [Generator loss: 0.8026%]\n",
            "11255 [Discriminator loss: 0.6717%, acc.: 60.94%] [Generator loss: 0.8009%]\n",
            "11256 [Discriminator loss: 0.6621%, acc.: 60.55%] [Generator loss: 0.7741%]\n",
            "11257 [Discriminator loss: 0.6637%, acc.: 62.89%] [Generator loss: 0.7868%]\n",
            "11258 [Discriminator loss: 0.6814%, acc.: 56.64%] [Generator loss: 0.7763%]\n",
            "11259 [Discriminator loss: 0.6661%, acc.: 62.11%] [Generator loss: 0.8166%]\n",
            "11260 [Discriminator loss: 0.6671%, acc.: 58.59%] [Generator loss: 0.7694%]\n",
            "11261 [Discriminator loss: 0.6542%, acc.: 66.41%] [Generator loss: 0.7864%]\n",
            "11262 [Discriminator loss: 0.6640%, acc.: 57.42%] [Generator loss: 0.7934%]\n",
            "11263 [Discriminator loss: 0.6414%, acc.: 65.23%] [Generator loss: 0.8049%]\n",
            "11264 [Discriminator loss: 0.6582%, acc.: 64.84%] [Generator loss: 0.7897%]\n",
            "11265 [Discriminator loss: 0.6781%, acc.: 58.59%] [Generator loss: 0.7715%]\n",
            "11266 [Discriminator loss: 0.6781%, acc.: 54.69%] [Generator loss: 0.7810%]\n",
            "11267 [Discriminator loss: 0.6584%, acc.: 61.33%] [Generator loss: 0.7787%]\n",
            "11268 [Discriminator loss: 0.6770%, acc.: 57.42%] [Generator loss: 0.7905%]\n",
            "11269 [Discriminator loss: 0.6836%, acc.: 47.66%] [Generator loss: 0.7843%]\n",
            "11270 [Discriminator loss: 0.6712%, acc.: 61.72%] [Generator loss: 0.7910%]\n",
            "11271 [Discriminator loss: 0.6662%, acc.: 58.20%] [Generator loss: 0.7673%]\n",
            "11272 [Discriminator loss: 0.6698%, acc.: 58.98%] [Generator loss: 0.7840%]\n",
            "11273 [Discriminator loss: 0.6557%, acc.: 59.77%] [Generator loss: 0.7728%]\n",
            "11274 [Discriminator loss: 0.6593%, acc.: 60.55%] [Generator loss: 0.7996%]\n",
            "11275 [Discriminator loss: 0.6792%, acc.: 57.03%] [Generator loss: 0.7787%]\n",
            "11276 [Discriminator loss: 0.6591%, acc.: 62.11%] [Generator loss: 0.7900%]\n",
            "11277 [Discriminator loss: 0.6715%, acc.: 53.91%] [Generator loss: 0.7867%]\n",
            "11278 [Discriminator loss: 0.6835%, acc.: 53.52%] [Generator loss: 0.7938%]\n",
            "11279 [Discriminator loss: 0.6628%, acc.: 62.11%] [Generator loss: 0.7972%]\n",
            "11280 [Discriminator loss: 0.6792%, acc.: 55.86%] [Generator loss: 0.8148%]\n",
            "11281 [Discriminator loss: 0.6797%, acc.: 58.59%] [Generator loss: 0.7944%]\n",
            "11282 [Discriminator loss: 0.6738%, acc.: 57.03%] [Generator loss: 0.7832%]\n",
            "11283 [Discriminator loss: 0.6719%, acc.: 55.86%] [Generator loss: 0.7879%]\n",
            "11284 [Discriminator loss: 0.6583%, acc.: 62.11%] [Generator loss: 0.7739%]\n",
            "11285 [Discriminator loss: 0.6647%, acc.: 60.94%] [Generator loss: 0.7871%]\n",
            "11286 [Discriminator loss: 0.6660%, acc.: 60.16%] [Generator loss: 0.8129%]\n",
            "11287 [Discriminator loss: 0.6731%, acc.: 55.86%] [Generator loss: 0.8075%]\n",
            "11288 [Discriminator loss: 0.6640%, acc.: 61.72%] [Generator loss: 0.8084%]\n",
            "11289 [Discriminator loss: 0.6608%, acc.: 55.86%] [Generator loss: 0.7708%]\n",
            "11290 [Discriminator loss: 0.6678%, acc.: 62.50%] [Generator loss: 0.7838%]\n",
            "11291 [Discriminator loss: 0.6742%, acc.: 56.64%] [Generator loss: 0.7706%]\n",
            "11292 [Discriminator loss: 0.6725%, acc.: 57.81%] [Generator loss: 0.7871%]\n",
            "11293 [Discriminator loss: 0.6658%, acc.: 60.94%] [Generator loss: 0.7788%]\n",
            "11294 [Discriminator loss: 0.6735%, acc.: 59.38%] [Generator loss: 0.8153%]\n",
            "11295 [Discriminator loss: 0.6415%, acc.: 67.58%] [Generator loss: 0.7842%]\n",
            "11296 [Discriminator loss: 0.6713%, acc.: 57.81%] [Generator loss: 0.8119%]\n",
            "11297 [Discriminator loss: 0.6894%, acc.: 54.30%] [Generator loss: 0.7904%]\n",
            "11298 [Discriminator loss: 0.6593%, acc.: 63.67%] [Generator loss: 0.7838%]\n",
            "11299 [Discriminator loss: 0.6718%, acc.: 56.64%] [Generator loss: 0.7770%]\n",
            "11300 [Discriminator loss: 0.6707%, acc.: 59.38%] [Generator loss: 0.7908%]\n",
            "11301 [Discriminator loss: 0.6593%, acc.: 59.38%] [Generator loss: 0.7968%]\n",
            "11302 [Discriminator loss: 0.6550%, acc.: 58.98%] [Generator loss: 0.7836%]\n",
            "11303 [Discriminator loss: 0.6636%, acc.: 60.16%] [Generator loss: 0.7887%]\n",
            "11304 [Discriminator loss: 0.6660%, acc.: 60.55%] [Generator loss: 0.7893%]\n",
            "11305 [Discriminator loss: 0.6685%, acc.: 59.77%] [Generator loss: 0.8049%]\n",
            "11306 [Discriminator loss: 0.6844%, acc.: 53.91%] [Generator loss: 0.7756%]\n",
            "11307 [Discriminator loss: 0.6582%, acc.: 58.59%] [Generator loss: 0.7717%]\n",
            "11308 [Discriminator loss: 0.6811%, acc.: 53.52%] [Generator loss: 0.7753%]\n",
            "11309 [Discriminator loss: 0.6804%, acc.: 58.59%] [Generator loss: 0.7584%]\n",
            "11310 [Discriminator loss: 0.6673%, acc.: 55.86%] [Generator loss: 0.7937%]\n",
            "11311 [Discriminator loss: 0.6600%, acc.: 62.50%] [Generator loss: 0.7804%]\n",
            "11312 [Discriminator loss: 0.6606%, acc.: 64.06%] [Generator loss: 0.7903%]\n",
            "11313 [Discriminator loss: 0.6710%, acc.: 57.42%] [Generator loss: 0.7720%]\n",
            "11314 [Discriminator loss: 0.6633%, acc.: 60.55%] [Generator loss: 0.7853%]\n",
            "11315 [Discriminator loss: 0.6833%, acc.: 55.47%] [Generator loss: 0.7969%]\n",
            "11316 [Discriminator loss: 0.6824%, acc.: 54.30%] [Generator loss: 0.8026%]\n",
            "11317 [Discriminator loss: 0.6776%, acc.: 59.38%] [Generator loss: 0.7900%]\n",
            "11318 [Discriminator loss: 0.6787%, acc.: 54.30%] [Generator loss: 0.8058%]\n",
            "11319 [Discriminator loss: 0.6475%, acc.: 66.02%] [Generator loss: 0.7890%]\n",
            "11320 [Discriminator loss: 0.6772%, acc.: 56.25%] [Generator loss: 0.8044%]\n",
            "11321 [Discriminator loss: 0.6784%, acc.: 54.69%] [Generator loss: 0.7697%]\n",
            "11322 [Discriminator loss: 0.6628%, acc.: 58.20%] [Generator loss: 0.7652%]\n",
            "11323 [Discriminator loss: 0.6559%, acc.: 62.89%] [Generator loss: 0.7628%]\n",
            "11324 [Discriminator loss: 0.6684%, acc.: 56.64%] [Generator loss: 0.7849%]\n",
            "11325 [Discriminator loss: 0.6656%, acc.: 63.28%] [Generator loss: 0.7939%]\n",
            "11326 [Discriminator loss: 0.6656%, acc.: 57.81%] [Generator loss: 0.7755%]\n",
            "11327 [Discriminator loss: 0.6973%, acc.: 52.73%] [Generator loss: 0.7899%]\n",
            "11328 [Discriminator loss: 0.6647%, acc.: 58.20%] [Generator loss: 0.7794%]\n",
            "11329 [Discriminator loss: 0.6728%, acc.: 56.64%] [Generator loss: 0.8034%]\n",
            "11330 [Discriminator loss: 0.6709%, acc.: 59.38%] [Generator loss: 0.8128%]\n",
            "11331 [Discriminator loss: 0.6710%, acc.: 57.03%] [Generator loss: 0.7745%]\n",
            "11332 [Discriminator loss: 0.6721%, acc.: 59.77%] [Generator loss: 0.8089%]\n",
            "11333 [Discriminator loss: 0.6625%, acc.: 59.38%] [Generator loss: 0.7948%]\n",
            "11334 [Discriminator loss: 0.6632%, acc.: 61.72%] [Generator loss: 0.7948%]\n",
            "11335 [Discriminator loss: 0.6606%, acc.: 59.77%] [Generator loss: 0.7914%]\n",
            "11336 [Discriminator loss: 0.6791%, acc.: 55.86%] [Generator loss: 0.7855%]\n",
            "11337 [Discriminator loss: 0.6857%, acc.: 58.20%] [Generator loss: 0.7758%]\n",
            "11338 [Discriminator loss: 0.6707%, acc.: 60.16%] [Generator loss: 0.7733%]\n",
            "11339 [Discriminator loss: 0.6578%, acc.: 59.38%] [Generator loss: 0.7853%]\n",
            "11340 [Discriminator loss: 0.6747%, acc.: 55.47%] [Generator loss: 0.8060%]\n",
            "11341 [Discriminator loss: 0.6948%, acc.: 46.88%] [Generator loss: 0.8204%]\n",
            "11342 [Discriminator loss: 0.6791%, acc.: 57.03%] [Generator loss: 0.8078%]\n",
            "11343 [Discriminator loss: 0.6645%, acc.: 57.42%] [Generator loss: 0.7999%]\n",
            "11344 [Discriminator loss: 0.6603%, acc.: 60.94%] [Generator loss: 0.7989%]\n",
            "11345 [Discriminator loss: 0.6723%, acc.: 56.64%] [Generator loss: 0.7920%]\n",
            "11346 [Discriminator loss: 0.6668%, acc.: 58.98%] [Generator loss: 0.7822%]\n",
            "11347 [Discriminator loss: 0.6749%, acc.: 56.25%] [Generator loss: 0.7882%]\n",
            "11348 [Discriminator loss: 0.6624%, acc.: 63.28%] [Generator loss: 0.7751%]\n",
            "11349 [Discriminator loss: 0.6736%, acc.: 57.42%] [Generator loss: 0.7789%]\n",
            "11350 [Discriminator loss: 0.6745%, acc.: 57.81%] [Generator loss: 0.7694%]\n",
            "11351 [Discriminator loss: 0.6721%, acc.: 57.42%] [Generator loss: 0.8046%]\n",
            "11352 [Discriminator loss: 0.6609%, acc.: 59.77%] [Generator loss: 0.7821%]\n",
            "11353 [Discriminator loss: 0.6685%, acc.: 55.47%] [Generator loss: 0.7749%]\n",
            "11354 [Discriminator loss: 0.6845%, acc.: 55.08%] [Generator loss: 0.7884%]\n",
            "11355 [Discriminator loss: 0.6664%, acc.: 57.03%] [Generator loss: 0.7981%]\n",
            "11356 [Discriminator loss: 0.6592%, acc.: 63.67%] [Generator loss: 0.7817%]\n",
            "11357 [Discriminator loss: 0.6621%, acc.: 61.72%] [Generator loss: 0.7845%]\n",
            "11358 [Discriminator loss: 0.6533%, acc.: 64.06%] [Generator loss: 0.8111%]\n",
            "11359 [Discriminator loss: 0.6571%, acc.: 60.55%] [Generator loss: 0.8047%]\n",
            "11360 [Discriminator loss: 0.6591%, acc.: 60.55%] [Generator loss: 0.8003%]\n",
            "11361 [Discriminator loss: 0.6648%, acc.: 58.59%] [Generator loss: 0.8041%]\n",
            "11362 [Discriminator loss: 0.6556%, acc.: 57.03%] [Generator loss: 0.7772%]\n",
            "11363 [Discriminator loss: 0.6642%, acc.: 57.03%] [Generator loss: 0.7903%]\n",
            "11364 [Discriminator loss: 0.6690%, acc.: 56.64%] [Generator loss: 0.7773%]\n",
            "11365 [Discriminator loss: 0.6949%, acc.: 56.25%] [Generator loss: 0.7880%]\n",
            "11366 [Discriminator loss: 0.6688%, acc.: 59.38%] [Generator loss: 0.7805%]\n",
            "11367 [Discriminator loss: 0.6730%, acc.: 60.55%] [Generator loss: 0.7802%]\n",
            "11368 [Discriminator loss: 0.6673%, acc.: 60.94%] [Generator loss: 0.7770%]\n",
            "11369 [Discriminator loss: 0.6871%, acc.: 55.08%] [Generator loss: 0.7662%]\n",
            "11370 [Discriminator loss: 0.6693%, acc.: 58.59%] [Generator loss: 0.7641%]\n",
            "11371 [Discriminator loss: 0.6682%, acc.: 57.42%] [Generator loss: 0.8276%]\n",
            "11372 [Discriminator loss: 0.6502%, acc.: 59.77%] [Generator loss: 0.8015%]\n",
            "11373 [Discriminator loss: 0.6718%, acc.: 55.08%] [Generator loss: 0.7998%]\n",
            "11374 [Discriminator loss: 0.6695%, acc.: 60.16%] [Generator loss: 0.8020%]\n",
            "11375 [Discriminator loss: 0.6691%, acc.: 60.16%] [Generator loss: 0.7981%]\n",
            "11376 [Discriminator loss: 0.6728%, acc.: 59.38%] [Generator loss: 0.8150%]\n",
            "11377 [Discriminator loss: 0.6811%, acc.: 58.20%] [Generator loss: 0.8328%]\n",
            "11378 [Discriminator loss: 0.6799%, acc.: 55.86%] [Generator loss: 0.7842%]\n",
            "11379 [Discriminator loss: 0.6823%, acc.: 55.86%] [Generator loss: 0.7979%]\n",
            "11380 [Discriminator loss: 0.6789%, acc.: 59.38%] [Generator loss: 0.7937%]\n",
            "11381 [Discriminator loss: 0.6710%, acc.: 57.81%] [Generator loss: 0.8152%]\n",
            "11382 [Discriminator loss: 0.6717%, acc.: 55.47%] [Generator loss: 0.7848%]\n",
            "11383 [Discriminator loss: 0.6642%, acc.: 63.67%] [Generator loss: 0.7793%]\n",
            "11384 [Discriminator loss: 0.6809%, acc.: 58.20%] [Generator loss: 0.7834%]\n",
            "11385 [Discriminator loss: 0.6818%, acc.: 56.64%] [Generator loss: 0.7763%]\n",
            "11386 [Discriminator loss: 0.6577%, acc.: 61.33%] [Generator loss: 0.7663%]\n",
            "11387 [Discriminator loss: 0.6657%, acc.: 60.55%] [Generator loss: 0.7896%]\n",
            "11388 [Discriminator loss: 0.6905%, acc.: 53.52%] [Generator loss: 0.7904%]\n",
            "11389 [Discriminator loss: 0.6711%, acc.: 60.55%] [Generator loss: 0.8154%]\n",
            "11390 [Discriminator loss: 0.6870%, acc.: 55.08%] [Generator loss: 0.7826%]\n",
            "11391 [Discriminator loss: 0.6720%, acc.: 58.20%] [Generator loss: 0.7825%]\n",
            "11392 [Discriminator loss: 0.6774%, acc.: 57.42%] [Generator loss: 0.7904%]\n",
            "11393 [Discriminator loss: 0.6719%, acc.: 58.59%] [Generator loss: 0.7922%]\n",
            "11394 [Discriminator loss: 0.6705%, acc.: 57.81%] [Generator loss: 0.8311%]\n",
            "11395 [Discriminator loss: 0.6792%, acc.: 60.16%] [Generator loss: 0.7884%]\n",
            "11396 [Discriminator loss: 0.6692%, acc.: 57.42%] [Generator loss: 0.7877%]\n",
            "11397 [Discriminator loss: 0.6824%, acc.: 54.30%] [Generator loss: 0.8030%]\n",
            "11398 [Discriminator loss: 0.6748%, acc.: 54.69%] [Generator loss: 0.8000%]\n",
            "11399 [Discriminator loss: 0.6632%, acc.: 58.98%] [Generator loss: 0.7839%]\n",
            "11400 [Discriminator loss: 0.6601%, acc.: 62.89%] [Generator loss: 0.7518%]\n",
            "11401 [Discriminator loss: 0.6644%, acc.: 61.72%] [Generator loss: 0.7794%]\n",
            "11402 [Discriminator loss: 0.6844%, acc.: 57.81%] [Generator loss: 0.7637%]\n",
            "11403 [Discriminator loss: 0.6716%, acc.: 56.25%] [Generator loss: 0.8117%]\n",
            "11404 [Discriminator loss: 0.6832%, acc.: 53.52%] [Generator loss: 0.8021%]\n",
            "11405 [Discriminator loss: 0.6614%, acc.: 59.77%] [Generator loss: 0.7903%]\n",
            "11406 [Discriminator loss: 0.6635%, acc.: 60.55%] [Generator loss: 0.7710%]\n",
            "11407 [Discriminator loss: 0.6822%, acc.: 54.30%] [Generator loss: 0.8062%]\n",
            "11408 [Discriminator loss: 0.6954%, acc.: 54.69%] [Generator loss: 0.7930%]\n",
            "11409 [Discriminator loss: 0.6683%, acc.: 64.84%] [Generator loss: 0.7737%]\n",
            "11410 [Discriminator loss: 0.6788%, acc.: 60.94%] [Generator loss: 0.7780%]\n",
            "11411 [Discriminator loss: 0.6615%, acc.: 60.16%] [Generator loss: 0.7692%]\n",
            "11412 [Discriminator loss: 0.6868%, acc.: 53.91%] [Generator loss: 0.7939%]\n",
            "11413 [Discriminator loss: 0.6639%, acc.: 60.94%] [Generator loss: 0.7844%]\n",
            "11414 [Discriminator loss: 0.6734%, acc.: 55.08%] [Generator loss: 0.7855%]\n",
            "11415 [Discriminator loss: 0.6936%, acc.: 51.56%] [Generator loss: 0.7834%]\n",
            "11416 [Discriminator loss: 0.6714%, acc.: 60.94%] [Generator loss: 0.7636%]\n",
            "11417 [Discriminator loss: 0.6924%, acc.: 50.39%] [Generator loss: 0.7721%]\n",
            "11418 [Discriminator loss: 0.6666%, acc.: 61.33%] [Generator loss: 0.7904%]\n",
            "11419 [Discriminator loss: 0.6747%, acc.: 58.98%] [Generator loss: 0.7929%]\n",
            "11420 [Discriminator loss: 0.6529%, acc.: 63.28%] [Generator loss: 0.7761%]\n",
            "11421 [Discriminator loss: 0.6656%, acc.: 60.94%] [Generator loss: 0.8170%]\n",
            "11422 [Discriminator loss: 0.6775%, acc.: 58.59%] [Generator loss: 0.7999%]\n",
            "11423 [Discriminator loss: 0.6485%, acc.: 60.55%] [Generator loss: 0.7754%]\n",
            "11424 [Discriminator loss: 0.6692%, acc.: 61.72%] [Generator loss: 0.8070%]\n",
            "11425 [Discriminator loss: 0.6843%, acc.: 53.52%] [Generator loss: 0.7910%]\n",
            "11426 [Discriminator loss: 0.6726%, acc.: 55.08%] [Generator loss: 0.7939%]\n",
            "11427 [Discriminator loss: 0.6761%, acc.: 55.08%] [Generator loss: 0.7528%]\n",
            "11428 [Discriminator loss: 0.6731%, acc.: 55.08%] [Generator loss: 0.7665%]\n",
            "11429 [Discriminator loss: 0.6668%, acc.: 59.38%] [Generator loss: 0.7771%]\n",
            "11430 [Discriminator loss: 0.6779%, acc.: 56.64%] [Generator loss: 0.7830%]\n",
            "11431 [Discriminator loss: 0.6682%, acc.: 55.86%] [Generator loss: 0.7957%]\n",
            "11432 [Discriminator loss: 0.6730%, acc.: 57.03%] [Generator loss: 0.8011%]\n",
            "11433 [Discriminator loss: 0.6867%, acc.: 54.69%] [Generator loss: 0.7693%]\n",
            "11434 [Discriminator loss: 0.6663%, acc.: 60.55%] [Generator loss: 0.7530%]\n",
            "11435 [Discriminator loss: 0.6626%, acc.: 62.11%] [Generator loss: 0.7698%]\n",
            "11436 [Discriminator loss: 0.6840%, acc.: 50.78%] [Generator loss: 0.7830%]\n",
            "11437 [Discriminator loss: 0.6745%, acc.: 58.98%] [Generator loss: 0.7743%]\n",
            "11438 [Discriminator loss: 0.6650%, acc.: 64.45%] [Generator loss: 0.7789%]\n",
            "11439 [Discriminator loss: 0.6540%, acc.: 63.28%] [Generator loss: 0.7630%]\n",
            "11440 [Discriminator loss: 0.6796%, acc.: 58.20%] [Generator loss: 0.7780%]\n",
            "11441 [Discriminator loss: 0.6774%, acc.: 58.98%] [Generator loss: 0.7805%]\n",
            "11442 [Discriminator loss: 0.6806%, acc.: 55.47%] [Generator loss: 0.7624%]\n",
            "11443 [Discriminator loss: 0.6754%, acc.: 59.38%] [Generator loss: 0.7718%]\n",
            "11444 [Discriminator loss: 0.6909%, acc.: 53.91%] [Generator loss: 0.7730%]\n",
            "11445 [Discriminator loss: 0.6745%, acc.: 56.25%] [Generator loss: 0.8004%]\n",
            "11446 [Discriminator loss: 0.6676%, acc.: 59.77%] [Generator loss: 0.7945%]\n",
            "11447 [Discriminator loss: 0.6872%, acc.: 52.73%] [Generator loss: 0.8028%]\n",
            "11448 [Discriminator loss: 0.6722%, acc.: 55.86%] [Generator loss: 0.7943%]\n",
            "11449 [Discriminator loss: 0.6689%, acc.: 58.20%] [Generator loss: 0.7958%]\n",
            "11450 [Discriminator loss: 0.6685%, acc.: 62.11%] [Generator loss: 0.7876%]\n",
            "11451 [Discriminator loss: 0.6701%, acc.: 58.20%] [Generator loss: 0.7879%]\n",
            "11452 [Discriminator loss: 0.6644%, acc.: 63.28%] [Generator loss: 0.7588%]\n",
            "11453 [Discriminator loss: 0.6791%, acc.: 58.20%] [Generator loss: 0.7961%]\n",
            "11454 [Discriminator loss: 0.6719%, acc.: 58.59%] [Generator loss: 0.7855%]\n",
            "11455 [Discriminator loss: 0.6691%, acc.: 60.55%] [Generator loss: 0.7677%]\n",
            "11456 [Discriminator loss: 0.6702%, acc.: 60.55%] [Generator loss: 0.7898%]\n",
            "11457 [Discriminator loss: 0.6694%, acc.: 55.86%] [Generator loss: 0.7931%]\n",
            "11458 [Discriminator loss: 0.6580%, acc.: 66.80%] [Generator loss: 0.7730%]\n",
            "11459 [Discriminator loss: 0.6582%, acc.: 58.20%] [Generator loss: 0.7802%]\n",
            "11460 [Discriminator loss: 0.6736%, acc.: 53.91%] [Generator loss: 0.7822%]\n",
            "11461 [Discriminator loss: 0.6801%, acc.: 59.38%] [Generator loss: 0.8010%]\n",
            "11462 [Discriminator loss: 0.6790%, acc.: 57.03%] [Generator loss: 0.8118%]\n",
            "11463 [Discriminator loss: 0.6664%, acc.: 61.72%] [Generator loss: 0.7870%]\n",
            "11464 [Discriminator loss: 0.6751%, acc.: 55.86%] [Generator loss: 0.8251%]\n",
            "11465 [Discriminator loss: 0.6783%, acc.: 60.16%] [Generator loss: 0.8045%]\n",
            "11466 [Discriminator loss: 0.6738%, acc.: 57.03%] [Generator loss: 0.7819%]\n",
            "11467 [Discriminator loss: 0.6695%, acc.: 60.16%] [Generator loss: 0.7775%]\n",
            "11468 [Discriminator loss: 0.6665%, acc.: 58.59%] [Generator loss: 0.7648%]\n",
            "11469 [Discriminator loss: 0.6731%, acc.: 62.89%] [Generator loss: 0.7991%]\n",
            "11470 [Discriminator loss: 0.6793%, acc.: 56.64%] [Generator loss: 0.7727%]\n",
            "11471 [Discriminator loss: 0.6724%, acc.: 58.98%] [Generator loss: 0.7874%]\n",
            "11472 [Discriminator loss: 0.6623%, acc.: 62.89%] [Generator loss: 0.7777%]\n",
            "11473 [Discriminator loss: 0.6510%, acc.: 63.67%] [Generator loss: 0.7779%]\n",
            "11474 [Discriminator loss: 0.6882%, acc.: 53.12%] [Generator loss: 0.8176%]\n",
            "11475 [Discriminator loss: 0.6552%, acc.: 57.81%] [Generator loss: 0.7924%]\n",
            "11476 [Discriminator loss: 0.6764%, acc.: 55.86%] [Generator loss: 0.7979%]\n",
            "11477 [Discriminator loss: 0.6601%, acc.: 60.94%] [Generator loss: 0.7852%]\n",
            "11478 [Discriminator loss: 0.6767%, acc.: 58.20%] [Generator loss: 0.8006%]\n",
            "11479 [Discriminator loss: 0.6577%, acc.: 63.28%] [Generator loss: 0.7969%]\n",
            "11480 [Discriminator loss: 0.6563%, acc.: 64.45%] [Generator loss: 0.7881%]\n",
            "11481 [Discriminator loss: 0.6671%, acc.: 58.20%] [Generator loss: 0.8259%]\n",
            "11482 [Discriminator loss: 0.6560%, acc.: 62.50%] [Generator loss: 0.7892%]\n",
            "11483 [Discriminator loss: 0.6542%, acc.: 67.19%] [Generator loss: 0.7822%]\n",
            "11484 [Discriminator loss: 0.6838%, acc.: 53.91%] [Generator loss: 0.7725%]\n",
            "11485 [Discriminator loss: 0.6611%, acc.: 60.94%] [Generator loss: 0.7933%]\n",
            "11486 [Discriminator loss: 0.6858%, acc.: 53.12%] [Generator loss: 0.7822%]\n",
            "11487 [Discriminator loss: 0.6733%, acc.: 55.86%] [Generator loss: 0.8005%]\n",
            "11488 [Discriminator loss: 0.6688%, acc.: 57.81%] [Generator loss: 0.8049%]\n",
            "11489 [Discriminator loss: 0.6665%, acc.: 59.77%] [Generator loss: 0.7945%]\n",
            "11490 [Discriminator loss: 0.6763%, acc.: 58.20%] [Generator loss: 0.8041%]\n",
            "11491 [Discriminator loss: 0.6773%, acc.: 53.91%] [Generator loss: 0.8066%]\n",
            "11492 [Discriminator loss: 0.6709%, acc.: 57.03%] [Generator loss: 0.7864%]\n",
            "11493 [Discriminator loss: 0.6750%, acc.: 57.42%] [Generator loss: 0.7795%]\n",
            "11494 [Discriminator loss: 0.6706%, acc.: 60.16%] [Generator loss: 0.7834%]\n",
            "11495 [Discriminator loss: 0.6790%, acc.: 56.64%] [Generator loss: 0.8077%]\n",
            "11496 [Discriminator loss: 0.6646%, acc.: 62.11%] [Generator loss: 0.7732%]\n",
            "11497 [Discriminator loss: 0.6808%, acc.: 57.42%] [Generator loss: 0.7904%]\n",
            "11498 [Discriminator loss: 0.6622%, acc.: 61.72%] [Generator loss: 0.7865%]\n",
            "11499 [Discriminator loss: 0.6642%, acc.: 61.33%] [Generator loss: 0.7830%]\n",
            "11500 [Discriminator loss: 0.6863%, acc.: 57.42%] [Generator loss: 0.7899%]\n",
            "11501 [Discriminator loss: 0.6750%, acc.: 57.03%] [Generator loss: 0.7720%]\n",
            "11502 [Discriminator loss: 0.6623%, acc.: 60.94%] [Generator loss: 0.7904%]\n",
            "11503 [Discriminator loss: 0.6810%, acc.: 58.59%] [Generator loss: 0.7902%]\n",
            "11504 [Discriminator loss: 0.6592%, acc.: 58.59%] [Generator loss: 0.8083%]\n",
            "11505 [Discriminator loss: 0.6739%, acc.: 56.64%] [Generator loss: 0.8092%]\n",
            "11506 [Discriminator loss: 0.6689%, acc.: 57.81%] [Generator loss: 0.7931%]\n",
            "11507 [Discriminator loss: 0.6810%, acc.: 57.03%] [Generator loss: 0.8067%]\n",
            "11508 [Discriminator loss: 0.6823%, acc.: 56.25%] [Generator loss: 0.8078%]\n",
            "11509 [Discriminator loss: 0.6610%, acc.: 59.38%] [Generator loss: 0.7713%]\n",
            "11510 [Discriminator loss: 0.6548%, acc.: 62.89%] [Generator loss: 0.7943%]\n",
            "11511 [Discriminator loss: 0.6711%, acc.: 60.16%] [Generator loss: 0.7711%]\n",
            "11512 [Discriminator loss: 0.6631%, acc.: 58.20%] [Generator loss: 0.7806%]\n",
            "11513 [Discriminator loss: 0.6516%, acc.: 61.72%] [Generator loss: 0.7884%]\n",
            "11514 [Discriminator loss: 0.6765%, acc.: 56.64%] [Generator loss: 0.7973%]\n",
            "11515 [Discriminator loss: 0.6808%, acc.: 54.69%] [Generator loss: 0.7684%]\n",
            "11516 [Discriminator loss: 0.6581%, acc.: 59.77%] [Generator loss: 0.8063%]\n",
            "11517 [Discriminator loss: 0.6609%, acc.: 61.33%] [Generator loss: 0.7897%]\n",
            "11518 [Discriminator loss: 0.6674%, acc.: 57.42%] [Generator loss: 0.7723%]\n",
            "11519 [Discriminator loss: 0.6869%, acc.: 56.64%] [Generator loss: 0.7838%]\n",
            "11520 [Discriminator loss: 0.6631%, acc.: 60.16%] [Generator loss: 0.7914%]\n",
            "11521 [Discriminator loss: 0.6720%, acc.: 56.25%] [Generator loss: 0.7858%]\n",
            "11522 [Discriminator loss: 0.6608%, acc.: 61.33%] [Generator loss: 0.8117%]\n",
            "11523 [Discriminator loss: 0.6501%, acc.: 66.41%] [Generator loss: 0.7871%]\n",
            "11524 [Discriminator loss: 0.6460%, acc.: 64.45%] [Generator loss: 0.7742%]\n",
            "11525 [Discriminator loss: 0.6627%, acc.: 62.11%] [Generator loss: 0.7996%]\n",
            "11526 [Discriminator loss: 0.6567%, acc.: 57.42%] [Generator loss: 0.7756%]\n",
            "11527 [Discriminator loss: 0.6612%, acc.: 60.16%] [Generator loss: 0.7794%]\n",
            "11528 [Discriminator loss: 0.6808%, acc.: 59.38%] [Generator loss: 0.7797%]\n",
            "11529 [Discriminator loss: 0.6743%, acc.: 58.59%] [Generator loss: 0.8132%]\n",
            "11530 [Discriminator loss: 0.6609%, acc.: 61.33%] [Generator loss: 0.7994%]\n",
            "11531 [Discriminator loss: 0.6716%, acc.: 57.42%] [Generator loss: 0.8029%]\n",
            "11532 [Discriminator loss: 0.6664%, acc.: 58.98%] [Generator loss: 0.7752%]\n",
            "11533 [Discriminator loss: 0.6879%, acc.: 55.86%] [Generator loss: 0.8071%]\n",
            "11534 [Discriminator loss: 0.6800%, acc.: 56.25%] [Generator loss: 0.7853%]\n",
            "11535 [Discriminator loss: 0.6704%, acc.: 55.47%] [Generator loss: 0.8015%]\n",
            "11536 [Discriminator loss: 0.6557%, acc.: 65.23%] [Generator loss: 0.7985%]\n",
            "11537 [Discriminator loss: 0.6766%, acc.: 58.59%] [Generator loss: 0.7959%]\n",
            "11538 [Discriminator loss: 0.6881%, acc.: 53.12%] [Generator loss: 0.7721%]\n",
            "11539 [Discriminator loss: 0.6651%, acc.: 60.55%] [Generator loss: 0.7855%]\n",
            "11540 [Discriminator loss: 0.6666%, acc.: 60.16%] [Generator loss: 0.7826%]\n",
            "11541 [Discriminator loss: 0.6757%, acc.: 63.67%] [Generator loss: 0.7965%]\n",
            "11542 [Discriminator loss: 0.6712%, acc.: 58.20%] [Generator loss: 0.7856%]\n",
            "11543 [Discriminator loss: 0.6384%, acc.: 65.62%] [Generator loss: 0.7956%]\n",
            "11544 [Discriminator loss: 0.6623%, acc.: 60.16%] [Generator loss: 0.8029%]\n",
            "11545 [Discriminator loss: 0.6802%, acc.: 57.03%] [Generator loss: 0.7906%]\n",
            "11546 [Discriminator loss: 0.6845%, acc.: 57.03%] [Generator loss: 0.7918%]\n",
            "11547 [Discriminator loss: 0.6701%, acc.: 60.55%] [Generator loss: 0.7936%]\n",
            "11548 [Discriminator loss: 0.6827%, acc.: 52.73%] [Generator loss: 0.8002%]\n",
            "11549 [Discriminator loss: 0.6572%, acc.: 65.23%] [Generator loss: 0.7933%]\n",
            "11550 [Discriminator loss: 0.6750%, acc.: 58.20%] [Generator loss: 0.8056%]\n",
            "11551 [Discriminator loss: 0.6683%, acc.: 60.94%] [Generator loss: 0.7845%]\n",
            "11552 [Discriminator loss: 0.6595%, acc.: 58.59%] [Generator loss: 0.8056%]\n",
            "11553 [Discriminator loss: 0.6785%, acc.: 56.25%] [Generator loss: 0.7789%]\n",
            "11554 [Discriminator loss: 0.6506%, acc.: 59.38%] [Generator loss: 0.7857%]\n",
            "11555 [Discriminator loss: 0.6831%, acc.: 56.64%] [Generator loss: 0.8015%]\n",
            "11556 [Discriminator loss: 0.6678%, acc.: 58.98%] [Generator loss: 0.7964%]\n",
            "11557 [Discriminator loss: 0.6719%, acc.: 58.20%] [Generator loss: 0.7729%]\n",
            "11558 [Discriminator loss: 0.6648%, acc.: 61.72%] [Generator loss: 0.8047%]\n",
            "11559 [Discriminator loss: 0.6740%, acc.: 60.16%] [Generator loss: 0.8073%]\n",
            "11560 [Discriminator loss: 0.6800%, acc.: 57.42%] [Generator loss: 0.7959%]\n",
            "11561 [Discriminator loss: 0.6652%, acc.: 61.72%] [Generator loss: 0.7950%]\n",
            "11562 [Discriminator loss: 0.6595%, acc.: 60.94%] [Generator loss: 0.7753%]\n",
            "11563 [Discriminator loss: 0.6659%, acc.: 61.72%] [Generator loss: 0.7866%]\n",
            "11564 [Discriminator loss: 0.6614%, acc.: 62.89%] [Generator loss: 0.7706%]\n",
            "11565 [Discriminator loss: 0.6645%, acc.: 59.38%] [Generator loss: 0.8063%]\n",
            "11566 [Discriminator loss: 0.6461%, acc.: 64.84%] [Generator loss: 0.7794%]\n",
            "11567 [Discriminator loss: 0.6876%, acc.: 52.34%] [Generator loss: 0.7858%]\n",
            "11568 [Discriminator loss: 0.6772%, acc.: 55.86%] [Generator loss: 0.7662%]\n",
            "11569 [Discriminator loss: 0.6623%, acc.: 60.55%] [Generator loss: 0.7819%]\n",
            "11570 [Discriminator loss: 0.6553%, acc.: 60.55%] [Generator loss: 0.7896%]\n",
            "11571 [Discriminator loss: 0.6604%, acc.: 61.33%] [Generator loss: 0.8023%]\n",
            "11572 [Discriminator loss: 0.6695%, acc.: 58.20%] [Generator loss: 0.7936%]\n",
            "11573 [Discriminator loss: 0.6656%, acc.: 57.42%] [Generator loss: 0.7758%]\n",
            "11574 [Discriminator loss: 0.6595%, acc.: 62.89%] [Generator loss: 0.8026%]\n",
            "11575 [Discriminator loss: 0.6633%, acc.: 60.16%] [Generator loss: 0.7669%]\n",
            "11576 [Discriminator loss: 0.6880%, acc.: 55.08%] [Generator loss: 0.7799%]\n",
            "11577 [Discriminator loss: 0.6624%, acc.: 60.16%] [Generator loss: 0.8116%]\n",
            "11578 [Discriminator loss: 0.6689%, acc.: 59.38%] [Generator loss: 0.8123%]\n",
            "11579 [Discriminator loss: 0.6829%, acc.: 55.08%] [Generator loss: 0.8032%]\n",
            "11580 [Discriminator loss: 0.6687%, acc.: 60.16%] [Generator loss: 0.8054%]\n",
            "11581 [Discriminator loss: 0.6811%, acc.: 56.25%] [Generator loss: 0.7763%]\n",
            "11582 [Discriminator loss: 0.6513%, acc.: 63.28%] [Generator loss: 0.7918%]\n",
            "11583 [Discriminator loss: 0.6990%, acc.: 53.52%] [Generator loss: 0.7913%]\n",
            "11584 [Discriminator loss: 0.6636%, acc.: 60.16%] [Generator loss: 0.7904%]\n",
            "11585 [Discriminator loss: 0.6711%, acc.: 59.38%] [Generator loss: 0.7880%]\n",
            "11586 [Discriminator loss: 0.6584%, acc.: 62.50%] [Generator loss: 0.8226%]\n",
            "11587 [Discriminator loss: 0.6670%, acc.: 62.50%] [Generator loss: 0.7916%]\n",
            "11588 [Discriminator loss: 0.6808%, acc.: 57.42%] [Generator loss: 0.7848%]\n",
            "11589 [Discriminator loss: 0.6696%, acc.: 59.77%] [Generator loss: 0.7863%]\n",
            "11590 [Discriminator loss: 0.6652%, acc.: 61.72%] [Generator loss: 0.7996%]\n",
            "11591 [Discriminator loss: 0.6640%, acc.: 60.94%] [Generator loss: 0.7904%]\n",
            "11592 [Discriminator loss: 0.6854%, acc.: 55.47%] [Generator loss: 0.7969%]\n",
            "11593 [Discriminator loss: 0.6575%, acc.: 62.89%] [Generator loss: 0.7805%]\n",
            "11594 [Discriminator loss: 0.6664%, acc.: 60.16%] [Generator loss: 0.7731%]\n",
            "11595 [Discriminator loss: 0.6626%, acc.: 61.33%] [Generator loss: 0.7646%]\n",
            "11596 [Discriminator loss: 0.6626%, acc.: 61.72%] [Generator loss: 0.7826%]\n",
            "11597 [Discriminator loss: 0.6770%, acc.: 53.91%] [Generator loss: 0.7759%]\n",
            "11598 [Discriminator loss: 0.6877%, acc.: 51.56%] [Generator loss: 0.7984%]\n",
            "11599 [Discriminator loss: 0.6706%, acc.: 60.94%] [Generator loss: 0.7853%]\n",
            "11600 [Discriminator loss: 0.6520%, acc.: 66.02%] [Generator loss: 0.7803%]\n",
            "11601 [Discriminator loss: 0.6708%, acc.: 61.33%] [Generator loss: 0.7953%]\n",
            "11602 [Discriminator loss: 0.6564%, acc.: 60.94%] [Generator loss: 0.7926%]\n",
            "11603 [Discriminator loss: 0.6517%, acc.: 61.72%] [Generator loss: 0.7980%]\n",
            "11604 [Discriminator loss: 0.6598%, acc.: 62.11%] [Generator loss: 0.7668%]\n",
            "11605 [Discriminator loss: 0.6830%, acc.: 54.69%] [Generator loss: 0.7878%]\n",
            "11606 [Discriminator loss: 0.6572%, acc.: 64.06%] [Generator loss: 0.7730%]\n",
            "11607 [Discriminator loss: 0.6623%, acc.: 61.72%] [Generator loss: 0.7873%]\n",
            "11608 [Discriminator loss: 0.6718%, acc.: 58.20%] [Generator loss: 0.7916%]\n",
            "11609 [Discriminator loss: 0.6734%, acc.: 58.20%] [Generator loss: 0.8005%]\n",
            "11610 [Discriminator loss: 0.6696%, acc.: 60.94%] [Generator loss: 0.8213%]\n",
            "11611 [Discriminator loss: 0.6627%, acc.: 62.11%] [Generator loss: 0.7818%]\n",
            "11612 [Discriminator loss: 0.6655%, acc.: 58.98%] [Generator loss: 0.8052%]\n",
            "11613 [Discriminator loss: 0.6688%, acc.: 58.20%] [Generator loss: 0.8097%]\n",
            "11614 [Discriminator loss: 0.6596%, acc.: 63.67%] [Generator loss: 0.7938%]\n",
            "11615 [Discriminator loss: 0.6678%, acc.: 62.50%] [Generator loss: 0.7903%]\n",
            "11616 [Discriminator loss: 0.6641%, acc.: 60.55%] [Generator loss: 0.7940%]\n",
            "11617 [Discriminator loss: 0.6781%, acc.: 59.77%] [Generator loss: 0.8051%]\n",
            "11618 [Discriminator loss: 0.6573%, acc.: 59.77%] [Generator loss: 0.7875%]\n",
            "11619 [Discriminator loss: 0.6633%, acc.: 59.77%] [Generator loss: 0.7850%]\n",
            "11620 [Discriminator loss: 0.6806%, acc.: 58.98%] [Generator loss: 0.7860%]\n",
            "11621 [Discriminator loss: 0.6657%, acc.: 61.33%] [Generator loss: 0.7918%]\n",
            "11622 [Discriminator loss: 0.6807%, acc.: 55.86%] [Generator loss: 0.7959%]\n",
            "11623 [Discriminator loss: 0.6931%, acc.: 53.52%] [Generator loss: 0.8386%]\n",
            "11624 [Discriminator loss: 0.6605%, acc.: 62.89%] [Generator loss: 0.7923%]\n",
            "11625 [Discriminator loss: 0.6589%, acc.: 59.77%] [Generator loss: 0.8083%]\n",
            "11626 [Discriminator loss: 0.6738%, acc.: 58.98%] [Generator loss: 0.7946%]\n",
            "11627 [Discriminator loss: 0.6737%, acc.: 57.81%] [Generator loss: 0.7898%]\n",
            "11628 [Discriminator loss: 0.6610%, acc.: 58.59%] [Generator loss: 0.8011%]\n",
            "11629 [Discriminator loss: 0.6714%, acc.: 57.42%] [Generator loss: 0.8135%]\n",
            "11630 [Discriminator loss: 0.6732%, acc.: 55.47%] [Generator loss: 0.7634%]\n",
            "11631 [Discriminator loss: 0.6817%, acc.: 52.73%] [Generator loss: 0.7741%]\n",
            "11632 [Discriminator loss: 0.6689%, acc.: 59.38%] [Generator loss: 0.7856%]\n",
            "11633 [Discriminator loss: 0.6704%, acc.: 59.38%] [Generator loss: 0.7750%]\n",
            "11634 [Discriminator loss: 0.6512%, acc.: 62.11%] [Generator loss: 0.7849%]\n",
            "11635 [Discriminator loss: 0.6770%, acc.: 57.03%] [Generator loss: 0.7895%]\n",
            "11636 [Discriminator loss: 0.6680%, acc.: 56.25%] [Generator loss: 0.7737%]\n",
            "11637 [Discriminator loss: 0.6721%, acc.: 60.16%] [Generator loss: 0.7941%]\n",
            "11638 [Discriminator loss: 0.6617%, acc.: 59.77%] [Generator loss: 0.7666%]\n",
            "11639 [Discriminator loss: 0.6942%, acc.: 50.78%] [Generator loss: 0.7899%]\n",
            "11640 [Discriminator loss: 0.6918%, acc.: 57.81%] [Generator loss: 0.7841%]\n",
            "11641 [Discriminator loss: 0.6713%, acc.: 58.98%] [Generator loss: 0.7884%]\n",
            "11642 [Discriminator loss: 0.6886%, acc.: 55.08%] [Generator loss: 0.7953%]\n",
            "11643 [Discriminator loss: 0.6823%, acc.: 54.69%] [Generator loss: 0.7733%]\n",
            "11644 [Discriminator loss: 0.6651%, acc.: 57.42%] [Generator loss: 0.7825%]\n",
            "11645 [Discriminator loss: 0.6654%, acc.: 58.59%] [Generator loss: 0.7722%]\n",
            "11646 [Discriminator loss: 0.6715%, acc.: 58.20%] [Generator loss: 0.7748%]\n",
            "11647 [Discriminator loss: 0.6651%, acc.: 62.11%] [Generator loss: 0.7903%]\n",
            "11648 [Discriminator loss: 0.6552%, acc.: 58.98%] [Generator loss: 0.7773%]\n",
            "11649 [Discriminator loss: 0.6590%, acc.: 58.59%] [Generator loss: 0.7909%]\n",
            "11650 [Discriminator loss: 0.6652%, acc.: 57.42%] [Generator loss: 0.7842%]\n",
            "11651 [Discriminator loss: 0.6489%, acc.: 62.11%] [Generator loss: 0.8006%]\n",
            "11652 [Discriminator loss: 0.6876%, acc.: 57.81%] [Generator loss: 0.7835%]\n",
            "11653 [Discriminator loss: 0.6651%, acc.: 58.20%] [Generator loss: 0.8049%]\n",
            "11654 [Discriminator loss: 0.6631%, acc.: 62.89%] [Generator loss: 0.7791%]\n",
            "11655 [Discriminator loss: 0.6882%, acc.: 60.16%] [Generator loss: 0.7989%]\n",
            "11656 [Discriminator loss: 0.6647%, acc.: 59.77%] [Generator loss: 0.8085%]\n",
            "11657 [Discriminator loss: 0.6616%, acc.: 62.50%] [Generator loss: 0.8175%]\n",
            "11658 [Discriminator loss: 0.6826%, acc.: 52.73%] [Generator loss: 0.8077%]\n",
            "11659 [Discriminator loss: 0.6750%, acc.: 58.98%] [Generator loss: 0.7897%]\n",
            "11660 [Discriminator loss: 0.6544%, acc.: 60.16%] [Generator loss: 0.7854%]\n",
            "11661 [Discriminator loss: 0.6715%, acc.: 57.42%] [Generator loss: 0.7775%]\n",
            "11662 [Discriminator loss: 0.6584%, acc.: 60.16%] [Generator loss: 0.7998%]\n",
            "11663 [Discriminator loss: 0.6659%, acc.: 60.55%] [Generator loss: 0.8081%]\n",
            "11664 [Discriminator loss: 0.6704%, acc.: 61.33%] [Generator loss: 0.8042%]\n",
            "11665 [Discriminator loss: 0.6571%, acc.: 62.50%] [Generator loss: 0.7874%]\n",
            "11666 [Discriminator loss: 0.6779%, acc.: 57.03%] [Generator loss: 0.7990%]\n",
            "11667 [Discriminator loss: 0.6893%, acc.: 53.12%] [Generator loss: 0.8001%]\n",
            "11668 [Discriminator loss: 0.6625%, acc.: 58.98%] [Generator loss: 0.7934%]\n",
            "11669 [Discriminator loss: 0.6699%, acc.: 58.59%] [Generator loss: 0.7659%]\n",
            "11670 [Discriminator loss: 0.6822%, acc.: 56.25%] [Generator loss: 0.7714%]\n",
            "11671 [Discriminator loss: 0.6584%, acc.: 61.72%] [Generator loss: 0.7772%]\n",
            "11672 [Discriminator loss: 0.6642%, acc.: 61.33%] [Generator loss: 0.8010%]\n",
            "11673 [Discriminator loss: 0.6789%, acc.: 57.03%] [Generator loss: 0.7838%]\n",
            "11674 [Discriminator loss: 0.6621%, acc.: 63.67%] [Generator loss: 0.7990%]\n",
            "11675 [Discriminator loss: 0.6856%, acc.: 52.73%] [Generator loss: 0.7982%]\n",
            "11676 [Discriminator loss: 0.6732%, acc.: 57.81%] [Generator loss: 0.7649%]\n",
            "11677 [Discriminator loss: 0.6672%, acc.: 60.55%] [Generator loss: 0.7840%]\n",
            "11678 [Discriminator loss: 0.6691%, acc.: 59.38%] [Generator loss: 0.7631%]\n",
            "11679 [Discriminator loss: 0.6751%, acc.: 60.16%] [Generator loss: 0.8027%]\n",
            "11680 [Discriminator loss: 0.6874%, acc.: 58.59%] [Generator loss: 0.7697%]\n",
            "11681 [Discriminator loss: 0.6758%, acc.: 53.91%] [Generator loss: 0.8079%]\n",
            "11682 [Discriminator loss: 0.6738%, acc.: 55.86%] [Generator loss: 0.8019%]\n",
            "11683 [Discriminator loss: 0.6676%, acc.: 63.67%] [Generator loss: 0.7959%]\n",
            "11684 [Discriminator loss: 0.6755%, acc.: 59.38%] [Generator loss: 0.7902%]\n",
            "11685 [Discriminator loss: 0.6694%, acc.: 56.64%] [Generator loss: 0.7843%]\n",
            "11686 [Discriminator loss: 0.6744%, acc.: 58.59%] [Generator loss: 0.7949%]\n",
            "11687 [Discriminator loss: 0.6695%, acc.: 58.59%] [Generator loss: 0.8006%]\n",
            "11688 [Discriminator loss: 0.6539%, acc.: 62.89%] [Generator loss: 0.7965%]\n",
            "11689 [Discriminator loss: 0.6612%, acc.: 66.02%] [Generator loss: 0.8083%]\n",
            "11690 [Discriminator loss: 0.6758%, acc.: 58.59%] [Generator loss: 0.7977%]\n",
            "11691 [Discriminator loss: 0.6737%, acc.: 53.12%] [Generator loss: 0.8253%]\n",
            "11692 [Discriminator loss: 0.6656%, acc.: 57.42%] [Generator loss: 0.7949%]\n",
            "11693 [Discriminator loss: 0.6683%, acc.: 60.94%] [Generator loss: 0.7751%]\n",
            "11694 [Discriminator loss: 0.6694%, acc.: 59.77%] [Generator loss: 0.7883%]\n",
            "11695 [Discriminator loss: 0.6701%, acc.: 58.20%] [Generator loss: 0.7953%]\n",
            "11696 [Discriminator loss: 0.6618%, acc.: 58.98%] [Generator loss: 0.7757%]\n",
            "11697 [Discriminator loss: 0.6526%, acc.: 60.16%] [Generator loss: 0.7960%]\n",
            "11698 [Discriminator loss: 0.6774%, acc.: 59.77%] [Generator loss: 0.7986%]\n",
            "11699 [Discriminator loss: 0.6773%, acc.: 56.25%] [Generator loss: 0.7942%]\n",
            "11700 [Discriminator loss: 0.6566%, acc.: 60.94%] [Generator loss: 0.7809%]\n",
            "11701 [Discriminator loss: 0.6663%, acc.: 59.38%] [Generator loss: 0.7852%]\n",
            "11702 [Discriminator loss: 0.6733%, acc.: 60.16%] [Generator loss: 0.7913%]\n",
            "11703 [Discriminator loss: 0.6621%, acc.: 62.89%] [Generator loss: 0.7991%]\n",
            "11704 [Discriminator loss: 0.6608%, acc.: 63.67%] [Generator loss: 0.7849%]\n",
            "11705 [Discriminator loss: 0.6801%, acc.: 56.25%] [Generator loss: 0.7920%]\n",
            "11706 [Discriminator loss: 0.6625%, acc.: 58.20%] [Generator loss: 0.8078%]\n",
            "11707 [Discriminator loss: 0.6706%, acc.: 58.59%] [Generator loss: 0.7812%]\n",
            "11708 [Discriminator loss: 0.6688%, acc.: 58.20%] [Generator loss: 0.7963%]\n",
            "11709 [Discriminator loss: 0.6682%, acc.: 61.72%] [Generator loss: 0.7832%]\n",
            "11710 [Discriminator loss: 0.6750%, acc.: 59.77%] [Generator loss: 0.7952%]\n",
            "11711 [Discriminator loss: 0.6673%, acc.: 61.33%] [Generator loss: 0.8073%]\n",
            "11712 [Discriminator loss: 0.6771%, acc.: 55.86%] [Generator loss: 0.8201%]\n",
            "11713 [Discriminator loss: 0.6826%, acc.: 56.64%] [Generator loss: 0.7653%]\n",
            "11714 [Discriminator loss: 0.6813%, acc.: 54.69%] [Generator loss: 0.8083%]\n",
            "11715 [Discriminator loss: 0.6701%, acc.: 55.47%] [Generator loss: 0.8016%]\n",
            "11716 [Discriminator loss: 0.6780%, acc.: 55.86%] [Generator loss: 0.7904%]\n",
            "11717 [Discriminator loss: 0.6468%, acc.: 65.23%] [Generator loss: 0.7961%]\n",
            "11718 [Discriminator loss: 0.6753%, acc.: 54.30%] [Generator loss: 0.7618%]\n",
            "11719 [Discriminator loss: 0.6647%, acc.: 60.94%] [Generator loss: 0.7987%]\n",
            "11720 [Discriminator loss: 0.6559%, acc.: 63.67%] [Generator loss: 0.8061%]\n",
            "11721 [Discriminator loss: 0.6621%, acc.: 58.20%] [Generator loss: 0.7775%]\n",
            "11722 [Discriminator loss: 0.6704%, acc.: 55.86%] [Generator loss: 0.7710%]\n",
            "11723 [Discriminator loss: 0.6534%, acc.: 62.11%] [Generator loss: 0.7745%]\n",
            "11724 [Discriminator loss: 0.6585%, acc.: 60.94%] [Generator loss: 0.7720%]\n",
            "11725 [Discriminator loss: 0.6539%, acc.: 61.72%] [Generator loss: 0.7867%]\n",
            "11726 [Discriminator loss: 0.6585%, acc.: 60.55%] [Generator loss: 0.7961%]\n",
            "11727 [Discriminator loss: 0.6644%, acc.: 58.20%] [Generator loss: 0.7818%]\n",
            "11728 [Discriminator loss: 0.6626%, acc.: 57.03%] [Generator loss: 0.8124%]\n",
            "11729 [Discriminator loss: 0.6810%, acc.: 57.81%] [Generator loss: 0.7859%]\n",
            "11730 [Discriminator loss: 0.6726%, acc.: 60.94%] [Generator loss: 0.7963%]\n",
            "11731 [Discriminator loss: 0.6790%, acc.: 57.03%] [Generator loss: 0.7993%]\n",
            "11732 [Discriminator loss: 0.6858%, acc.: 52.73%] [Generator loss: 0.7901%]\n",
            "11733 [Discriminator loss: 0.6799%, acc.: 55.08%] [Generator loss: 0.8212%]\n",
            "11734 [Discriminator loss: 0.6705%, acc.: 57.81%] [Generator loss: 0.8078%]\n",
            "11735 [Discriminator loss: 0.6639%, acc.: 61.33%] [Generator loss: 0.8355%]\n",
            "11736 [Discriminator loss: 0.6566%, acc.: 62.11%] [Generator loss: 0.8130%]\n",
            "11737 [Discriminator loss: 0.6679%, acc.: 56.64%] [Generator loss: 0.7804%]\n",
            "11738 [Discriminator loss: 0.6717%, acc.: 57.03%] [Generator loss: 0.7853%]\n",
            "11739 [Discriminator loss: 0.6612%, acc.: 60.55%] [Generator loss: 0.8125%]\n",
            "11740 [Discriminator loss: 0.6683%, acc.: 57.81%] [Generator loss: 0.8065%]\n",
            "11741 [Discriminator loss: 0.6699%, acc.: 62.50%] [Generator loss: 0.7990%]\n",
            "11742 [Discriminator loss: 0.6623%, acc.: 59.77%] [Generator loss: 0.8167%]\n",
            "11743 [Discriminator loss: 0.6785%, acc.: 60.94%] [Generator loss: 0.7996%]\n",
            "11744 [Discriminator loss: 0.6615%, acc.: 56.25%] [Generator loss: 0.7792%]\n",
            "11745 [Discriminator loss: 0.6626%, acc.: 59.38%] [Generator loss: 0.7763%]\n",
            "11746 [Discriminator loss: 0.6807%, acc.: 56.25%] [Generator loss: 0.7762%]\n",
            "11747 [Discriminator loss: 0.6705%, acc.: 60.55%] [Generator loss: 0.7794%]\n",
            "11748 [Discriminator loss: 0.6774%, acc.: 58.59%] [Generator loss: 0.7777%]\n",
            "11749 [Discriminator loss: 0.6931%, acc.: 52.73%] [Generator loss: 0.7891%]\n",
            "11750 [Discriminator loss: 0.6811%, acc.: 55.86%] [Generator loss: 0.7693%]\n",
            "11751 [Discriminator loss: 0.6824%, acc.: 58.20%] [Generator loss: 0.8130%]\n",
            "11752 [Discriminator loss: 0.6688%, acc.: 57.42%] [Generator loss: 0.7793%]\n",
            "11753 [Discriminator loss: 0.6785%, acc.: 53.52%] [Generator loss: 0.7926%]\n",
            "11754 [Discriminator loss: 0.6713%, acc.: 61.72%] [Generator loss: 0.7926%]\n",
            "11755 [Discriminator loss: 0.6646%, acc.: 60.55%] [Generator loss: 0.8401%]\n",
            "11756 [Discriminator loss: 0.6783%, acc.: 55.86%] [Generator loss: 0.8044%]\n",
            "11757 [Discriminator loss: 0.6659%, acc.: 58.59%] [Generator loss: 0.8049%]\n",
            "11758 [Discriminator loss: 0.6537%, acc.: 62.11%] [Generator loss: 0.8113%]\n",
            "11759 [Discriminator loss: 0.6716%, acc.: 62.50%] [Generator loss: 0.7882%]\n",
            "11760 [Discriminator loss: 0.6577%, acc.: 63.28%] [Generator loss: 0.8073%]\n",
            "11761 [Discriminator loss: 0.6575%, acc.: 63.67%] [Generator loss: 0.8010%]\n",
            "11762 [Discriminator loss: 0.6690%, acc.: 64.45%] [Generator loss: 0.7846%]\n",
            "11763 [Discriminator loss: 0.6701%, acc.: 55.47%] [Generator loss: 0.7864%]\n",
            "11764 [Discriminator loss: 0.6643%, acc.: 62.11%] [Generator loss: 0.7882%]\n",
            "11765 [Discriminator loss: 0.6719%, acc.: 59.77%] [Generator loss: 0.7788%]\n",
            "11766 [Discriminator loss: 0.6745%, acc.: 56.64%] [Generator loss: 0.7923%]\n",
            "11767 [Discriminator loss: 0.6782%, acc.: 57.81%] [Generator loss: 0.8061%]\n",
            "11768 [Discriminator loss: 0.6639%, acc.: 60.16%] [Generator loss: 0.7996%]\n",
            "11769 [Discriminator loss: 0.6668%, acc.: 58.59%] [Generator loss: 0.7972%]\n",
            "11770 [Discriminator loss: 0.6702%, acc.: 57.42%] [Generator loss: 0.7889%]\n",
            "11771 [Discriminator loss: 0.6617%, acc.: 60.16%] [Generator loss: 0.7834%]\n",
            "11772 [Discriminator loss: 0.6788%, acc.: 56.25%] [Generator loss: 0.7964%]\n",
            "11773 [Discriminator loss: 0.6551%, acc.: 63.67%] [Generator loss: 0.7959%]\n",
            "11774 [Discriminator loss: 0.6808%, acc.: 57.42%] [Generator loss: 0.8079%]\n",
            "11775 [Discriminator loss: 0.6702%, acc.: 56.25%] [Generator loss: 0.7926%]\n",
            "11776 [Discriminator loss: 0.6724%, acc.: 56.64%] [Generator loss: 0.7938%]\n",
            "11777 [Discriminator loss: 0.6616%, acc.: 61.33%] [Generator loss: 0.7900%]\n",
            "11778 [Discriminator loss: 0.6709%, acc.: 56.25%] [Generator loss: 0.8292%]\n",
            "11779 [Discriminator loss: 0.6797%, acc.: 58.20%] [Generator loss: 0.7719%]\n",
            "11780 [Discriminator loss: 0.6534%, acc.: 66.41%] [Generator loss: 0.8005%]\n",
            "11781 [Discriminator loss: 0.6864%, acc.: 50.78%] [Generator loss: 0.7994%]\n",
            "11782 [Discriminator loss: 0.6727%, acc.: 55.47%] [Generator loss: 0.7850%]\n",
            "11783 [Discriminator loss: 0.6594%, acc.: 65.62%] [Generator loss: 0.7934%]\n",
            "11784 [Discriminator loss: 0.6563%, acc.: 59.38%] [Generator loss: 0.7973%]\n",
            "11785 [Discriminator loss: 0.6574%, acc.: 57.81%] [Generator loss: 0.8164%]\n",
            "11786 [Discriminator loss: 0.6903%, acc.: 54.30%] [Generator loss: 0.7712%]\n",
            "11787 [Discriminator loss: 0.6574%, acc.: 61.33%] [Generator loss: 0.7713%]\n",
            "11788 [Discriminator loss: 0.6548%, acc.: 57.42%] [Generator loss: 0.8145%]\n",
            "11789 [Discriminator loss: 0.6671%, acc.: 63.28%] [Generator loss: 0.7718%]\n",
            "11790 [Discriminator loss: 0.6579%, acc.: 64.06%] [Generator loss: 0.7882%]\n",
            "11791 [Discriminator loss: 0.6734%, acc.: 56.64%] [Generator loss: 0.7960%]\n",
            "11792 [Discriminator loss: 0.6750%, acc.: 55.47%] [Generator loss: 0.7938%]\n",
            "11793 [Discriminator loss: 0.6747%, acc.: 53.52%] [Generator loss: 0.7830%]\n",
            "11794 [Discriminator loss: 0.6718%, acc.: 57.81%] [Generator loss: 0.7723%]\n",
            "11795 [Discriminator loss: 0.6451%, acc.: 66.02%] [Generator loss: 0.7831%]\n",
            "11796 [Discriminator loss: 0.6889%, acc.: 51.95%] [Generator loss: 0.7645%]\n",
            "11797 [Discriminator loss: 0.6810%, acc.: 56.64%] [Generator loss: 0.7843%]\n",
            "11798 [Discriminator loss: 0.6705%, acc.: 58.20%] [Generator loss: 0.7861%]\n",
            "11799 [Discriminator loss: 0.6664%, acc.: 60.94%] [Generator loss: 0.7918%]\n",
            "11800 [Discriminator loss: 0.6657%, acc.: 57.81%] [Generator loss: 0.7968%]\n",
            "11801 [Discriminator loss: 0.6733%, acc.: 58.59%] [Generator loss: 0.8107%]\n",
            "11802 [Discriminator loss: 0.6630%, acc.: 58.20%] [Generator loss: 0.8176%]\n",
            "11803 [Discriminator loss: 0.6516%, acc.: 58.98%] [Generator loss: 0.7960%]\n",
            "11804 [Discriminator loss: 0.6566%, acc.: 64.06%] [Generator loss: 0.8290%]\n",
            "11805 [Discriminator loss: 0.6743%, acc.: 60.55%] [Generator loss: 0.7939%]\n",
            "11806 [Discriminator loss: 0.6641%, acc.: 61.72%] [Generator loss: 0.8112%]\n",
            "11807 [Discriminator loss: 0.6895%, acc.: 50.78%] [Generator loss: 0.7828%]\n",
            "11808 [Discriminator loss: 0.6796%, acc.: 53.91%] [Generator loss: 0.7897%]\n",
            "11809 [Discriminator loss: 0.6792%, acc.: 56.64%] [Generator loss: 0.7846%]\n",
            "11810 [Discriminator loss: 0.6854%, acc.: 53.12%] [Generator loss: 0.8122%]\n",
            "11811 [Discriminator loss: 0.6647%, acc.: 59.77%] [Generator loss: 0.8002%]\n",
            "11812 [Discriminator loss: 0.6580%, acc.: 61.33%] [Generator loss: 0.7999%]\n",
            "11813 [Discriminator loss: 0.6579%, acc.: 61.33%] [Generator loss: 0.8015%]\n",
            "11814 [Discriminator loss: 0.6626%, acc.: 57.03%] [Generator loss: 0.7934%]\n",
            "11815 [Discriminator loss: 0.6758%, acc.: 55.47%] [Generator loss: 0.8166%]\n",
            "11816 [Discriminator loss: 0.6691%, acc.: 57.03%] [Generator loss: 0.7933%]\n",
            "11817 [Discriminator loss: 0.6718%, acc.: 57.81%] [Generator loss: 0.7934%]\n",
            "11818 [Discriminator loss: 0.6607%, acc.: 59.38%] [Generator loss: 0.8154%]\n",
            "11819 [Discriminator loss: 0.6647%, acc.: 62.50%] [Generator loss: 0.8135%]\n",
            "11820 [Discriminator loss: 0.6729%, acc.: 57.81%] [Generator loss: 0.8043%]\n",
            "11821 [Discriminator loss: 0.6864%, acc.: 54.69%] [Generator loss: 0.7927%]\n",
            "11822 [Discriminator loss: 0.6634%, acc.: 58.59%] [Generator loss: 0.7764%]\n",
            "11823 [Discriminator loss: 0.6812%, acc.: 57.03%] [Generator loss: 0.7967%]\n",
            "11824 [Discriminator loss: 0.6848%, acc.: 57.81%] [Generator loss: 0.8072%]\n",
            "11825 [Discriminator loss: 0.6608%, acc.: 58.98%] [Generator loss: 0.8024%]\n",
            "11826 [Discriminator loss: 0.6755%, acc.: 55.86%] [Generator loss: 0.7917%]\n",
            "11827 [Discriminator loss: 0.6405%, acc.: 66.80%] [Generator loss: 0.8093%]\n",
            "11828 [Discriminator loss: 0.6644%, acc.: 60.16%] [Generator loss: 0.7942%]\n",
            "11829 [Discriminator loss: 0.6799%, acc.: 55.47%] [Generator loss: 0.7965%]\n",
            "11830 [Discriminator loss: 0.6773%, acc.: 58.20%] [Generator loss: 0.7986%]\n",
            "11831 [Discriminator loss: 0.6780%, acc.: 55.08%] [Generator loss: 0.7947%]\n",
            "11832 [Discriminator loss: 0.6696%, acc.: 58.59%] [Generator loss: 0.8022%]\n",
            "11833 [Discriminator loss: 0.6779%, acc.: 55.47%] [Generator loss: 0.7943%]\n",
            "11834 [Discriminator loss: 0.6720%, acc.: 56.64%] [Generator loss: 0.7765%]\n",
            "11835 [Discriminator loss: 0.6762%, acc.: 58.20%] [Generator loss: 0.7814%]\n",
            "11836 [Discriminator loss: 0.6776%, acc.: 59.38%] [Generator loss: 0.7648%]\n",
            "11837 [Discriminator loss: 0.6740%, acc.: 60.16%] [Generator loss: 0.7848%]\n",
            "11838 [Discriminator loss: 0.6830%, acc.: 51.95%] [Generator loss: 0.7729%]\n",
            "11839 [Discriminator loss: 0.6676%, acc.: 60.94%] [Generator loss: 0.7818%]\n",
            "11840 [Discriminator loss: 0.6843%, acc.: 55.47%] [Generator loss: 0.7704%]\n",
            "11841 [Discriminator loss: 0.6657%, acc.: 59.77%] [Generator loss: 0.7893%]\n",
            "11842 [Discriminator loss: 0.6735%, acc.: 55.47%] [Generator loss: 0.7824%]\n",
            "11843 [Discriminator loss: 0.6719%, acc.: 57.42%] [Generator loss: 0.7817%]\n",
            "11844 [Discriminator loss: 0.6877%, acc.: 54.30%] [Generator loss: 0.7930%]\n",
            "11845 [Discriminator loss: 0.6739%, acc.: 57.03%] [Generator loss: 0.7846%]\n",
            "11846 [Discriminator loss: 0.6617%, acc.: 59.77%] [Generator loss: 0.8060%]\n",
            "11847 [Discriminator loss: 0.6638%, acc.: 61.72%] [Generator loss: 0.7768%]\n",
            "11848 [Discriminator loss: 0.6704%, acc.: 60.55%] [Generator loss: 0.7927%]\n",
            "11849 [Discriminator loss: 0.6839%, acc.: 56.64%] [Generator loss: 0.7765%]\n",
            "11850 [Discriminator loss: 0.6575%, acc.: 60.55%] [Generator loss: 0.7828%]\n",
            "11851 [Discriminator loss: 0.6894%, acc.: 58.20%] [Generator loss: 0.7935%]\n",
            "11852 [Discriminator loss: 0.6673%, acc.: 55.86%] [Generator loss: 0.7401%]\n",
            "11853 [Discriminator loss: 0.6661%, acc.: 60.94%] [Generator loss: 0.7891%]\n",
            "11854 [Discriminator loss: 0.6576%, acc.: 62.11%] [Generator loss: 0.7898%]\n",
            "11855 [Discriminator loss: 0.6529%, acc.: 64.06%] [Generator loss: 0.8027%]\n",
            "11856 [Discriminator loss: 0.6628%, acc.: 57.81%] [Generator loss: 0.7799%]\n",
            "11857 [Discriminator loss: 0.6818%, acc.: 58.20%] [Generator loss: 0.7838%]\n",
            "11858 [Discriminator loss: 0.6622%, acc.: 63.28%] [Generator loss: 0.8161%]\n",
            "11859 [Discriminator loss: 0.6706%, acc.: 55.86%] [Generator loss: 0.7990%]\n",
            "11860 [Discriminator loss: 0.6802%, acc.: 56.64%] [Generator loss: 0.7788%]\n",
            "11861 [Discriminator loss: 0.6719%, acc.: 54.30%] [Generator loss: 0.7917%]\n",
            "11862 [Discriminator loss: 0.6732%, acc.: 57.03%] [Generator loss: 0.8047%]\n",
            "11863 [Discriminator loss: 0.6768%, acc.: 57.42%] [Generator loss: 0.7970%]\n",
            "11864 [Discriminator loss: 0.6731%, acc.: 59.38%] [Generator loss: 0.7686%]\n",
            "11865 [Discriminator loss: 0.6503%, acc.: 64.45%] [Generator loss: 0.7925%]\n",
            "11866 [Discriminator loss: 0.6567%, acc.: 62.89%] [Generator loss: 0.7860%]\n",
            "11867 [Discriminator loss: 0.6637%, acc.: 59.77%] [Generator loss: 0.7888%]\n",
            "11868 [Discriminator loss: 0.6656%, acc.: 60.16%] [Generator loss: 0.7673%]\n",
            "11869 [Discriminator loss: 0.6742%, acc.: 56.64%] [Generator loss: 0.7854%]\n",
            "11870 [Discriminator loss: 0.6788%, acc.: 59.38%] [Generator loss: 0.7769%]\n",
            "11871 [Discriminator loss: 0.6767%, acc.: 56.64%] [Generator loss: 0.8029%]\n",
            "11872 [Discriminator loss: 0.6729%, acc.: 60.94%] [Generator loss: 0.7644%]\n",
            "11873 [Discriminator loss: 0.6675%, acc.: 56.25%] [Generator loss: 0.8049%]\n",
            "11874 [Discriminator loss: 0.6569%, acc.: 60.55%] [Generator loss: 0.7749%]\n",
            "11875 [Discriminator loss: 0.6694%, acc.: 56.25%] [Generator loss: 0.7888%]\n",
            "11876 [Discriminator loss: 0.6827%, acc.: 57.81%] [Generator loss: 0.8087%]\n",
            "11877 [Discriminator loss: 0.6773%, acc.: 57.81%] [Generator loss: 0.8108%]\n",
            "11878 [Discriminator loss: 0.6837%, acc.: 57.03%] [Generator loss: 0.8114%]\n",
            "11879 [Discriminator loss: 0.6807%, acc.: 57.42%] [Generator loss: 0.7851%]\n",
            "11880 [Discriminator loss: 0.6711%, acc.: 60.16%] [Generator loss: 0.7934%]\n",
            "11881 [Discriminator loss: 0.6853%, acc.: 58.20%] [Generator loss: 0.8030%]\n",
            "11882 [Discriminator loss: 0.6834%, acc.: 56.64%] [Generator loss: 0.7841%]\n",
            "11883 [Discriminator loss: 0.6816%, acc.: 57.42%] [Generator loss: 0.7810%]\n",
            "11884 [Discriminator loss: 0.6789%, acc.: 57.81%] [Generator loss: 0.7797%]\n",
            "11885 [Discriminator loss: 0.6671%, acc.: 56.64%] [Generator loss: 0.8031%]\n",
            "11886 [Discriminator loss: 0.6781%, acc.: 59.77%] [Generator loss: 0.7610%]\n",
            "11887 [Discriminator loss: 0.6741%, acc.: 61.33%] [Generator loss: 0.7550%]\n",
            "11888 [Discriminator loss: 0.6713%, acc.: 60.16%] [Generator loss: 0.7687%]\n",
            "11889 [Discriminator loss: 0.6716%, acc.: 60.55%] [Generator loss: 0.7782%]\n",
            "11890 [Discriminator loss: 0.6683%, acc.: 59.38%] [Generator loss: 0.7775%]\n",
            "11891 [Discriminator loss: 0.6595%, acc.: 61.33%] [Generator loss: 0.7853%]\n",
            "11892 [Discriminator loss: 0.6807%, acc.: 55.47%] [Generator loss: 0.7793%]\n",
            "11893 [Discriminator loss: 0.6766%, acc.: 55.08%] [Generator loss: 0.7802%]\n",
            "11894 [Discriminator loss: 0.6962%, acc.: 53.52%] [Generator loss: 0.7914%]\n",
            "11895 [Discriminator loss: 0.6707%, acc.: 61.72%] [Generator loss: 0.7952%]\n",
            "11896 [Discriminator loss: 0.6698%, acc.: 60.55%] [Generator loss: 0.7939%]\n",
            "11897 [Discriminator loss: 0.6743%, acc.: 56.25%] [Generator loss: 0.7884%]\n",
            "11898 [Discriminator loss: 0.6674%, acc.: 60.55%] [Generator loss: 0.7719%]\n",
            "11899 [Discriminator loss: 0.6781%, acc.: 57.81%] [Generator loss: 0.7859%]\n",
            "11900 [Discriminator loss: 0.6657%, acc.: 59.38%] [Generator loss: 0.7986%]\n",
            "11901 [Discriminator loss: 0.6780%, acc.: 57.03%] [Generator loss: 0.7744%]\n",
            "11902 [Discriminator loss: 0.6597%, acc.: 59.77%] [Generator loss: 0.7965%]\n",
            "11903 [Discriminator loss: 0.6874%, acc.: 54.69%] [Generator loss: 0.7877%]\n",
            "11904 [Discriminator loss: 0.6529%, acc.: 62.89%] [Generator loss: 0.7785%]\n",
            "11905 [Discriminator loss: 0.6613%, acc.: 63.67%] [Generator loss: 0.7769%]\n",
            "11906 [Discriminator loss: 0.6619%, acc.: 59.77%] [Generator loss: 0.7657%]\n",
            "11907 [Discriminator loss: 0.6701%, acc.: 57.03%] [Generator loss: 0.8042%]\n",
            "11908 [Discriminator loss: 0.6776%, acc.: 59.77%] [Generator loss: 0.7938%]\n",
            "11909 [Discriminator loss: 0.6758%, acc.: 56.25%] [Generator loss: 0.7868%]\n",
            "11910 [Discriminator loss: 0.6761%, acc.: 59.38%] [Generator loss: 0.7989%]\n",
            "11911 [Discriminator loss: 0.6690%, acc.: 60.94%] [Generator loss: 0.7571%]\n",
            "11912 [Discriminator loss: 0.6759%, acc.: 58.20%] [Generator loss: 0.7893%]\n",
            "11913 [Discriminator loss: 0.6584%, acc.: 63.28%] [Generator loss: 0.7696%]\n",
            "11914 [Discriminator loss: 0.6606%, acc.: 62.50%] [Generator loss: 0.7832%]\n",
            "11915 [Discriminator loss: 0.6672%, acc.: 58.59%] [Generator loss: 0.7875%]\n",
            "11916 [Discriminator loss: 0.6581%, acc.: 61.33%] [Generator loss: 0.7851%]\n",
            "11917 [Discriminator loss: 0.6652%, acc.: 62.11%] [Generator loss: 0.7792%]\n",
            "11918 [Discriminator loss: 0.6684%, acc.: 55.08%] [Generator loss: 0.8115%]\n",
            "11919 [Discriminator loss: 0.6491%, acc.: 65.62%] [Generator loss: 0.8144%]\n",
            "11920 [Discriminator loss: 0.6846%, acc.: 57.03%] [Generator loss: 0.7795%]\n",
            "11921 [Discriminator loss: 0.6769%, acc.: 53.52%] [Generator loss: 0.7846%]\n",
            "11922 [Discriminator loss: 0.6764%, acc.: 58.59%] [Generator loss: 0.7724%]\n",
            "11923 [Discriminator loss: 0.6632%, acc.: 60.55%] [Generator loss: 0.8091%]\n",
            "11924 [Discriminator loss: 0.6738%, acc.: 56.25%] [Generator loss: 0.8023%]\n",
            "11925 [Discriminator loss: 0.6861%, acc.: 56.64%] [Generator loss: 0.8027%]\n",
            "11926 [Discriminator loss: 0.6595%, acc.: 63.28%] [Generator loss: 0.7908%]\n",
            "11927 [Discriminator loss: 0.6823%, acc.: 54.30%] [Generator loss: 0.8123%]\n",
            "11928 [Discriminator loss: 0.6690%, acc.: 58.98%] [Generator loss: 0.7857%]\n",
            "11929 [Discriminator loss: 0.6611%, acc.: 59.77%] [Generator loss: 0.7756%]\n",
            "11930 [Discriminator loss: 0.6730%, acc.: 58.98%] [Generator loss: 0.7736%]\n",
            "11931 [Discriminator loss: 0.6747%, acc.: 56.25%] [Generator loss: 0.7517%]\n",
            "11932 [Discriminator loss: 0.6653%, acc.: 60.55%] [Generator loss: 0.7707%]\n",
            "11933 [Discriminator loss: 0.6925%, acc.: 50.39%] [Generator loss: 0.7734%]\n",
            "11934 [Discriminator loss: 0.6655%, acc.: 59.77%] [Generator loss: 0.8088%]\n",
            "11935 [Discriminator loss: 0.6688%, acc.: 60.94%] [Generator loss: 0.7985%]\n",
            "11936 [Discriminator loss: 0.6561%, acc.: 63.28%] [Generator loss: 0.8021%]\n",
            "11937 [Discriminator loss: 0.6737%, acc.: 56.25%] [Generator loss: 0.7894%]\n",
            "11938 [Discriminator loss: 0.6666%, acc.: 57.03%] [Generator loss: 0.7934%]\n",
            "11939 [Discriminator loss: 0.6765%, acc.: 54.69%] [Generator loss: 0.7885%]\n",
            "11940 [Discriminator loss: 0.6625%, acc.: 60.94%] [Generator loss: 0.8013%]\n",
            "11941 [Discriminator loss: 0.6576%, acc.: 64.84%] [Generator loss: 0.7905%]\n",
            "11942 [Discriminator loss: 0.6819%, acc.: 53.91%] [Generator loss: 0.7986%]\n",
            "11943 [Discriminator loss: 0.6561%, acc.: 59.77%] [Generator loss: 0.7871%]\n",
            "11944 [Discriminator loss: 0.6828%, acc.: 60.94%] [Generator loss: 0.7784%]\n",
            "11945 [Discriminator loss: 0.6647%, acc.: 60.16%] [Generator loss: 0.7745%]\n",
            "11946 [Discriminator loss: 0.6765%, acc.: 55.86%] [Generator loss: 0.7725%]\n",
            "11947 [Discriminator loss: 0.6648%, acc.: 62.89%] [Generator loss: 0.7795%]\n",
            "11948 [Discriminator loss: 0.6631%, acc.: 58.98%] [Generator loss: 0.8081%]\n",
            "11949 [Discriminator loss: 0.6618%, acc.: 58.98%] [Generator loss: 0.7674%]\n",
            "11950 [Discriminator loss: 0.6560%, acc.: 63.28%] [Generator loss: 0.7915%]\n",
            "11951 [Discriminator loss: 0.6668%, acc.: 57.03%] [Generator loss: 0.7833%]\n",
            "11952 [Discriminator loss: 0.6459%, acc.: 65.23%] [Generator loss: 0.7932%]\n",
            "11953 [Discriminator loss: 0.6616%, acc.: 62.50%] [Generator loss: 0.8083%]\n",
            "11954 [Discriminator loss: 0.6546%, acc.: 57.81%] [Generator loss: 0.7952%]\n",
            "11955 [Discriminator loss: 0.6713%, acc.: 57.03%] [Generator loss: 0.7716%]\n",
            "11956 [Discriminator loss: 0.6692%, acc.: 57.42%] [Generator loss: 0.7836%]\n",
            "11957 [Discriminator loss: 0.6735%, acc.: 58.59%] [Generator loss: 0.7904%]\n",
            "11958 [Discriminator loss: 0.6567%, acc.: 61.72%] [Generator loss: 0.7735%]\n",
            "11959 [Discriminator loss: 0.6744%, acc.: 56.25%] [Generator loss: 0.7884%]\n",
            "11960 [Discriminator loss: 0.6621%, acc.: 62.89%] [Generator loss: 0.7931%]\n",
            "11961 [Discriminator loss: 0.6768%, acc.: 55.86%] [Generator loss: 0.8062%]\n",
            "11962 [Discriminator loss: 0.6505%, acc.: 62.89%] [Generator loss: 0.8097%]\n",
            "11963 [Discriminator loss: 0.6675%, acc.: 59.38%] [Generator loss: 0.8144%]\n",
            "11964 [Discriminator loss: 0.6704%, acc.: 62.50%] [Generator loss: 0.7963%]\n",
            "11965 [Discriminator loss: 0.6814%, acc.: 55.08%] [Generator loss: 0.8023%]\n",
            "11966 [Discriminator loss: 0.6774%, acc.: 56.64%] [Generator loss: 0.8221%]\n",
            "11967 [Discriminator loss: 0.6452%, acc.: 66.41%] [Generator loss: 0.7754%]\n",
            "11968 [Discriminator loss: 0.6668%, acc.: 60.55%] [Generator loss: 0.7766%]\n",
            "11969 [Discriminator loss: 0.6955%, acc.: 52.34%] [Generator loss: 0.7911%]\n",
            "11970 [Discriminator loss: 0.6667%, acc.: 57.81%] [Generator loss: 0.7866%]\n",
            "11971 [Discriminator loss: 0.6648%, acc.: 58.59%] [Generator loss: 0.7991%]\n",
            "11972 [Discriminator loss: 0.6668%, acc.: 64.06%] [Generator loss: 0.7986%]\n",
            "11973 [Discriminator loss: 0.6856%, acc.: 55.08%] [Generator loss: 0.7831%]\n",
            "11974 [Discriminator loss: 0.6767%, acc.: 56.64%] [Generator loss: 0.7961%]\n",
            "11975 [Discriminator loss: 0.6799%, acc.: 54.30%] [Generator loss: 0.7976%]\n",
            "11976 [Discriminator loss: 0.6761%, acc.: 57.81%] [Generator loss: 0.7604%]\n",
            "11977 [Discriminator loss: 0.6944%, acc.: 52.34%] [Generator loss: 0.7877%]\n",
            "11978 [Discriminator loss: 0.6883%, acc.: 54.69%] [Generator loss: 0.7527%]\n",
            "11979 [Discriminator loss: 0.6728%, acc.: 57.42%] [Generator loss: 0.7642%]\n",
            "11980 [Discriminator loss: 0.6955%, acc.: 52.73%] [Generator loss: 0.7827%]\n",
            "11981 [Discriminator loss: 0.6735%, acc.: 56.64%] [Generator loss: 0.7817%]\n",
            "11982 [Discriminator loss: 0.6789%, acc.: 57.42%] [Generator loss: 0.7920%]\n",
            "11983 [Discriminator loss: 0.6522%, acc.: 65.23%] [Generator loss: 0.7963%]\n",
            "11984 [Discriminator loss: 0.6569%, acc.: 62.11%] [Generator loss: 0.7878%]\n",
            "11985 [Discriminator loss: 0.6763%, acc.: 55.47%] [Generator loss: 0.7811%]\n",
            "11986 [Discriminator loss: 0.6590%, acc.: 60.55%] [Generator loss: 0.7910%]\n",
            "11987 [Discriminator loss: 0.6750%, acc.: 54.69%] [Generator loss: 0.7866%]\n",
            "11988 [Discriminator loss: 0.6689%, acc.: 59.38%] [Generator loss: 0.7983%]\n",
            "11989 [Discriminator loss: 0.6716%, acc.: 57.81%] [Generator loss: 0.7850%]\n",
            "11990 [Discriminator loss: 0.6728%, acc.: 60.55%] [Generator loss: 0.7901%]\n",
            "11991 [Discriminator loss: 0.6911%, acc.: 54.69%] [Generator loss: 0.7535%]\n",
            "11992 [Discriminator loss: 0.6621%, acc.: 64.84%] [Generator loss: 0.7784%]\n",
            "11993 [Discriminator loss: 0.6797%, acc.: 58.59%] [Generator loss: 0.8012%]\n",
            "11994 [Discriminator loss: 0.6838%, acc.: 57.03%] [Generator loss: 0.7741%]\n",
            "11995 [Discriminator loss: 0.6960%, acc.: 53.12%] [Generator loss: 0.7748%]\n",
            "11996 [Discriminator loss: 0.6726%, acc.: 57.03%] [Generator loss: 0.7695%]\n",
            "11997 [Discriminator loss: 0.6754%, acc.: 54.69%] [Generator loss: 0.7904%]\n",
            "11998 [Discriminator loss: 0.6640%, acc.: 58.59%] [Generator loss: 0.7630%]\n",
            "11999 [Discriminator loss: 0.6655%, acc.: 61.72%] [Generator loss: 0.7814%]\n",
            "12000 [Discriminator loss: 0.6739%, acc.: 60.94%] [Generator loss: 0.7825%]\n",
            "12001 [Discriminator loss: 0.6786%, acc.: 60.16%] [Generator loss: 0.7886%]\n",
            "12002 [Discriminator loss: 0.6576%, acc.: 60.16%] [Generator loss: 0.7862%]\n",
            "12003 [Discriminator loss: 0.6549%, acc.: 64.06%] [Generator loss: 0.7924%]\n",
            "12004 [Discriminator loss: 0.6638%, acc.: 58.20%] [Generator loss: 0.8168%]\n",
            "12005 [Discriminator loss: 0.6702%, acc.: 60.94%] [Generator loss: 0.7782%]\n",
            "12006 [Discriminator loss: 0.6631%, acc.: 60.55%] [Generator loss: 0.7973%]\n",
            "12007 [Discriminator loss: 0.6738%, acc.: 56.25%] [Generator loss: 0.7397%]\n",
            "12008 [Discriminator loss: 0.6627%, acc.: 60.94%] [Generator loss: 0.8109%]\n",
            "12009 [Discriminator loss: 0.6707%, acc.: 58.98%] [Generator loss: 0.8064%]\n",
            "12010 [Discriminator loss: 0.6623%, acc.: 59.77%] [Generator loss: 0.7736%]\n",
            "12011 [Discriminator loss: 0.6782%, acc.: 60.94%] [Generator loss: 0.7935%]\n",
            "12012 [Discriminator loss: 0.6779%, acc.: 58.59%] [Generator loss: 0.7954%]\n",
            "12013 [Discriminator loss: 0.6740%, acc.: 57.42%] [Generator loss: 0.7788%]\n",
            "12014 [Discriminator loss: 0.6986%, acc.: 50.39%] [Generator loss: 0.7803%]\n",
            "12015 [Discriminator loss: 0.6574%, acc.: 60.55%] [Generator loss: 0.7764%]\n",
            "12016 [Discriminator loss: 0.6663%, acc.: 59.38%] [Generator loss: 0.7964%]\n",
            "12017 [Discriminator loss: 0.6724%, acc.: 57.03%] [Generator loss: 0.7808%]\n",
            "12018 [Discriminator loss: 0.6689%, acc.: 58.98%] [Generator loss: 0.7966%]\n",
            "12019 [Discriminator loss: 0.6614%, acc.: 62.11%] [Generator loss: 0.7885%]\n",
            "12020 [Discriminator loss: 0.6650%, acc.: 60.16%] [Generator loss: 0.7994%]\n",
            "12021 [Discriminator loss: 0.6517%, acc.: 63.67%] [Generator loss: 0.7979%]\n",
            "12022 [Discriminator loss: 0.6529%, acc.: 63.67%] [Generator loss: 0.7894%]\n",
            "12023 [Discriminator loss: 0.6874%, acc.: 54.30%] [Generator loss: 0.8162%]\n",
            "12024 [Discriminator loss: 0.6890%, acc.: 53.91%] [Generator loss: 0.8143%]\n",
            "12025 [Discriminator loss: 0.6706%, acc.: 58.98%] [Generator loss: 0.7891%]\n",
            "12026 [Discriminator loss: 0.6817%, acc.: 58.20%] [Generator loss: 0.7806%]\n",
            "12027 [Discriminator loss: 0.6650%, acc.: 59.77%] [Generator loss: 0.7960%]\n",
            "12028 [Discriminator loss: 0.6599%, acc.: 59.38%] [Generator loss: 0.7939%]\n",
            "12029 [Discriminator loss: 0.6770%, acc.: 53.91%] [Generator loss: 0.7570%]\n",
            "12030 [Discriminator loss: 0.6736%, acc.: 54.30%] [Generator loss: 0.7624%]\n",
            "12031 [Discriminator loss: 0.6674%, acc.: 61.33%] [Generator loss: 0.7638%]\n",
            "12032 [Discriminator loss: 0.6740%, acc.: 54.30%] [Generator loss: 0.7666%]\n",
            "12033 [Discriminator loss: 0.6659%, acc.: 52.73%] [Generator loss: 0.7473%]\n",
            "12034 [Discriminator loss: 0.6698%, acc.: 59.38%] [Generator loss: 0.7824%]\n",
            "12035 [Discriminator loss: 0.6502%, acc.: 64.45%] [Generator loss: 0.7852%]\n",
            "12036 [Discriminator loss: 0.6635%, acc.: 60.16%] [Generator loss: 0.7936%]\n",
            "12037 [Discriminator loss: 0.6616%, acc.: 59.77%] [Generator loss: 0.7611%]\n",
            "12038 [Discriminator loss: 0.6655%, acc.: 60.94%] [Generator loss: 0.7682%]\n",
            "12039 [Discriminator loss: 0.6615%, acc.: 64.06%] [Generator loss: 0.7939%]\n",
            "12040 [Discriminator loss: 0.6525%, acc.: 61.33%] [Generator loss: 0.8001%]\n",
            "12041 [Discriminator loss: 0.6626%, acc.: 60.55%] [Generator loss: 0.8174%]\n",
            "12042 [Discriminator loss: 0.6830%, acc.: 54.69%] [Generator loss: 0.7818%]\n",
            "12043 [Discriminator loss: 0.6634%, acc.: 62.50%] [Generator loss: 0.7859%]\n",
            "12044 [Discriminator loss: 0.6882%, acc.: 53.52%] [Generator loss: 0.7605%]\n",
            "12045 [Discriminator loss: 0.6683%, acc.: 59.38%] [Generator loss: 0.7783%]\n",
            "12046 [Discriminator loss: 0.6720%, acc.: 59.38%] [Generator loss: 0.7561%]\n",
            "12047 [Discriminator loss: 0.6599%, acc.: 63.28%] [Generator loss: 0.7812%]\n",
            "12048 [Discriminator loss: 0.6605%, acc.: 58.20%] [Generator loss: 0.7816%]\n",
            "12049 [Discriminator loss: 0.6689%, acc.: 58.59%] [Generator loss: 0.7874%]\n",
            "12050 [Discriminator loss: 0.6496%, acc.: 64.06%] [Generator loss: 0.8163%]\n",
            "12051 [Discriminator loss: 0.6887%, acc.: 53.52%] [Generator loss: 0.7812%]\n",
            "12052 [Discriminator loss: 0.6670%, acc.: 58.20%] [Generator loss: 0.7923%]\n",
            "12053 [Discriminator loss: 0.6749%, acc.: 58.59%] [Generator loss: 0.7820%]\n",
            "12054 [Discriminator loss: 0.6749%, acc.: 57.42%] [Generator loss: 0.7784%]\n",
            "12055 [Discriminator loss: 0.6757%, acc.: 60.16%] [Generator loss: 0.7702%]\n",
            "12056 [Discriminator loss: 0.6796%, acc.: 55.47%] [Generator loss: 0.7937%]\n",
            "12057 [Discriminator loss: 0.6862%, acc.: 57.42%] [Generator loss: 0.7943%]\n",
            "12058 [Discriminator loss: 0.6761%, acc.: 58.20%] [Generator loss: 0.7841%]\n",
            "12059 [Discriminator loss: 0.6849%, acc.: 56.25%] [Generator loss: 0.7767%]\n",
            "12060 [Discriminator loss: 0.6726%, acc.: 56.25%] [Generator loss: 0.7688%]\n",
            "12061 [Discriminator loss: 0.6776%, acc.: 59.77%] [Generator loss: 0.7749%]\n",
            "12062 [Discriminator loss: 0.6754%, acc.: 58.98%] [Generator loss: 0.7851%]\n",
            "12063 [Discriminator loss: 0.6842%, acc.: 55.86%] [Generator loss: 0.7944%]\n",
            "12064 [Discriminator loss: 0.6766%, acc.: 58.20%] [Generator loss: 0.8061%]\n",
            "12065 [Discriminator loss: 0.6632%, acc.: 60.94%] [Generator loss: 0.7982%]\n",
            "12066 [Discriminator loss: 0.6669%, acc.: 62.11%] [Generator loss: 0.8120%]\n",
            "12067 [Discriminator loss: 0.6846%, acc.: 56.25%] [Generator loss: 0.7805%]\n",
            "12068 [Discriminator loss: 0.6875%, acc.: 54.69%] [Generator loss: 0.7787%]\n",
            "12069 [Discriminator loss: 0.6729%, acc.: 62.11%] [Generator loss: 0.7802%]\n",
            "12070 [Discriminator loss: 0.6647%, acc.: 58.20%] [Generator loss: 0.7776%]\n",
            "12071 [Discriminator loss: 0.6826%, acc.: 56.64%] [Generator loss: 0.7986%]\n",
            "12072 [Discriminator loss: 0.6510%, acc.: 62.89%] [Generator loss: 0.7957%]\n",
            "12073 [Discriminator loss: 0.6827%, acc.: 53.12%] [Generator loss: 0.7625%]\n",
            "12074 [Discriminator loss: 0.6823%, acc.: 51.17%] [Generator loss: 0.7836%]\n",
            "12075 [Discriminator loss: 0.6744%, acc.: 60.55%] [Generator loss: 0.7790%]\n",
            "12076 [Discriminator loss: 0.6830%, acc.: 57.03%] [Generator loss: 0.7987%]\n",
            "12077 [Discriminator loss: 0.6641%, acc.: 62.50%] [Generator loss: 0.7875%]\n",
            "12078 [Discriminator loss: 0.6659%, acc.: 59.38%] [Generator loss: 0.8073%]\n",
            "12079 [Discriminator loss: 0.6545%, acc.: 58.98%] [Generator loss: 0.8040%]\n",
            "12080 [Discriminator loss: 0.6579%, acc.: 61.33%] [Generator loss: 0.7861%]\n",
            "12081 [Discriminator loss: 0.6668%, acc.: 57.03%] [Generator loss: 0.7844%]\n",
            "12082 [Discriminator loss: 0.6638%, acc.: 58.59%] [Generator loss: 0.7876%]\n",
            "12083 [Discriminator loss: 0.6531%, acc.: 58.98%] [Generator loss: 0.8027%]\n",
            "12084 [Discriminator loss: 0.6673%, acc.: 58.59%] [Generator loss: 0.8069%]\n",
            "12085 [Discriminator loss: 0.6772%, acc.: 57.03%] [Generator loss: 0.7957%]\n",
            "12086 [Discriminator loss: 0.6752%, acc.: 57.42%] [Generator loss: 0.7800%]\n",
            "12087 [Discriminator loss: 0.6416%, acc.: 67.58%] [Generator loss: 0.7916%]\n",
            "12088 [Discriminator loss: 0.6780%, acc.: 56.64%] [Generator loss: 0.7587%]\n",
            "12089 [Discriminator loss: 0.6810%, acc.: 55.86%] [Generator loss: 0.7658%]\n",
            "12090 [Discriminator loss: 0.6539%, acc.: 60.55%] [Generator loss: 0.7484%]\n",
            "12091 [Discriminator loss: 0.6715%, acc.: 53.12%] [Generator loss: 0.7883%]\n",
            "12092 [Discriminator loss: 0.6541%, acc.: 64.06%] [Generator loss: 0.7928%]\n",
            "12093 [Discriminator loss: 0.6721%, acc.: 59.77%] [Generator loss: 0.7915%]\n",
            "12094 [Discriminator loss: 0.6554%, acc.: 62.89%] [Generator loss: 0.7759%]\n",
            "12095 [Discriminator loss: 0.6861%, acc.: 55.47%] [Generator loss: 0.7744%]\n",
            "12096 [Discriminator loss: 0.6725%, acc.: 56.64%] [Generator loss: 0.7893%]\n",
            "12097 [Discriminator loss: 0.6614%, acc.: 58.20%] [Generator loss: 0.7736%]\n",
            "12098 [Discriminator loss: 0.6795%, acc.: 57.03%] [Generator loss: 0.7604%]\n",
            "12099 [Discriminator loss: 0.6762%, acc.: 54.69%] [Generator loss: 0.7996%]\n",
            "12100 [Discriminator loss: 0.6755%, acc.: 56.64%] [Generator loss: 0.7975%]\n",
            "12101 [Discriminator loss: 0.6612%, acc.: 62.50%] [Generator loss: 0.7906%]\n",
            "12102 [Discriminator loss: 0.6742%, acc.: 56.25%] [Generator loss: 0.7893%]\n",
            "12103 [Discriminator loss: 0.6631%, acc.: 60.16%] [Generator loss: 0.7828%]\n",
            "12104 [Discriminator loss: 0.6754%, acc.: 56.25%] [Generator loss: 0.7788%]\n",
            "12105 [Discriminator loss: 0.6562%, acc.: 62.11%] [Generator loss: 0.7586%]\n",
            "12106 [Discriminator loss: 0.6610%, acc.: 59.77%] [Generator loss: 0.7585%]\n",
            "12107 [Discriminator loss: 0.6638%, acc.: 58.59%] [Generator loss: 0.8061%]\n",
            "12108 [Discriminator loss: 0.6794%, acc.: 55.47%] [Generator loss: 0.7972%]\n",
            "12109 [Discriminator loss: 0.6665%, acc.: 59.38%] [Generator loss: 0.7772%]\n",
            "12110 [Discriminator loss: 0.6570%, acc.: 63.67%] [Generator loss: 0.7909%]\n",
            "12111 [Discriminator loss: 0.6624%, acc.: 59.77%] [Generator loss: 0.8156%]\n",
            "12112 [Discriminator loss: 0.6850%, acc.: 58.98%] [Generator loss: 0.7958%]\n",
            "12113 [Discriminator loss: 0.6735%, acc.: 60.94%] [Generator loss: 0.7753%]\n",
            "12114 [Discriminator loss: 0.6644%, acc.: 62.50%] [Generator loss: 0.8112%]\n",
            "12115 [Discriminator loss: 0.6620%, acc.: 60.16%] [Generator loss: 0.7763%]\n",
            "12116 [Discriminator loss: 0.6589%, acc.: 60.16%] [Generator loss: 0.7937%]\n",
            "12117 [Discriminator loss: 0.6729%, acc.: 55.47%] [Generator loss: 0.7782%]\n",
            "12118 [Discriminator loss: 0.6634%, acc.: 61.33%] [Generator loss: 0.7805%]\n",
            "12119 [Discriminator loss: 0.6571%, acc.: 58.20%] [Generator loss: 0.7904%]\n",
            "12120 [Discriminator loss: 0.6671%, acc.: 60.16%] [Generator loss: 0.7812%]\n",
            "12121 [Discriminator loss: 0.6756%, acc.: 58.98%] [Generator loss: 0.7946%]\n",
            "12122 [Discriminator loss: 0.6859%, acc.: 54.69%] [Generator loss: 0.7968%]\n",
            "12123 [Discriminator loss: 0.6732%, acc.: 57.81%] [Generator loss: 0.8004%]\n",
            "12124 [Discriminator loss: 0.6626%, acc.: 62.50%] [Generator loss: 0.7981%]\n",
            "12125 [Discriminator loss: 0.6635%, acc.: 58.98%] [Generator loss: 0.7903%]\n",
            "12126 [Discriminator loss: 0.6611%, acc.: 61.33%] [Generator loss: 0.8170%]\n",
            "12127 [Discriminator loss: 0.6784%, acc.: 56.64%] [Generator loss: 0.8291%]\n",
            "12128 [Discriminator loss: 0.6695%, acc.: 55.08%] [Generator loss: 0.7913%]\n",
            "12129 [Discriminator loss: 0.6764%, acc.: 58.59%] [Generator loss: 0.8094%]\n",
            "12130 [Discriminator loss: 0.6816%, acc.: 55.47%] [Generator loss: 0.7934%]\n",
            "12131 [Discriminator loss: 0.6652%, acc.: 59.77%] [Generator loss: 0.7903%]\n",
            "12132 [Discriminator loss: 0.6635%, acc.: 60.94%] [Generator loss: 0.8109%]\n",
            "12133 [Discriminator loss: 0.6489%, acc.: 59.38%] [Generator loss: 0.7888%]\n",
            "12134 [Discriminator loss: 0.6741%, acc.: 56.64%] [Generator loss: 0.7875%]\n",
            "12135 [Discriminator loss: 0.6585%, acc.: 58.59%] [Generator loss: 0.8199%]\n",
            "12136 [Discriminator loss: 0.6756%, acc.: 51.95%] [Generator loss: 0.8191%]\n",
            "12137 [Discriminator loss: 0.6656%, acc.: 58.98%] [Generator loss: 0.7959%]\n",
            "12138 [Discriminator loss: 0.6720%, acc.: 56.64%] [Generator loss: 0.7875%]\n",
            "12139 [Discriminator loss: 0.6669%, acc.: 56.25%] [Generator loss: 0.8133%]\n",
            "12140 [Discriminator loss: 0.6943%, acc.: 55.08%] [Generator loss: 0.7972%]\n",
            "12141 [Discriminator loss: 0.6736%, acc.: 58.59%] [Generator loss: 0.7916%]\n",
            "12142 [Discriminator loss: 0.6674%, acc.: 57.42%] [Generator loss: 0.7987%]\n",
            "12143 [Discriminator loss: 0.6843%, acc.: 53.12%] [Generator loss: 0.7966%]\n",
            "12144 [Discriminator loss: 0.6870%, acc.: 53.91%] [Generator loss: 0.7839%]\n",
            "12145 [Discriminator loss: 0.6565%, acc.: 62.89%] [Generator loss: 0.7994%]\n",
            "12146 [Discriminator loss: 0.7102%, acc.: 49.61%] [Generator loss: 0.7986%]\n",
            "12147 [Discriminator loss: 0.6740%, acc.: 56.25%] [Generator loss: 0.8081%]\n",
            "12148 [Discriminator loss: 0.6639%, acc.: 58.59%] [Generator loss: 0.8049%]\n",
            "12149 [Discriminator loss: 0.6800%, acc.: 55.47%] [Generator loss: 0.8058%]\n",
            "12150 [Discriminator loss: 0.6715%, acc.: 58.20%] [Generator loss: 0.8075%]\n",
            "12151 [Discriminator loss: 0.6775%, acc.: 57.81%] [Generator loss: 0.7851%]\n",
            "12152 [Discriminator loss: 0.6847%, acc.: 56.25%] [Generator loss: 0.7806%]\n",
            "12153 [Discriminator loss: 0.6578%, acc.: 62.50%] [Generator loss: 0.8185%]\n",
            "12154 [Discriminator loss: 0.6919%, acc.: 50.00%] [Generator loss: 0.7819%]\n",
            "12155 [Discriminator loss: 0.6712%, acc.: 59.77%] [Generator loss: 0.8216%]\n",
            "12156 [Discriminator loss: 0.6581%, acc.: 58.20%] [Generator loss: 0.8038%]\n",
            "12157 [Discriminator loss: 0.6803%, acc.: 58.98%] [Generator loss: 0.7895%]\n",
            "12158 [Discriminator loss: 0.6653%, acc.: 60.16%] [Generator loss: 0.7701%]\n",
            "12159 [Discriminator loss: 0.6683%, acc.: 57.42%] [Generator loss: 0.7982%]\n",
            "12160 [Discriminator loss: 0.6797%, acc.: 55.47%] [Generator loss: 0.7994%]\n",
            "12161 [Discriminator loss: 0.6936%, acc.: 54.69%] [Generator loss: 0.8073%]\n",
            "12162 [Discriminator loss: 0.6931%, acc.: 48.83%] [Generator loss: 0.7734%]\n",
            "12163 [Discriminator loss: 0.6660%, acc.: 57.81%] [Generator loss: 0.7844%]\n",
            "12164 [Discriminator loss: 0.6628%, acc.: 58.59%] [Generator loss: 0.7816%]\n",
            "12165 [Discriminator loss: 0.6498%, acc.: 64.06%] [Generator loss: 0.7942%]\n",
            "12166 [Discriminator loss: 0.6893%, acc.: 50.39%] [Generator loss: 0.7998%]\n",
            "12167 [Discriminator loss: 0.6575%, acc.: 64.45%] [Generator loss: 0.8019%]\n",
            "12168 [Discriminator loss: 0.6812%, acc.: 57.42%] [Generator loss: 0.7893%]\n",
            "12169 [Discriminator loss: 0.6761%, acc.: 56.25%] [Generator loss: 0.7850%]\n",
            "12170 [Discriminator loss: 0.6772%, acc.: 57.81%] [Generator loss: 0.7873%]\n",
            "12171 [Discriminator loss: 0.6770%, acc.: 59.38%] [Generator loss: 0.7977%]\n",
            "12172 [Discriminator loss: 0.6553%, acc.: 61.72%] [Generator loss: 0.7924%]\n",
            "12173 [Discriminator loss: 0.6639%, acc.: 59.77%] [Generator loss: 0.7870%]\n",
            "12174 [Discriminator loss: 0.6667%, acc.: 58.98%] [Generator loss: 0.7933%]\n",
            "12175 [Discriminator loss: 0.6520%, acc.: 58.98%] [Generator loss: 0.8008%]\n",
            "12176 [Discriminator loss: 0.6862%, acc.: 56.64%] [Generator loss: 0.7829%]\n",
            "12177 [Discriminator loss: 0.6720%, acc.: 53.91%] [Generator loss: 0.7960%]\n",
            "12178 [Discriminator loss: 0.6884%, acc.: 54.69%] [Generator loss: 0.7728%]\n",
            "12179 [Discriminator loss: 0.6705%, acc.: 58.98%] [Generator loss: 0.7672%]\n",
            "12180 [Discriminator loss: 0.6687%, acc.: 59.77%] [Generator loss: 0.7827%]\n",
            "12181 [Discriminator loss: 0.6532%, acc.: 60.55%] [Generator loss: 0.8070%]\n",
            "12182 [Discriminator loss: 0.6592%, acc.: 59.38%] [Generator loss: 0.8085%]\n",
            "12183 [Discriminator loss: 0.6732%, acc.: 62.50%] [Generator loss: 0.7766%]\n",
            "12184 [Discriminator loss: 0.6700%, acc.: 59.77%] [Generator loss: 0.7887%]\n",
            "12185 [Discriminator loss: 0.6819%, acc.: 58.59%] [Generator loss: 0.7878%]\n",
            "12186 [Discriminator loss: 0.6675%, acc.: 58.59%] [Generator loss: 0.8023%]\n",
            "12187 [Discriminator loss: 0.6758%, acc.: 58.59%] [Generator loss: 0.8118%]\n",
            "12188 [Discriminator loss: 0.6740%, acc.: 56.64%] [Generator loss: 0.7951%]\n",
            "12189 [Discriminator loss: 0.6809%, acc.: 54.30%] [Generator loss: 0.7862%]\n",
            "12190 [Discriminator loss: 0.6596%, acc.: 61.33%] [Generator loss: 0.7942%]\n",
            "12191 [Discriminator loss: 0.6817%, acc.: 51.56%] [Generator loss: 0.7924%]\n",
            "12192 [Discriminator loss: 0.6785%, acc.: 53.52%] [Generator loss: 0.7693%]\n",
            "12193 [Discriminator loss: 0.6721%, acc.: 57.81%] [Generator loss: 0.7753%]\n",
            "12194 [Discriminator loss: 0.6640%, acc.: 62.11%] [Generator loss: 0.7930%]\n",
            "12195 [Discriminator loss: 0.6760%, acc.: 55.86%] [Generator loss: 0.7785%]\n",
            "12196 [Discriminator loss: 0.6813%, acc.: 57.81%] [Generator loss: 0.7725%]\n",
            "12197 [Discriminator loss: 0.6743%, acc.: 60.16%] [Generator loss: 0.7977%]\n",
            "12198 [Discriminator loss: 0.6961%, acc.: 50.78%] [Generator loss: 0.8050%]\n",
            "12199 [Discriminator loss: 0.6620%, acc.: 60.94%] [Generator loss: 0.7821%]\n",
            "12200 [Discriminator loss: 0.6685%, acc.: 60.16%] [Generator loss: 0.8262%]\n",
            "12201 [Discriminator loss: 0.6661%, acc.: 60.16%] [Generator loss: 0.7804%]\n",
            "12202 [Discriminator loss: 0.6704%, acc.: 57.42%] [Generator loss: 0.7981%]\n",
            "12203 [Discriminator loss: 0.6714%, acc.: 56.64%] [Generator loss: 0.7769%]\n",
            "12204 [Discriminator loss: 0.6498%, acc.: 60.94%] [Generator loss: 0.7835%]\n",
            "12205 [Discriminator loss: 0.6766%, acc.: 53.91%] [Generator loss: 0.7927%]\n",
            "12206 [Discriminator loss: 0.6677%, acc.: 58.98%] [Generator loss: 0.7929%]\n",
            "12207 [Discriminator loss: 0.6657%, acc.: 58.98%] [Generator loss: 0.8171%]\n",
            "12208 [Discriminator loss: 0.6593%, acc.: 60.55%] [Generator loss: 0.7966%]\n",
            "12209 [Discriminator loss: 0.6546%, acc.: 64.84%] [Generator loss: 0.7741%]\n",
            "12210 [Discriminator loss: 0.6595%, acc.: 61.72%] [Generator loss: 0.7962%]\n",
            "12211 [Discriminator loss: 0.6955%, acc.: 50.39%] [Generator loss: 0.7880%]\n",
            "12212 [Discriminator loss: 0.6629%, acc.: 58.20%] [Generator loss: 0.7804%]\n",
            "12213 [Discriminator loss: 0.6722%, acc.: 57.81%] [Generator loss: 0.7876%]\n",
            "12214 [Discriminator loss: 0.6633%, acc.: 60.16%] [Generator loss: 0.8180%]\n",
            "12215 [Discriminator loss: 0.6588%, acc.: 62.89%] [Generator loss: 0.8083%]\n",
            "12216 [Discriminator loss: 0.6533%, acc.: 60.16%] [Generator loss: 0.8102%]\n",
            "12217 [Discriminator loss: 0.6574%, acc.: 62.89%] [Generator loss: 0.7837%]\n",
            "12218 [Discriminator loss: 0.6739%, acc.: 58.20%] [Generator loss: 0.7854%]\n",
            "12219 [Discriminator loss: 0.6680%, acc.: 58.98%] [Generator loss: 0.7676%]\n",
            "12220 [Discriminator loss: 0.6574%, acc.: 60.16%] [Generator loss: 0.8105%]\n",
            "12221 [Discriminator loss: 0.6680%, acc.: 58.59%] [Generator loss: 0.7759%]\n",
            "12222 [Discriminator loss: 0.6677%, acc.: 58.59%] [Generator loss: 0.7988%]\n",
            "12223 [Discriminator loss: 0.6644%, acc.: 59.38%] [Generator loss: 0.8000%]\n",
            "12224 [Discriminator loss: 0.6729%, acc.: 55.47%] [Generator loss: 0.7883%]\n",
            "12225 [Discriminator loss: 0.6820%, acc.: 55.47%] [Generator loss: 0.8133%]\n",
            "12226 [Discriminator loss: 0.6737%, acc.: 58.20%] [Generator loss: 0.8127%]\n",
            "12227 [Discriminator loss: 0.6846%, acc.: 50.78%] [Generator loss: 0.7813%]\n",
            "12228 [Discriminator loss: 0.6734%, acc.: 59.77%] [Generator loss: 0.7766%]\n",
            "12229 [Discriminator loss: 0.6734%, acc.: 58.20%] [Generator loss: 0.7695%]\n",
            "12230 [Discriminator loss: 0.6596%, acc.: 64.06%] [Generator loss: 0.8249%]\n",
            "12231 [Discriminator loss: 0.6791%, acc.: 58.98%] [Generator loss: 0.7799%]\n",
            "12232 [Discriminator loss: 0.6864%, acc.: 52.73%] [Generator loss: 0.7851%]\n",
            "12233 [Discriminator loss: 0.6724%, acc.: 55.08%] [Generator loss: 0.7638%]\n",
            "12234 [Discriminator loss: 0.6642%, acc.: 59.77%] [Generator loss: 0.7824%]\n",
            "12235 [Discriminator loss: 0.6702%, acc.: 54.30%] [Generator loss: 0.8023%]\n",
            "12236 [Discriminator loss: 0.6736%, acc.: 56.64%] [Generator loss: 0.7861%]\n",
            "12237 [Discriminator loss: 0.6876%, acc.: 57.81%] [Generator loss: 0.7742%]\n",
            "12238 [Discriminator loss: 0.6493%, acc.: 63.28%] [Generator loss: 0.7870%]\n",
            "12239 [Discriminator loss: 0.6621%, acc.: 57.81%] [Generator loss: 0.8086%]\n",
            "12240 [Discriminator loss: 0.6753%, acc.: 57.42%] [Generator loss: 0.8000%]\n",
            "12241 [Discriminator loss: 0.6676%, acc.: 60.55%] [Generator loss: 0.7896%]\n",
            "12242 [Discriminator loss: 0.6585%, acc.: 65.62%] [Generator loss: 0.7930%]\n",
            "12243 [Discriminator loss: 0.6668%, acc.: 63.28%] [Generator loss: 0.7827%]\n",
            "12244 [Discriminator loss: 0.6735%, acc.: 57.03%] [Generator loss: 0.7839%]\n",
            "12245 [Discriminator loss: 0.6692%, acc.: 60.94%] [Generator loss: 0.7862%]\n",
            "12246 [Discriminator loss: 0.6767%, acc.: 60.16%] [Generator loss: 0.7876%]\n",
            "12247 [Discriminator loss: 0.6750%, acc.: 57.81%] [Generator loss: 0.7897%]\n",
            "12248 [Discriminator loss: 0.6791%, acc.: 57.03%] [Generator loss: 0.7997%]\n",
            "12249 [Discriminator loss: 0.6960%, acc.: 52.73%] [Generator loss: 0.8240%]\n",
            "12250 [Discriminator loss: 0.6872%, acc.: 53.52%] [Generator loss: 0.7911%]\n",
            "12251 [Discriminator loss: 0.6690%, acc.: 60.16%] [Generator loss: 0.7907%]\n",
            "12252 [Discriminator loss: 0.6766%, acc.: 59.38%] [Generator loss: 0.7702%]\n",
            "12253 [Discriminator loss: 0.6642%, acc.: 59.77%] [Generator loss: 0.7627%]\n",
            "12254 [Discriminator loss: 0.6714%, acc.: 57.81%] [Generator loss: 0.8012%]\n",
            "12255 [Discriminator loss: 0.6494%, acc.: 64.06%] [Generator loss: 0.8075%]\n",
            "12256 [Discriminator loss: 0.6736%, acc.: 57.42%] [Generator loss: 0.7859%]\n",
            "12257 [Discriminator loss: 0.6714%, acc.: 60.16%] [Generator loss: 0.8125%]\n",
            "12258 [Discriminator loss: 0.6838%, acc.: 53.91%] [Generator loss: 0.8237%]\n",
            "12259 [Discriminator loss: 0.6698%, acc.: 61.33%] [Generator loss: 0.8058%]\n",
            "12260 [Discriminator loss: 0.6669%, acc.: 60.94%] [Generator loss: 0.7539%]\n",
            "12261 [Discriminator loss: 0.6778%, acc.: 57.03%] [Generator loss: 0.7696%]\n",
            "12262 [Discriminator loss: 0.6669%, acc.: 61.72%] [Generator loss: 0.7648%]\n",
            "12263 [Discriminator loss: 0.6598%, acc.: 60.16%] [Generator loss: 0.7682%]\n",
            "12264 [Discriminator loss: 0.6597%, acc.: 59.38%] [Generator loss: 0.7644%]\n",
            "12265 [Discriminator loss: 0.6498%, acc.: 58.98%] [Generator loss: 0.7975%]\n",
            "12266 [Discriminator loss: 0.6674%, acc.: 55.47%] [Generator loss: 0.7668%]\n",
            "12267 [Discriminator loss: 0.6876%, acc.: 57.03%] [Generator loss: 0.7843%]\n",
            "12268 [Discriminator loss: 0.6564%, acc.: 60.16%] [Generator loss: 0.7824%]\n",
            "12269 [Discriminator loss: 0.6769%, acc.: 53.12%] [Generator loss: 0.7895%]\n",
            "12270 [Discriminator loss: 0.6777%, acc.: 57.81%] [Generator loss: 0.8098%]\n",
            "12271 [Discriminator loss: 0.6750%, acc.: 58.59%] [Generator loss: 0.7953%]\n",
            "12272 [Discriminator loss: 0.6771%, acc.: 58.98%] [Generator loss: 0.7832%]\n",
            "12273 [Discriminator loss: 0.6620%, acc.: 61.72%] [Generator loss: 0.8318%]\n",
            "12274 [Discriminator loss: 0.6625%, acc.: 56.64%] [Generator loss: 0.8041%]\n",
            "12275 [Discriminator loss: 0.6609%, acc.: 60.55%] [Generator loss: 0.8031%]\n",
            "12276 [Discriminator loss: 0.6581%, acc.: 63.28%] [Generator loss: 0.7815%]\n",
            "12277 [Discriminator loss: 0.6761%, acc.: 55.47%] [Generator loss: 0.8151%]\n",
            "12278 [Discriminator loss: 0.6790%, acc.: 57.42%] [Generator loss: 0.7714%]\n",
            "12279 [Discriminator loss: 0.6891%, acc.: 52.73%] [Generator loss: 0.7790%]\n",
            "12280 [Discriminator loss: 0.6806%, acc.: 55.86%] [Generator loss: 0.7994%]\n",
            "12281 [Discriminator loss: 0.6550%, acc.: 64.06%] [Generator loss: 0.7981%]\n",
            "12282 [Discriminator loss: 0.6630%, acc.: 60.94%] [Generator loss: 0.7960%]\n",
            "12283 [Discriminator loss: 0.6615%, acc.: 61.72%] [Generator loss: 0.7914%]\n",
            "12284 [Discriminator loss: 0.6808%, acc.: 57.42%] [Generator loss: 0.7851%]\n",
            "12285 [Discriminator loss: 0.6671%, acc.: 58.98%] [Generator loss: 0.8056%]\n",
            "12286 [Discriminator loss: 0.6676%, acc.: 61.72%] [Generator loss: 0.7995%]\n",
            "12287 [Discriminator loss: 0.6745%, acc.: 59.38%] [Generator loss: 0.7874%]\n",
            "12288 [Discriminator loss: 0.6688%, acc.: 57.42%] [Generator loss: 0.7750%]\n",
            "12289 [Discriminator loss: 0.6609%, acc.: 60.16%] [Generator loss: 0.7617%]\n",
            "12290 [Discriminator loss: 0.6665%, acc.: 61.33%] [Generator loss: 0.7835%]\n",
            "12291 [Discriminator loss: 0.6579%, acc.: 64.06%] [Generator loss: 0.7867%]\n",
            "12292 [Discriminator loss: 0.6670%, acc.: 59.38%] [Generator loss: 0.7943%]\n",
            "12293 [Discriminator loss: 0.6459%, acc.: 60.94%] [Generator loss: 0.7913%]\n",
            "12294 [Discriminator loss: 0.6778%, acc.: 55.08%] [Generator loss: 0.7757%]\n",
            "12295 [Discriminator loss: 0.6588%, acc.: 59.77%] [Generator loss: 0.7773%]\n",
            "12296 [Discriminator loss: 0.6668%, acc.: 58.20%] [Generator loss: 0.8150%]\n",
            "12297 [Discriminator loss: 0.6690%, acc.: 54.69%] [Generator loss: 0.8008%]\n",
            "12298 [Discriminator loss: 0.6603%, acc.: 61.72%] [Generator loss: 0.7735%]\n",
            "12299 [Discriminator loss: 0.6887%, acc.: 55.08%] [Generator loss: 0.7936%]\n",
            "12300 [Discriminator loss: 0.6701%, acc.: 58.20%] [Generator loss: 0.8020%]\n",
            "12301 [Discriminator loss: 0.6619%, acc.: 58.59%] [Generator loss: 0.7983%]\n",
            "12302 [Discriminator loss: 0.6761%, acc.: 56.25%] [Generator loss: 0.8175%]\n",
            "12303 [Discriminator loss: 0.6865%, acc.: 51.56%] [Generator loss: 0.7880%]\n",
            "12304 [Discriminator loss: 0.6540%, acc.: 62.11%] [Generator loss: 0.8079%]\n",
            "12305 [Discriminator loss: 0.6683%, acc.: 60.94%] [Generator loss: 0.7814%]\n",
            "12306 [Discriminator loss: 0.6468%, acc.: 62.50%] [Generator loss: 0.7964%]\n",
            "12307 [Discriminator loss: 0.6730%, acc.: 59.38%] [Generator loss: 0.7780%]\n",
            "12308 [Discriminator loss: 0.6817%, acc.: 54.69%] [Generator loss: 0.7911%]\n",
            "12309 [Discriminator loss: 0.6868%, acc.: 53.52%] [Generator loss: 0.7912%]\n",
            "12310 [Discriminator loss: 0.6779%, acc.: 57.42%] [Generator loss: 0.7738%]\n",
            "12311 [Discriminator loss: 0.6675%, acc.: 62.11%] [Generator loss: 0.7753%]\n",
            "12312 [Discriminator loss: 0.6670%, acc.: 58.59%] [Generator loss: 0.7674%]\n",
            "12313 [Discriminator loss: 0.6743%, acc.: 56.64%] [Generator loss: 0.7688%]\n",
            "12314 [Discriminator loss: 0.6620%, acc.: 61.33%] [Generator loss: 0.7886%]\n",
            "12315 [Discriminator loss: 0.6475%, acc.: 63.28%] [Generator loss: 0.8125%]\n",
            "12316 [Discriminator loss: 0.6700%, acc.: 61.72%] [Generator loss: 0.7830%]\n",
            "12317 [Discriminator loss: 0.6738%, acc.: 57.81%] [Generator loss: 0.7906%]\n",
            "12318 [Discriminator loss: 0.6673%, acc.: 60.55%] [Generator loss: 0.7897%]\n",
            "12319 [Discriminator loss: 0.6570%, acc.: 64.06%] [Generator loss: 0.7666%]\n",
            "12320 [Discriminator loss: 0.6951%, acc.: 57.03%] [Generator loss: 0.7838%]\n",
            "12321 [Discriminator loss: 0.6587%, acc.: 62.89%] [Generator loss: 0.7734%]\n",
            "12322 [Discriminator loss: 0.6559%, acc.: 60.94%] [Generator loss: 0.7996%]\n",
            "12323 [Discriminator loss: 0.6680%, acc.: 58.20%] [Generator loss: 0.7755%]\n",
            "12324 [Discriminator loss: 0.6558%, acc.: 59.77%] [Generator loss: 0.7840%]\n",
            "12325 [Discriminator loss: 0.6510%, acc.: 63.67%] [Generator loss: 0.7748%]\n",
            "12326 [Discriminator loss: 0.6897%, acc.: 53.91%] [Generator loss: 0.7927%]\n",
            "12327 [Discriminator loss: 0.6821%, acc.: 58.20%] [Generator loss: 0.8052%]\n",
            "12328 [Discriminator loss: 0.6888%, acc.: 53.52%] [Generator loss: 0.7918%]\n",
            "12329 [Discriminator loss: 0.6728%, acc.: 55.47%] [Generator loss: 0.7933%]\n",
            "12330 [Discriminator loss: 0.6957%, acc.: 53.52%] [Generator loss: 0.7953%]\n",
            "12331 [Discriminator loss: 0.6772%, acc.: 57.81%] [Generator loss: 0.7753%]\n",
            "12332 [Discriminator loss: 0.6724%, acc.: 57.81%] [Generator loss: 0.7848%]\n",
            "12333 [Discriminator loss: 0.6650%, acc.: 59.77%] [Generator loss: 0.8131%]\n",
            "12334 [Discriminator loss: 0.6628%, acc.: 59.38%] [Generator loss: 0.7853%]\n",
            "12335 [Discriminator loss: 0.6788%, acc.: 54.30%] [Generator loss: 0.7892%]\n",
            "12336 [Discriminator loss: 0.6842%, acc.: 56.25%] [Generator loss: 0.7705%]\n",
            "12337 [Discriminator loss: 0.6652%, acc.: 59.77%] [Generator loss: 0.7987%]\n",
            "12338 [Discriminator loss: 0.6850%, acc.: 51.56%] [Generator loss: 0.7803%]\n",
            "12339 [Discriminator loss: 0.6831%, acc.: 52.34%] [Generator loss: 0.7889%]\n",
            "12340 [Discriminator loss: 0.6786%, acc.: 54.30%] [Generator loss: 0.7555%]\n",
            "12341 [Discriminator loss: 0.6710%, acc.: 56.25%] [Generator loss: 0.7832%]\n",
            "12342 [Discriminator loss: 0.6767%, acc.: 57.03%] [Generator loss: 0.7889%]\n",
            "12343 [Discriminator loss: 0.6467%, acc.: 66.41%] [Generator loss: 0.8033%]\n",
            "12344 [Discriminator loss: 0.6796%, acc.: 55.08%] [Generator loss: 0.7991%]\n",
            "12345 [Discriminator loss: 0.6610%, acc.: 62.50%] [Generator loss: 0.7908%]\n",
            "12346 [Discriminator loss: 0.6658%, acc.: 60.55%] [Generator loss: 0.7878%]\n",
            "12347 [Discriminator loss: 0.6559%, acc.: 61.72%] [Generator loss: 0.7774%]\n",
            "12348 [Discriminator loss: 0.6568%, acc.: 65.62%] [Generator loss: 0.7635%]\n",
            "12349 [Discriminator loss: 0.6621%, acc.: 58.59%] [Generator loss: 0.7943%]\n",
            "12350 [Discriminator loss: 0.6830%, acc.: 55.47%] [Generator loss: 0.7844%]\n",
            "12351 [Discriminator loss: 0.6694%, acc.: 60.55%] [Generator loss: 0.7821%]\n",
            "12352 [Discriminator loss: 0.6627%, acc.: 59.77%] [Generator loss: 0.7799%]\n",
            "12353 [Discriminator loss: 0.6773%, acc.: 58.20%] [Generator loss: 0.7955%]\n",
            "12354 [Discriminator loss: 0.6559%, acc.: 64.84%] [Generator loss: 0.7939%]\n",
            "12355 [Discriminator loss: 0.6746%, acc.: 55.47%] [Generator loss: 0.7736%]\n",
            "12356 [Discriminator loss: 0.6675%, acc.: 59.38%] [Generator loss: 0.8177%]\n",
            "12357 [Discriminator loss: 0.6699%, acc.: 60.94%] [Generator loss: 0.8088%]\n",
            "12358 [Discriminator loss: 0.6667%, acc.: 62.11%] [Generator loss: 0.7883%]\n",
            "12359 [Discriminator loss: 0.6698%, acc.: 57.03%] [Generator loss: 0.8030%]\n",
            "12360 [Discriminator loss: 0.6833%, acc.: 49.61%] [Generator loss: 0.8058%]\n",
            "12361 [Discriminator loss: 0.6867%, acc.: 53.91%] [Generator loss: 0.7952%]\n",
            "12362 [Discriminator loss: 0.6776%, acc.: 59.38%] [Generator loss: 0.7880%]\n",
            "12363 [Discriminator loss: 0.6450%, acc.: 64.84%] [Generator loss: 0.7888%]\n",
            "12364 [Discriminator loss: 0.6786%, acc.: 58.59%] [Generator loss: 0.7845%]\n",
            "12365 [Discriminator loss: 0.6742%, acc.: 58.59%] [Generator loss: 0.7875%]\n",
            "12366 [Discriminator loss: 0.6784%, acc.: 55.08%] [Generator loss: 0.7838%]\n",
            "12367 [Discriminator loss: 0.6742%, acc.: 60.16%] [Generator loss: 0.7890%]\n",
            "12368 [Discriminator loss: 0.6621%, acc.: 61.33%] [Generator loss: 0.8163%]\n",
            "12369 [Discriminator loss: 0.6754%, acc.: 56.25%] [Generator loss: 0.7746%]\n",
            "12370 [Discriminator loss: 0.6713%, acc.: 60.55%] [Generator loss: 0.7975%]\n",
            "12371 [Discriminator loss: 0.6800%, acc.: 54.69%] [Generator loss: 0.7927%]\n",
            "12372 [Discriminator loss: 0.6681%, acc.: 58.98%] [Generator loss: 0.7808%]\n",
            "12373 [Discriminator loss: 0.6751%, acc.: 58.59%] [Generator loss: 0.7736%]\n",
            "12374 [Discriminator loss: 0.6927%, acc.: 55.47%] [Generator loss: 0.7434%]\n",
            "12375 [Discriminator loss: 0.6705%, acc.: 57.03%] [Generator loss: 0.8067%]\n",
            "12376 [Discriminator loss: 0.6725%, acc.: 55.47%] [Generator loss: 0.7772%]\n",
            "12377 [Discriminator loss: 0.6782%, acc.: 58.20%] [Generator loss: 0.7812%]\n",
            "12378 [Discriminator loss: 0.6738%, acc.: 61.33%] [Generator loss: 0.7990%]\n",
            "12379 [Discriminator loss: 0.6703%, acc.: 57.81%] [Generator loss: 0.8046%]\n",
            "12380 [Discriminator loss: 0.6638%, acc.: 61.33%] [Generator loss: 0.8109%]\n",
            "12381 [Discriminator loss: 0.6728%, acc.: 53.12%] [Generator loss: 0.7827%]\n",
            "12382 [Discriminator loss: 0.6627%, acc.: 60.55%] [Generator loss: 0.8115%]\n",
            "12383 [Discriminator loss: 0.6770%, acc.: 56.25%] [Generator loss: 0.7826%]\n",
            "12384 [Discriminator loss: 0.6676%, acc.: 62.89%] [Generator loss: 0.7858%]\n",
            "12385 [Discriminator loss: 0.6614%, acc.: 62.50%] [Generator loss: 0.7968%]\n",
            "12386 [Discriminator loss: 0.6897%, acc.: 55.47%] [Generator loss: 0.7563%]\n",
            "12387 [Discriminator loss: 0.6581%, acc.: 60.94%] [Generator loss: 0.8043%]\n",
            "12388 [Discriminator loss: 0.6844%, acc.: 52.73%] [Generator loss: 0.7721%]\n",
            "12389 [Discriminator loss: 0.6765%, acc.: 56.25%] [Generator loss: 0.7898%]\n",
            "12390 [Discriminator loss: 0.6658%, acc.: 54.30%] [Generator loss: 0.7694%]\n",
            "12391 [Discriminator loss: 0.6662%, acc.: 60.16%] [Generator loss: 0.7827%]\n",
            "12392 [Discriminator loss: 0.6717%, acc.: 60.16%] [Generator loss: 0.7868%]\n",
            "12393 [Discriminator loss: 0.6597%, acc.: 62.50%] [Generator loss: 0.8345%]\n",
            "12394 [Discriminator loss: 0.6629%, acc.: 58.20%] [Generator loss: 0.7930%]\n",
            "12395 [Discriminator loss: 0.6795%, acc.: 60.16%] [Generator loss: 0.7812%]\n",
            "12396 [Discriminator loss: 0.6730%, acc.: 61.33%] [Generator loss: 0.7935%]\n",
            "12397 [Discriminator loss: 0.6745%, acc.: 60.55%] [Generator loss: 0.7993%]\n",
            "12398 [Discriminator loss: 0.6666%, acc.: 57.42%] [Generator loss: 0.7960%]\n",
            "12399 [Discriminator loss: 0.6793%, acc.: 55.47%] [Generator loss: 0.8052%]\n",
            "12400 [Discriminator loss: 0.6717%, acc.: 56.64%] [Generator loss: 0.7705%]\n",
            "12401 [Discriminator loss: 0.6550%, acc.: 59.77%] [Generator loss: 0.7840%]\n",
            "12402 [Discriminator loss: 0.6625%, acc.: 62.11%] [Generator loss: 0.7708%]\n",
            "12403 [Discriminator loss: 0.6795%, acc.: 57.03%] [Generator loss: 0.8246%]\n",
            "12404 [Discriminator loss: 0.6848%, acc.: 53.52%] [Generator loss: 0.7968%]\n",
            "12405 [Discriminator loss: 0.6694%, acc.: 59.38%] [Generator loss: 0.8091%]\n",
            "12406 [Discriminator loss: 0.6748%, acc.: 56.64%] [Generator loss: 0.8026%]\n",
            "12407 [Discriminator loss: 0.6715%, acc.: 60.16%] [Generator loss: 0.8134%]\n",
            "12408 [Discriminator loss: 0.6682%, acc.: 60.55%] [Generator loss: 0.7846%]\n",
            "12409 [Discriminator loss: 0.6554%, acc.: 61.72%] [Generator loss: 0.8140%]\n",
            "12410 [Discriminator loss: 0.6471%, acc.: 67.19%] [Generator loss: 0.8228%]\n",
            "12411 [Discriminator loss: 0.6769%, acc.: 53.52%] [Generator loss: 0.7987%]\n",
            "12412 [Discriminator loss: 0.6815%, acc.: 55.08%] [Generator loss: 0.7921%]\n",
            "12413 [Discriminator loss: 0.6695%, acc.: 57.42%] [Generator loss: 0.8089%]\n",
            "12414 [Discriminator loss: 0.6678%, acc.: 58.20%] [Generator loss: 0.7805%]\n",
            "12415 [Discriminator loss: 0.6744%, acc.: 60.94%] [Generator loss: 0.8001%]\n",
            "12416 [Discriminator loss: 0.6526%, acc.: 65.62%] [Generator loss: 0.7956%]\n",
            "12417 [Discriminator loss: 0.6782%, acc.: 59.38%] [Generator loss: 0.7897%]\n",
            "12418 [Discriminator loss: 0.6668%, acc.: 56.64%] [Generator loss: 0.8055%]\n",
            "12419 [Discriminator loss: 0.6831%, acc.: 58.20%] [Generator loss: 0.7952%]\n",
            "12420 [Discriminator loss: 0.6777%, acc.: 55.47%] [Generator loss: 0.8003%]\n",
            "12421 [Discriminator loss: 0.6536%, acc.: 66.41%] [Generator loss: 0.7969%]\n",
            "12422 [Discriminator loss: 0.6555%, acc.: 62.11%] [Generator loss: 0.7562%]\n",
            "12423 [Discriminator loss: 0.6722%, acc.: 58.98%] [Generator loss: 0.7923%]\n",
            "12424 [Discriminator loss: 0.6635%, acc.: 60.16%] [Generator loss: 0.7731%]\n",
            "12425 [Discriminator loss: 0.6518%, acc.: 58.59%] [Generator loss: 0.7756%]\n",
            "12426 [Discriminator loss: 0.6554%, acc.: 63.67%] [Generator loss: 0.8019%]\n",
            "12427 [Discriminator loss: 0.6676%, acc.: 58.20%] [Generator loss: 0.7705%]\n",
            "12428 [Discriminator loss: 0.6583%, acc.: 63.67%] [Generator loss: 0.7867%]\n",
            "12429 [Discriminator loss: 0.6670%, acc.: 55.47%] [Generator loss: 0.7632%]\n",
            "12430 [Discriminator loss: 0.6661%, acc.: 59.77%] [Generator loss: 0.7867%]\n",
            "12431 [Discriminator loss: 0.6781%, acc.: 58.98%] [Generator loss: 0.7726%]\n",
            "12432 [Discriminator loss: 0.6728%, acc.: 55.08%] [Generator loss: 0.7679%]\n",
            "12433 [Discriminator loss: 0.6665%, acc.: 56.25%] [Generator loss: 0.7772%]\n",
            "12434 [Discriminator loss: 0.6852%, acc.: 54.30%] [Generator loss: 0.7811%]\n",
            "12435 [Discriminator loss: 0.6512%, acc.: 61.33%] [Generator loss: 0.8123%]\n",
            "12436 [Discriminator loss: 0.6536%, acc.: 62.89%] [Generator loss: 0.7919%]\n",
            "12437 [Discriminator loss: 0.6614%, acc.: 62.11%] [Generator loss: 0.7558%]\n",
            "12438 [Discriminator loss: 0.6559%, acc.: 63.28%] [Generator loss: 0.7839%]\n",
            "12439 [Discriminator loss: 0.6827%, acc.: 55.86%] [Generator loss: 0.7721%]\n",
            "12440 [Discriminator loss: 0.6819%, acc.: 54.69%] [Generator loss: 0.8047%]\n",
            "12441 [Discriminator loss: 0.6674%, acc.: 55.86%] [Generator loss: 0.8139%]\n",
            "12442 [Discriminator loss: 0.6768%, acc.: 57.03%] [Generator loss: 0.7851%]\n",
            "12443 [Discriminator loss: 0.6669%, acc.: 60.55%] [Generator loss: 0.7843%]\n",
            "12444 [Discriminator loss: 0.6740%, acc.: 60.94%] [Generator loss: 0.7526%]\n",
            "12445 [Discriminator loss: 0.6651%, acc.: 56.64%] [Generator loss: 0.7920%]\n",
            "12446 [Discriminator loss: 0.6621%, acc.: 63.28%] [Generator loss: 0.7851%]\n",
            "12447 [Discriminator loss: 0.6714%, acc.: 56.25%] [Generator loss: 0.8057%]\n",
            "12448 [Discriminator loss: 0.6632%, acc.: 58.20%] [Generator loss: 0.8015%]\n",
            "12449 [Discriminator loss: 0.6726%, acc.: 54.30%] [Generator loss: 0.8185%]\n",
            "12450 [Discriminator loss: 0.6851%, acc.: 52.34%] [Generator loss: 0.7709%]\n",
            "12451 [Discriminator loss: 0.6709%, acc.: 60.55%] [Generator loss: 0.7580%]\n",
            "12452 [Discriminator loss: 0.6776%, acc.: 51.95%] [Generator loss: 0.7762%]\n",
            "12453 [Discriminator loss: 0.6564%, acc.: 62.50%] [Generator loss: 0.7825%]\n",
            "12454 [Discriminator loss: 0.6639%, acc.: 56.64%] [Generator loss: 0.7904%]\n",
            "12455 [Discriminator loss: 0.6579%, acc.: 64.06%] [Generator loss: 0.7866%]\n",
            "12456 [Discriminator loss: 0.6598%, acc.: 61.72%] [Generator loss: 0.7904%]\n",
            "12457 [Discriminator loss: 0.6698%, acc.: 56.64%] [Generator loss: 0.7891%]\n",
            "12458 [Discriminator loss: 0.6790%, acc.: 58.59%] [Generator loss: 0.8003%]\n",
            "12459 [Discriminator loss: 0.6726%, acc.: 60.16%] [Generator loss: 0.7800%]\n",
            "12460 [Discriminator loss: 0.6498%, acc.: 62.11%] [Generator loss: 0.7729%]\n",
            "12461 [Discriminator loss: 0.6693%, acc.: 58.59%] [Generator loss: 0.7933%]\n",
            "12462 [Discriminator loss: 0.6570%, acc.: 62.11%] [Generator loss: 0.8130%]\n",
            "12463 [Discriminator loss: 0.6605%, acc.: 60.94%] [Generator loss: 0.7873%]\n",
            "12464 [Discriminator loss: 0.6772%, acc.: 55.86%] [Generator loss: 0.8071%]\n",
            "12465 [Discriminator loss: 0.6702%, acc.: 60.94%] [Generator loss: 0.7858%]\n",
            "12466 [Discriminator loss: 0.6787%, acc.: 57.81%] [Generator loss: 0.7781%]\n",
            "12467 [Discriminator loss: 0.6715%, acc.: 59.38%] [Generator loss: 0.7745%]\n",
            "12468 [Discriminator loss: 0.6520%, acc.: 62.50%] [Generator loss: 0.7925%]\n",
            "12469 [Discriminator loss: 0.6735%, acc.: 59.77%] [Generator loss: 0.7992%]\n",
            "12470 [Discriminator loss: 0.6904%, acc.: 55.86%] [Generator loss: 0.7951%]\n",
            "12471 [Discriminator loss: 0.6893%, acc.: 55.08%] [Generator loss: 0.7986%]\n",
            "12472 [Discriminator loss: 0.6684%, acc.: 58.59%] [Generator loss: 0.7840%]\n",
            "12473 [Discriminator loss: 0.6758%, acc.: 54.69%] [Generator loss: 0.7810%]\n",
            "12474 [Discriminator loss: 0.6666%, acc.: 57.42%] [Generator loss: 0.8009%]\n",
            "12475 [Discriminator loss: 0.6677%, acc.: 61.72%] [Generator loss: 0.7745%]\n",
            "12476 [Discriminator loss: 0.6634%, acc.: 60.55%] [Generator loss: 0.8038%]\n",
            "12477 [Discriminator loss: 0.6776%, acc.: 58.98%] [Generator loss: 0.7804%]\n",
            "12478 [Discriminator loss: 0.6556%, acc.: 68.36%] [Generator loss: 0.7825%]\n",
            "12479 [Discriminator loss: 0.6721%, acc.: 62.50%] [Generator loss: 0.7611%]\n",
            "12480 [Discriminator loss: 0.6840%, acc.: 54.30%] [Generator loss: 0.8090%]\n",
            "12481 [Discriminator loss: 0.6600%, acc.: 58.98%] [Generator loss: 0.7780%]\n",
            "12482 [Discriminator loss: 0.7028%, acc.: 52.34%] [Generator loss: 0.7629%]\n",
            "12483 [Discriminator loss: 0.6737%, acc.: 60.55%] [Generator loss: 0.7689%]\n",
            "12484 [Discriminator loss: 0.6563%, acc.: 64.84%] [Generator loss: 0.7676%]\n",
            "12485 [Discriminator loss: 0.6893%, acc.: 52.34%] [Generator loss: 0.7878%]\n",
            "12486 [Discriminator loss: 0.6659%, acc.: 61.33%] [Generator loss: 0.8097%]\n",
            "12487 [Discriminator loss: 0.6762%, acc.: 56.25%] [Generator loss: 0.7795%]\n",
            "12488 [Discriminator loss: 0.6791%, acc.: 59.77%] [Generator loss: 0.7681%]\n",
            "12489 [Discriminator loss: 0.6673%, acc.: 60.94%] [Generator loss: 0.7797%]\n",
            "12490 [Discriminator loss: 0.6744%, acc.: 53.91%] [Generator loss: 0.8035%]\n",
            "12491 [Discriminator loss: 0.6709%, acc.: 58.98%] [Generator loss: 0.7611%]\n",
            "12492 [Discriminator loss: 0.6564%, acc.: 62.50%] [Generator loss: 0.8033%]\n",
            "12493 [Discriminator loss: 0.6647%, acc.: 58.20%] [Generator loss: 0.7674%]\n",
            "12494 [Discriminator loss: 0.6795%, acc.: 52.34%] [Generator loss: 0.7817%]\n",
            "12495 [Discriminator loss: 0.6775%, acc.: 53.52%] [Generator loss: 0.7927%]\n",
            "12496 [Discriminator loss: 0.6551%, acc.: 60.94%] [Generator loss: 0.7936%]\n",
            "12497 [Discriminator loss: 0.6799%, acc.: 58.59%] [Generator loss: 0.8223%]\n",
            "12498 [Discriminator loss: 0.6628%, acc.: 59.38%] [Generator loss: 0.8110%]\n",
            "12499 [Discriminator loss: 0.6732%, acc.: 59.38%] [Generator loss: 0.8293%]\n",
            "12500 [Discriminator loss: 0.6862%, acc.: 54.69%] [Generator loss: 0.8117%]\n",
            "12501 [Discriminator loss: 0.6667%, acc.: 59.77%] [Generator loss: 0.8153%]\n",
            "12502 [Discriminator loss: 0.6824%, acc.: 55.47%] [Generator loss: 0.7886%]\n",
            "12503 [Discriminator loss: 0.6845%, acc.: 55.86%] [Generator loss: 0.7694%]\n",
            "12504 [Discriminator loss: 0.6711%, acc.: 58.98%] [Generator loss: 0.7801%]\n",
            "12505 [Discriminator loss: 0.6669%, acc.: 60.55%] [Generator loss: 0.7973%]\n",
            "12506 [Discriminator loss: 0.6608%, acc.: 61.33%] [Generator loss: 0.7914%]\n",
            "12507 [Discriminator loss: 0.6715%, acc.: 59.38%] [Generator loss: 0.8231%]\n",
            "12508 [Discriminator loss: 0.6625%, acc.: 60.94%] [Generator loss: 0.8049%]\n",
            "12509 [Discriminator loss: 0.6686%, acc.: 60.16%] [Generator loss: 0.7931%]\n",
            "12510 [Discriminator loss: 0.6624%, acc.: 60.16%] [Generator loss: 0.7904%]\n",
            "12511 [Discriminator loss: 0.6619%, acc.: 60.16%] [Generator loss: 0.7981%]\n",
            "12512 [Discriminator loss: 0.6721%, acc.: 62.50%] [Generator loss: 0.7975%]\n",
            "12513 [Discriminator loss: 0.6568%, acc.: 62.50%] [Generator loss: 0.8038%]\n",
            "12514 [Discriminator loss: 0.6470%, acc.: 60.55%] [Generator loss: 0.7968%]\n",
            "12515 [Discriminator loss: 0.6764%, acc.: 58.20%] [Generator loss: 0.8093%]\n",
            "12516 [Discriminator loss: 0.6627%, acc.: 62.50%] [Generator loss: 0.7866%]\n",
            "12517 [Discriminator loss: 0.6619%, acc.: 58.59%] [Generator loss: 0.8229%]\n",
            "12518 [Discriminator loss: 0.6709%, acc.: 58.98%] [Generator loss: 0.7902%]\n",
            "12519 [Discriminator loss: 0.6709%, acc.: 56.64%] [Generator loss: 0.7792%]\n",
            "12520 [Discriminator loss: 0.6775%, acc.: 54.69%] [Generator loss: 0.7692%]\n",
            "12521 [Discriminator loss: 0.6653%, acc.: 58.98%] [Generator loss: 0.7721%]\n",
            "12522 [Discriminator loss: 0.6520%, acc.: 62.89%] [Generator loss: 0.7581%]\n",
            "12523 [Discriminator loss: 0.6617%, acc.: 60.55%] [Generator loss: 0.7726%]\n",
            "12524 [Discriminator loss: 0.6610%, acc.: 58.98%] [Generator loss: 0.7747%]\n",
            "12525 [Discriminator loss: 0.6662%, acc.: 57.42%] [Generator loss: 0.7888%]\n",
            "12526 [Discriminator loss: 0.6764%, acc.: 58.98%] [Generator loss: 0.7909%]\n",
            "12527 [Discriminator loss: 0.6790%, acc.: 57.81%] [Generator loss: 0.7970%]\n",
            "12528 [Discriminator loss: 0.6648%, acc.: 60.94%] [Generator loss: 0.7876%]\n",
            "12529 [Discriminator loss: 0.6695%, acc.: 56.64%] [Generator loss: 0.7925%]\n",
            "12530 [Discriminator loss: 0.6624%, acc.: 59.77%] [Generator loss: 0.8045%]\n",
            "12531 [Discriminator loss: 0.6578%, acc.: 63.28%] [Generator loss: 0.8233%]\n",
            "12532 [Discriminator loss: 0.6701%, acc.: 55.86%] [Generator loss: 0.8033%]\n",
            "12533 [Discriminator loss: 0.6571%, acc.: 64.84%] [Generator loss: 0.7946%]\n",
            "12534 [Discriminator loss: 0.6835%, acc.: 56.25%] [Generator loss: 0.7893%]\n",
            "12535 [Discriminator loss: 0.6588%, acc.: 60.16%] [Generator loss: 0.7678%]\n",
            "12536 [Discriminator loss: 0.6557%, acc.: 63.67%] [Generator loss: 0.7994%]\n",
            "12537 [Discriminator loss: 0.6673%, acc.: 58.98%] [Generator loss: 0.7743%]\n",
            "12538 [Discriminator loss: 0.6744%, acc.: 57.81%] [Generator loss: 0.7896%]\n",
            "12539 [Discriminator loss: 0.6609%, acc.: 60.94%] [Generator loss: 0.7953%]\n",
            "12540 [Discriminator loss: 0.6801%, acc.: 57.42%] [Generator loss: 0.7948%]\n",
            "12541 [Discriminator loss: 0.6458%, acc.: 66.41%] [Generator loss: 0.8037%]\n",
            "12542 [Discriminator loss: 0.6624%, acc.: 56.64%] [Generator loss: 0.7823%]\n",
            "12543 [Discriminator loss: 0.6646%, acc.: 60.55%] [Generator loss: 0.7876%]\n",
            "12544 [Discriminator loss: 0.6661%, acc.: 58.20%] [Generator loss: 0.7860%]\n",
            "12545 [Discriminator loss: 0.6884%, acc.: 52.34%] [Generator loss: 0.8140%]\n",
            "12546 [Discriminator loss: 0.6774%, acc.: 57.03%] [Generator loss: 0.7944%]\n",
            "12547 [Discriminator loss: 0.6725%, acc.: 58.59%] [Generator loss: 0.7703%]\n",
            "12548 [Discriminator loss: 0.6477%, acc.: 64.06%] [Generator loss: 0.8239%]\n",
            "12549 [Discriminator loss: 0.6546%, acc.: 62.89%] [Generator loss: 0.7951%]\n",
            "12550 [Discriminator loss: 0.6613%, acc.: 58.20%] [Generator loss: 0.7865%]\n",
            "12551 [Discriminator loss: 0.6492%, acc.: 62.11%] [Generator loss: 0.7848%]\n",
            "12552 [Discriminator loss: 0.6828%, acc.: 55.08%] [Generator loss: 0.7940%]\n",
            "12553 [Discriminator loss: 0.6634%, acc.: 62.11%] [Generator loss: 0.7882%]\n",
            "12554 [Discriminator loss: 0.6944%, acc.: 50.78%] [Generator loss: 0.7842%]\n",
            "12555 [Discriminator loss: 0.6786%, acc.: 57.42%] [Generator loss: 0.7907%]\n",
            "12556 [Discriminator loss: 0.6879%, acc.: 56.25%] [Generator loss: 0.8076%]\n",
            "12557 [Discriminator loss: 0.6560%, acc.: 58.20%] [Generator loss: 0.7923%]\n",
            "12558 [Discriminator loss: 0.6626%, acc.: 59.38%] [Generator loss: 0.8025%]\n",
            "12559 [Discriminator loss: 0.6705%, acc.: 56.64%] [Generator loss: 0.7661%]\n",
            "12560 [Discriminator loss: 0.6835%, acc.: 53.91%] [Generator loss: 0.8037%]\n",
            "12561 [Discriminator loss: 0.6487%, acc.: 66.80%] [Generator loss: 0.7811%]\n",
            "12562 [Discriminator loss: 0.6791%, acc.: 57.03%] [Generator loss: 0.7828%]\n",
            "12563 [Discriminator loss: 0.6662%, acc.: 58.59%] [Generator loss: 0.7831%]\n",
            "12564 [Discriminator loss: 0.6964%, acc.: 58.20%] [Generator loss: 0.8082%]\n",
            "12565 [Discriminator loss: 0.6509%, acc.: 62.50%] [Generator loss: 0.7931%]\n",
            "12566 [Discriminator loss: 0.6454%, acc.: 61.72%] [Generator loss: 0.7878%]\n",
            "12567 [Discriminator loss: 0.6523%, acc.: 61.72%] [Generator loss: 0.7779%]\n",
            "12568 [Discriminator loss: 0.6707%, acc.: 58.20%] [Generator loss: 0.7827%]\n",
            "12569 [Discriminator loss: 0.6611%, acc.: 62.50%] [Generator loss: 0.8171%]\n",
            "12570 [Discriminator loss: 0.6615%, acc.: 58.59%] [Generator loss: 0.7926%]\n",
            "12571 [Discriminator loss: 0.6669%, acc.: 62.11%] [Generator loss: 0.8014%]\n",
            "12572 [Discriminator loss: 0.6607%, acc.: 59.77%] [Generator loss: 0.7835%]\n",
            "12573 [Discriminator loss: 0.6684%, acc.: 60.55%] [Generator loss: 0.7601%]\n",
            "12574 [Discriminator loss: 0.6675%, acc.: 59.38%] [Generator loss: 0.7944%]\n",
            "12575 [Discriminator loss: 0.6690%, acc.: 62.89%] [Generator loss: 0.7909%]\n",
            "12576 [Discriminator loss: 0.6576%, acc.: 61.33%] [Generator loss: 0.8103%]\n",
            "12577 [Discriminator loss: 0.6639%, acc.: 60.16%] [Generator loss: 0.8062%]\n",
            "12578 [Discriminator loss: 0.6564%, acc.: 58.98%] [Generator loss: 0.8019%]\n",
            "12579 [Discriminator loss: 0.6600%, acc.: 59.77%] [Generator loss: 0.7860%]\n",
            "12580 [Discriminator loss: 0.6652%, acc.: 57.42%] [Generator loss: 0.7855%]\n",
            "12581 [Discriminator loss: 0.6415%, acc.: 66.41%] [Generator loss: 0.8196%]\n",
            "12582 [Discriminator loss: 0.6751%, acc.: 55.08%] [Generator loss: 0.8032%]\n",
            "12583 [Discriminator loss: 0.6765%, acc.: 58.59%] [Generator loss: 0.7842%]\n",
            "12584 [Discriminator loss: 0.6859%, acc.: 55.08%] [Generator loss: 0.7889%]\n",
            "12585 [Discriminator loss: 0.6692%, acc.: 60.55%] [Generator loss: 0.7857%]\n",
            "12586 [Discriminator loss: 0.6764%, acc.: 56.64%] [Generator loss: 0.7980%]\n",
            "12587 [Discriminator loss: 0.6610%, acc.: 62.89%] [Generator loss: 0.8007%]\n",
            "12588 [Discriminator loss: 0.6860%, acc.: 53.12%] [Generator loss: 0.7977%]\n",
            "12589 [Discriminator loss: 0.6838%, acc.: 53.91%] [Generator loss: 0.7933%]\n",
            "12590 [Discriminator loss: 0.6751%, acc.: 58.59%] [Generator loss: 0.7975%]\n",
            "12591 [Discriminator loss: 0.6560%, acc.: 64.45%] [Generator loss: 0.7872%]\n",
            "12592 [Discriminator loss: 0.6512%, acc.: 64.84%] [Generator loss: 0.8115%]\n",
            "12593 [Discriminator loss: 0.6633%, acc.: 63.28%] [Generator loss: 0.7911%]\n",
            "12594 [Discriminator loss: 0.6716%, acc.: 61.33%] [Generator loss: 0.7718%]\n",
            "12595 [Discriminator loss: 0.6697%, acc.: 57.42%] [Generator loss: 0.8009%]\n",
            "12596 [Discriminator loss: 0.6788%, acc.: 57.03%] [Generator loss: 0.7890%]\n",
            "12597 [Discriminator loss: 0.6613%, acc.: 62.11%] [Generator loss: 0.7883%]\n",
            "12598 [Discriminator loss: 0.6505%, acc.: 59.38%] [Generator loss: 0.7894%]\n",
            "12599 [Discriminator loss: 0.6737%, acc.: 59.77%] [Generator loss: 0.7773%]\n",
            "12600 [Discriminator loss: 0.6668%, acc.: 60.55%] [Generator loss: 0.7904%]\n",
            "12601 [Discriminator loss: 0.6647%, acc.: 64.06%] [Generator loss: 0.7942%]\n",
            "12602 [Discriminator loss: 0.6788%, acc.: 55.86%] [Generator loss: 0.8040%]\n",
            "12603 [Discriminator loss: 0.6607%, acc.: 58.20%] [Generator loss: 0.7922%]\n",
            "12604 [Discriminator loss: 0.6689%, acc.: 62.50%] [Generator loss: 0.8065%]\n",
            "12605 [Discriminator loss: 0.6737%, acc.: 56.25%] [Generator loss: 0.8249%]\n",
            "12606 [Discriminator loss: 0.6914%, acc.: 52.73%] [Generator loss: 0.8001%]\n",
            "12607 [Discriminator loss: 0.6836%, acc.: 57.81%] [Generator loss: 0.7826%]\n",
            "12608 [Discriminator loss: 0.6682%, acc.: 57.03%] [Generator loss: 0.7643%]\n",
            "12609 [Discriminator loss: 0.6700%, acc.: 57.03%] [Generator loss: 0.8007%]\n",
            "12610 [Discriminator loss: 0.6787%, acc.: 57.81%] [Generator loss: 0.7907%]\n",
            "12611 [Discriminator loss: 0.6741%, acc.: 55.47%] [Generator loss: 0.7537%]\n",
            "12612 [Discriminator loss: 0.6708%, acc.: 61.33%] [Generator loss: 0.7943%]\n",
            "12613 [Discriminator loss: 0.6536%, acc.: 62.89%] [Generator loss: 0.7819%]\n",
            "12614 [Discriminator loss: 0.6719%, acc.: 53.12%] [Generator loss: 0.8021%]\n",
            "12615 [Discriminator loss: 0.6757%, acc.: 59.77%] [Generator loss: 0.7878%]\n",
            "12616 [Discriminator loss: 0.6836%, acc.: 55.86%] [Generator loss: 0.8190%]\n",
            "12617 [Discriminator loss: 0.6479%, acc.: 64.45%] [Generator loss: 0.8072%]\n",
            "12618 [Discriminator loss: 0.6970%, acc.: 50.78%] [Generator loss: 0.7753%]\n",
            "12619 [Discriminator loss: 0.6789%, acc.: 56.25%] [Generator loss: 0.7760%]\n",
            "12620 [Discriminator loss: 0.6701%, acc.: 53.52%] [Generator loss: 0.7870%]\n",
            "12621 [Discriminator loss: 0.6685%, acc.: 57.42%] [Generator loss: 0.7517%]\n",
            "12622 [Discriminator loss: 0.6803%, acc.: 55.47%] [Generator loss: 0.7810%]\n",
            "12623 [Discriminator loss: 0.6663%, acc.: 57.81%] [Generator loss: 0.7841%]\n",
            "12624 [Discriminator loss: 0.6750%, acc.: 56.25%] [Generator loss: 0.8032%]\n",
            "12625 [Discriminator loss: 0.6848%, acc.: 52.73%] [Generator loss: 0.8225%]\n",
            "12626 [Discriminator loss: 0.6651%, acc.: 58.20%] [Generator loss: 0.8017%]\n",
            "12627 [Discriminator loss: 0.6756%, acc.: 56.64%] [Generator loss: 0.7765%]\n",
            "12628 [Discriminator loss: 0.6840%, acc.: 51.95%] [Generator loss: 0.7722%]\n",
            "12629 [Discriminator loss: 0.6602%, acc.: 58.20%] [Generator loss: 0.7941%]\n",
            "12630 [Discriminator loss: 0.6702%, acc.: 56.25%] [Generator loss: 0.7661%]\n",
            "12631 [Discriminator loss: 0.6920%, acc.: 53.12%] [Generator loss: 0.8049%]\n",
            "12632 [Discriminator loss: 0.6624%, acc.: 59.77%] [Generator loss: 0.7924%]\n",
            "12633 [Discriminator loss: 0.6770%, acc.: 57.42%] [Generator loss: 0.7826%]\n",
            "12634 [Discriminator loss: 0.6773%, acc.: 56.25%] [Generator loss: 0.7879%]\n",
            "12635 [Discriminator loss: 0.6625%, acc.: 63.28%] [Generator loss: 0.8112%]\n",
            "12636 [Discriminator loss: 0.6692%, acc.: 55.86%] [Generator loss: 0.8193%]\n",
            "12637 [Discriminator loss: 0.6635%, acc.: 56.64%] [Generator loss: 0.8071%]\n",
            "12638 [Discriminator loss: 0.6785%, acc.: 57.81%] [Generator loss: 0.7925%]\n",
            "12639 [Discriminator loss: 0.6728%, acc.: 59.77%] [Generator loss: 0.8085%]\n",
            "12640 [Discriminator loss: 0.6728%, acc.: 57.81%] [Generator loss: 0.7698%]\n",
            "12641 [Discriminator loss: 0.6516%, acc.: 68.75%] [Generator loss: 0.8003%]\n",
            "12642 [Discriminator loss: 0.6608%, acc.: 57.81%] [Generator loss: 0.7728%]\n",
            "12643 [Discriminator loss: 0.6782%, acc.: 54.69%] [Generator loss: 0.7871%]\n",
            "12644 [Discriminator loss: 0.6896%, acc.: 50.78%] [Generator loss: 0.7900%]\n",
            "12645 [Discriminator loss: 0.6894%, acc.: 50.78%] [Generator loss: 0.7829%]\n",
            "12646 [Discriminator loss: 0.6763%, acc.: 57.03%] [Generator loss: 0.8039%]\n",
            "12647 [Discriminator loss: 0.6800%, acc.: 54.69%] [Generator loss: 0.8038%]\n",
            "12648 [Discriminator loss: 0.6621%, acc.: 62.50%] [Generator loss: 0.8221%]\n",
            "12649 [Discriminator loss: 0.6779%, acc.: 59.38%] [Generator loss: 0.7816%]\n",
            "12650 [Discriminator loss: 0.6611%, acc.: 61.33%] [Generator loss: 0.8187%]\n",
            "12651 [Discriminator loss: 0.6713%, acc.: 60.16%] [Generator loss: 0.7897%]\n",
            "12652 [Discriminator loss: 0.6512%, acc.: 61.33%] [Generator loss: 0.7911%]\n",
            "12653 [Discriminator loss: 0.6669%, acc.: 56.64%] [Generator loss: 0.8065%]\n",
            "12654 [Discriminator loss: 0.6495%, acc.: 66.02%] [Generator loss: 0.7972%]\n",
            "12655 [Discriminator loss: 0.6556%, acc.: 61.72%] [Generator loss: 0.7873%]\n",
            "12656 [Discriminator loss: 0.6828%, acc.: 54.30%] [Generator loss: 0.8008%]\n",
            "12657 [Discriminator loss: 0.6729%, acc.: 57.81%] [Generator loss: 0.8060%]\n",
            "12658 [Discriminator loss: 0.6777%, acc.: 57.03%] [Generator loss: 0.8107%]\n",
            "12659 [Discriminator loss: 0.6700%, acc.: 58.98%] [Generator loss: 0.7661%]\n",
            "12660 [Discriminator loss: 0.6775%, acc.: 56.25%] [Generator loss: 0.8248%]\n",
            "12661 [Discriminator loss: 0.6715%, acc.: 63.28%] [Generator loss: 0.7782%]\n",
            "12662 [Discriminator loss: 0.6548%, acc.: 59.77%] [Generator loss: 0.7650%]\n",
            "12663 [Discriminator loss: 0.6638%, acc.: 58.98%] [Generator loss: 0.7673%]\n",
            "12664 [Discriminator loss: 0.6579%, acc.: 62.89%] [Generator loss: 0.7888%]\n",
            "12665 [Discriminator loss: 0.6698%, acc.: 59.77%] [Generator loss: 0.7881%]\n",
            "12666 [Discriminator loss: 0.6432%, acc.: 64.06%] [Generator loss: 0.7891%]\n",
            "12667 [Discriminator loss: 0.6688%, acc.: 60.94%] [Generator loss: 0.8196%]\n",
            "12668 [Discriminator loss: 0.6784%, acc.: 55.86%] [Generator loss: 0.7864%]\n",
            "12669 [Discriminator loss: 0.6752%, acc.: 57.42%] [Generator loss: 0.7726%]\n",
            "12670 [Discriminator loss: 0.6722%, acc.: 56.25%] [Generator loss: 0.7831%]\n",
            "12671 [Discriminator loss: 0.6622%, acc.: 60.94%] [Generator loss: 0.7974%]\n",
            "12672 [Discriminator loss: 0.6816%, acc.: 55.08%] [Generator loss: 0.8084%]\n",
            "12673 [Discriminator loss: 0.6476%, acc.: 63.28%] [Generator loss: 0.8024%]\n",
            "12674 [Discriminator loss: 0.6461%, acc.: 64.45%] [Generator loss: 0.7561%]\n",
            "12675 [Discriminator loss: 0.6708%, acc.: 60.16%] [Generator loss: 0.7911%]\n",
            "12676 [Discriminator loss: 0.6753%, acc.: 57.03%] [Generator loss: 0.7723%]\n",
            "12677 [Discriminator loss: 0.6721%, acc.: 57.42%] [Generator loss: 0.7445%]\n",
            "12678 [Discriminator loss: 0.6832%, acc.: 56.25%] [Generator loss: 0.7650%]\n",
            "12679 [Discriminator loss: 0.6576%, acc.: 59.38%] [Generator loss: 0.7449%]\n",
            "12680 [Discriminator loss: 0.6529%, acc.: 64.84%] [Generator loss: 0.7602%]\n",
            "12681 [Discriminator loss: 0.6965%, acc.: 53.12%] [Generator loss: 0.7582%]\n",
            "12682 [Discriminator loss: 0.6668%, acc.: 61.72%] [Generator loss: 0.7882%]\n",
            "12683 [Discriminator loss: 0.6681%, acc.: 58.98%] [Generator loss: 0.7764%]\n",
            "12684 [Discriminator loss: 0.6689%, acc.: 58.98%] [Generator loss: 0.7653%]\n",
            "12685 [Discriminator loss: 0.6993%, acc.: 50.00%] [Generator loss: 0.7724%]\n",
            "12686 [Discriminator loss: 0.6731%, acc.: 53.52%] [Generator loss: 0.7647%]\n",
            "12687 [Discriminator loss: 0.6678%, acc.: 59.38%] [Generator loss: 0.7804%]\n",
            "12688 [Discriminator loss: 0.6789%, acc.: 52.73%] [Generator loss: 0.7689%]\n",
            "12689 [Discriminator loss: 0.6622%, acc.: 58.59%] [Generator loss: 0.7818%]\n",
            "12690 [Discriminator loss: 0.6847%, acc.: 53.12%] [Generator loss: 0.7875%]\n",
            "12691 [Discriminator loss: 0.6517%, acc.: 60.16%] [Generator loss: 0.7992%]\n",
            "12692 [Discriminator loss: 0.6760%, acc.: 56.64%] [Generator loss: 0.7846%]\n",
            "12693 [Discriminator loss: 0.6913%, acc.: 50.39%] [Generator loss: 0.7656%]\n",
            "12694 [Discriminator loss: 0.6848%, acc.: 54.69%] [Generator loss: 0.7760%]\n",
            "12695 [Discriminator loss: 0.6696%, acc.: 59.38%] [Generator loss: 0.7880%]\n",
            "12696 [Discriminator loss: 0.6738%, acc.: 58.20%] [Generator loss: 0.7955%]\n",
            "12697 [Discriminator loss: 0.6583%, acc.: 63.28%] [Generator loss: 0.7842%]\n",
            "12698 [Discriminator loss: 0.6569%, acc.: 60.94%] [Generator loss: 0.7883%]\n",
            "12699 [Discriminator loss: 0.6753%, acc.: 55.08%] [Generator loss: 0.7856%]\n",
            "12700 [Discriminator loss: 0.6500%, acc.: 63.67%] [Generator loss: 0.7962%]\n",
            "12701 [Discriminator loss: 0.6805%, acc.: 53.91%] [Generator loss: 0.7782%]\n",
            "12702 [Discriminator loss: 0.6679%, acc.: 58.98%] [Generator loss: 0.8114%]\n",
            "12703 [Discriminator loss: 0.6677%, acc.: 58.20%] [Generator loss: 0.7903%]\n",
            "12704 [Discriminator loss: 0.6669%, acc.: 57.03%] [Generator loss: 0.7929%]\n",
            "12705 [Discriminator loss: 0.6740%, acc.: 58.59%] [Generator loss: 0.7734%]\n",
            "12706 [Discriminator loss: 0.6640%, acc.: 61.33%] [Generator loss: 0.7869%]\n",
            "12707 [Discriminator loss: 0.6694%, acc.: 57.03%] [Generator loss: 0.7717%]\n",
            "12708 [Discriminator loss: 0.6669%, acc.: 56.25%] [Generator loss: 0.7675%]\n",
            "12709 [Discriminator loss: 0.6868%, acc.: 57.03%] [Generator loss: 0.7789%]\n",
            "12710 [Discriminator loss: 0.6664%, acc.: 59.77%] [Generator loss: 0.8097%]\n",
            "12711 [Discriminator loss: 0.6701%, acc.: 57.03%] [Generator loss: 0.7976%]\n",
            "12712 [Discriminator loss: 0.6780%, acc.: 54.30%] [Generator loss: 0.7682%]\n",
            "12713 [Discriminator loss: 0.6702%, acc.: 62.11%] [Generator loss: 0.7814%]\n",
            "12714 [Discriminator loss: 0.6798%, acc.: 54.69%] [Generator loss: 0.7934%]\n",
            "12715 [Discriminator loss: 0.6569%, acc.: 61.72%] [Generator loss: 0.7854%]\n",
            "12716 [Discriminator loss: 0.6591%, acc.: 60.94%] [Generator loss: 0.7739%]\n",
            "12717 [Discriminator loss: 0.6643%, acc.: 59.38%] [Generator loss: 0.7910%]\n",
            "12718 [Discriminator loss: 0.6630%, acc.: 61.33%] [Generator loss: 0.7999%]\n",
            "12719 [Discriminator loss: 0.6464%, acc.: 66.41%] [Generator loss: 0.7924%]\n",
            "12720 [Discriminator loss: 0.6661%, acc.: 57.42%] [Generator loss: 0.7926%]\n",
            "12721 [Discriminator loss: 0.6673%, acc.: 60.16%] [Generator loss: 0.7875%]\n",
            "12722 [Discriminator loss: 0.6665%, acc.: 64.06%] [Generator loss: 0.7977%]\n",
            "12723 [Discriminator loss: 0.6609%, acc.: 58.20%] [Generator loss: 0.7667%]\n",
            "12724 [Discriminator loss: 0.6755%, acc.: 57.42%] [Generator loss: 0.7801%]\n",
            "12725 [Discriminator loss: 0.6764%, acc.: 55.47%] [Generator loss: 0.7867%]\n",
            "12726 [Discriminator loss: 0.6610%, acc.: 57.03%] [Generator loss: 0.7559%]\n",
            "12727 [Discriminator loss: 0.6811%, acc.: 57.42%] [Generator loss: 0.7684%]\n",
            "12728 [Discriminator loss: 0.6572%, acc.: 62.89%] [Generator loss: 0.7812%]\n",
            "12729 [Discriminator loss: 0.6876%, acc.: 55.08%] [Generator loss: 0.7764%]\n",
            "12730 [Discriminator loss: 0.6737%, acc.: 60.16%] [Generator loss: 0.7928%]\n",
            "12731 [Discriminator loss: 0.6618%, acc.: 60.94%] [Generator loss: 0.7920%]\n",
            "12732 [Discriminator loss: 0.6577%, acc.: 56.25%] [Generator loss: 0.7732%]\n",
            "12733 [Discriminator loss: 0.6643%, acc.: 62.11%] [Generator loss: 0.7760%]\n",
            "12734 [Discriminator loss: 0.6525%, acc.: 61.33%] [Generator loss: 0.7681%]\n",
            "12735 [Discriminator loss: 0.6715%, acc.: 56.64%] [Generator loss: 0.7819%]\n",
            "12736 [Discriminator loss: 0.6733%, acc.: 56.25%] [Generator loss: 0.8186%]\n",
            "12737 [Discriminator loss: 0.6507%, acc.: 61.72%] [Generator loss: 0.8262%]\n",
            "12738 [Discriminator loss: 0.6761%, acc.: 57.03%] [Generator loss: 0.8069%]\n",
            "12739 [Discriminator loss: 0.6871%, acc.: 52.34%] [Generator loss: 0.7845%]\n",
            "12740 [Discriminator loss: 0.6631%, acc.: 59.38%] [Generator loss: 0.7946%]\n",
            "12741 [Discriminator loss: 0.6632%, acc.: 60.55%] [Generator loss: 0.8091%]\n",
            "12742 [Discriminator loss: 0.6928%, acc.: 50.00%] [Generator loss: 0.7897%]\n",
            "12743 [Discriminator loss: 0.6539%, acc.: 62.50%] [Generator loss: 0.8133%]\n",
            "12744 [Discriminator loss: 0.6643%, acc.: 58.98%] [Generator loss: 0.7971%]\n",
            "12745 [Discriminator loss: 0.6935%, acc.: 55.47%] [Generator loss: 0.7740%]\n",
            "12746 [Discriminator loss: 0.6725%, acc.: 59.38%] [Generator loss: 0.7681%]\n",
            "12747 [Discriminator loss: 0.6726%, acc.: 59.38%] [Generator loss: 0.7815%]\n",
            "12748 [Discriminator loss: 0.6722%, acc.: 57.81%] [Generator loss: 0.7807%]\n",
            "12749 [Discriminator loss: 0.6647%, acc.: 57.81%] [Generator loss: 0.7921%]\n",
            "12750 [Discriminator loss: 0.6727%, acc.: 58.98%] [Generator loss: 0.7734%]\n",
            "12751 [Discriminator loss: 0.6707%, acc.: 58.59%] [Generator loss: 0.7985%]\n",
            "12752 [Discriminator loss: 0.6656%, acc.: 57.81%] [Generator loss: 0.7705%]\n",
            "12753 [Discriminator loss: 0.6728%, acc.: 57.81%] [Generator loss: 0.7647%]\n",
            "12754 [Discriminator loss: 0.6717%, acc.: 60.55%] [Generator loss: 0.7937%]\n",
            "12755 [Discriminator loss: 0.6719%, acc.: 58.98%] [Generator loss: 0.7633%]\n",
            "12756 [Discriminator loss: 0.7005%, acc.: 50.39%] [Generator loss: 0.7850%]\n",
            "12757 [Discriminator loss: 0.6659%, acc.: 60.55%] [Generator loss: 0.8027%]\n",
            "12758 [Discriminator loss: 0.6727%, acc.: 57.42%] [Generator loss: 0.7855%]\n",
            "12759 [Discriminator loss: 0.6655%, acc.: 60.94%] [Generator loss: 0.7885%]\n",
            "12760 [Discriminator loss: 0.6710%, acc.: 59.77%] [Generator loss: 0.8072%]\n",
            "12761 [Discriminator loss: 0.6847%, acc.: 55.86%] [Generator loss: 0.7743%]\n",
            "12762 [Discriminator loss: 0.6758%, acc.: 57.42%] [Generator loss: 0.8031%]\n",
            "12763 [Discriminator loss: 0.6733%, acc.: 61.33%] [Generator loss: 0.7669%]\n",
            "12764 [Discriminator loss: 0.6666%, acc.: 62.50%] [Generator loss: 0.7950%]\n",
            "12765 [Discriminator loss: 0.6538%, acc.: 62.11%] [Generator loss: 0.7912%]\n",
            "12766 [Discriminator loss: 0.6652%, acc.: 62.11%] [Generator loss: 0.7986%]\n",
            "12767 [Discriminator loss: 0.6694%, acc.: 58.59%] [Generator loss: 0.7954%]\n",
            "12768 [Discriminator loss: 0.6782%, acc.: 57.03%] [Generator loss: 0.7742%]\n",
            "12769 [Discriminator loss: 0.6856%, acc.: 57.03%] [Generator loss: 0.7674%]\n",
            "12770 [Discriminator loss: 0.6573%, acc.: 60.94%] [Generator loss: 0.7616%]\n",
            "12771 [Discriminator loss: 0.6574%, acc.: 62.50%] [Generator loss: 0.7989%]\n",
            "12772 [Discriminator loss: 0.6899%, acc.: 53.12%] [Generator loss: 0.7945%]\n",
            "12773 [Discriminator loss: 0.6721%, acc.: 57.81%] [Generator loss: 0.7837%]\n",
            "12774 [Discriminator loss: 0.6730%, acc.: 60.16%] [Generator loss: 0.7645%]\n",
            "12775 [Discriminator loss: 0.6721%, acc.: 62.11%] [Generator loss: 0.7853%]\n",
            "12776 [Discriminator loss: 0.6673%, acc.: 60.16%] [Generator loss: 0.7968%]\n",
            "12777 [Discriminator loss: 0.6492%, acc.: 65.23%] [Generator loss: 0.7654%]\n",
            "12778 [Discriminator loss: 0.6739%, acc.: 59.77%] [Generator loss: 0.7917%]\n",
            "12779 [Discriminator loss: 0.6633%, acc.: 59.38%] [Generator loss: 0.8066%]\n",
            "12780 [Discriminator loss: 0.6515%, acc.: 61.72%] [Generator loss: 0.7938%]\n",
            "12781 [Discriminator loss: 0.6683%, acc.: 60.55%] [Generator loss: 0.7952%]\n",
            "12782 [Discriminator loss: 0.6854%, acc.: 56.64%] [Generator loss: 0.7902%]\n",
            "12783 [Discriminator loss: 0.6528%, acc.: 62.50%] [Generator loss: 0.7825%]\n",
            "12784 [Discriminator loss: 0.6614%, acc.: 61.72%] [Generator loss: 0.7675%]\n",
            "12785 [Discriminator loss: 0.6504%, acc.: 62.89%] [Generator loss: 0.8096%]\n",
            "12786 [Discriminator loss: 0.6845%, acc.: 52.73%] [Generator loss: 0.7954%]\n",
            "12787 [Discriminator loss: 0.6605%, acc.: 60.16%] [Generator loss: 0.7744%]\n",
            "12788 [Discriminator loss: 0.6824%, acc.: 56.25%] [Generator loss: 0.8172%]\n",
            "12789 [Discriminator loss: 0.6568%, acc.: 61.72%] [Generator loss: 0.7843%]\n",
            "12790 [Discriminator loss: 0.6606%, acc.: 58.20%] [Generator loss: 0.8059%]\n",
            "12791 [Discriminator loss: 0.6695%, acc.: 60.16%] [Generator loss: 0.7859%]\n",
            "12792 [Discriminator loss: 0.6655%, acc.: 60.16%] [Generator loss: 0.7862%]\n",
            "12793 [Discriminator loss: 0.6772%, acc.: 54.69%] [Generator loss: 0.7829%]\n",
            "12794 [Discriminator loss: 0.6682%, acc.: 59.38%] [Generator loss: 0.7691%]\n",
            "12795 [Discriminator loss: 0.6511%, acc.: 60.55%] [Generator loss: 0.7999%]\n",
            "12796 [Discriminator loss: 0.6586%, acc.: 60.16%] [Generator loss: 0.8060%]\n",
            "12797 [Discriminator loss: 0.6758%, acc.: 57.81%] [Generator loss: 0.8064%]\n",
            "12798 [Discriminator loss: 0.6668%, acc.: 59.38%] [Generator loss: 0.7938%]\n",
            "12799 [Discriminator loss: 0.6610%, acc.: 62.50%] [Generator loss: 0.7925%]\n",
            "12800 [Discriminator loss: 0.6624%, acc.: 60.94%] [Generator loss: 0.8002%]\n",
            "12801 [Discriminator loss: 0.6683%, acc.: 61.33%] [Generator loss: 0.8063%]\n",
            "12802 [Discriminator loss: 0.6663%, acc.: 60.55%] [Generator loss: 0.8022%]\n",
            "12803 [Discriminator loss: 0.6594%, acc.: 61.72%] [Generator loss: 0.8191%]\n",
            "12804 [Discriminator loss: 0.6731%, acc.: 53.91%] [Generator loss: 0.8057%]\n",
            "12805 [Discriminator loss: 0.6724%, acc.: 56.25%] [Generator loss: 0.7970%]\n",
            "12806 [Discriminator loss: 0.6817%, acc.: 58.59%] [Generator loss: 0.8040%]\n",
            "12807 [Discriminator loss: 0.6873%, acc.: 55.47%] [Generator loss: 0.8049%]\n",
            "12808 [Discriminator loss: 0.6575%, acc.: 59.77%] [Generator loss: 0.7821%]\n",
            "12809 [Discriminator loss: 0.6713%, acc.: 57.42%] [Generator loss: 0.8217%]\n",
            "12810 [Discriminator loss: 0.6647%, acc.: 63.28%] [Generator loss: 0.7818%]\n",
            "12811 [Discriminator loss: 0.6677%, acc.: 55.08%] [Generator loss: 0.7811%]\n",
            "12812 [Discriminator loss: 0.6761%, acc.: 57.03%] [Generator loss: 0.8027%]\n",
            "12813 [Discriminator loss: 0.6525%, acc.: 64.06%] [Generator loss: 0.7876%]\n",
            "12814 [Discriminator loss: 0.6698%, acc.: 58.59%] [Generator loss: 0.7852%]\n",
            "12815 [Discriminator loss: 0.6650%, acc.: 59.77%] [Generator loss: 0.7702%]\n",
            "12816 [Discriminator loss: 0.6907%, acc.: 49.61%] [Generator loss: 0.7817%]\n",
            "12817 [Discriminator loss: 0.6605%, acc.: 58.59%] [Generator loss: 0.8116%]\n",
            "12818 [Discriminator loss: 0.6609%, acc.: 57.42%] [Generator loss: 0.7785%]\n",
            "12819 [Discriminator loss: 0.6738%, acc.: 55.86%] [Generator loss: 0.8096%]\n",
            "12820 [Discriminator loss: 0.6645%, acc.: 57.03%] [Generator loss: 0.7969%]\n",
            "12821 [Discriminator loss: 0.6661%, acc.: 59.77%] [Generator loss: 0.7879%]\n",
            "12822 [Discriminator loss: 0.6426%, acc.: 66.80%] [Generator loss: 0.7916%]\n",
            "12823 [Discriminator loss: 0.6807%, acc.: 55.08%] [Generator loss: 0.7906%]\n",
            "12824 [Discriminator loss: 0.6562%, acc.: 61.33%] [Generator loss: 0.8033%]\n",
            "12825 [Discriminator loss: 0.6729%, acc.: 58.98%] [Generator loss: 0.8003%]\n",
            "12826 [Discriminator loss: 0.6584%, acc.: 58.98%] [Generator loss: 0.7871%]\n",
            "12827 [Discriminator loss: 0.6542%, acc.: 60.55%] [Generator loss: 0.8080%]\n",
            "12828 [Discriminator loss: 0.6769%, acc.: 56.64%] [Generator loss: 0.8052%]\n",
            "12829 [Discriminator loss: 0.6468%, acc.: 65.23%] [Generator loss: 0.8082%]\n",
            "12830 [Discriminator loss: 0.6621%, acc.: 57.81%] [Generator loss: 0.7812%]\n",
            "12831 [Discriminator loss: 0.6329%, acc.: 68.75%] [Generator loss: 0.7934%]\n",
            "12832 [Discriminator loss: 0.6580%, acc.: 58.98%] [Generator loss: 0.7912%]\n",
            "12833 [Discriminator loss: 0.6716%, acc.: 57.81%] [Generator loss: 0.7714%]\n",
            "12834 [Discriminator loss: 0.6562%, acc.: 60.94%] [Generator loss: 0.7723%]\n",
            "12835 [Discriminator loss: 0.6716%, acc.: 59.38%] [Generator loss: 0.8035%]\n",
            "12836 [Discriminator loss: 0.6805%, acc.: 55.47%] [Generator loss: 0.7826%]\n",
            "12837 [Discriminator loss: 0.6910%, acc.: 55.86%] [Generator loss: 0.7797%]\n",
            "12838 [Discriminator loss: 0.6687%, acc.: 57.03%] [Generator loss: 0.7736%]\n",
            "12839 [Discriminator loss: 0.6752%, acc.: 58.20%] [Generator loss: 0.7815%]\n",
            "12840 [Discriminator loss: 0.6752%, acc.: 57.42%] [Generator loss: 0.7927%]\n",
            "12841 [Discriminator loss: 0.6790%, acc.: 57.81%] [Generator loss: 0.7962%]\n",
            "12842 [Discriminator loss: 0.6780%, acc.: 60.55%] [Generator loss: 0.8061%]\n",
            "12843 [Discriminator loss: 0.6577%, acc.: 64.06%] [Generator loss: 0.8109%]\n",
            "12844 [Discriminator loss: 0.6582%, acc.: 63.67%] [Generator loss: 0.8038%]\n",
            "12845 [Discriminator loss: 0.6896%, acc.: 55.08%] [Generator loss: 0.7712%]\n",
            "12846 [Discriminator loss: 0.6615%, acc.: 57.81%] [Generator loss: 0.7846%]\n",
            "12847 [Discriminator loss: 0.6638%, acc.: 58.98%] [Generator loss: 0.7807%]\n",
            "12848 [Discriminator loss: 0.6797%, acc.: 56.25%] [Generator loss: 0.7683%]\n",
            "12849 [Discriminator loss: 0.6717%, acc.: 61.33%] [Generator loss: 0.7960%]\n",
            "12850 [Discriminator loss: 0.6608%, acc.: 58.20%] [Generator loss: 0.8166%]\n",
            "12851 [Discriminator loss: 0.6689%, acc.: 57.81%] [Generator loss: 0.8026%]\n",
            "12852 [Discriminator loss: 0.6782%, acc.: 55.47%] [Generator loss: 0.7864%]\n",
            "12853 [Discriminator loss: 0.6660%, acc.: 60.16%] [Generator loss: 0.8046%]\n",
            "12854 [Discriminator loss: 0.6516%, acc.: 63.28%] [Generator loss: 0.8126%]\n",
            "12855 [Discriminator loss: 0.6659%, acc.: 63.28%] [Generator loss: 0.8105%]\n",
            "12856 [Discriminator loss: 0.6685%, acc.: 61.33%] [Generator loss: 0.8061%]\n",
            "12857 [Discriminator loss: 0.6710%, acc.: 58.59%] [Generator loss: 0.7978%]\n",
            "12858 [Discriminator loss: 0.6556%, acc.: 64.45%] [Generator loss: 0.7863%]\n",
            "12859 [Discriminator loss: 0.6673%, acc.: 56.25%] [Generator loss: 0.7587%]\n",
            "12860 [Discriminator loss: 0.6808%, acc.: 58.98%] [Generator loss: 0.7995%]\n",
            "12861 [Discriminator loss: 0.6636%, acc.: 61.33%] [Generator loss: 0.7876%]\n",
            "12862 [Discriminator loss: 0.6445%, acc.: 65.62%] [Generator loss: 0.8086%]\n",
            "12863 [Discriminator loss: 0.6739%, acc.: 54.69%] [Generator loss: 0.7860%]\n",
            "12864 [Discriminator loss: 0.6692%, acc.: 57.42%] [Generator loss: 0.8040%]\n",
            "12865 [Discriminator loss: 0.6713%, acc.: 55.86%] [Generator loss: 0.7815%]\n",
            "12866 [Discriminator loss: 0.6656%, acc.: 61.72%] [Generator loss: 0.7844%]\n",
            "12867 [Discriminator loss: 0.6608%, acc.: 62.89%] [Generator loss: 0.7979%]\n",
            "12868 [Discriminator loss: 0.6753%, acc.: 57.03%] [Generator loss: 0.8063%]\n",
            "12869 [Discriminator loss: 0.6634%, acc.: 58.20%] [Generator loss: 0.8057%]\n",
            "12870 [Discriminator loss: 0.6753%, acc.: 55.08%] [Generator loss: 0.7921%]\n",
            "12871 [Discriminator loss: 0.6732%, acc.: 53.91%] [Generator loss: 0.7947%]\n",
            "12872 [Discriminator loss: 0.6814%, acc.: 58.98%] [Generator loss: 0.7930%]\n",
            "12873 [Discriminator loss: 0.6867%, acc.: 53.12%] [Generator loss: 0.7826%]\n",
            "12874 [Discriminator loss: 0.6557%, acc.: 61.72%] [Generator loss: 0.8013%]\n",
            "12875 [Discriminator loss: 0.6535%, acc.: 61.33%] [Generator loss: 0.7834%]\n",
            "12876 [Discriminator loss: 0.6452%, acc.: 64.06%] [Generator loss: 0.7879%]\n",
            "12877 [Discriminator loss: 0.6635%, acc.: 57.81%] [Generator loss: 0.7889%]\n",
            "12878 [Discriminator loss: 0.6778%, acc.: 56.64%] [Generator loss: 0.7933%]\n",
            "12879 [Discriminator loss: 0.6560%, acc.: 60.55%] [Generator loss: 0.8119%]\n",
            "12880 [Discriminator loss: 0.6626%, acc.: 62.50%] [Generator loss: 0.7866%]\n",
            "12881 [Discriminator loss: 0.6750%, acc.: 57.42%] [Generator loss: 0.7692%]\n",
            "12882 [Discriminator loss: 0.6655%, acc.: 63.28%] [Generator loss: 0.7962%]\n",
            "12883 [Discriminator loss: 0.6696%, acc.: 59.38%] [Generator loss: 0.7878%]\n",
            "12884 [Discriminator loss: 0.6702%, acc.: 59.38%] [Generator loss: 0.7744%]\n",
            "12885 [Discriminator loss: 0.6639%, acc.: 57.81%] [Generator loss: 0.8050%]\n",
            "12886 [Discriminator loss: 0.6514%, acc.: 63.28%] [Generator loss: 0.8106%]\n",
            "12887 [Discriminator loss: 0.6713%, acc.: 55.86%] [Generator loss: 0.8101%]\n",
            "12888 [Discriminator loss: 0.6568%, acc.: 67.19%] [Generator loss: 0.7688%]\n",
            "12889 [Discriminator loss: 0.6635%, acc.: 55.86%] [Generator loss: 0.7936%]\n",
            "12890 [Discriminator loss: 0.6668%, acc.: 62.50%] [Generator loss: 0.8074%]\n",
            "12891 [Discriminator loss: 0.6640%, acc.: 60.94%] [Generator loss: 0.7771%]\n",
            "12892 [Discriminator loss: 0.6736%, acc.: 58.98%] [Generator loss: 0.8033%]\n",
            "12893 [Discriminator loss: 0.6518%, acc.: 61.72%] [Generator loss: 0.7760%]\n",
            "12894 [Discriminator loss: 0.6830%, acc.: 51.56%] [Generator loss: 0.7633%]\n",
            "12895 [Discriminator loss: 0.6561%, acc.: 60.94%] [Generator loss: 0.7468%]\n",
            "12896 [Discriminator loss: 0.6530%, acc.: 61.33%] [Generator loss: 0.7622%]\n",
            "12897 [Discriminator loss: 0.6546%, acc.: 60.55%] [Generator loss: 0.7736%]\n",
            "12898 [Discriminator loss: 0.6775%, acc.: 57.42%] [Generator loss: 0.7777%]\n",
            "12899 [Discriminator loss: 0.6624%, acc.: 60.16%] [Generator loss: 0.7695%]\n",
            "12900 [Discriminator loss: 0.6600%, acc.: 58.98%] [Generator loss: 0.8014%]\n",
            "12901 [Discriminator loss: 0.6593%, acc.: 60.94%] [Generator loss: 0.7909%]\n",
            "12902 [Discriminator loss: 0.6665%, acc.: 61.72%] [Generator loss: 0.7958%]\n",
            "12903 [Discriminator loss: 0.6703%, acc.: 59.77%] [Generator loss: 0.7748%]\n",
            "12904 [Discriminator loss: 0.6632%, acc.: 60.94%] [Generator loss: 0.7979%]\n",
            "12905 [Discriminator loss: 0.6522%, acc.: 66.02%] [Generator loss: 0.8063%]\n",
            "12906 [Discriminator loss: 0.6622%, acc.: 62.89%] [Generator loss: 0.7983%]\n",
            "12907 [Discriminator loss: 0.6500%, acc.: 60.55%] [Generator loss: 0.8087%]\n",
            "12908 [Discriminator loss: 0.6608%, acc.: 63.28%] [Generator loss: 0.8088%]\n",
            "12909 [Discriminator loss: 0.6672%, acc.: 58.20%] [Generator loss: 0.7873%]\n",
            "12910 [Discriminator loss: 0.6832%, acc.: 54.30%] [Generator loss: 0.7961%]\n",
            "12911 [Discriminator loss: 0.6770%, acc.: 57.81%] [Generator loss: 0.7675%]\n",
            "12912 [Discriminator loss: 0.6698%, acc.: 57.03%] [Generator loss: 0.7958%]\n",
            "12913 [Discriminator loss: 0.6691%, acc.: 59.77%] [Generator loss: 0.7828%]\n",
            "12914 [Discriminator loss: 0.6638%, acc.: 59.38%] [Generator loss: 0.7867%]\n",
            "12915 [Discriminator loss: 0.6506%, acc.: 64.45%] [Generator loss: 0.7608%]\n",
            "12916 [Discriminator loss: 0.6594%, acc.: 61.72%] [Generator loss: 0.7981%]\n",
            "12917 [Discriminator loss: 0.6623%, acc.: 60.16%] [Generator loss: 0.8078%]\n",
            "12918 [Discriminator loss: 0.6755%, acc.: 58.20%] [Generator loss: 0.8045%]\n",
            "12919 [Discriminator loss: 0.6538%, acc.: 63.67%] [Generator loss: 0.7645%]\n",
            "12920 [Discriminator loss: 0.6442%, acc.: 63.67%] [Generator loss: 0.7922%]\n",
            "12921 [Discriminator loss: 0.6761%, acc.: 58.98%] [Generator loss: 0.7906%]\n",
            "12922 [Discriminator loss: 0.6775%, acc.: 54.69%] [Generator loss: 0.8220%]\n",
            "12923 [Discriminator loss: 0.6849%, acc.: 56.25%] [Generator loss: 0.7826%]\n",
            "12924 [Discriminator loss: 0.6464%, acc.: 64.84%] [Generator loss: 0.8052%]\n",
            "12925 [Discriminator loss: 0.6527%, acc.: 60.55%] [Generator loss: 0.7994%]\n",
            "12926 [Discriminator loss: 0.6566%, acc.: 60.94%] [Generator loss: 0.8066%]\n",
            "12927 [Discriminator loss: 0.6552%, acc.: 60.16%] [Generator loss: 0.7874%]\n",
            "12928 [Discriminator loss: 0.6752%, acc.: 58.98%] [Generator loss: 0.7909%]\n",
            "12929 [Discriminator loss: 0.6804%, acc.: 57.03%] [Generator loss: 0.8192%]\n",
            "12930 [Discriminator loss: 0.6717%, acc.: 57.03%] [Generator loss: 0.8073%]\n",
            "12931 [Discriminator loss: 0.6605%, acc.: 60.55%] [Generator loss: 0.7670%]\n",
            "12932 [Discriminator loss: 0.6573%, acc.: 59.38%] [Generator loss: 0.7700%]\n",
            "12933 [Discriminator loss: 0.6848%, acc.: 55.47%] [Generator loss: 0.7883%]\n",
            "12934 [Discriminator loss: 0.6619%, acc.: 60.94%] [Generator loss: 0.7756%]\n",
            "12935 [Discriminator loss: 0.6724%, acc.: 57.81%] [Generator loss: 0.7745%]\n",
            "12936 [Discriminator loss: 0.6612%, acc.: 60.94%] [Generator loss: 0.7815%]\n",
            "12937 [Discriminator loss: 0.6767%, acc.: 53.12%] [Generator loss: 0.8107%]\n",
            "12938 [Discriminator loss: 0.6619%, acc.: 60.94%] [Generator loss: 0.8017%]\n",
            "12939 [Discriminator loss: 0.6623%, acc.: 58.98%] [Generator loss: 0.7753%]\n",
            "12940 [Discriminator loss: 0.6515%, acc.: 64.45%] [Generator loss: 0.7845%]\n",
            "12941 [Discriminator loss: 0.6552%, acc.: 62.89%] [Generator loss: 0.8094%]\n",
            "12942 [Discriminator loss: 0.6589%, acc.: 60.16%] [Generator loss: 0.7925%]\n",
            "12943 [Discriminator loss: 0.6507%, acc.: 60.94%] [Generator loss: 0.7804%]\n",
            "12944 [Discriminator loss: 0.6598%, acc.: 61.72%] [Generator loss: 0.7775%]\n",
            "12945 [Discriminator loss: 0.6527%, acc.: 60.55%] [Generator loss: 0.7954%]\n",
            "12946 [Discriminator loss: 0.6727%, acc.: 57.42%] [Generator loss: 0.7813%]\n",
            "12947 [Discriminator loss: 0.6666%, acc.: 64.06%] [Generator loss: 0.8118%]\n",
            "12948 [Discriminator loss: 0.6670%, acc.: 58.98%] [Generator loss: 0.7959%]\n",
            "12949 [Discriminator loss: 0.6776%, acc.: 57.03%] [Generator loss: 0.7967%]\n",
            "12950 [Discriminator loss: 0.6734%, acc.: 54.30%] [Generator loss: 0.8010%]\n",
            "12951 [Discriminator loss: 0.6920%, acc.: 54.69%] [Generator loss: 0.7922%]\n",
            "12952 [Discriminator loss: 0.6724%, acc.: 58.59%] [Generator loss: 0.7870%]\n",
            "12953 [Discriminator loss: 0.6807%, acc.: 52.73%] [Generator loss: 0.7396%]\n",
            "12954 [Discriminator loss: 0.6807%, acc.: 53.91%] [Generator loss: 0.7698%]\n",
            "12955 [Discriminator loss: 0.6802%, acc.: 55.47%] [Generator loss: 0.7748%]\n",
            "12956 [Discriminator loss: 0.6758%, acc.: 56.64%] [Generator loss: 0.7747%]\n",
            "12957 [Discriminator loss: 0.6705%, acc.: 59.77%] [Generator loss: 0.7582%]\n",
            "12958 [Discriminator loss: 0.6748%, acc.: 57.81%] [Generator loss: 0.7801%]\n",
            "12959 [Discriminator loss: 0.6730%, acc.: 57.42%] [Generator loss: 0.7747%]\n",
            "12960 [Discriminator loss: 0.6903%, acc.: 52.34%] [Generator loss: 0.7518%]\n",
            "12961 [Discriminator loss: 0.6606%, acc.: 59.77%] [Generator loss: 0.7875%]\n",
            "12962 [Discriminator loss: 0.6510%, acc.: 64.84%] [Generator loss: 0.7793%]\n",
            "12963 [Discriminator loss: 0.6723%, acc.: 57.81%] [Generator loss: 0.7840%]\n",
            "12964 [Discriminator loss: 0.6523%, acc.: 60.16%] [Generator loss: 0.8066%]\n",
            "12965 [Discriminator loss: 0.6636%, acc.: 60.94%] [Generator loss: 0.7933%]\n",
            "12966 [Discriminator loss: 0.6683%, acc.: 58.20%] [Generator loss: 0.8003%]\n",
            "12967 [Discriminator loss: 0.6902%, acc.: 55.08%] [Generator loss: 0.7979%]\n",
            "12968 [Discriminator loss: 0.6663%, acc.: 64.06%] [Generator loss: 0.7938%]\n",
            "12969 [Discriminator loss: 0.6700%, acc.: 58.59%] [Generator loss: 0.8151%]\n",
            "12970 [Discriminator loss: 0.6729%, acc.: 58.98%] [Generator loss: 0.7805%]\n",
            "12971 [Discriminator loss: 0.6825%, acc.: 61.72%] [Generator loss: 0.7846%]\n",
            "12972 [Discriminator loss: 0.6838%, acc.: 57.42%] [Generator loss: 0.8094%]\n",
            "12973 [Discriminator loss: 0.6569%, acc.: 63.28%] [Generator loss: 0.8166%]\n",
            "12974 [Discriminator loss: 0.6598%, acc.: 61.33%] [Generator loss: 0.8020%]\n",
            "12975 [Discriminator loss: 0.6736%, acc.: 56.25%] [Generator loss: 0.8023%]\n",
            "12976 [Discriminator loss: 0.6765%, acc.: 56.64%] [Generator loss: 0.7903%]\n",
            "12977 [Discriminator loss: 0.6506%, acc.: 63.28%] [Generator loss: 0.8031%]\n",
            "12978 [Discriminator loss: 0.6673%, acc.: 61.33%] [Generator loss: 0.7945%]\n",
            "12979 [Discriminator loss: 0.6719%, acc.: 58.20%] [Generator loss: 0.7941%]\n",
            "12980 [Discriminator loss: 0.6654%, acc.: 58.98%] [Generator loss: 0.7916%]\n",
            "12981 [Discriminator loss: 0.6815%, acc.: 57.42%] [Generator loss: 0.7930%]\n",
            "12982 [Discriminator loss: 0.6631%, acc.: 62.89%] [Generator loss: 0.7767%]\n",
            "12983 [Discriminator loss: 0.6656%, acc.: 58.59%] [Generator loss: 0.7941%]\n",
            "12984 [Discriminator loss: 0.6770%, acc.: 55.47%] [Generator loss: 0.7931%]\n",
            "12985 [Discriminator loss: 0.6766%, acc.: 55.86%] [Generator loss: 0.7784%]\n",
            "12986 [Discriminator loss: 0.6800%, acc.: 55.47%] [Generator loss: 0.7787%]\n",
            "12987 [Discriminator loss: 0.6688%, acc.: 58.98%] [Generator loss: 0.7788%]\n",
            "12988 [Discriminator loss: 0.6801%, acc.: 57.03%] [Generator loss: 0.7882%]\n",
            "12989 [Discriminator loss: 0.6786%, acc.: 56.64%] [Generator loss: 0.7767%]\n",
            "12990 [Discriminator loss: 0.6617%, acc.: 59.77%] [Generator loss: 0.7782%]\n",
            "12991 [Discriminator loss: 0.6622%, acc.: 61.72%] [Generator loss: 0.7891%]\n",
            "12992 [Discriminator loss: 0.6634%, acc.: 61.33%] [Generator loss: 0.8120%]\n",
            "12993 [Discriminator loss: 0.6668%, acc.: 58.59%] [Generator loss: 0.8091%]\n",
            "12994 [Discriminator loss: 0.6799%, acc.: 55.86%] [Generator loss: 0.7851%]\n",
            "12995 [Discriminator loss: 0.6743%, acc.: 57.42%] [Generator loss: 0.8028%]\n",
            "12996 [Discriminator loss: 0.6625%, acc.: 60.55%] [Generator loss: 0.7926%]\n",
            "12997 [Discriminator loss: 0.6758%, acc.: 55.86%] [Generator loss: 0.7777%]\n",
            "12998 [Discriminator loss: 0.6653%, acc.: 60.16%] [Generator loss: 0.8021%]\n",
            "12999 [Discriminator loss: 0.6754%, acc.: 54.30%] [Generator loss: 0.8195%]\n",
            "13000 [Discriminator loss: 0.6717%, acc.: 58.59%] [Generator loss: 0.7961%]\n",
            "13001 [Discriminator loss: 0.6605%, acc.: 64.45%] [Generator loss: 0.7682%]\n",
            "13002 [Discriminator loss: 0.6729%, acc.: 57.03%] [Generator loss: 0.7758%]\n",
            "13003 [Discriminator loss: 0.6599%, acc.: 61.72%] [Generator loss: 0.7755%]\n",
            "13004 [Discriminator loss: 0.6646%, acc.: 61.33%] [Generator loss: 0.7859%]\n",
            "13005 [Discriminator loss: 0.6889%, acc.: 49.22%] [Generator loss: 0.8151%]\n",
            "13006 [Discriminator loss: 0.6758%, acc.: 57.81%] [Generator loss: 0.7789%]\n",
            "13007 [Discriminator loss: 0.6603%, acc.: 59.77%] [Generator loss: 0.7866%]\n",
            "13008 [Discriminator loss: 0.6597%, acc.: 60.94%] [Generator loss: 0.7637%]\n",
            "13009 [Discriminator loss: 0.6726%, acc.: 57.81%] [Generator loss: 0.7798%]\n",
            "13010 [Discriminator loss: 0.6695%, acc.: 57.03%] [Generator loss: 0.7834%]\n",
            "13011 [Discriminator loss: 0.6871%, acc.: 53.52%] [Generator loss: 0.8158%]\n",
            "13012 [Discriminator loss: 0.6762%, acc.: 58.59%] [Generator loss: 0.8197%]\n",
            "13013 [Discriminator loss: 0.6784%, acc.: 56.25%] [Generator loss: 0.8180%]\n",
            "13014 [Discriminator loss: 0.6744%, acc.: 57.03%] [Generator loss: 0.8150%]\n",
            "13015 [Discriminator loss: 0.6556%, acc.: 61.72%] [Generator loss: 0.7702%]\n",
            "13016 [Discriminator loss: 0.6719%, acc.: 58.59%] [Generator loss: 0.7956%]\n",
            "13017 [Discriminator loss: 0.6517%, acc.: 60.16%] [Generator loss: 0.8078%]\n",
            "13018 [Discriminator loss: 0.6731%, acc.: 57.03%] [Generator loss: 0.8232%]\n",
            "13019 [Discriminator loss: 0.6539%, acc.: 63.28%] [Generator loss: 0.7892%]\n",
            "13020 [Discriminator loss: 0.6639%, acc.: 57.03%] [Generator loss: 0.8293%]\n",
            "13021 [Discriminator loss: 0.6700%, acc.: 61.33%] [Generator loss: 0.7898%]\n",
            "13022 [Discriminator loss: 0.6608%, acc.: 62.50%] [Generator loss: 0.8170%]\n",
            "13023 [Discriminator loss: 0.6551%, acc.: 62.50%] [Generator loss: 0.8100%]\n",
            "13024 [Discriminator loss: 0.6636%, acc.: 57.42%] [Generator loss: 0.8376%]\n",
            "13025 [Discriminator loss: 0.6823%, acc.: 55.47%] [Generator loss: 0.7803%]\n",
            "13026 [Discriminator loss: 0.6702%, acc.: 53.52%] [Generator loss: 0.8175%]\n",
            "13027 [Discriminator loss: 0.6649%, acc.: 58.98%] [Generator loss: 0.7869%]\n",
            "13028 [Discriminator loss: 0.6599%, acc.: 60.16%] [Generator loss: 0.7764%]\n",
            "13029 [Discriminator loss: 0.6706%, acc.: 56.64%] [Generator loss: 0.7941%]\n",
            "13030 [Discriminator loss: 0.6501%, acc.: 62.89%] [Generator loss: 0.8023%]\n",
            "13031 [Discriminator loss: 0.6498%, acc.: 64.45%] [Generator loss: 0.8040%]\n",
            "13032 [Discriminator loss: 0.6679%, acc.: 57.42%] [Generator loss: 0.7933%]\n",
            "13033 [Discriminator loss: 0.6627%, acc.: 61.72%] [Generator loss: 0.8098%]\n",
            "13034 [Discriminator loss: 0.6706%, acc.: 62.89%] [Generator loss: 0.8216%]\n",
            "13035 [Discriminator loss: 0.6802%, acc.: 57.03%] [Generator loss: 0.8047%]\n",
            "13036 [Discriminator loss: 0.6600%, acc.: 62.11%] [Generator loss: 0.8020%]\n",
            "13037 [Discriminator loss: 0.6894%, acc.: 55.86%] [Generator loss: 0.7768%]\n",
            "13038 [Discriminator loss: 0.6580%, acc.: 64.45%] [Generator loss: 0.7693%]\n",
            "13039 [Discriminator loss: 0.6904%, acc.: 54.30%] [Generator loss: 0.7784%]\n",
            "13040 [Discriminator loss: 0.6555%, acc.: 61.72%] [Generator loss: 0.8119%]\n",
            "13041 [Discriminator loss: 0.6412%, acc.: 63.28%] [Generator loss: 0.7848%]\n",
            "13042 [Discriminator loss: 0.6842%, acc.: 52.34%] [Generator loss: 0.8156%]\n",
            "13043 [Discriminator loss: 0.6783%, acc.: 57.03%] [Generator loss: 0.8014%]\n",
            "13044 [Discriminator loss: 0.6626%, acc.: 59.38%] [Generator loss: 0.8211%]\n",
            "13045 [Discriminator loss: 0.6579%, acc.: 63.28%] [Generator loss: 0.8338%]\n",
            "13046 [Discriminator loss: 0.6856%, acc.: 55.08%] [Generator loss: 0.8055%]\n",
            "13047 [Discriminator loss: 0.6797%, acc.: 52.73%] [Generator loss: 0.7917%]\n",
            "13048 [Discriminator loss: 0.6730%, acc.: 55.86%] [Generator loss: 0.8285%]\n",
            "13049 [Discriminator loss: 0.6556%, acc.: 60.16%] [Generator loss: 0.8010%]\n",
            "13050 [Discriminator loss: 0.6742%, acc.: 58.20%] [Generator loss: 0.7858%]\n",
            "13051 [Discriminator loss: 0.6716%, acc.: 58.20%] [Generator loss: 0.8100%]\n",
            "13052 [Discriminator loss: 0.6818%, acc.: 57.81%] [Generator loss: 0.7883%]\n",
            "13053 [Discriminator loss: 0.6514%, acc.: 63.28%] [Generator loss: 0.8352%]\n",
            "13054 [Discriminator loss: 0.6610%, acc.: 65.62%] [Generator loss: 0.8170%]\n",
            "13055 [Discriminator loss: 0.6502%, acc.: 62.89%] [Generator loss: 0.8088%]\n",
            "13056 [Discriminator loss: 0.6785%, acc.: 54.30%] [Generator loss: 0.8097%]\n",
            "13057 [Discriminator loss: 0.6503%, acc.: 57.03%] [Generator loss: 0.7891%]\n",
            "13058 [Discriminator loss: 0.6656%, acc.: 60.16%] [Generator loss: 0.7814%]\n",
            "13059 [Discriminator loss: 0.6616%, acc.: 61.72%] [Generator loss: 0.7801%]\n",
            "13060 [Discriminator loss: 0.6674%, acc.: 56.64%] [Generator loss: 0.7984%]\n",
            "13061 [Discriminator loss: 0.6714%, acc.: 56.64%] [Generator loss: 0.8026%]\n",
            "13062 [Discriminator loss: 0.6626%, acc.: 58.59%] [Generator loss: 0.7976%]\n",
            "13063 [Discriminator loss: 0.6809%, acc.: 57.42%] [Generator loss: 0.7881%]\n",
            "13064 [Discriminator loss: 0.6811%, acc.: 55.86%] [Generator loss: 0.8107%]\n",
            "13065 [Discriminator loss: 0.6620%, acc.: 60.94%] [Generator loss: 0.7927%]\n",
            "13066 [Discriminator loss: 0.6760%, acc.: 57.81%] [Generator loss: 0.8130%]\n",
            "13067 [Discriminator loss: 0.6707%, acc.: 57.03%] [Generator loss: 0.8198%]\n",
            "13068 [Discriminator loss: 0.6675%, acc.: 54.69%] [Generator loss: 0.8044%]\n",
            "13069 [Discriminator loss: 0.6749%, acc.: 57.42%] [Generator loss: 0.8148%]\n",
            "13070 [Discriminator loss: 0.6567%, acc.: 60.94%] [Generator loss: 0.8035%]\n",
            "13071 [Discriminator loss: 0.6579%, acc.: 60.16%] [Generator loss: 0.8013%]\n",
            "13072 [Discriminator loss: 0.6754%, acc.: 55.08%] [Generator loss: 0.7986%]\n",
            "13073 [Discriminator loss: 0.6566%, acc.: 60.55%] [Generator loss: 0.7904%]\n",
            "13074 [Discriminator loss: 0.6653%, acc.: 57.03%] [Generator loss: 0.7967%]\n",
            "13075 [Discriminator loss: 0.6699%, acc.: 60.55%] [Generator loss: 0.8062%]\n",
            "13076 [Discriminator loss: 0.6690%, acc.: 58.20%] [Generator loss: 0.7940%]\n",
            "13077 [Discriminator loss: 0.6651%, acc.: 59.77%] [Generator loss: 0.8090%]\n",
            "13078 [Discriminator loss: 0.6854%, acc.: 53.52%] [Generator loss: 0.8083%]\n",
            "13079 [Discriminator loss: 0.6758%, acc.: 55.86%] [Generator loss: 0.8047%]\n",
            "13080 [Discriminator loss: 0.6553%, acc.: 59.38%] [Generator loss: 0.8230%]\n",
            "13081 [Discriminator loss: 0.6774%, acc.: 56.25%] [Generator loss: 0.8139%]\n",
            "13082 [Discriminator loss: 0.6570%, acc.: 60.55%] [Generator loss: 0.8236%]\n",
            "13083 [Discriminator loss: 0.6629%, acc.: 58.98%] [Generator loss: 0.8286%]\n",
            "13084 [Discriminator loss: 0.6598%, acc.: 62.11%] [Generator loss: 0.8058%]\n",
            "13085 [Discriminator loss: 0.6791%, acc.: 56.64%] [Generator loss: 0.7843%]\n",
            "13086 [Discriminator loss: 0.6490%, acc.: 63.28%] [Generator loss: 0.7643%]\n",
            "13087 [Discriminator loss: 0.6850%, acc.: 53.91%] [Generator loss: 0.7713%]\n",
            "13088 [Discriminator loss: 0.6668%, acc.: 54.69%] [Generator loss: 0.8049%]\n",
            "13089 [Discriminator loss: 0.6752%, acc.: 59.38%] [Generator loss: 0.8100%]\n",
            "13090 [Discriminator loss: 0.6555%, acc.: 60.94%] [Generator loss: 0.7850%]\n",
            "13091 [Discriminator loss: 0.6583%, acc.: 58.98%] [Generator loss: 0.8091%]\n",
            "13092 [Discriminator loss: 0.6574%, acc.: 60.16%] [Generator loss: 0.7831%]\n",
            "13093 [Discriminator loss: 0.6540%, acc.: 60.55%] [Generator loss: 0.8125%]\n",
            "13094 [Discriminator loss: 0.6712%, acc.: 57.42%] [Generator loss: 0.8102%]\n",
            "13095 [Discriminator loss: 0.6760%, acc.: 55.47%] [Generator loss: 0.7893%]\n",
            "13096 [Discriminator loss: 0.6707%, acc.: 56.64%] [Generator loss: 0.7966%]\n",
            "13097 [Discriminator loss: 0.6524%, acc.: 62.89%] [Generator loss: 0.7826%]\n",
            "13098 [Discriminator loss: 0.6672%, acc.: 60.16%] [Generator loss: 0.7769%]\n",
            "13099 [Discriminator loss: 0.6735%, acc.: 57.81%] [Generator loss: 0.8162%]\n",
            "13100 [Discriminator loss: 0.6800%, acc.: 58.20%] [Generator loss: 0.7760%]\n",
            "13101 [Discriminator loss: 0.6681%, acc.: 59.77%] [Generator loss: 0.7625%]\n",
            "13102 [Discriminator loss: 0.6763%, acc.: 57.03%] [Generator loss: 0.7799%]\n",
            "13103 [Discriminator loss: 0.6635%, acc.: 57.42%] [Generator loss: 0.7938%]\n",
            "13104 [Discriminator loss: 0.6814%, acc.: 57.42%] [Generator loss: 0.8190%]\n",
            "13105 [Discriminator loss: 0.6858%, acc.: 57.81%] [Generator loss: 0.7826%]\n",
            "13106 [Discriminator loss: 0.6649%, acc.: 62.50%] [Generator loss: 0.8033%]\n",
            "13107 [Discriminator loss: 0.6664%, acc.: 59.77%] [Generator loss: 0.8134%]\n",
            "13108 [Discriminator loss: 0.6483%, acc.: 66.41%] [Generator loss: 0.7731%]\n",
            "13109 [Discriminator loss: 0.6700%, acc.: 57.81%] [Generator loss: 0.7940%]\n",
            "13110 [Discriminator loss: 0.6631%, acc.: 59.38%] [Generator loss: 0.8408%]\n",
            "13111 [Discriminator loss: 0.6848%, acc.: 56.64%] [Generator loss: 0.8217%]\n",
            "13112 [Discriminator loss: 0.6833%, acc.: 55.08%] [Generator loss: 0.7994%]\n",
            "13113 [Discriminator loss: 0.6763%, acc.: 55.86%] [Generator loss: 0.7958%]\n",
            "13114 [Discriminator loss: 0.6803%, acc.: 58.20%] [Generator loss: 0.7947%]\n",
            "13115 [Discriminator loss: 0.6636%, acc.: 58.20%] [Generator loss: 0.7962%]\n",
            "13116 [Discriminator loss: 0.6814%, acc.: 55.86%] [Generator loss: 0.7713%]\n",
            "13117 [Discriminator loss: 0.6694%, acc.: 53.91%] [Generator loss: 0.7748%]\n",
            "13118 [Discriminator loss: 0.6848%, acc.: 55.86%] [Generator loss: 0.7672%]\n",
            "13119 [Discriminator loss: 0.6756%, acc.: 55.08%] [Generator loss: 0.7596%]\n",
            "13120 [Discriminator loss: 0.6628%, acc.: 62.11%] [Generator loss: 0.7865%]\n",
            "13121 [Discriminator loss: 0.6685%, acc.: 58.20%] [Generator loss: 0.8206%]\n",
            "13122 [Discriminator loss: 0.6596%, acc.: 62.50%] [Generator loss: 0.7678%]\n",
            "13123 [Discriminator loss: 0.6686%, acc.: 58.98%] [Generator loss: 0.7898%]\n",
            "13124 [Discriminator loss: 0.6725%, acc.: 58.20%] [Generator loss: 0.7766%]\n",
            "13125 [Discriminator loss: 0.6761%, acc.: 58.98%] [Generator loss: 0.7834%]\n",
            "13126 [Discriminator loss: 0.6698%, acc.: 56.25%] [Generator loss: 0.7766%]\n",
            "13127 [Discriminator loss: 0.6664%, acc.: 57.81%] [Generator loss: 0.7821%]\n",
            "13128 [Discriminator loss: 0.6774%, acc.: 57.81%] [Generator loss: 0.8109%]\n",
            "13129 [Discriminator loss: 0.6662%, acc.: 57.81%] [Generator loss: 0.7865%]\n",
            "13130 [Discriminator loss: 0.6828%, acc.: 58.20%] [Generator loss: 0.7718%]\n",
            "13131 [Discriminator loss: 0.6655%, acc.: 56.64%] [Generator loss: 0.7675%]\n",
            "13132 [Discriminator loss: 0.6534%, acc.: 64.45%] [Generator loss: 0.8042%]\n",
            "13133 [Discriminator loss: 0.6770%, acc.: 52.73%] [Generator loss: 0.8035%]\n",
            "13134 [Discriminator loss: 0.6624%, acc.: 58.98%] [Generator loss: 0.8004%]\n",
            "13135 [Discriminator loss: 0.6798%, acc.: 56.64%] [Generator loss: 0.7687%]\n",
            "13136 [Discriminator loss: 0.6605%, acc.: 59.77%] [Generator loss: 0.7809%]\n",
            "13137 [Discriminator loss: 0.6841%, acc.: 57.42%] [Generator loss: 0.7978%]\n",
            "13138 [Discriminator loss: 0.6643%, acc.: 61.72%] [Generator loss: 0.7723%]\n",
            "13139 [Discriminator loss: 0.6701%, acc.: 57.03%] [Generator loss: 0.7676%]\n",
            "13140 [Discriminator loss: 0.6675%, acc.: 60.55%] [Generator loss: 0.7917%]\n",
            "13141 [Discriminator loss: 0.6664%, acc.: 61.33%] [Generator loss: 0.7852%]\n",
            "13142 [Discriminator loss: 0.6855%, acc.: 55.86%] [Generator loss: 0.7825%]\n",
            "13143 [Discriminator loss: 0.6686%, acc.: 55.47%] [Generator loss: 0.7818%]\n",
            "13144 [Discriminator loss: 0.6646%, acc.: 61.33%] [Generator loss: 0.7615%]\n",
            "13145 [Discriminator loss: 0.6688%, acc.: 60.16%] [Generator loss: 0.7796%]\n",
            "13146 [Discriminator loss: 0.6569%, acc.: 63.28%] [Generator loss: 0.7930%]\n",
            "13147 [Discriminator loss: 0.6615%, acc.: 64.06%] [Generator loss: 0.7773%]\n",
            "13148 [Discriminator loss: 0.6518%, acc.: 62.89%] [Generator loss: 0.7632%]\n",
            "13149 [Discriminator loss: 0.6696%, acc.: 62.11%] [Generator loss: 0.7873%]\n",
            "13150 [Discriminator loss: 0.6740%, acc.: 56.64%] [Generator loss: 0.7735%]\n",
            "13151 [Discriminator loss: 0.6693%, acc.: 62.11%] [Generator loss: 0.7758%]\n",
            "13152 [Discriminator loss: 0.6760%, acc.: 58.59%] [Generator loss: 0.7838%]\n",
            "13153 [Discriminator loss: 0.6801%, acc.: 58.59%] [Generator loss: 0.8052%]\n",
            "13154 [Discriminator loss: 0.6693%, acc.: 58.20%] [Generator loss: 0.8019%]\n",
            "13155 [Discriminator loss: 0.6539%, acc.: 65.23%] [Generator loss: 0.8041%]\n",
            "13156 [Discriminator loss: 0.6492%, acc.: 61.33%] [Generator loss: 0.8062%]\n",
            "13157 [Discriminator loss: 0.6734%, acc.: 57.81%] [Generator loss: 0.8179%]\n",
            "13158 [Discriminator loss: 0.6670%, acc.: 59.77%] [Generator loss: 0.8112%]\n",
            "13159 [Discriminator loss: 0.6723%, acc.: 57.42%] [Generator loss: 0.8158%]\n",
            "13160 [Discriminator loss: 0.6725%, acc.: 55.86%] [Generator loss: 0.7898%]\n",
            "13161 [Discriminator loss: 0.6556%, acc.: 62.50%] [Generator loss: 0.7819%]\n",
            "13162 [Discriminator loss: 0.6781%, acc.: 56.25%] [Generator loss: 0.7701%]\n",
            "13163 [Discriminator loss: 0.6777%, acc.: 58.20%] [Generator loss: 0.7838%]\n",
            "13164 [Discriminator loss: 0.6566%, acc.: 60.55%] [Generator loss: 0.8033%]\n",
            "13165 [Discriminator loss: 0.6496%, acc.: 64.06%] [Generator loss: 0.8069%]\n",
            "13166 [Discriminator loss: 0.6670%, acc.: 60.16%] [Generator loss: 0.8193%]\n",
            "13167 [Discriminator loss: 0.6938%, acc.: 53.12%] [Generator loss: 0.8313%]\n",
            "13168 [Discriminator loss: 0.6734%, acc.: 58.59%] [Generator loss: 0.7984%]\n",
            "13169 [Discriminator loss: 0.6915%, acc.: 53.52%] [Generator loss: 0.7882%]\n",
            "13170 [Discriminator loss: 0.6621%, acc.: 60.94%] [Generator loss: 0.8028%]\n",
            "13171 [Discriminator loss: 0.6688%, acc.: 59.38%] [Generator loss: 0.7859%]\n",
            "13172 [Discriminator loss: 0.6800%, acc.: 53.91%] [Generator loss: 0.7961%]\n",
            "13173 [Discriminator loss: 0.6772%, acc.: 55.47%] [Generator loss: 0.7810%]\n",
            "13174 [Discriminator loss: 0.6568%, acc.: 60.16%] [Generator loss: 0.7794%]\n",
            "13175 [Discriminator loss: 0.6926%, acc.: 53.52%] [Generator loss: 0.7865%]\n",
            "13176 [Discriminator loss: 0.6742%, acc.: 57.42%] [Generator loss: 0.8112%]\n",
            "13177 [Discriminator loss: 0.6614%, acc.: 60.16%] [Generator loss: 0.8165%]\n",
            "13178 [Discriminator loss: 0.6555%, acc.: 62.11%] [Generator loss: 0.8020%]\n",
            "13179 [Discriminator loss: 0.6712%, acc.: 56.25%] [Generator loss: 0.8008%]\n",
            "13180 [Discriminator loss: 0.6659%, acc.: 60.94%] [Generator loss: 0.7955%]\n",
            "13181 [Discriminator loss: 0.6844%, acc.: 53.12%] [Generator loss: 0.7988%]\n",
            "13182 [Discriminator loss: 0.6717%, acc.: 59.77%] [Generator loss: 0.7980%]\n",
            "13183 [Discriminator loss: 0.6639%, acc.: 58.20%] [Generator loss: 0.7962%]\n",
            "13184 [Discriminator loss: 0.6595%, acc.: 63.67%] [Generator loss: 0.8199%]\n",
            "13185 [Discriminator loss: 0.6838%, acc.: 56.64%] [Generator loss: 0.8071%]\n",
            "13186 [Discriminator loss: 0.6526%, acc.: 58.59%] [Generator loss: 0.8051%]\n",
            "13187 [Discriminator loss: 0.6757%, acc.: 52.34%] [Generator loss: 0.8079%]\n",
            "13188 [Discriminator loss: 0.6689%, acc.: 59.38%] [Generator loss: 0.8023%]\n",
            "13189 [Discriminator loss: 0.6506%, acc.: 61.33%] [Generator loss: 0.8035%]\n",
            "13190 [Discriminator loss: 0.6823%, acc.: 55.08%] [Generator loss: 0.7526%]\n",
            "13191 [Discriminator loss: 0.6558%, acc.: 63.67%] [Generator loss: 0.8036%]\n",
            "13192 [Discriminator loss: 0.6513%, acc.: 64.84%] [Generator loss: 0.8105%]\n",
            "13193 [Discriminator loss: 0.6865%, acc.: 53.12%] [Generator loss: 0.7821%]\n",
            "13194 [Discriminator loss: 0.6729%, acc.: 57.81%] [Generator loss: 0.7901%]\n",
            "13195 [Discriminator loss: 0.6753%, acc.: 58.98%] [Generator loss: 0.7950%]\n",
            "13196 [Discriminator loss: 0.6677%, acc.: 58.20%] [Generator loss: 0.7904%]\n",
            "13197 [Discriminator loss: 0.6592%, acc.: 58.98%] [Generator loss: 0.8094%]\n",
            "13198 [Discriminator loss: 0.6649%, acc.: 58.20%] [Generator loss: 0.8017%]\n",
            "13199 [Discriminator loss: 0.6544%, acc.: 64.45%] [Generator loss: 0.8146%]\n",
            "13200 [Discriminator loss: 0.6608%, acc.: 58.98%] [Generator loss: 0.8270%]\n",
            "13201 [Discriminator loss: 0.6822%, acc.: 53.91%] [Generator loss: 0.8250%]\n",
            "13202 [Discriminator loss: 0.6497%, acc.: 60.55%] [Generator loss: 0.8373%]\n",
            "13203 [Discriminator loss: 0.6569%, acc.: 62.50%] [Generator loss: 0.8033%]\n",
            "13204 [Discriminator loss: 0.6618%, acc.: 57.81%] [Generator loss: 0.7824%]\n",
            "13205 [Discriminator loss: 0.6643%, acc.: 55.08%] [Generator loss: 0.8046%]\n",
            "13206 [Discriminator loss: 0.6481%, acc.: 64.06%] [Generator loss: 0.7933%]\n",
            "13207 [Discriminator loss: 0.6766%, acc.: 53.12%] [Generator loss: 0.8125%]\n",
            "13208 [Discriminator loss: 0.6699%, acc.: 57.42%] [Generator loss: 0.7803%]\n",
            "13209 [Discriminator loss: 0.6563%, acc.: 56.64%] [Generator loss: 0.8087%]\n",
            "13210 [Discriminator loss: 0.6799%, acc.: 55.86%] [Generator loss: 0.7970%]\n",
            "13211 [Discriminator loss: 0.6570%, acc.: 64.45%] [Generator loss: 0.7879%]\n",
            "13212 [Discriminator loss: 0.6688%, acc.: 60.55%] [Generator loss: 0.7793%]\n",
            "13213 [Discriminator loss: 0.6479%, acc.: 64.84%] [Generator loss: 0.8080%]\n",
            "13214 [Discriminator loss: 0.6668%, acc.: 60.94%] [Generator loss: 0.8141%]\n",
            "13215 [Discriminator loss: 0.6505%, acc.: 64.45%] [Generator loss: 0.8012%]\n",
            "13216 [Discriminator loss: 0.6584%, acc.: 59.38%] [Generator loss: 0.8141%]\n",
            "13217 [Discriminator loss: 0.6830%, acc.: 51.95%] [Generator loss: 0.8349%]\n",
            "13218 [Discriminator loss: 0.6754%, acc.: 56.64%] [Generator loss: 0.7953%]\n",
            "13219 [Discriminator loss: 0.6567%, acc.: 64.84%] [Generator loss: 0.8079%]\n",
            "13220 [Discriminator loss: 0.6696%, acc.: 58.98%] [Generator loss: 0.7955%]\n",
            "13221 [Discriminator loss: 0.6706%, acc.: 58.59%] [Generator loss: 0.7920%]\n",
            "13222 [Discriminator loss: 0.6637%, acc.: 60.94%] [Generator loss: 0.7695%]\n",
            "13223 [Discriminator loss: 0.6726%, acc.: 61.72%] [Generator loss: 0.7890%]\n",
            "13224 [Discriminator loss: 0.6416%, acc.: 66.80%] [Generator loss: 0.8000%]\n",
            "13225 [Discriminator loss: 0.6795%, acc.: 57.42%] [Generator loss: 0.7775%]\n",
            "13226 [Discriminator loss: 0.6681%, acc.: 59.38%] [Generator loss: 0.7702%]\n",
            "13227 [Discriminator loss: 0.6867%, acc.: 53.12%] [Generator loss: 0.7990%]\n",
            "13228 [Discriminator loss: 0.6613%, acc.: 59.77%] [Generator loss: 0.7968%]\n",
            "13229 [Discriminator loss: 0.6441%, acc.: 65.62%] [Generator loss: 0.8106%]\n",
            "13230 [Discriminator loss: 0.6769%, acc.: 58.98%] [Generator loss: 0.8093%]\n",
            "13231 [Discriminator loss: 0.6567%, acc.: 64.06%] [Generator loss: 0.7983%]\n",
            "13232 [Discriminator loss: 0.6532%, acc.: 60.55%] [Generator loss: 0.8178%]\n",
            "13233 [Discriminator loss: 0.6952%, acc.: 50.00%] [Generator loss: 0.8050%]\n",
            "13234 [Discriminator loss: 0.6587%, acc.: 61.33%] [Generator loss: 0.8091%]\n",
            "13235 [Discriminator loss: 0.6588%, acc.: 59.38%] [Generator loss: 0.8198%]\n",
            "13236 [Discriminator loss: 0.6645%, acc.: 59.77%] [Generator loss: 0.8137%]\n",
            "13237 [Discriminator loss: 0.6770%, acc.: 57.42%] [Generator loss: 0.7768%]\n",
            "13238 [Discriminator loss: 0.6844%, acc.: 50.00%] [Generator loss: 0.8196%]\n",
            "13239 [Discriminator loss: 0.6731%, acc.: 59.77%] [Generator loss: 0.8051%]\n",
            "13240 [Discriminator loss: 0.6634%, acc.: 62.89%] [Generator loss: 0.7895%]\n",
            "13241 [Discriminator loss: 0.6865%, acc.: 54.69%] [Generator loss: 0.8017%]\n",
            "13242 [Discriminator loss: 0.6698%, acc.: 60.94%] [Generator loss: 0.7932%]\n",
            "13243 [Discriminator loss: 0.6572%, acc.: 59.77%] [Generator loss: 0.7683%]\n",
            "13244 [Discriminator loss: 0.6842%, acc.: 55.86%] [Generator loss: 0.7741%]\n",
            "13245 [Discriminator loss: 0.6602%, acc.: 61.72%] [Generator loss: 0.7638%]\n",
            "13246 [Discriminator loss: 0.6717%, acc.: 55.47%] [Generator loss: 0.7748%]\n",
            "13247 [Discriminator loss: 0.6509%, acc.: 64.84%] [Generator loss: 0.7743%]\n",
            "13248 [Discriminator loss: 0.6725%, acc.: 56.64%] [Generator loss: 0.7793%]\n",
            "13249 [Discriminator loss: 0.6635%, acc.: 63.28%] [Generator loss: 0.7837%]\n",
            "13250 [Discriminator loss: 0.6759%, acc.: 54.30%] [Generator loss: 0.7920%]\n",
            "13251 [Discriminator loss: 0.6593%, acc.: 64.45%] [Generator loss: 0.8109%]\n",
            "13252 [Discriminator loss: 0.6934%, acc.: 51.56%] [Generator loss: 0.7915%]\n",
            "13253 [Discriminator loss: 0.6643%, acc.: 58.20%] [Generator loss: 0.8136%]\n",
            "13254 [Discriminator loss: 0.6657%, acc.: 60.55%] [Generator loss: 0.7627%]\n",
            "13255 [Discriminator loss: 0.6707%, acc.: 60.16%] [Generator loss: 0.7865%]\n",
            "13256 [Discriminator loss: 0.6546%, acc.: 64.06%] [Generator loss: 0.7777%]\n",
            "13257 [Discriminator loss: 0.6633%, acc.: 61.72%] [Generator loss: 0.7832%]\n",
            "13258 [Discriminator loss: 0.6754%, acc.: 57.42%] [Generator loss: 0.8008%]\n",
            "13259 [Discriminator loss: 0.6648%, acc.: 57.03%] [Generator loss: 0.8122%]\n",
            "13260 [Discriminator loss: 0.6891%, acc.: 53.12%] [Generator loss: 0.7810%]\n",
            "13261 [Discriminator loss: 0.6764%, acc.: 55.47%] [Generator loss: 0.8047%]\n",
            "13262 [Discriminator loss: 0.6695%, acc.: 57.42%] [Generator loss: 0.7905%]\n",
            "13263 [Discriminator loss: 0.6532%, acc.: 63.28%] [Generator loss: 0.7829%]\n",
            "13264 [Discriminator loss: 0.6586%, acc.: 58.59%] [Generator loss: 0.8040%]\n",
            "13265 [Discriminator loss: 0.6631%, acc.: 62.11%] [Generator loss: 0.8265%]\n",
            "13266 [Discriminator loss: 0.6715%, acc.: 55.47%] [Generator loss: 0.7842%]\n",
            "13267 [Discriminator loss: 0.6889%, acc.: 53.52%] [Generator loss: 0.7904%]\n",
            "13268 [Discriminator loss: 0.6587%, acc.: 63.28%] [Generator loss: 0.7841%]\n",
            "13269 [Discriminator loss: 0.6683%, acc.: 58.59%] [Generator loss: 0.7993%]\n",
            "13270 [Discriminator loss: 0.6647%, acc.: 58.98%] [Generator loss: 0.8062%]\n",
            "13271 [Discriminator loss: 0.6516%, acc.: 66.41%] [Generator loss: 0.7888%]\n",
            "13272 [Discriminator loss: 0.6750%, acc.: 60.16%] [Generator loss: 0.8057%]\n",
            "13273 [Discriminator loss: 0.6850%, acc.: 51.95%] [Generator loss: 0.7730%]\n",
            "13274 [Discriminator loss: 0.6577%, acc.: 61.72%] [Generator loss: 0.7709%]\n",
            "13275 [Discriminator loss: 0.6713%, acc.: 55.08%] [Generator loss: 0.7781%]\n",
            "13276 [Discriminator loss: 0.6396%, acc.: 65.62%] [Generator loss: 0.7852%]\n",
            "13277 [Discriminator loss: 0.6560%, acc.: 58.59%] [Generator loss: 0.8222%]\n",
            "13278 [Discriminator loss: 0.6652%, acc.: 60.55%] [Generator loss: 0.7827%]\n",
            "13279 [Discriminator loss: 0.6731%, acc.: 53.52%] [Generator loss: 0.7790%]\n",
            "13280 [Discriminator loss: 0.6745%, acc.: 59.77%] [Generator loss: 0.7932%]\n",
            "13281 [Discriminator loss: 0.6649%, acc.: 62.50%] [Generator loss: 0.7935%]\n",
            "13282 [Discriminator loss: 0.6825%, acc.: 53.91%] [Generator loss: 0.7920%]\n",
            "13283 [Discriminator loss: 0.6795%, acc.: 54.69%] [Generator loss: 0.8124%]\n",
            "13284 [Discriminator loss: 0.6698%, acc.: 57.03%] [Generator loss: 0.7850%]\n",
            "13285 [Discriminator loss: 0.6687%, acc.: 58.20%] [Generator loss: 0.8150%]\n",
            "13286 [Discriminator loss: 0.6627%, acc.: 60.94%] [Generator loss: 0.7745%]\n",
            "13287 [Discriminator loss: 0.6724%, acc.: 56.25%] [Generator loss: 0.7888%]\n",
            "13288 [Discriminator loss: 0.6784%, acc.: 56.25%] [Generator loss: 0.7860%]\n",
            "13289 [Discriminator loss: 0.6608%, acc.: 57.81%] [Generator loss: 0.7911%]\n",
            "13290 [Discriminator loss: 0.6489%, acc.: 66.41%] [Generator loss: 0.7942%]\n",
            "13291 [Discriminator loss: 0.6606%, acc.: 61.33%] [Generator loss: 0.8037%]\n",
            "13292 [Discriminator loss: 0.6640%, acc.: 62.11%] [Generator loss: 0.7806%]\n",
            "13293 [Discriminator loss: 0.6775%, acc.: 56.25%] [Generator loss: 0.8121%]\n",
            "13294 [Discriminator loss: 0.6821%, acc.: 51.95%] [Generator loss: 0.8031%]\n",
            "13295 [Discriminator loss: 0.6582%, acc.: 59.38%] [Generator loss: 0.8125%]\n",
            "13296 [Discriminator loss: 0.6863%, acc.: 53.12%] [Generator loss: 0.8073%]\n",
            "13297 [Discriminator loss: 0.6836%, acc.: 51.95%] [Generator loss: 0.8088%]\n",
            "13298 [Discriminator loss: 0.6635%, acc.: 56.64%] [Generator loss: 0.8274%]\n",
            "13299 [Discriminator loss: 0.6643%, acc.: 57.03%] [Generator loss: 0.7757%]\n",
            "13300 [Discriminator loss: 0.6791%, acc.: 58.20%] [Generator loss: 0.7889%]\n",
            "13301 [Discriminator loss: 0.6568%, acc.: 60.94%] [Generator loss: 0.7893%]\n",
            "13302 [Discriminator loss: 0.6547%, acc.: 64.45%] [Generator loss: 0.7764%]\n",
            "13303 [Discriminator loss: 0.6613%, acc.: 61.72%] [Generator loss: 0.7816%]\n",
            "13304 [Discriminator loss: 0.6734%, acc.: 55.86%] [Generator loss: 0.7742%]\n",
            "13305 [Discriminator loss: 0.6636%, acc.: 60.16%] [Generator loss: 0.8049%]\n",
            "13306 [Discriminator loss: 0.6630%, acc.: 62.11%] [Generator loss: 0.8076%]\n",
            "13307 [Discriminator loss: 0.6640%, acc.: 60.16%] [Generator loss: 0.8053%]\n",
            "13308 [Discriminator loss: 0.6560%, acc.: 64.45%] [Generator loss: 0.7948%]\n",
            "13309 [Discriminator loss: 0.6731%, acc.: 59.38%] [Generator loss: 0.8012%]\n",
            "13310 [Discriminator loss: 0.6766%, acc.: 60.55%] [Generator loss: 0.7969%]\n",
            "13311 [Discriminator loss: 0.6606%, acc.: 63.28%] [Generator loss: 0.8156%]\n",
            "13312 [Discriminator loss: 0.6783%, acc.: 58.20%] [Generator loss: 0.7831%]\n",
            "13313 [Discriminator loss: 0.6700%, acc.: 56.64%] [Generator loss: 0.7996%]\n",
            "13314 [Discriminator loss: 0.6786%, acc.: 59.38%] [Generator loss: 0.7742%]\n",
            "13315 [Discriminator loss: 0.6777%, acc.: 56.25%] [Generator loss: 0.8036%]\n",
            "13316 [Discriminator loss: 0.6760%, acc.: 56.64%] [Generator loss: 0.7734%]\n",
            "13317 [Discriminator loss: 0.6711%, acc.: 54.69%] [Generator loss: 0.7879%]\n",
            "13318 [Discriminator loss: 0.6773%, acc.: 56.64%] [Generator loss: 0.8206%]\n",
            "13319 [Discriminator loss: 0.6495%, acc.: 66.02%] [Generator loss: 0.8055%]\n",
            "13320 [Discriminator loss: 0.6943%, acc.: 56.64%] [Generator loss: 0.8193%]\n",
            "13321 [Discriminator loss: 0.6834%, acc.: 55.08%] [Generator loss: 0.7817%]\n",
            "13322 [Discriminator loss: 0.6653%, acc.: 60.16%] [Generator loss: 0.7607%]\n",
            "13323 [Discriminator loss: 0.6743%, acc.: 58.20%] [Generator loss: 0.8093%]\n",
            "13324 [Discriminator loss: 0.6319%, acc.: 65.62%] [Generator loss: 0.7907%]\n",
            "13325 [Discriminator loss: 0.6528%, acc.: 65.23%] [Generator loss: 0.7705%]\n",
            "13326 [Discriminator loss: 0.6588%, acc.: 60.55%] [Generator loss: 0.8180%]\n",
            "13327 [Discriminator loss: 0.6620%, acc.: 58.59%] [Generator loss: 0.7986%]\n",
            "13328 [Discriminator loss: 0.6562%, acc.: 58.98%] [Generator loss: 0.7796%]\n",
            "13329 [Discriminator loss: 0.6645%, acc.: 58.59%] [Generator loss: 0.7918%]\n",
            "13330 [Discriminator loss: 0.6564%, acc.: 60.55%] [Generator loss: 0.7872%]\n",
            "13331 [Discriminator loss: 0.6698%, acc.: 58.98%] [Generator loss: 0.8100%]\n",
            "13332 [Discriminator loss: 0.6644%, acc.: 58.98%] [Generator loss: 0.8400%]\n",
            "13333 [Discriminator loss: 0.6782%, acc.: 55.08%] [Generator loss: 0.8366%]\n",
            "13334 [Discriminator loss: 0.6728%, acc.: 58.98%] [Generator loss: 0.8166%]\n",
            "13335 [Discriminator loss: 0.6829%, acc.: 53.52%] [Generator loss: 0.7966%]\n",
            "13336 [Discriminator loss: 0.6722%, acc.: 60.16%] [Generator loss: 0.8065%]\n",
            "13337 [Discriminator loss: 0.6648%, acc.: 57.81%] [Generator loss: 0.8218%]\n",
            "13338 [Discriminator loss: 0.6404%, acc.: 67.19%] [Generator loss: 0.7904%]\n",
            "13339 [Discriminator loss: 0.6816%, acc.: 53.91%] [Generator loss: 0.8039%]\n",
            "13340 [Discriminator loss: 0.6729%, acc.: 58.20%] [Generator loss: 0.8120%]\n",
            "13341 [Discriminator loss: 0.6759%, acc.: 53.91%] [Generator loss: 0.7819%]\n",
            "13342 [Discriminator loss: 0.7010%, acc.: 53.52%] [Generator loss: 0.8088%]\n",
            "13343 [Discriminator loss: 0.6801%, acc.: 56.25%] [Generator loss: 0.8237%]\n",
            "13344 [Discriminator loss: 0.6812%, acc.: 53.91%] [Generator loss: 0.7971%]\n",
            "13345 [Discriminator loss: 0.6558%, acc.: 62.89%] [Generator loss: 0.7699%]\n",
            "13346 [Discriminator loss: 0.6658%, acc.: 63.28%] [Generator loss: 0.8152%]\n",
            "13347 [Discriminator loss: 0.6623%, acc.: 59.77%] [Generator loss: 0.7770%]\n",
            "13348 [Discriminator loss: 0.6642%, acc.: 60.55%] [Generator loss: 0.7953%]\n",
            "13349 [Discriminator loss: 0.6637%, acc.: 59.77%] [Generator loss: 0.8015%]\n",
            "13350 [Discriminator loss: 0.6681%, acc.: 59.77%] [Generator loss: 0.7966%]\n",
            "13351 [Discriminator loss: 0.6812%, acc.: 59.38%] [Generator loss: 0.8254%]\n",
            "13352 [Discriminator loss: 0.6673%, acc.: 59.77%] [Generator loss: 0.8071%]\n",
            "13353 [Discriminator loss: 0.6510%, acc.: 64.06%] [Generator loss: 0.7883%]\n",
            "13354 [Discriminator loss: 0.6734%, acc.: 61.33%] [Generator loss: 0.8033%]\n",
            "13355 [Discriminator loss: 0.6775%, acc.: 58.59%] [Generator loss: 0.7816%]\n",
            "13356 [Discriminator loss: 0.6843%, acc.: 51.56%] [Generator loss: 0.8156%]\n",
            "13357 [Discriminator loss: 0.6754%, acc.: 57.03%] [Generator loss: 0.7884%]\n",
            "13358 [Discriminator loss: 0.6489%, acc.: 62.50%] [Generator loss: 0.7743%]\n",
            "13359 [Discriminator loss: 0.6804%, acc.: 55.47%] [Generator loss: 0.7753%]\n",
            "13360 [Discriminator loss: 0.6623%, acc.: 58.59%] [Generator loss: 0.8216%]\n",
            "13361 [Discriminator loss: 0.6804%, acc.: 55.47%] [Generator loss: 0.7851%]\n",
            "13362 [Discriminator loss: 0.6630%, acc.: 58.20%] [Generator loss: 0.8223%]\n",
            "13363 [Discriminator loss: 0.6730%, acc.: 58.59%] [Generator loss: 0.7761%]\n",
            "13364 [Discriminator loss: 0.6681%, acc.: 60.94%] [Generator loss: 0.7755%]\n",
            "13365 [Discriminator loss: 0.6416%, acc.: 64.45%] [Generator loss: 0.7885%]\n",
            "13366 [Discriminator loss: 0.6813%, acc.: 59.77%] [Generator loss: 0.7936%]\n",
            "13367 [Discriminator loss: 0.6744%, acc.: 55.08%] [Generator loss: 0.7794%]\n",
            "13368 [Discriminator loss: 0.6665%, acc.: 59.38%] [Generator loss: 0.7832%]\n",
            "13369 [Discriminator loss: 0.6458%, acc.: 63.67%] [Generator loss: 0.8123%]\n",
            "13370 [Discriminator loss: 0.6546%, acc.: 61.33%] [Generator loss: 0.8067%]\n",
            "13371 [Discriminator loss: 0.6596%, acc.: 61.72%] [Generator loss: 0.8163%]\n",
            "13372 [Discriminator loss: 0.6703%, acc.: 56.64%] [Generator loss: 0.8140%]\n",
            "13373 [Discriminator loss: 0.6618%, acc.: 60.94%] [Generator loss: 0.8217%]\n",
            "13374 [Discriminator loss: 0.6812%, acc.: 53.91%] [Generator loss: 0.7911%]\n",
            "13375 [Discriminator loss: 0.6441%, acc.: 65.62%] [Generator loss: 0.8329%]\n",
            "13376 [Discriminator loss: 0.6665%, acc.: 60.55%] [Generator loss: 0.7954%]\n",
            "13377 [Discriminator loss: 0.6694%, acc.: 57.81%] [Generator loss: 0.7912%]\n",
            "13378 [Discriminator loss: 0.6593%, acc.: 60.55%] [Generator loss: 0.7924%]\n",
            "13379 [Discriminator loss: 0.6533%, acc.: 62.89%] [Generator loss: 0.8045%]\n",
            "13380 [Discriminator loss: 0.6638%, acc.: 60.94%] [Generator loss: 0.7745%]\n",
            "13381 [Discriminator loss: 0.6791%, acc.: 53.91%] [Generator loss: 0.7781%]\n",
            "13382 [Discriminator loss: 0.6550%, acc.: 61.72%] [Generator loss: 0.8261%]\n",
            "13383 [Discriminator loss: 0.6757%, acc.: 54.69%] [Generator loss: 0.8014%]\n",
            "13384 [Discriminator loss: 0.6684%, acc.: 59.38%] [Generator loss: 0.7971%]\n",
            "13385 [Discriminator loss: 0.6606%, acc.: 62.11%] [Generator loss: 0.8220%]\n",
            "13386 [Discriminator loss: 0.6594%, acc.: 60.55%] [Generator loss: 0.7713%]\n",
            "13387 [Discriminator loss: 0.6575%, acc.: 61.33%] [Generator loss: 0.8130%]\n",
            "13388 [Discriminator loss: 0.6781%, acc.: 59.77%] [Generator loss: 0.8049%]\n",
            "13389 [Discriminator loss: 0.6540%, acc.: 60.55%] [Generator loss: 0.7914%]\n",
            "13390 [Discriminator loss: 0.6512%, acc.: 64.84%] [Generator loss: 0.7788%]\n",
            "13391 [Discriminator loss: 0.6548%, acc.: 59.38%] [Generator loss: 0.8017%]\n",
            "13392 [Discriminator loss: 0.6666%, acc.: 58.59%] [Generator loss: 0.7952%]\n",
            "13393 [Discriminator loss: 0.6648%, acc.: 53.12%] [Generator loss: 0.7898%]\n",
            "13394 [Discriminator loss: 0.6702%, acc.: 62.50%] [Generator loss: 0.7750%]\n",
            "13395 [Discriminator loss: 0.6613%, acc.: 60.55%] [Generator loss: 0.7850%]\n",
            "13396 [Discriminator loss: 0.6419%, acc.: 62.89%] [Generator loss: 0.7939%]\n",
            "13397 [Discriminator loss: 0.6707%, acc.: 55.86%] [Generator loss: 0.7878%]\n",
            "13398 [Discriminator loss: 0.6788%, acc.: 56.64%] [Generator loss: 0.8093%]\n",
            "13399 [Discriminator loss: 0.6613%, acc.: 60.16%] [Generator loss: 0.7825%]\n",
            "13400 [Discriminator loss: 0.6596%, acc.: 61.72%] [Generator loss: 0.7904%]\n",
            "13401 [Discriminator loss: 0.6680%, acc.: 61.33%] [Generator loss: 0.7963%]\n",
            "13402 [Discriminator loss: 0.6577%, acc.: 61.33%] [Generator loss: 0.8070%]\n",
            "13403 [Discriminator loss: 0.6699%, acc.: 61.33%] [Generator loss: 0.7737%]\n",
            "13404 [Discriminator loss: 0.6864%, acc.: 51.95%] [Generator loss: 0.7954%]\n",
            "13405 [Discriminator loss: 0.6798%, acc.: 56.25%] [Generator loss: 0.7861%]\n",
            "13406 [Discriminator loss: 0.6662%, acc.: 62.11%] [Generator loss: 0.7900%]\n",
            "13407 [Discriminator loss: 0.6848%, acc.: 58.59%] [Generator loss: 0.8034%]\n",
            "13408 [Discriminator loss: 0.6700%, acc.: 54.69%] [Generator loss: 0.7908%]\n",
            "13409 [Discriminator loss: 0.6714%, acc.: 58.20%] [Generator loss: 0.7850%]\n",
            "13410 [Discriminator loss: 0.6741%, acc.: 58.98%] [Generator loss: 0.7888%]\n",
            "13411 [Discriminator loss: 0.6493%, acc.: 64.84%] [Generator loss: 0.8099%]\n",
            "13412 [Discriminator loss: 0.6662%, acc.: 59.77%] [Generator loss: 0.7747%]\n",
            "13413 [Discriminator loss: 0.6633%, acc.: 60.16%] [Generator loss: 0.7756%]\n",
            "13414 [Discriminator loss: 0.6641%, acc.: 60.16%] [Generator loss: 0.7790%]\n",
            "13415 [Discriminator loss: 0.6611%, acc.: 64.84%] [Generator loss: 0.7788%]\n",
            "13416 [Discriminator loss: 0.6637%, acc.: 60.16%] [Generator loss: 0.7990%]\n",
            "13417 [Discriminator loss: 0.6588%, acc.: 61.72%] [Generator loss: 0.7887%]\n",
            "13418 [Discriminator loss: 0.6636%, acc.: 62.89%] [Generator loss: 0.7846%]\n",
            "13419 [Discriminator loss: 0.6518%, acc.: 63.67%] [Generator loss: 0.7885%]\n",
            "13420 [Discriminator loss: 0.6522%, acc.: 62.50%] [Generator loss: 0.7886%]\n",
            "13421 [Discriminator loss: 0.6784%, acc.: 59.77%] [Generator loss: 0.7858%]\n",
            "13422 [Discriminator loss: 0.6452%, acc.: 61.33%] [Generator loss: 0.8228%]\n",
            "13423 [Discriminator loss: 0.6885%, acc.: 53.52%] [Generator loss: 0.8200%]\n",
            "13424 [Discriminator loss: 0.6551%, acc.: 55.86%] [Generator loss: 0.7932%]\n",
            "13425 [Discriminator loss: 0.6517%, acc.: 64.45%] [Generator loss: 0.7973%]\n",
            "13426 [Discriminator loss: 0.6632%, acc.: 60.16%] [Generator loss: 0.7616%]\n",
            "13427 [Discriminator loss: 0.6770%, acc.: 56.25%] [Generator loss: 0.7706%]\n",
            "13428 [Discriminator loss: 0.6725%, acc.: 57.81%] [Generator loss: 0.7859%]\n",
            "13429 [Discriminator loss: 0.6759%, acc.: 58.59%] [Generator loss: 0.7855%]\n",
            "13430 [Discriminator loss: 0.6560%, acc.: 58.59%] [Generator loss: 0.7702%]\n",
            "13431 [Discriminator loss: 0.6381%, acc.: 64.45%] [Generator loss: 0.7844%]\n",
            "13432 [Discriminator loss: 0.6731%, acc.: 60.55%] [Generator loss: 0.7856%]\n",
            "13433 [Discriminator loss: 0.6637%, acc.: 60.16%] [Generator loss: 0.7925%]\n",
            "13434 [Discriminator loss: 0.6770%, acc.: 53.52%] [Generator loss: 0.7906%]\n",
            "13435 [Discriminator loss: 0.6656%, acc.: 58.98%] [Generator loss: 0.8291%]\n",
            "13436 [Discriminator loss: 0.6698%, acc.: 55.86%] [Generator loss: 0.7973%]\n",
            "13437 [Discriminator loss: 0.6686%, acc.: 60.55%] [Generator loss: 0.7932%]\n",
            "13438 [Discriminator loss: 0.6692%, acc.: 56.64%] [Generator loss: 0.7929%]\n",
            "13439 [Discriminator loss: 0.6675%, acc.: 62.11%] [Generator loss: 0.7863%]\n",
            "13440 [Discriminator loss: 0.6668%, acc.: 57.03%] [Generator loss: 0.8021%]\n",
            "13441 [Discriminator loss: 0.6581%, acc.: 60.55%] [Generator loss: 0.7651%]\n",
            "13442 [Discriminator loss: 0.6619%, acc.: 57.03%] [Generator loss: 0.7561%]\n",
            "13443 [Discriminator loss: 0.6640%, acc.: 59.38%] [Generator loss: 0.7804%]\n",
            "13444 [Discriminator loss: 0.6547%, acc.: 61.72%] [Generator loss: 0.7927%]\n",
            "13445 [Discriminator loss: 0.6773%, acc.: 55.47%] [Generator loss: 0.7995%]\n",
            "13446 [Discriminator loss: 0.6449%, acc.: 65.62%] [Generator loss: 0.8070%]\n",
            "13447 [Discriminator loss: 0.6634%, acc.: 55.86%] [Generator loss: 0.7882%]\n",
            "13448 [Discriminator loss: 0.6620%, acc.: 57.03%] [Generator loss: 0.7786%]\n",
            "13449 [Discriminator loss: 0.6703%, acc.: 55.08%] [Generator loss: 0.7853%]\n",
            "13450 [Discriminator loss: 0.6623%, acc.: 60.16%] [Generator loss: 0.7723%]\n",
            "13451 [Discriminator loss: 0.6729%, acc.: 55.08%] [Generator loss: 0.7887%]\n",
            "13452 [Discriminator loss: 0.6613%, acc.: 57.03%] [Generator loss: 0.8051%]\n",
            "13453 [Discriminator loss: 0.6875%, acc.: 53.91%] [Generator loss: 0.7951%]\n",
            "13454 [Discriminator loss: 0.6614%, acc.: 58.98%] [Generator loss: 0.7843%]\n",
            "13455 [Discriminator loss: 0.6986%, acc.: 52.34%] [Generator loss: 0.7746%]\n",
            "13456 [Discriminator loss: 0.6577%, acc.: 65.62%] [Generator loss: 0.7684%]\n",
            "13457 [Discriminator loss: 0.6755%, acc.: 55.47%] [Generator loss: 0.7780%]\n",
            "13458 [Discriminator loss: 0.6518%, acc.: 61.72%] [Generator loss: 0.7933%]\n",
            "13459 [Discriminator loss: 0.6492%, acc.: 62.50%] [Generator loss: 0.7903%]\n",
            "13460 [Discriminator loss: 0.6647%, acc.: 60.55%] [Generator loss: 0.8224%]\n",
            "13461 [Discriminator loss: 0.6555%, acc.: 63.28%] [Generator loss: 0.8284%]\n",
            "13462 [Discriminator loss: 0.6622%, acc.: 61.72%] [Generator loss: 0.7972%]\n",
            "13463 [Discriminator loss: 0.6769%, acc.: 56.25%] [Generator loss: 0.8156%]\n",
            "13464 [Discriminator loss: 0.6812%, acc.: 58.20%] [Generator loss: 0.7825%]\n",
            "13465 [Discriminator loss: 0.6578%, acc.: 59.38%] [Generator loss: 0.7869%]\n",
            "13466 [Discriminator loss: 0.6706%, acc.: 61.72%] [Generator loss: 0.7937%]\n",
            "13467 [Discriminator loss: 0.6696%, acc.: 60.16%] [Generator loss: 0.8233%]\n",
            "13468 [Discriminator loss: 0.6628%, acc.: 55.86%] [Generator loss: 0.7931%]\n",
            "13469 [Discriminator loss: 0.6874%, acc.: 53.91%] [Generator loss: 0.7635%]\n",
            "13470 [Discriminator loss: 0.6562%, acc.: 64.45%] [Generator loss: 0.7940%]\n",
            "13471 [Discriminator loss: 0.6939%, acc.: 54.69%] [Generator loss: 0.8013%]\n",
            "13472 [Discriminator loss: 0.6807%, acc.: 57.42%] [Generator loss: 0.7860%]\n",
            "13473 [Discriminator loss: 0.6715%, acc.: 57.03%] [Generator loss: 0.7793%]\n",
            "13474 [Discriminator loss: 0.6894%, acc.: 50.78%] [Generator loss: 0.7967%]\n",
            "13475 [Discriminator loss: 0.6758%, acc.: 56.64%] [Generator loss: 0.7753%]\n",
            "13476 [Discriminator loss: 0.6653%, acc.: 62.89%] [Generator loss: 0.7927%]\n",
            "13477 [Discriminator loss: 0.6779%, acc.: 57.03%] [Generator loss: 0.7796%]\n",
            "13478 [Discriminator loss: 0.6827%, acc.: 53.52%] [Generator loss: 0.7979%]\n",
            "13479 [Discriminator loss: 0.6547%, acc.: 62.89%] [Generator loss: 0.7816%]\n",
            "13480 [Discriminator loss: 0.6910%, acc.: 53.12%] [Generator loss: 0.8022%]\n",
            "13481 [Discriminator loss: 0.6745%, acc.: 58.98%] [Generator loss: 0.8074%]\n",
            "13482 [Discriminator loss: 0.6899%, acc.: 55.86%] [Generator loss: 0.7951%]\n",
            "13483 [Discriminator loss: 0.6712%, acc.: 59.38%] [Generator loss: 0.8187%]\n",
            "13484 [Discriminator loss: 0.6666%, acc.: 63.28%] [Generator loss: 0.7831%]\n",
            "13485 [Discriminator loss: 0.6756%, acc.: 54.69%] [Generator loss: 0.7788%]\n",
            "13486 [Discriminator loss: 0.6631%, acc.: 64.06%] [Generator loss: 0.8216%]\n",
            "13487 [Discriminator loss: 0.6723%, acc.: 55.47%] [Generator loss: 0.8083%]\n",
            "13488 [Discriminator loss: 0.6872%, acc.: 50.39%] [Generator loss: 0.8071%]\n",
            "13489 [Discriminator loss: 0.6826%, acc.: 56.25%] [Generator loss: 0.7746%]\n",
            "13490 [Discriminator loss: 0.6613%, acc.: 60.94%] [Generator loss: 0.7885%]\n",
            "13491 [Discriminator loss: 0.6645%, acc.: 60.55%] [Generator loss: 0.7799%]\n",
            "13492 [Discriminator loss: 0.6708%, acc.: 54.69%] [Generator loss: 0.7784%]\n",
            "13493 [Discriminator loss: 0.6798%, acc.: 53.12%] [Generator loss: 0.7809%]\n",
            "13494 [Discriminator loss: 0.6660%, acc.: 58.59%] [Generator loss: 0.7837%]\n",
            "13495 [Discriminator loss: 0.6617%, acc.: 58.98%] [Generator loss: 0.7747%]\n",
            "13496 [Discriminator loss: 0.6624%, acc.: 66.02%] [Generator loss: 0.8044%]\n",
            "13497 [Discriminator loss: 0.6644%, acc.: 57.42%] [Generator loss: 0.7773%]\n",
            "13498 [Discriminator loss: 0.6589%, acc.: 64.06%] [Generator loss: 0.7883%]\n",
            "13499 [Discriminator loss: 0.6751%, acc.: 53.52%] [Generator loss: 0.8062%]\n",
            "13500 [Discriminator loss: 0.6877%, acc.: 53.52%] [Generator loss: 0.8007%]\n",
            "13501 [Discriminator loss: 0.6752%, acc.: 56.25%] [Generator loss: 0.7966%]\n",
            "13502 [Discriminator loss: 0.6635%, acc.: 61.33%] [Generator loss: 0.7984%]\n",
            "13503 [Discriminator loss: 0.6755%, acc.: 57.03%] [Generator loss: 0.7773%]\n",
            "13504 [Discriminator loss: 0.6633%, acc.: 59.38%] [Generator loss: 0.7985%]\n",
            "13505 [Discriminator loss: 0.6790%, acc.: 53.52%] [Generator loss: 0.8106%]\n",
            "13506 [Discriminator loss: 0.6698%, acc.: 57.42%] [Generator loss: 0.7978%]\n",
            "13507 [Discriminator loss: 0.6692%, acc.: 57.42%] [Generator loss: 0.7937%]\n",
            "13508 [Discriminator loss: 0.7097%, acc.: 54.30%] [Generator loss: 0.8024%]\n",
            "13509 [Discriminator loss: 0.6832%, acc.: 55.86%] [Generator loss: 0.7889%]\n",
            "13510 [Discriminator loss: 0.6618%, acc.: 61.33%] [Generator loss: 0.8039%]\n",
            "13511 [Discriminator loss: 0.6652%, acc.: 60.16%] [Generator loss: 0.7998%]\n",
            "13512 [Discriminator loss: 0.6523%, acc.: 63.28%] [Generator loss: 0.8000%]\n",
            "13513 [Discriminator loss: 0.6724%, acc.: 58.98%] [Generator loss: 0.8255%]\n",
            "13514 [Discriminator loss: 0.6928%, acc.: 51.17%] [Generator loss: 0.7955%]\n",
            "13515 [Discriminator loss: 0.6458%, acc.: 62.89%] [Generator loss: 0.8002%]\n",
            "13516 [Discriminator loss: 0.6699%, acc.: 58.59%] [Generator loss: 0.7920%]\n",
            "13517 [Discriminator loss: 0.6796%, acc.: 52.34%] [Generator loss: 0.7874%]\n",
            "13518 [Discriminator loss: 0.6695%, acc.: 55.86%] [Generator loss: 0.8065%]\n",
            "13519 [Discriminator loss: 0.6754%, acc.: 55.47%] [Generator loss: 0.8119%]\n",
            "13520 [Discriminator loss: 0.6749%, acc.: 57.81%] [Generator loss: 0.7958%]\n",
            "13521 [Discriminator loss: 0.6694%, acc.: 57.03%] [Generator loss: 0.7975%]\n",
            "13522 [Discriminator loss: 0.6601%, acc.: 61.33%] [Generator loss: 0.7731%]\n",
            "13523 [Discriminator loss: 0.6835%, acc.: 55.08%] [Generator loss: 0.7735%]\n",
            "13524 [Discriminator loss: 0.6928%, acc.: 53.91%] [Generator loss: 0.8011%]\n",
            "13525 [Discriminator loss: 0.6795%, acc.: 56.25%] [Generator loss: 0.7652%]\n",
            "13526 [Discriminator loss: 0.6787%, acc.: 60.55%] [Generator loss: 0.7650%]\n",
            "13527 [Discriminator loss: 0.6724%, acc.: 54.30%] [Generator loss: 0.7616%]\n",
            "13528 [Discriminator loss: 0.6650%, acc.: 59.77%] [Generator loss: 0.7884%]\n",
            "13529 [Discriminator loss: 0.6497%, acc.: 64.84%] [Generator loss: 0.7608%]\n",
            "13530 [Discriminator loss: 0.6748%, acc.: 56.64%] [Generator loss: 0.7882%]\n",
            "13531 [Discriminator loss: 0.6711%, acc.: 59.38%] [Generator loss: 0.7624%]\n",
            "13532 [Discriminator loss: 0.6740%, acc.: 58.20%] [Generator loss: 0.7620%]\n",
            "13533 [Discriminator loss: 0.6715%, acc.: 59.38%] [Generator loss: 0.8063%]\n",
            "13534 [Discriminator loss: 0.6666%, acc.: 61.72%] [Generator loss: 0.7980%]\n",
            "13535 [Discriminator loss: 0.6544%, acc.: 61.72%] [Generator loss: 0.8191%]\n",
            "13536 [Discriminator loss: 0.6602%, acc.: 57.81%] [Generator loss: 0.7816%]\n",
            "13537 [Discriminator loss: 0.6852%, acc.: 54.69%] [Generator loss: 0.8115%]\n",
            "13538 [Discriminator loss: 0.6622%, acc.: 60.94%] [Generator loss: 0.8050%]\n",
            "13539 [Discriminator loss: 0.6666%, acc.: 58.20%] [Generator loss: 0.7979%]\n",
            "13540 [Discriminator loss: 0.6611%, acc.: 60.55%] [Generator loss: 0.7815%]\n",
            "13541 [Discriminator loss: 0.6656%, acc.: 60.16%] [Generator loss: 0.7843%]\n",
            "13542 [Discriminator loss: 0.6690%, acc.: 58.59%] [Generator loss: 0.7784%]\n",
            "13543 [Discriminator loss: 0.6842%, acc.: 54.69%] [Generator loss: 0.7888%]\n",
            "13544 [Discriminator loss: 0.6609%, acc.: 58.59%] [Generator loss: 0.7923%]\n",
            "13545 [Discriminator loss: 0.6570%, acc.: 62.50%] [Generator loss: 0.8236%]\n",
            "13546 [Discriminator loss: 0.6948%, acc.: 54.30%] [Generator loss: 0.7801%]\n",
            "13547 [Discriminator loss: 0.6833%, acc.: 58.20%] [Generator loss: 0.8089%]\n",
            "13548 [Discriminator loss: 0.6722%, acc.: 60.16%] [Generator loss: 0.7830%]\n",
            "13549 [Discriminator loss: 0.6606%, acc.: 58.98%] [Generator loss: 0.7653%]\n",
            "13550 [Discriminator loss: 0.6697%, acc.: 57.42%] [Generator loss: 0.7587%]\n",
            "13551 [Discriminator loss: 0.6838%, acc.: 56.64%] [Generator loss: 0.7888%]\n",
            "13552 [Discriminator loss: 0.6558%, acc.: 62.11%] [Generator loss: 0.7811%]\n",
            "13553 [Discriminator loss: 0.6720%, acc.: 57.03%] [Generator loss: 0.7989%]\n",
            "13554 [Discriminator loss: 0.6832%, acc.: 56.64%] [Generator loss: 0.7881%]\n",
            "13555 [Discriminator loss: 0.6563%, acc.: 57.81%] [Generator loss: 0.7958%]\n",
            "13556 [Discriminator loss: 0.6878%, acc.: 54.69%] [Generator loss: 0.7951%]\n",
            "13557 [Discriminator loss: 0.6561%, acc.: 63.67%] [Generator loss: 0.8091%]\n",
            "13558 [Discriminator loss: 0.6805%, acc.: 59.77%] [Generator loss: 0.8007%]\n",
            "13559 [Discriminator loss: 0.6580%, acc.: 63.67%] [Generator loss: 0.7939%]\n",
            "13560 [Discriminator loss: 0.6792%, acc.: 55.47%] [Generator loss: 0.7908%]\n",
            "13561 [Discriminator loss: 0.6587%, acc.: 63.67%] [Generator loss: 0.7974%]\n",
            "13562 [Discriminator loss: 0.6775%, acc.: 55.47%] [Generator loss: 0.7773%]\n",
            "13563 [Discriminator loss: 0.6742%, acc.: 59.77%] [Generator loss: 0.7689%]\n",
            "13564 [Discriminator loss: 0.6676%, acc.: 57.81%] [Generator loss: 0.7630%]\n",
            "13565 [Discriminator loss: 0.6618%, acc.: 58.98%] [Generator loss: 0.8192%]\n",
            "13566 [Discriminator loss: 0.6779%, acc.: 56.25%] [Generator loss: 0.8159%]\n",
            "13567 [Discriminator loss: 0.6489%, acc.: 64.06%] [Generator loss: 0.7916%]\n",
            "13568 [Discriminator loss: 0.6715%, acc.: 58.59%] [Generator loss: 0.7981%]\n",
            "13569 [Discriminator loss: 0.6865%, acc.: 53.91%] [Generator loss: 0.8033%]\n",
            "13570 [Discriminator loss: 0.6754%, acc.: 57.42%] [Generator loss: 0.8115%]\n",
            "13571 [Discriminator loss: 0.6654%, acc.: 58.20%] [Generator loss: 0.7969%]\n",
            "13572 [Discriminator loss: 0.6712%, acc.: 57.03%] [Generator loss: 0.7936%]\n",
            "13573 [Discriminator loss: 0.6690%, acc.: 60.94%] [Generator loss: 0.8123%]\n",
            "13574 [Discriminator loss: 0.6796%, acc.: 54.30%] [Generator loss: 0.7776%]\n",
            "13575 [Discriminator loss: 0.6587%, acc.: 62.11%] [Generator loss: 0.7924%]\n",
            "13576 [Discriminator loss: 0.6618%, acc.: 59.77%] [Generator loss: 0.8251%]\n",
            "13577 [Discriminator loss: 0.6703%, acc.: 58.20%] [Generator loss: 0.7706%]\n",
            "13578 [Discriminator loss: 0.6885%, acc.: 55.08%] [Generator loss: 0.7996%]\n",
            "13579 [Discriminator loss: 0.6582%, acc.: 56.64%] [Generator loss: 0.8104%]\n",
            "13580 [Discriminator loss: 0.6659%, acc.: 59.38%] [Generator loss: 0.7975%]\n",
            "13581 [Discriminator loss: 0.6677%, acc.: 59.77%] [Generator loss: 0.7912%]\n",
            "13582 [Discriminator loss: 0.6800%, acc.: 58.20%] [Generator loss: 0.7679%]\n",
            "13583 [Discriminator loss: 0.6673%, acc.: 60.94%] [Generator loss: 0.7964%]\n",
            "13584 [Discriminator loss: 0.6672%, acc.: 60.94%] [Generator loss: 0.7959%]\n",
            "13585 [Discriminator loss: 0.6658%, acc.: 59.38%] [Generator loss: 0.7849%]\n",
            "13586 [Discriminator loss: 0.6604%, acc.: 58.59%] [Generator loss: 0.8028%]\n",
            "13587 [Discriminator loss: 0.6723%, acc.: 59.38%] [Generator loss: 0.8020%]\n",
            "13588 [Discriminator loss: 0.6809%, acc.: 54.69%] [Generator loss: 0.8033%]\n",
            "13589 [Discriminator loss: 0.6710%, acc.: 58.20%] [Generator loss: 0.7795%]\n",
            "13590 [Discriminator loss: 0.6700%, acc.: 58.20%] [Generator loss: 0.7957%]\n",
            "13591 [Discriminator loss: 0.6644%, acc.: 57.81%] [Generator loss: 0.7889%]\n",
            "13592 [Discriminator loss: 0.6771%, acc.: 56.64%] [Generator loss: 0.7850%]\n",
            "13593 [Discriminator loss: 0.6768%, acc.: 53.91%] [Generator loss: 0.7798%]\n",
            "13594 [Discriminator loss: 0.6751%, acc.: 55.86%] [Generator loss: 0.7795%]\n",
            "13595 [Discriminator loss: 0.6603%, acc.: 60.94%] [Generator loss: 0.7842%]\n",
            "13596 [Discriminator loss: 0.6787%, acc.: 54.30%] [Generator loss: 0.7779%]\n",
            "13597 [Discriminator loss: 0.6748%, acc.: 61.72%] [Generator loss: 0.8060%]\n",
            "13598 [Discriminator loss: 0.6476%, acc.: 64.06%] [Generator loss: 0.7904%]\n",
            "13599 [Discriminator loss: 0.6383%, acc.: 67.19%] [Generator loss: 0.7847%]\n",
            "13600 [Discriminator loss: 0.6587%, acc.: 58.98%] [Generator loss: 0.8042%]\n",
            "13601 [Discriminator loss: 0.6701%, acc.: 58.59%] [Generator loss: 0.7626%]\n",
            "13602 [Discriminator loss: 0.6331%, acc.: 66.80%] [Generator loss: 0.8026%]\n",
            "13603 [Discriminator loss: 0.6739%, acc.: 54.69%] [Generator loss: 0.7846%]\n",
            "13604 [Discriminator loss: 0.6754%, acc.: 58.59%] [Generator loss: 0.7708%]\n",
            "13605 [Discriminator loss: 0.6726%, acc.: 60.16%] [Generator loss: 0.7761%]\n",
            "13606 [Discriminator loss: 0.6781%, acc.: 56.64%] [Generator loss: 0.7658%]\n",
            "13607 [Discriminator loss: 0.6746%, acc.: 54.69%] [Generator loss: 0.7955%]\n",
            "13608 [Discriminator loss: 0.6567%, acc.: 60.94%] [Generator loss: 0.7944%]\n",
            "13609 [Discriminator loss: 0.6770%, acc.: 53.91%] [Generator loss: 0.8106%]\n",
            "13610 [Discriminator loss: 0.6574%, acc.: 60.55%] [Generator loss: 0.8036%]\n",
            "13611 [Discriminator loss: 0.6749%, acc.: 56.64%] [Generator loss: 0.8035%]\n",
            "13612 [Discriminator loss: 0.6573%, acc.: 60.94%] [Generator loss: 0.8009%]\n",
            "13613 [Discriminator loss: 0.6915%, acc.: 52.73%] [Generator loss: 0.7957%]\n",
            "13614 [Discriminator loss: 0.6748%, acc.: 57.03%] [Generator loss: 0.7883%]\n",
            "13615 [Discriminator loss: 0.6596%, acc.: 60.94%] [Generator loss: 0.7886%]\n",
            "13616 [Discriminator loss: 0.6641%, acc.: 58.59%] [Generator loss: 0.8068%]\n",
            "13617 [Discriminator loss: 0.6445%, acc.: 64.45%] [Generator loss: 0.7826%]\n",
            "13618 [Discriminator loss: 0.6792%, acc.: 58.20%] [Generator loss: 0.8399%]\n",
            "13619 [Discriminator loss: 0.6787%, acc.: 53.91%] [Generator loss: 0.8311%]\n",
            "13620 [Discriminator loss: 0.6568%, acc.: 59.38%] [Generator loss: 0.7994%]\n",
            "13621 [Discriminator loss: 0.6496%, acc.: 64.84%] [Generator loss: 0.7963%]\n",
            "13622 [Discriminator loss: 0.6666%, acc.: 56.64%] [Generator loss: 0.7929%]\n",
            "13623 [Discriminator loss: 0.6654%, acc.: 58.98%] [Generator loss: 0.8093%]\n",
            "13624 [Discriminator loss: 0.6545%, acc.: 63.28%] [Generator loss: 0.7916%]\n",
            "13625 [Discriminator loss: 0.6664%, acc.: 58.59%] [Generator loss: 0.7743%]\n",
            "13626 [Discriminator loss: 0.6829%, acc.: 54.30%] [Generator loss: 0.7717%]\n",
            "13627 [Discriminator loss: 0.6682%, acc.: 59.77%] [Generator loss: 0.7936%]\n",
            "13628 [Discriminator loss: 0.6668%, acc.: 60.55%] [Generator loss: 0.7830%]\n",
            "13629 [Discriminator loss: 0.6796%, acc.: 55.47%] [Generator loss: 0.8014%]\n",
            "13630 [Discriminator loss: 0.6625%, acc.: 58.20%] [Generator loss: 0.7922%]\n",
            "13631 [Discriminator loss: 0.6768%, acc.: 57.42%] [Generator loss: 0.7976%]\n",
            "13632 [Discriminator loss: 0.6575%, acc.: 62.50%] [Generator loss: 0.7867%]\n",
            "13633 [Discriminator loss: 0.6486%, acc.: 66.80%] [Generator loss: 0.8172%]\n",
            "13634 [Discriminator loss: 0.6687%, acc.: 57.81%] [Generator loss: 0.7887%]\n",
            "13635 [Discriminator loss: 0.6612%, acc.: 62.11%] [Generator loss: 0.7925%]\n",
            "13636 [Discriminator loss: 0.6614%, acc.: 60.55%] [Generator loss: 0.8059%]\n",
            "13637 [Discriminator loss: 0.6608%, acc.: 62.50%] [Generator loss: 0.7886%]\n",
            "13638 [Discriminator loss: 0.6757%, acc.: 60.16%] [Generator loss: 0.7748%]\n",
            "13639 [Discriminator loss: 0.6587%, acc.: 59.38%] [Generator loss: 0.7748%]\n",
            "13640 [Discriminator loss: 0.6812%, acc.: 55.47%] [Generator loss: 0.8131%]\n",
            "13641 [Discriminator loss: 0.6844%, acc.: 53.52%] [Generator loss: 0.8073%]\n",
            "13642 [Discriminator loss: 0.6729%, acc.: 55.86%] [Generator loss: 0.7978%]\n",
            "13643 [Discriminator loss: 0.6749%, acc.: 58.98%] [Generator loss: 0.7835%]\n",
            "13644 [Discriminator loss: 0.6705%, acc.: 58.59%] [Generator loss: 0.7964%]\n",
            "13645 [Discriminator loss: 0.6668%, acc.: 56.25%] [Generator loss: 0.7955%]\n",
            "13646 [Discriminator loss: 0.6740%, acc.: 57.42%] [Generator loss: 0.8124%]\n",
            "13647 [Discriminator loss: 0.6842%, acc.: 55.86%] [Generator loss: 0.7931%]\n",
            "13648 [Discriminator loss: 0.6610%, acc.: 62.11%] [Generator loss: 0.7941%]\n",
            "13649 [Discriminator loss: 0.6567%, acc.: 62.50%] [Generator loss: 0.7708%]\n",
            "13650 [Discriminator loss: 0.6717%, acc.: 60.16%] [Generator loss: 0.7865%]\n",
            "13651 [Discriminator loss: 0.6405%, acc.: 65.23%] [Generator loss: 0.7657%]\n",
            "13652 [Discriminator loss: 0.6674%, acc.: 59.77%] [Generator loss: 0.7757%]\n",
            "13653 [Discriminator loss: 0.6668%, acc.: 57.42%] [Generator loss: 0.7929%]\n",
            "13654 [Discriminator loss: 0.6763%, acc.: 57.42%] [Generator loss: 0.7748%]\n",
            "13655 [Discriminator loss: 0.6528%, acc.: 62.89%] [Generator loss: 0.7989%]\n",
            "13656 [Discriminator loss: 0.6675%, acc.: 57.42%] [Generator loss: 0.7999%]\n",
            "13657 [Discriminator loss: 0.6458%, acc.: 65.62%] [Generator loss: 0.8201%]\n",
            "13658 [Discriminator loss: 0.6779%, acc.: 57.03%] [Generator loss: 0.7830%]\n",
            "13659 [Discriminator loss: 0.6635%, acc.: 58.98%] [Generator loss: 0.7897%]\n",
            "13660 [Discriminator loss: 0.6673%, acc.: 57.42%] [Generator loss: 0.8078%]\n",
            "13661 [Discriminator loss: 0.6586%, acc.: 62.11%] [Generator loss: 0.8265%]\n",
            "13662 [Discriminator loss: 0.6675%, acc.: 58.59%] [Generator loss: 0.8309%]\n",
            "13663 [Discriminator loss: 0.6520%, acc.: 63.67%] [Generator loss: 0.7889%]\n",
            "13664 [Discriminator loss: 0.6629%, acc.: 57.81%] [Generator loss: 0.8232%]\n",
            "13665 [Discriminator loss: 0.6672%, acc.: 58.20%] [Generator loss: 0.7750%]\n",
            "13666 [Discriminator loss: 0.6749%, acc.: 55.86%] [Generator loss: 0.7637%]\n",
            "13667 [Discriminator loss: 0.6651%, acc.: 57.42%] [Generator loss: 0.7779%]\n",
            "13668 [Discriminator loss: 0.6687%, acc.: 59.77%] [Generator loss: 0.7921%]\n",
            "13669 [Discriminator loss: 0.6849%, acc.: 54.30%] [Generator loss: 0.7719%]\n",
            "13670 [Discriminator loss: 0.6682%, acc.: 57.03%] [Generator loss: 0.7949%]\n",
            "13671 [Discriminator loss: 0.6588%, acc.: 58.20%] [Generator loss: 0.8009%]\n",
            "13672 [Discriminator loss: 0.6891%, acc.: 51.95%] [Generator loss: 0.8060%]\n",
            "13673 [Discriminator loss: 0.6873%, acc.: 55.47%] [Generator loss: 0.8136%]\n",
            "13674 [Discriminator loss: 0.6707%, acc.: 56.64%] [Generator loss: 0.7710%]\n",
            "13675 [Discriminator loss: 0.6643%, acc.: 60.94%] [Generator loss: 0.7872%]\n",
            "13676 [Discriminator loss: 0.6542%, acc.: 60.16%] [Generator loss: 0.7841%]\n",
            "13677 [Discriminator loss: 0.6585%, acc.: 61.72%] [Generator loss: 0.8115%]\n",
            "13678 [Discriminator loss: 0.6737%, acc.: 56.64%] [Generator loss: 0.7769%]\n",
            "13679 [Discriminator loss: 0.6642%, acc.: 60.94%] [Generator loss: 0.7700%]\n",
            "13680 [Discriminator loss: 0.6559%, acc.: 62.89%] [Generator loss: 0.7863%]\n",
            "13681 [Discriminator loss: 0.6619%, acc.: 58.59%] [Generator loss: 0.8153%]\n",
            "13682 [Discriminator loss: 0.6787%, acc.: 61.72%] [Generator loss: 0.8037%]\n",
            "13683 [Discriminator loss: 0.6561%, acc.: 65.62%] [Generator loss: 0.7910%]\n",
            "13684 [Discriminator loss: 0.6523%, acc.: 66.02%] [Generator loss: 0.7864%]\n",
            "13685 [Discriminator loss: 0.6681%, acc.: 58.59%] [Generator loss: 0.7609%]\n",
            "13686 [Discriminator loss: 0.6577%, acc.: 60.94%] [Generator loss: 0.7817%]\n",
            "13687 [Discriminator loss: 0.6437%, acc.: 65.23%] [Generator loss: 0.7747%]\n",
            "13688 [Discriminator loss: 0.6868%, acc.: 57.42%] [Generator loss: 0.7984%]\n",
            "13689 [Discriminator loss: 0.6808%, acc.: 55.08%] [Generator loss: 0.7626%]\n",
            "13690 [Discriminator loss: 0.6554%, acc.: 62.11%] [Generator loss: 0.7842%]\n",
            "13691 [Discriminator loss: 0.6698%, acc.: 60.94%] [Generator loss: 0.7685%]\n",
            "13692 [Discriminator loss: 0.6725%, acc.: 60.55%] [Generator loss: 0.8071%]\n",
            "13693 [Discriminator loss: 0.6434%, acc.: 62.50%] [Generator loss: 0.8134%]\n",
            "13694 [Discriminator loss: 0.6579%, acc.: 63.28%] [Generator loss: 0.8027%]\n",
            "13695 [Discriminator loss: 0.6819%, acc.: 55.86%] [Generator loss: 0.7775%]\n",
            "13696 [Discriminator loss: 0.6625%, acc.: 62.11%] [Generator loss: 0.7909%]\n",
            "13697 [Discriminator loss: 0.6771%, acc.: 55.86%] [Generator loss: 0.7938%]\n",
            "13698 [Discriminator loss: 0.6538%, acc.: 60.55%] [Generator loss: 0.8269%]\n",
            "13699 [Discriminator loss: 0.6871%, acc.: 55.47%] [Generator loss: 0.8076%]\n",
            "13700 [Discriminator loss: 0.6624%, acc.: 58.20%] [Generator loss: 0.8176%]\n",
            "13701 [Discriminator loss: 0.6782%, acc.: 56.64%] [Generator loss: 0.8172%]\n",
            "13702 [Discriminator loss: 0.6813%, acc.: 57.03%] [Generator loss: 0.7961%]\n",
            "13703 [Discriminator loss: 0.6625%, acc.: 62.89%] [Generator loss: 0.8137%]\n",
            "13704 [Discriminator loss: 0.6505%, acc.: 66.41%] [Generator loss: 0.8000%]\n",
            "13705 [Discriminator loss: 0.6631%, acc.: 58.98%] [Generator loss: 0.7947%]\n",
            "13706 [Discriminator loss: 0.6742%, acc.: 60.55%] [Generator loss: 0.8000%]\n",
            "13707 [Discriminator loss: 0.6679%, acc.: 58.20%] [Generator loss: 0.7952%]\n",
            "13708 [Discriminator loss: 0.6929%, acc.: 50.78%] [Generator loss: 0.8030%]\n",
            "13709 [Discriminator loss: 0.6697%, acc.: 57.03%] [Generator loss: 0.8103%]\n",
            "13710 [Discriminator loss: 0.6809%, acc.: 53.52%] [Generator loss: 0.7908%]\n",
            "13711 [Discriminator loss: 0.6541%, acc.: 61.72%] [Generator loss: 0.8052%]\n",
            "13712 [Discriminator loss: 0.6617%, acc.: 60.16%] [Generator loss: 0.8169%]\n",
            "13713 [Discriminator loss: 0.6832%, acc.: 56.25%] [Generator loss: 0.7977%]\n",
            "13714 [Discriminator loss: 0.6836%, acc.: 53.12%] [Generator loss: 0.7849%]\n",
            "13715 [Discriminator loss: 0.6626%, acc.: 62.89%] [Generator loss: 0.7861%]\n",
            "13716 [Discriminator loss: 0.6726%, acc.: 57.03%] [Generator loss: 0.7809%]\n",
            "13717 [Discriminator loss: 0.6689%, acc.: 57.81%] [Generator loss: 0.8017%]\n",
            "13718 [Discriminator loss: 0.6529%, acc.: 67.19%] [Generator loss: 0.7788%]\n",
            "13719 [Discriminator loss: 0.6472%, acc.: 63.67%] [Generator loss: 0.7857%]\n",
            "13720 [Discriminator loss: 0.6968%, acc.: 54.30%] [Generator loss: 0.7600%]\n",
            "13721 [Discriminator loss: 0.6516%, acc.: 60.94%] [Generator loss: 0.7907%]\n",
            "13722 [Discriminator loss: 0.6817%, acc.: 57.81%] [Generator loss: 0.8120%]\n",
            "13723 [Discriminator loss: 0.6633%, acc.: 60.94%] [Generator loss: 0.7935%]\n",
            "13724 [Discriminator loss: 0.6687%, acc.: 60.16%] [Generator loss: 0.7907%]\n",
            "13725 [Discriminator loss: 0.6633%, acc.: 60.55%] [Generator loss: 0.7755%]\n",
            "13726 [Discriminator loss: 0.6699%, acc.: 58.20%] [Generator loss: 0.7984%]\n",
            "13727 [Discriminator loss: 0.6717%, acc.: 57.42%] [Generator loss: 0.8082%]\n",
            "13728 [Discriminator loss: 0.6934%, acc.: 55.47%] [Generator loss: 0.7769%]\n",
            "13729 [Discriminator loss: 0.6588%, acc.: 60.16%] [Generator loss: 0.7970%]\n",
            "13730 [Discriminator loss: 0.6640%, acc.: 58.59%] [Generator loss: 0.7931%]\n",
            "13731 [Discriminator loss: 0.6742%, acc.: 58.98%] [Generator loss: 0.7887%]\n",
            "13732 [Discriminator loss: 0.6785%, acc.: 57.42%] [Generator loss: 0.7653%]\n",
            "13733 [Discriminator loss: 0.6609%, acc.: 60.55%] [Generator loss: 0.7661%]\n",
            "13734 [Discriminator loss: 0.6652%, acc.: 60.94%] [Generator loss: 0.7880%]\n",
            "13735 [Discriminator loss: 0.6721%, acc.: 62.11%] [Generator loss: 0.7935%]\n",
            "13736 [Discriminator loss: 0.6744%, acc.: 55.86%] [Generator loss: 0.7876%]\n",
            "13737 [Discriminator loss: 0.6486%, acc.: 62.11%] [Generator loss: 0.8260%]\n",
            "13738 [Discriminator loss: 0.6952%, acc.: 51.56%] [Generator loss: 0.7983%]\n",
            "13739 [Discriminator loss: 0.6752%, acc.: 57.03%] [Generator loss: 0.8112%]\n",
            "13740 [Discriminator loss: 0.6595%, acc.: 62.11%] [Generator loss: 0.8144%]\n",
            "13741 [Discriminator loss: 0.6773%, acc.: 55.86%] [Generator loss: 0.7993%]\n",
            "13742 [Discriminator loss: 0.6924%, acc.: 52.73%] [Generator loss: 0.7941%]\n",
            "13743 [Discriminator loss: 0.6591%, acc.: 60.94%] [Generator loss: 0.8267%]\n",
            "13744 [Discriminator loss: 0.6807%, acc.: 54.30%] [Generator loss: 0.7918%]\n",
            "13745 [Discriminator loss: 0.6713%, acc.: 54.69%] [Generator loss: 0.8184%]\n",
            "13746 [Discriminator loss: 0.6982%, acc.: 51.17%] [Generator loss: 0.8061%]\n",
            "13747 [Discriminator loss: 0.6583%, acc.: 60.55%] [Generator loss: 0.8094%]\n",
            "13748 [Discriminator loss: 0.6834%, acc.: 58.20%] [Generator loss: 0.7805%]\n",
            "13749 [Discriminator loss: 0.6614%, acc.: 60.55%] [Generator loss: 0.7997%]\n",
            "13750 [Discriminator loss: 0.6740%, acc.: 57.81%] [Generator loss: 0.8104%]\n",
            "13751 [Discriminator loss: 0.6720%, acc.: 60.94%] [Generator loss: 0.8182%]\n",
            "13752 [Discriminator loss: 0.6725%, acc.: 56.25%] [Generator loss: 0.8069%]\n",
            "13753 [Discriminator loss: 0.6715%, acc.: 58.20%] [Generator loss: 0.8321%]\n",
            "13754 [Discriminator loss: 0.6660%, acc.: 60.55%] [Generator loss: 0.8141%]\n",
            "13755 [Discriminator loss: 0.6720%, acc.: 58.98%] [Generator loss: 0.8406%]\n",
            "13756 [Discriminator loss: 0.6618%, acc.: 56.25%] [Generator loss: 0.8092%]\n",
            "13757 [Discriminator loss: 0.6548%, acc.: 58.98%] [Generator loss: 0.8053%]\n",
            "13758 [Discriminator loss: 0.6673%, acc.: 60.55%] [Generator loss: 0.7682%]\n",
            "13759 [Discriminator loss: 0.6674%, acc.: 62.50%] [Generator loss: 0.7840%]\n",
            "13760 [Discriminator loss: 0.6626%, acc.: 59.38%] [Generator loss: 0.7792%]\n",
            "13761 [Discriminator loss: 0.6662%, acc.: 57.03%] [Generator loss: 0.7839%]\n",
            "13762 [Discriminator loss: 0.6664%, acc.: 58.20%] [Generator loss: 0.7964%]\n",
            "13763 [Discriminator loss: 0.6352%, acc.: 65.23%] [Generator loss: 0.7709%]\n",
            "13764 [Discriminator loss: 0.6627%, acc.: 61.33%] [Generator loss: 0.7720%]\n",
            "13765 [Discriminator loss: 0.6685%, acc.: 57.42%] [Generator loss: 0.7552%]\n",
            "13766 [Discriminator loss: 0.6513%, acc.: 62.11%] [Generator loss: 0.7914%]\n",
            "13767 [Discriminator loss: 0.6808%, acc.: 57.81%] [Generator loss: 0.7734%]\n",
            "13768 [Discriminator loss: 0.6797%, acc.: 53.52%] [Generator loss: 0.7794%]\n",
            "13769 [Discriminator loss: 0.6931%, acc.: 57.81%] [Generator loss: 0.7943%]\n",
            "13770 [Discriminator loss: 0.6621%, acc.: 58.20%] [Generator loss: 0.8127%]\n",
            "13771 [Discriminator loss: 0.6691%, acc.: 56.64%] [Generator loss: 0.8182%]\n",
            "13772 [Discriminator loss: 0.6768%, acc.: 54.30%] [Generator loss: 0.8175%]\n",
            "13773 [Discriminator loss: 0.6695%, acc.: 58.98%] [Generator loss: 0.8019%]\n",
            "13774 [Discriminator loss: 0.6674%, acc.: 59.38%] [Generator loss: 0.8194%]\n",
            "13775 [Discriminator loss: 0.6580%, acc.: 61.33%] [Generator loss: 0.7911%]\n",
            "13776 [Discriminator loss: 0.6767%, acc.: 57.03%] [Generator loss: 0.8231%]\n",
            "13777 [Discriminator loss: 0.6564%, acc.: 62.89%] [Generator loss: 0.8118%]\n",
            "13778 [Discriminator loss: 0.6747%, acc.: 58.98%] [Generator loss: 0.8430%]\n",
            "13779 [Discriminator loss: 0.6789%, acc.: 57.03%] [Generator loss: 0.7898%]\n",
            "13780 [Discriminator loss: 0.6612%, acc.: 64.06%] [Generator loss: 0.8023%]\n",
            "13781 [Discriminator loss: 0.6530%, acc.: 64.84%] [Generator loss: 0.8055%]\n",
            "13782 [Discriminator loss: 0.6828%, acc.: 57.03%] [Generator loss: 0.7970%]\n",
            "13783 [Discriminator loss: 0.6354%, acc.: 69.53%] [Generator loss: 0.7915%]\n",
            "13784 [Discriminator loss: 0.6670%, acc.: 57.03%] [Generator loss: 0.8231%]\n",
            "13785 [Discriminator loss: 0.6771%, acc.: 53.91%] [Generator loss: 0.8156%]\n",
            "13786 [Discriminator loss: 0.6733%, acc.: 58.98%] [Generator loss: 0.8059%]\n",
            "13787 [Discriminator loss: 0.6791%, acc.: 56.64%] [Generator loss: 0.8244%]\n",
            "13788 [Discriminator loss: 0.6835%, acc.: 54.30%] [Generator loss: 0.7902%]\n",
            "13789 [Discriminator loss: 0.6681%, acc.: 60.55%] [Generator loss: 0.7986%]\n",
            "13790 [Discriminator loss: 0.6756%, acc.: 58.59%] [Generator loss: 0.8143%]\n",
            "13791 [Discriminator loss: 0.6614%, acc.: 59.77%] [Generator loss: 0.8164%]\n",
            "13792 [Discriminator loss: 0.6611%, acc.: 64.06%] [Generator loss: 0.7919%]\n",
            "13793 [Discriminator loss: 0.6556%, acc.: 60.94%] [Generator loss: 0.8262%]\n",
            "13794 [Discriminator loss: 0.6525%, acc.: 64.45%] [Generator loss: 0.8248%]\n",
            "13795 [Discriminator loss: 0.6595%, acc.: 63.28%] [Generator loss: 0.7955%]\n",
            "13796 [Discriminator loss: 0.6657%, acc.: 60.16%] [Generator loss: 0.7813%]\n",
            "13797 [Discriminator loss: 0.6675%, acc.: 60.55%] [Generator loss: 0.7977%]\n",
            "13798 [Discriminator loss: 0.6571%, acc.: 60.94%] [Generator loss: 0.7773%]\n",
            "13799 [Discriminator loss: 0.6575%, acc.: 65.23%] [Generator loss: 0.7695%]\n",
            "13800 [Discriminator loss: 0.6572%, acc.: 61.72%] [Generator loss: 0.8243%]\n",
            "13801 [Discriminator loss: 0.6629%, acc.: 60.16%] [Generator loss: 0.7997%]\n",
            "13802 [Discriminator loss: 0.6460%, acc.: 64.45%] [Generator loss: 0.8174%]\n",
            "13803 [Discriminator loss: 0.6799%, acc.: 56.64%] [Generator loss: 0.7975%]\n",
            "13804 [Discriminator loss: 0.6533%, acc.: 61.72%] [Generator loss: 0.8106%]\n",
            "13805 [Discriminator loss: 0.6595%, acc.: 59.77%] [Generator loss: 0.8013%]\n",
            "13806 [Discriminator loss: 0.6790%, acc.: 57.81%] [Generator loss: 0.7926%]\n",
            "13807 [Discriminator loss: 0.6775%, acc.: 54.69%] [Generator loss: 0.7950%]\n",
            "13808 [Discriminator loss: 0.6802%, acc.: 55.47%] [Generator loss: 0.7918%]\n",
            "13809 [Discriminator loss: 0.6723%, acc.: 57.81%] [Generator loss: 0.7961%]\n",
            "13810 [Discriminator loss: 0.6727%, acc.: 57.81%] [Generator loss: 0.8072%]\n",
            "13811 [Discriminator loss: 0.6687%, acc.: 60.94%] [Generator loss: 0.8491%]\n",
            "13812 [Discriminator loss: 0.6738%, acc.: 56.25%] [Generator loss: 0.8407%]\n",
            "13813 [Discriminator loss: 0.6669%, acc.: 61.72%] [Generator loss: 0.8184%]\n",
            "13814 [Discriminator loss: 0.6556%, acc.: 63.67%] [Generator loss: 0.7876%]\n",
            "13815 [Discriminator loss: 0.6571%, acc.: 63.28%] [Generator loss: 0.8112%]\n",
            "13816 [Discriminator loss: 0.6569%, acc.: 58.59%] [Generator loss: 0.7949%]\n",
            "13817 [Discriminator loss: 0.6527%, acc.: 59.38%] [Generator loss: 0.7906%]\n",
            "13818 [Discriminator loss: 0.6395%, acc.: 63.67%] [Generator loss: 0.8083%]\n",
            "13819 [Discriminator loss: 0.6474%, acc.: 62.50%] [Generator loss: 0.8121%]\n",
            "13820 [Discriminator loss: 0.6784%, acc.: 54.69%] [Generator loss: 0.7931%]\n",
            "13821 [Discriminator loss: 0.6676%, acc.: 57.81%] [Generator loss: 0.8129%]\n",
            "13822 [Discriminator loss: 0.6497%, acc.: 64.45%] [Generator loss: 0.7920%]\n",
            "13823 [Discriminator loss: 0.6795%, acc.: 56.64%] [Generator loss: 0.7504%]\n",
            "13824 [Discriminator loss: 0.6638%, acc.: 61.72%] [Generator loss: 0.7827%]\n",
            "13825 [Discriminator loss: 0.6561%, acc.: 63.28%] [Generator loss: 0.8022%]\n",
            "13826 [Discriminator loss: 0.6565%, acc.: 61.72%] [Generator loss: 0.7968%]\n",
            "13827 [Discriminator loss: 0.6621%, acc.: 60.55%] [Generator loss: 0.8128%]\n",
            "13828 [Discriminator loss: 0.6737%, acc.: 53.91%] [Generator loss: 0.8090%]\n",
            "13829 [Discriminator loss: 0.6663%, acc.: 57.81%] [Generator loss: 0.7944%]\n",
            "13830 [Discriminator loss: 0.6554%, acc.: 60.94%] [Generator loss: 0.8337%]\n",
            "13831 [Discriminator loss: 0.6680%, acc.: 57.03%] [Generator loss: 0.7886%]\n",
            "13832 [Discriminator loss: 0.6634%, acc.: 62.11%] [Generator loss: 0.7713%]\n",
            "13833 [Discriminator loss: 0.6817%, acc.: 54.69%] [Generator loss: 0.8016%]\n",
            "13834 [Discriminator loss: 0.6638%, acc.: 60.16%] [Generator loss: 0.7773%]\n",
            "13835 [Discriminator loss: 0.6846%, acc.: 53.91%] [Generator loss: 0.7770%]\n",
            "13836 [Discriminator loss: 0.6488%, acc.: 65.62%] [Generator loss: 0.7663%]\n",
            "13837 [Discriminator loss: 0.6770%, acc.: 57.42%] [Generator loss: 0.7708%]\n",
            "13838 [Discriminator loss: 0.6587%, acc.: 61.33%] [Generator loss: 0.7875%]\n",
            "13839 [Discriminator loss: 0.6529%, acc.: 63.28%] [Generator loss: 0.7963%]\n",
            "13840 [Discriminator loss: 0.6663%, acc.: 60.94%] [Generator loss: 0.7988%]\n",
            "13841 [Discriminator loss: 0.6611%, acc.: 58.98%] [Generator loss: 0.8351%]\n",
            "13842 [Discriminator loss: 0.6778%, acc.: 57.81%] [Generator loss: 0.8121%]\n",
            "13843 [Discriminator loss: 0.6562%, acc.: 63.67%] [Generator loss: 0.8327%]\n",
            "13844 [Discriminator loss: 0.6632%, acc.: 58.20%] [Generator loss: 0.8206%]\n",
            "13845 [Discriminator loss: 0.6737%, acc.: 60.16%] [Generator loss: 0.8097%]\n",
            "13846 [Discriminator loss: 0.6656%, acc.: 61.33%] [Generator loss: 0.7921%]\n",
            "13847 [Discriminator loss: 0.6767%, acc.: 56.25%] [Generator loss: 0.7753%]\n",
            "13848 [Discriminator loss: 0.6735%, acc.: 58.59%] [Generator loss: 0.8022%]\n",
            "13849 [Discriminator loss: 0.6820%, acc.: 56.64%] [Generator loss: 0.7878%]\n",
            "13850 [Discriminator loss: 0.6829%, acc.: 56.25%] [Generator loss: 0.8158%]\n",
            "13851 [Discriminator loss: 0.6686%, acc.: 58.20%] [Generator loss: 0.7822%]\n",
            "13852 [Discriminator loss: 0.6850%, acc.: 55.47%] [Generator loss: 0.8045%]\n",
            "13853 [Discriminator loss: 0.6787%, acc.: 57.42%] [Generator loss: 0.8228%]\n",
            "13854 [Discriminator loss: 0.6693%, acc.: 58.20%] [Generator loss: 0.8117%]\n",
            "13855 [Discriminator loss: 0.6666%, acc.: 60.55%] [Generator loss: 0.8239%]\n",
            "13856 [Discriminator loss: 0.6573%, acc.: 63.67%] [Generator loss: 0.8027%]\n",
            "13857 [Discriminator loss: 0.6632%, acc.: 59.77%] [Generator loss: 0.8209%]\n",
            "13858 [Discriminator loss: 0.6735%, acc.: 58.98%] [Generator loss: 0.8102%]\n",
            "13859 [Discriminator loss: 0.6787%, acc.: 55.47%] [Generator loss: 0.8124%]\n",
            "13860 [Discriminator loss: 0.6726%, acc.: 55.47%] [Generator loss: 0.7946%]\n",
            "13861 [Discriminator loss: 0.6773%, acc.: 56.25%] [Generator loss: 0.7834%]\n",
            "13862 [Discriminator loss: 0.6548%, acc.: 62.89%] [Generator loss: 0.7766%]\n",
            "13863 [Discriminator loss: 0.6426%, acc.: 64.06%] [Generator loss: 0.8014%]\n",
            "13864 [Discriminator loss: 0.6660%, acc.: 61.72%] [Generator loss: 0.8045%]\n",
            "13865 [Discriminator loss: 0.6678%, acc.: 55.47%] [Generator loss: 0.8000%]\n",
            "13866 [Discriminator loss: 0.6671%, acc.: 62.89%] [Generator loss: 0.8011%]\n",
            "13867 [Discriminator loss: 0.6742%, acc.: 55.08%] [Generator loss: 0.8001%]\n",
            "13868 [Discriminator loss: 0.6600%, acc.: 60.16%] [Generator loss: 0.7952%]\n",
            "13869 [Discriminator loss: 0.6353%, acc.: 67.19%] [Generator loss: 0.7979%]\n",
            "13870 [Discriminator loss: 0.6525%, acc.: 62.89%] [Generator loss: 0.7899%]\n",
            "13871 [Discriminator loss: 0.6640%, acc.: 59.38%] [Generator loss: 0.7944%]\n",
            "13872 [Discriminator loss: 0.6794%, acc.: 56.25%] [Generator loss: 0.7900%]\n",
            "13873 [Discriminator loss: 0.6777%, acc.: 60.16%] [Generator loss: 0.8067%]\n",
            "13874 [Discriminator loss: 0.6652%, acc.: 60.16%] [Generator loss: 0.8242%]\n",
            "13875 [Discriminator loss: 0.6442%, acc.: 63.67%] [Generator loss: 0.7934%]\n",
            "13876 [Discriminator loss: 0.6697%, acc.: 64.45%] [Generator loss: 0.8020%]\n",
            "13877 [Discriminator loss: 0.6569%, acc.: 60.16%] [Generator loss: 0.8003%]\n",
            "13878 [Discriminator loss: 0.6938%, acc.: 52.73%] [Generator loss: 0.7935%]\n",
            "13879 [Discriminator loss: 0.6527%, acc.: 62.11%] [Generator loss: 0.8239%]\n",
            "13880 [Discriminator loss: 0.6618%, acc.: 59.77%] [Generator loss: 0.8025%]\n",
            "13881 [Discriminator loss: 0.6885%, acc.: 54.30%] [Generator loss: 0.8088%]\n",
            "13882 [Discriminator loss: 0.6654%, acc.: 58.59%] [Generator loss: 0.7529%]\n",
            "13883 [Discriminator loss: 0.6483%, acc.: 60.55%] [Generator loss: 0.7916%]\n",
            "13884 [Discriminator loss: 0.6625%, acc.: 61.33%] [Generator loss: 0.7645%]\n",
            "13885 [Discriminator loss: 0.6602%, acc.: 60.55%] [Generator loss: 0.8114%]\n",
            "13886 [Discriminator loss: 0.6809%, acc.: 57.81%] [Generator loss: 0.7787%]\n",
            "13887 [Discriminator loss: 0.6758%, acc.: 56.25%] [Generator loss: 0.7857%]\n",
            "13888 [Discriminator loss: 0.6686%, acc.: 57.81%] [Generator loss: 0.8079%]\n",
            "13889 [Discriminator loss: 0.6703%, acc.: 58.59%] [Generator loss: 0.7877%]\n",
            "13890 [Discriminator loss: 0.6585%, acc.: 57.81%] [Generator loss: 0.7742%]\n",
            "13891 [Discriminator loss: 0.6526%, acc.: 64.06%] [Generator loss: 0.7576%]\n",
            "13892 [Discriminator loss: 0.6689%, acc.: 57.42%] [Generator loss: 0.7951%]\n",
            "13893 [Discriminator loss: 0.6527%, acc.: 64.06%] [Generator loss: 0.8195%]\n",
            "13894 [Discriminator loss: 0.6703%, acc.: 55.47%] [Generator loss: 0.7739%]\n",
            "13895 [Discriminator loss: 0.6655%, acc.: 58.59%] [Generator loss: 0.7850%]\n",
            "13896 [Discriminator loss: 0.6506%, acc.: 63.67%] [Generator loss: 0.7782%]\n",
            "13897 [Discriminator loss: 0.6745%, acc.: 55.47%] [Generator loss: 0.8060%]\n",
            "13898 [Discriminator loss: 0.6863%, acc.: 53.91%] [Generator loss: 0.7860%]\n",
            "13899 [Discriminator loss: 0.6714%, acc.: 56.25%] [Generator loss: 0.7735%]\n",
            "13900 [Discriminator loss: 0.6632%, acc.: 58.20%] [Generator loss: 0.7938%]\n",
            "13901 [Discriminator loss: 0.6678%, acc.: 57.42%] [Generator loss: 0.7857%]\n",
            "13902 [Discriminator loss: 0.6776%, acc.: 55.47%] [Generator loss: 0.7919%]\n",
            "13903 [Discriminator loss: 0.6650%, acc.: 61.33%] [Generator loss: 0.7840%]\n",
            "13904 [Discriminator loss: 0.6592%, acc.: 62.11%] [Generator loss: 0.7993%]\n",
            "13905 [Discriminator loss: 0.6442%, acc.: 63.28%] [Generator loss: 0.7951%]\n",
            "13906 [Discriminator loss: 0.6844%, acc.: 55.86%] [Generator loss: 0.8006%]\n",
            "13907 [Discriminator loss: 0.6599%, acc.: 58.98%] [Generator loss: 0.8066%]\n",
            "13908 [Discriminator loss: 0.6751%, acc.: 59.77%] [Generator loss: 0.8009%]\n",
            "13909 [Discriminator loss: 0.6690%, acc.: 57.42%] [Generator loss: 0.7692%]\n",
            "13910 [Discriminator loss: 0.6748%, acc.: 58.20%] [Generator loss: 0.8046%]\n",
            "13911 [Discriminator loss: 0.6451%, acc.: 62.50%] [Generator loss: 0.7864%]\n",
            "13912 [Discriminator loss: 0.6614%, acc.: 61.33%] [Generator loss: 0.7783%]\n",
            "13913 [Discriminator loss: 0.6722%, acc.: 58.59%] [Generator loss: 0.7889%]\n",
            "13914 [Discriminator loss: 0.6526%, acc.: 63.28%] [Generator loss: 0.7817%]\n",
            "13915 [Discriminator loss: 0.6656%, acc.: 58.20%] [Generator loss: 0.7817%]\n",
            "13916 [Discriminator loss: 0.6834%, acc.: 55.86%] [Generator loss: 0.8025%]\n",
            "13917 [Discriminator loss: 0.6692%, acc.: 57.81%] [Generator loss: 0.7856%]\n",
            "13918 [Discriminator loss: 0.6558%, acc.: 63.28%] [Generator loss: 0.8090%]\n",
            "13919 [Discriminator loss: 0.6690%, acc.: 59.77%] [Generator loss: 0.7776%]\n",
            "13920 [Discriminator loss: 0.6597%, acc.: 64.84%] [Generator loss: 0.7832%]\n",
            "13921 [Discriminator loss: 0.6675%, acc.: 57.03%] [Generator loss: 0.7778%]\n",
            "13922 [Discriminator loss: 0.6665%, acc.: 61.72%] [Generator loss: 0.7949%]\n",
            "13923 [Discriminator loss: 0.6538%, acc.: 62.11%] [Generator loss: 0.8016%]\n",
            "13924 [Discriminator loss: 0.6662%, acc.: 57.42%] [Generator loss: 0.7778%]\n",
            "13925 [Discriminator loss: 0.6578%, acc.: 59.38%] [Generator loss: 0.7673%]\n",
            "13926 [Discriminator loss: 0.6624%, acc.: 58.98%] [Generator loss: 0.8064%]\n",
            "13927 [Discriminator loss: 0.6698%, acc.: 56.64%] [Generator loss: 0.8101%]\n",
            "13928 [Discriminator loss: 0.6534%, acc.: 58.98%] [Generator loss: 0.8020%]\n",
            "13929 [Discriminator loss: 0.6790%, acc.: 56.64%] [Generator loss: 0.8015%]\n",
            "13930 [Discriminator loss: 0.6692%, acc.: 54.69%] [Generator loss: 0.8043%]\n",
            "13931 [Discriminator loss: 0.6833%, acc.: 54.30%] [Generator loss: 0.7819%]\n",
            "13932 [Discriminator loss: 0.6776%, acc.: 57.42%] [Generator loss: 0.8210%]\n",
            "13933 [Discriminator loss: 0.6730%, acc.: 53.52%] [Generator loss: 0.8191%]\n",
            "13934 [Discriminator loss: 0.6719%, acc.: 57.81%] [Generator loss: 0.8032%]\n",
            "13935 [Discriminator loss: 0.6548%, acc.: 61.33%] [Generator loss: 0.7829%]\n",
            "13936 [Discriminator loss: 0.6635%, acc.: 60.16%] [Generator loss: 0.8106%]\n",
            "13937 [Discriminator loss: 0.6704%, acc.: 61.33%] [Generator loss: 0.7917%]\n",
            "13938 [Discriminator loss: 0.6576%, acc.: 62.89%] [Generator loss: 0.7657%]\n",
            "13939 [Discriminator loss: 0.6609%, acc.: 60.55%] [Generator loss: 0.7811%]\n",
            "13940 [Discriminator loss: 0.6675%, acc.: 60.16%] [Generator loss: 0.7835%]\n",
            "13941 [Discriminator loss: 0.6582%, acc.: 58.98%] [Generator loss: 0.7654%]\n",
            "13942 [Discriminator loss: 0.6769%, acc.: 56.64%] [Generator loss: 0.7819%]\n",
            "13943 [Discriminator loss: 0.6539%, acc.: 65.23%] [Generator loss: 0.7424%]\n",
            "13944 [Discriminator loss: 0.6817%, acc.: 55.86%] [Generator loss: 0.7689%]\n",
            "13945 [Discriminator loss: 0.6843%, acc.: 55.47%] [Generator loss: 0.7900%]\n",
            "13946 [Discriminator loss: 0.6889%, acc.: 55.86%] [Generator loss: 0.7800%]\n",
            "13947 [Discriminator loss: 0.6459%, acc.: 63.28%] [Generator loss: 0.7855%]\n",
            "13948 [Discriminator loss: 0.6491%, acc.: 66.02%] [Generator loss: 0.8090%]\n",
            "13949 [Discriminator loss: 0.6861%, acc.: 57.81%] [Generator loss: 0.7833%]\n",
            "13950 [Discriminator loss: 0.6748%, acc.: 58.59%] [Generator loss: 0.8019%]\n",
            "13951 [Discriminator loss: 0.6667%, acc.: 57.42%] [Generator loss: 0.7996%]\n",
            "13952 [Discriminator loss: 0.6810%, acc.: 55.86%] [Generator loss: 0.8132%]\n",
            "13953 [Discriminator loss: 0.6420%, acc.: 62.11%] [Generator loss: 0.7871%]\n",
            "13954 [Discriminator loss: 0.6550%, acc.: 58.20%] [Generator loss: 0.8018%]\n",
            "13955 [Discriminator loss: 0.6712%, acc.: 56.64%] [Generator loss: 0.7813%]\n",
            "13956 [Discriminator loss: 0.6563%, acc.: 60.55%] [Generator loss: 0.7914%]\n",
            "13957 [Discriminator loss: 0.6779%, acc.: 55.86%] [Generator loss: 0.7867%]\n",
            "13958 [Discriminator loss: 0.6615%, acc.: 58.98%] [Generator loss: 0.7802%]\n",
            "13959 [Discriminator loss: 0.6561%, acc.: 61.72%] [Generator loss: 0.8074%]\n",
            "13960 [Discriminator loss: 0.6699%, acc.: 57.42%] [Generator loss: 0.7850%]\n",
            "13961 [Discriminator loss: 0.6506%, acc.: 63.28%] [Generator loss: 0.8462%]\n",
            "13962 [Discriminator loss: 0.6807%, acc.: 53.12%] [Generator loss: 0.8021%]\n",
            "13963 [Discriminator loss: 0.6742%, acc.: 62.89%] [Generator loss: 0.7924%]\n",
            "13964 [Discriminator loss: 0.6727%, acc.: 58.98%] [Generator loss: 0.7861%]\n",
            "13965 [Discriminator loss: 0.6702%, acc.: 58.59%] [Generator loss: 0.8024%]\n",
            "13966 [Discriminator loss: 0.6780%, acc.: 59.38%] [Generator loss: 0.8000%]\n",
            "13967 [Discriminator loss: 0.6846%, acc.: 59.77%] [Generator loss: 0.7991%]\n",
            "13968 [Discriminator loss: 0.6784%, acc.: 57.03%] [Generator loss: 0.7722%]\n",
            "13969 [Discriminator loss: 0.6569%, acc.: 59.77%] [Generator loss: 0.8212%]\n",
            "13970 [Discriminator loss: 0.6581%, acc.: 64.45%] [Generator loss: 0.8197%]\n",
            "13971 [Discriminator loss: 0.6786%, acc.: 57.42%] [Generator loss: 0.8025%]\n",
            "13972 [Discriminator loss: 0.6736%, acc.: 59.38%] [Generator loss: 0.7823%]\n",
            "13973 [Discriminator loss: 0.6702%, acc.: 57.03%] [Generator loss: 0.7977%]\n",
            "13974 [Discriminator loss: 0.6640%, acc.: 57.81%] [Generator loss: 0.8266%]\n",
            "13975 [Discriminator loss: 0.6678%, acc.: 61.33%] [Generator loss: 0.7870%]\n",
            "13976 [Discriminator loss: 0.6719%, acc.: 63.28%] [Generator loss: 0.7816%]\n",
            "13977 [Discriminator loss: 0.6710%, acc.: 59.38%] [Generator loss: 0.7782%]\n",
            "13978 [Discriminator loss: 0.6880%, acc.: 50.78%] [Generator loss: 0.8018%]\n",
            "13979 [Discriminator loss: 0.6688%, acc.: 58.98%] [Generator loss: 0.7762%]\n",
            "13980 [Discriminator loss: 0.6754%, acc.: 57.81%] [Generator loss: 0.7793%]\n",
            "13981 [Discriminator loss: 0.6509%, acc.: 63.28%] [Generator loss: 0.8189%]\n",
            "13982 [Discriminator loss: 0.6744%, acc.: 60.94%] [Generator loss: 0.7974%]\n",
            "13983 [Discriminator loss: 0.6522%, acc.: 63.67%] [Generator loss: 0.7880%]\n",
            "13984 [Discriminator loss: 0.6793%, acc.: 54.69%] [Generator loss: 0.7842%]\n",
            "13985 [Discriminator loss: 0.6663%, acc.: 59.77%] [Generator loss: 0.7709%]\n",
            "13986 [Discriminator loss: 0.6744%, acc.: 57.81%] [Generator loss: 0.8001%]\n",
            "13987 [Discriminator loss: 0.6712%, acc.: 60.55%] [Generator loss: 0.7776%]\n",
            "13988 [Discriminator loss: 0.6685%, acc.: 58.20%] [Generator loss: 0.7791%]\n",
            "13989 [Discriminator loss: 0.6647%, acc.: 58.59%] [Generator loss: 0.7755%]\n",
            "13990 [Discriminator loss: 0.6666%, acc.: 61.72%] [Generator loss: 0.7565%]\n",
            "13991 [Discriminator loss: 0.6744%, acc.: 55.08%] [Generator loss: 0.8120%]\n",
            "13992 [Discriminator loss: 0.6504%, acc.: 62.89%] [Generator loss: 0.7938%]\n",
            "13993 [Discriminator loss: 0.6712%, acc.: 58.98%] [Generator loss: 0.7918%]\n",
            "13994 [Discriminator loss: 0.6658%, acc.: 57.42%] [Generator loss: 0.8005%]\n",
            "13995 [Discriminator loss: 0.6463%, acc.: 66.41%] [Generator loss: 0.8115%]\n",
            "13996 [Discriminator loss: 0.6686%, acc.: 62.11%] [Generator loss: 0.7864%]\n",
            "13997 [Discriminator loss: 0.6560%, acc.: 62.50%] [Generator loss: 0.8000%]\n",
            "13998 [Discriminator loss: 0.6750%, acc.: 55.47%] [Generator loss: 0.8068%]\n",
            "13999 [Discriminator loss: 0.6779%, acc.: 54.69%] [Generator loss: 0.7798%]\n",
            "14000 [Discriminator loss: 0.6707%, acc.: 59.77%] [Generator loss: 0.8095%]\n",
            "14001 [Discriminator loss: 0.6650%, acc.: 58.98%] [Generator loss: 0.8028%]\n",
            "14002 [Discriminator loss: 0.6585%, acc.: 59.38%] [Generator loss: 0.8020%]\n",
            "14003 [Discriminator loss: 0.6565%, acc.: 60.94%] [Generator loss: 0.8146%]\n",
            "14004 [Discriminator loss: 0.6559%, acc.: 63.28%] [Generator loss: 0.8313%]\n",
            "14005 [Discriminator loss: 0.6786%, acc.: 55.47%] [Generator loss: 0.8304%]\n",
            "14006 [Discriminator loss: 0.6844%, acc.: 55.86%] [Generator loss: 0.8062%]\n",
            "14007 [Discriminator loss: 0.6570%, acc.: 63.67%] [Generator loss: 0.8282%]\n",
            "14008 [Discriminator loss: 0.6755%, acc.: 59.77%] [Generator loss: 0.7964%]\n",
            "14009 [Discriminator loss: 0.6401%, acc.: 66.41%] [Generator loss: 0.8365%]\n",
            "14010 [Discriminator loss: 0.6760%, acc.: 55.08%] [Generator loss: 0.7958%]\n",
            "14011 [Discriminator loss: 0.6643%, acc.: 58.59%] [Generator loss: 0.7967%]\n",
            "14012 [Discriminator loss: 0.6810%, acc.: 58.20%] [Generator loss: 0.8198%]\n",
            "14013 [Discriminator loss: 0.6657%, acc.: 62.11%] [Generator loss: 0.8028%]\n",
            "14014 [Discriminator loss: 0.6599%, acc.: 58.98%] [Generator loss: 0.8072%]\n",
            "14015 [Discriminator loss: 0.6675%, acc.: 56.64%] [Generator loss: 0.8397%]\n",
            "14016 [Discriminator loss: 0.6641%, acc.: 58.20%] [Generator loss: 0.8250%]\n",
            "14017 [Discriminator loss: 0.6572%, acc.: 59.77%] [Generator loss: 0.7709%]\n",
            "14018 [Discriminator loss: 0.6605%, acc.: 60.16%] [Generator loss: 0.7714%]\n",
            "14019 [Discriminator loss: 0.6682%, acc.: 58.59%] [Generator loss: 0.7771%]\n",
            "14020 [Discriminator loss: 0.6786%, acc.: 55.47%] [Generator loss: 0.7881%]\n",
            "14021 [Discriminator loss: 0.6761%, acc.: 53.12%] [Generator loss: 0.7871%]\n",
            "14022 [Discriminator loss: 0.6498%, acc.: 66.02%] [Generator loss: 0.7833%]\n",
            "14023 [Discriminator loss: 0.6557%, acc.: 60.55%] [Generator loss: 0.7616%]\n",
            "14024 [Discriminator loss: 0.6701%, acc.: 61.33%] [Generator loss: 0.7981%]\n",
            "14025 [Discriminator loss: 0.6898%, acc.: 56.64%] [Generator loss: 0.7952%]\n",
            "14026 [Discriminator loss: 0.6690%, acc.: 60.55%] [Generator loss: 0.7952%]\n",
            "14027 [Discriminator loss: 0.6662%, acc.: 61.72%] [Generator loss: 0.8150%]\n",
            "14028 [Discriminator loss: 0.6848%, acc.: 55.47%] [Generator loss: 0.8251%]\n",
            "14029 [Discriminator loss: 0.6754%, acc.: 59.77%] [Generator loss: 0.7918%]\n",
            "14030 [Discriminator loss: 0.6819%, acc.: 53.91%] [Generator loss: 0.8119%]\n",
            "14031 [Discriminator loss: 0.6737%, acc.: 58.59%] [Generator loss: 0.7715%]\n",
            "14032 [Discriminator loss: 0.6679%, acc.: 57.81%] [Generator loss: 0.8150%]\n",
            "14033 [Discriminator loss: 0.6564%, acc.: 61.72%] [Generator loss: 0.8185%]\n",
            "14034 [Discriminator loss: 0.6503%, acc.: 60.16%] [Generator loss: 0.8174%]\n",
            "14035 [Discriminator loss: 0.6529%, acc.: 61.33%] [Generator loss: 0.7776%]\n",
            "14036 [Discriminator loss: 0.6777%, acc.: 56.64%] [Generator loss: 0.7711%]\n",
            "14037 [Discriminator loss: 0.6719%, acc.: 54.69%] [Generator loss: 0.7814%]\n",
            "14038 [Discriminator loss: 0.6616%, acc.: 60.55%] [Generator loss: 0.8003%]\n",
            "14039 [Discriminator loss: 0.6705%, acc.: 60.55%] [Generator loss: 0.7614%]\n",
            "14040 [Discriminator loss: 0.6694%, acc.: 55.47%] [Generator loss: 0.7847%]\n",
            "14041 [Discriminator loss: 0.6543%, acc.: 62.50%] [Generator loss: 0.8049%]\n",
            "14042 [Discriminator loss: 0.6738%, acc.: 58.59%] [Generator loss: 0.7736%]\n",
            "14043 [Discriminator loss: 0.6606%, acc.: 61.33%] [Generator loss: 0.7926%]\n",
            "14044 [Discriminator loss: 0.6609%, acc.: 58.59%] [Generator loss: 0.8067%]\n",
            "14045 [Discriminator loss: 0.6930%, acc.: 55.86%] [Generator loss: 0.8179%]\n",
            "14046 [Discriminator loss: 0.6418%, acc.: 63.28%] [Generator loss: 0.8169%]\n",
            "14047 [Discriminator loss: 0.6608%, acc.: 59.38%] [Generator loss: 0.7938%]\n",
            "14048 [Discriminator loss: 0.6795%, acc.: 53.12%] [Generator loss: 0.8055%]\n",
            "14049 [Discriminator loss: 0.6688%, acc.: 56.64%] [Generator loss: 0.7993%]\n",
            "14050 [Discriminator loss: 0.6543%, acc.: 60.55%] [Generator loss: 0.7674%]\n",
            "14051 [Discriminator loss: 0.6606%, acc.: 58.59%] [Generator loss: 0.8208%]\n",
            "14052 [Discriminator loss: 0.6555%, acc.: 60.55%] [Generator loss: 0.7750%]\n",
            "14053 [Discriminator loss: 0.6458%, acc.: 67.58%] [Generator loss: 0.7962%]\n",
            "14054 [Discriminator loss: 0.6763%, acc.: 55.86%] [Generator loss: 0.7815%]\n",
            "14055 [Discriminator loss: 0.6548%, acc.: 57.81%] [Generator loss: 0.7873%]\n",
            "14056 [Discriminator loss: 0.6703%, acc.: 58.59%] [Generator loss: 0.8177%]\n",
            "14057 [Discriminator loss: 0.6646%, acc.: 59.77%] [Generator loss: 0.7942%]\n",
            "14058 [Discriminator loss: 0.6379%, acc.: 65.62%] [Generator loss: 0.8026%]\n",
            "14059 [Discriminator loss: 0.6758%, acc.: 58.59%] [Generator loss: 0.7910%]\n",
            "14060 [Discriminator loss: 0.6806%, acc.: 56.64%] [Generator loss: 0.7731%]\n",
            "14061 [Discriminator loss: 0.6641%, acc.: 59.38%] [Generator loss: 0.7795%]\n",
            "14062 [Discriminator loss: 0.6571%, acc.: 60.94%] [Generator loss: 0.7988%]\n",
            "14063 [Discriminator loss: 0.6680%, acc.: 58.20%] [Generator loss: 0.8112%]\n",
            "14064 [Discriminator loss: 0.6642%, acc.: 57.42%] [Generator loss: 0.8216%]\n",
            "14065 [Discriminator loss: 0.6767%, acc.: 57.42%] [Generator loss: 0.8238%]\n",
            "14066 [Discriminator loss: 0.6764%, acc.: 56.25%] [Generator loss: 0.7972%]\n",
            "14067 [Discriminator loss: 0.6696%, acc.: 58.59%] [Generator loss: 0.7951%]\n",
            "14068 [Discriminator loss: 0.6862%, acc.: 55.47%] [Generator loss: 0.7965%]\n",
            "14069 [Discriminator loss: 0.6523%, acc.: 64.45%] [Generator loss: 0.7939%]\n",
            "14070 [Discriminator loss: 0.6736%, acc.: 58.59%] [Generator loss: 0.7947%]\n",
            "14071 [Discriminator loss: 0.6676%, acc.: 59.38%] [Generator loss: 0.7944%]\n",
            "14072 [Discriminator loss: 0.6653%, acc.: 59.77%] [Generator loss: 0.7984%]\n",
            "14073 [Discriminator loss: 0.6682%, acc.: 59.77%] [Generator loss: 0.7758%]\n",
            "14074 [Discriminator loss: 0.6485%, acc.: 64.45%] [Generator loss: 0.7685%]\n",
            "14075 [Discriminator loss: 0.6464%, acc.: 65.62%] [Generator loss: 0.8104%]\n",
            "14076 [Discriminator loss: 0.6522%, acc.: 62.11%] [Generator loss: 0.7893%]\n",
            "14077 [Discriminator loss: 0.6727%, acc.: 57.42%] [Generator loss: 0.7646%]\n",
            "14078 [Discriminator loss: 0.6792%, acc.: 58.98%] [Generator loss: 0.7821%]\n",
            "14079 [Discriminator loss: 0.6634%, acc.: 60.94%] [Generator loss: 0.7884%]\n",
            "14080 [Discriminator loss: 0.6822%, acc.: 59.77%] [Generator loss: 0.7916%]\n",
            "14081 [Discriminator loss: 0.6687%, acc.: 59.77%] [Generator loss: 0.8003%]\n",
            "14082 [Discriminator loss: 0.6597%, acc.: 61.72%] [Generator loss: 0.7839%]\n",
            "14083 [Discriminator loss: 0.6619%, acc.: 60.16%] [Generator loss: 0.8117%]\n",
            "14084 [Discriminator loss: 0.6750%, acc.: 59.77%] [Generator loss: 0.8175%]\n",
            "14085 [Discriminator loss: 0.6543%, acc.: 59.38%] [Generator loss: 0.7841%]\n",
            "14086 [Discriminator loss: 0.6513%, acc.: 60.16%] [Generator loss: 0.7946%]\n",
            "14087 [Discriminator loss: 0.6525%, acc.: 64.84%] [Generator loss: 0.8158%]\n",
            "14088 [Discriminator loss: 0.6584%, acc.: 62.50%] [Generator loss: 0.8099%]\n",
            "14089 [Discriminator loss: 0.6689%, acc.: 56.64%] [Generator loss: 0.7892%]\n",
            "14090 [Discriminator loss: 0.6764%, acc.: 55.08%] [Generator loss: 0.7968%]\n",
            "14091 [Discriminator loss: 0.6678%, acc.: 58.98%] [Generator loss: 0.8032%]\n",
            "14092 [Discriminator loss: 0.6679%, acc.: 57.03%] [Generator loss: 0.7815%]\n",
            "14093 [Discriminator loss: 0.6551%, acc.: 62.89%] [Generator loss: 0.8154%]\n",
            "14094 [Discriminator loss: 0.6623%, acc.: 64.45%] [Generator loss: 0.7969%]\n",
            "14095 [Discriminator loss: 0.6760%, acc.: 55.08%] [Generator loss: 0.7858%]\n",
            "14096 [Discriminator loss: 0.6728%, acc.: 57.81%] [Generator loss: 0.7842%]\n",
            "14097 [Discriminator loss: 0.6816%, acc.: 53.91%] [Generator loss: 0.8011%]\n",
            "14098 [Discriminator loss: 0.6675%, acc.: 59.77%] [Generator loss: 0.7911%]\n",
            "14099 [Discriminator loss: 0.6763%, acc.: 60.16%] [Generator loss: 0.8154%]\n",
            "14100 [Discriminator loss: 0.6772%, acc.: 55.86%] [Generator loss: 0.7963%]\n",
            "14101 [Discriminator loss: 0.6711%, acc.: 59.77%] [Generator loss: 0.7941%]\n",
            "14102 [Discriminator loss: 0.6618%, acc.: 60.55%] [Generator loss: 0.8328%]\n",
            "14103 [Discriminator loss: 0.6606%, acc.: 58.20%] [Generator loss: 0.7999%]\n",
            "14104 [Discriminator loss: 0.6559%, acc.: 60.55%] [Generator loss: 0.8114%]\n",
            "14105 [Discriminator loss: 0.6624%, acc.: 61.33%] [Generator loss: 0.8097%]\n",
            "14106 [Discriminator loss: 0.6497%, acc.: 63.67%] [Generator loss: 0.8115%]\n",
            "14107 [Discriminator loss: 0.6760%, acc.: 55.47%] [Generator loss: 0.8118%]\n",
            "14108 [Discriminator loss: 0.6610%, acc.: 64.45%] [Generator loss: 0.8195%]\n",
            "14109 [Discriminator loss: 0.6570%, acc.: 62.11%] [Generator loss: 0.8052%]\n",
            "14110 [Discriminator loss: 0.6674%, acc.: 55.86%] [Generator loss: 0.8220%]\n",
            "14111 [Discriminator loss: 0.6520%, acc.: 62.50%] [Generator loss: 0.8221%]\n",
            "14112 [Discriminator loss: 0.6568%, acc.: 61.33%] [Generator loss: 0.7683%]\n",
            "14113 [Discriminator loss: 0.6635%, acc.: 62.11%] [Generator loss: 0.7620%]\n",
            "14114 [Discriminator loss: 0.6467%, acc.: 61.33%] [Generator loss: 0.7886%]\n",
            "14115 [Discriminator loss: 0.6735%, acc.: 55.47%] [Generator loss: 0.8195%]\n",
            "14116 [Discriminator loss: 0.6757%, acc.: 60.16%] [Generator loss: 0.7811%]\n",
            "14117 [Discriminator loss: 0.6602%, acc.: 62.11%] [Generator loss: 0.7990%]\n",
            "14118 [Discriminator loss: 0.6620%, acc.: 58.98%] [Generator loss: 0.7874%]\n",
            "14119 [Discriminator loss: 0.6692%, acc.: 58.98%] [Generator loss: 0.8113%]\n",
            "14120 [Discriminator loss: 0.6605%, acc.: 59.38%] [Generator loss: 0.7832%]\n",
            "14121 [Discriminator loss: 0.6780%, acc.: 54.30%] [Generator loss: 0.8167%]\n",
            "14122 [Discriminator loss: 0.6691%, acc.: 57.03%] [Generator loss: 0.8059%]\n",
            "14123 [Discriminator loss: 0.6725%, acc.: 59.77%] [Generator loss: 0.8088%]\n",
            "14124 [Discriminator loss: 0.6670%, acc.: 62.11%] [Generator loss: 0.8017%]\n",
            "14125 [Discriminator loss: 0.6697%, acc.: 61.33%] [Generator loss: 0.7969%]\n",
            "14126 [Discriminator loss: 0.6582%, acc.: 60.94%] [Generator loss: 0.7963%]\n",
            "14127 [Discriminator loss: 0.6774%, acc.: 59.38%] [Generator loss: 0.7757%]\n",
            "14128 [Discriminator loss: 0.6647%, acc.: 60.55%] [Generator loss: 0.8059%]\n",
            "14129 [Discriminator loss: 0.6758%, acc.: 59.38%] [Generator loss: 0.7875%]\n",
            "14130 [Discriminator loss: 0.6797%, acc.: 57.42%] [Generator loss: 0.7902%]\n",
            "14131 [Discriminator loss: 0.6742%, acc.: 56.25%] [Generator loss: 0.7821%]\n",
            "14132 [Discriminator loss: 0.6600%, acc.: 60.94%] [Generator loss: 0.7964%]\n",
            "14133 [Discriminator loss: 0.6761%, acc.: 55.08%] [Generator loss: 0.7836%]\n",
            "14134 [Discriminator loss: 0.6682%, acc.: 57.81%] [Generator loss: 0.7919%]\n",
            "14135 [Discriminator loss: 0.6606%, acc.: 60.55%] [Generator loss: 0.7878%]\n",
            "14136 [Discriminator loss: 0.6660%, acc.: 60.94%] [Generator loss: 0.7805%]\n",
            "14137 [Discriminator loss: 0.6639%, acc.: 62.50%] [Generator loss: 0.7972%]\n",
            "14138 [Discriminator loss: 0.6558%, acc.: 65.62%] [Generator loss: 0.7896%]\n",
            "14139 [Discriminator loss: 0.6550%, acc.: 60.55%] [Generator loss: 0.8014%]\n",
            "14140 [Discriminator loss: 0.6652%, acc.: 60.55%] [Generator loss: 0.7855%]\n",
            "14141 [Discriminator loss: 0.6779%, acc.: 54.69%] [Generator loss: 0.7898%]\n",
            "14142 [Discriminator loss: 0.6667%, acc.: 58.98%] [Generator loss: 0.7919%]\n",
            "14143 [Discriminator loss: 0.7130%, acc.: 52.73%] [Generator loss: 0.7836%]\n",
            "14144 [Discriminator loss: 0.6720%, acc.: 62.11%] [Generator loss: 0.8101%]\n",
            "14145 [Discriminator loss: 0.6786%, acc.: 54.69%] [Generator loss: 0.7980%]\n",
            "14146 [Discriminator loss: 0.6768%, acc.: 57.03%] [Generator loss: 0.8352%]\n",
            "14147 [Discriminator loss: 0.6770%, acc.: 57.03%] [Generator loss: 0.7699%]\n",
            "14148 [Discriminator loss: 0.6772%, acc.: 57.81%] [Generator loss: 0.8059%]\n",
            "14149 [Discriminator loss: 0.6812%, acc.: 56.25%] [Generator loss: 0.7914%]\n",
            "14150 [Discriminator loss: 0.6601%, acc.: 64.45%] [Generator loss: 0.8009%]\n",
            "14151 [Discriminator loss: 0.6578%, acc.: 60.55%] [Generator loss: 0.7750%]\n",
            "14152 [Discriminator loss: 0.6579%, acc.: 59.38%] [Generator loss: 0.7864%]\n",
            "14153 [Discriminator loss: 0.6580%, acc.: 63.67%] [Generator loss: 0.7884%]\n",
            "14154 [Discriminator loss: 0.6615%, acc.: 61.72%] [Generator loss: 0.8087%]\n",
            "14155 [Discriminator loss: 0.6677%, acc.: 55.86%] [Generator loss: 0.7869%]\n",
            "14156 [Discriminator loss: 0.6652%, acc.: 56.25%] [Generator loss: 0.8027%]\n",
            "14157 [Discriminator loss: 0.6741%, acc.: 57.03%] [Generator loss: 0.7905%]\n",
            "14158 [Discriminator loss: 0.6743%, acc.: 59.38%] [Generator loss: 0.8308%]\n",
            "14159 [Discriminator loss: 0.6794%, acc.: 52.73%] [Generator loss: 0.7783%]\n",
            "14160 [Discriminator loss: 0.6636%, acc.: 63.67%] [Generator loss: 0.8116%]\n",
            "14161 [Discriminator loss: 0.6801%, acc.: 57.81%] [Generator loss: 0.7903%]\n",
            "14162 [Discriminator loss: 0.6634%, acc.: 59.38%] [Generator loss: 0.8230%]\n",
            "14163 [Discriminator loss: 0.6631%, acc.: 62.89%] [Generator loss: 0.7938%]\n",
            "14164 [Discriminator loss: 0.6475%, acc.: 63.67%] [Generator loss: 0.7757%]\n",
            "14165 [Discriminator loss: 0.6879%, acc.: 55.08%] [Generator loss: 0.7874%]\n",
            "14166 [Discriminator loss: 0.6707%, acc.: 59.38%] [Generator loss: 0.7961%]\n",
            "14167 [Discriminator loss: 0.6945%, acc.: 50.78%] [Generator loss: 0.7980%]\n",
            "14168 [Discriminator loss: 0.6515%, acc.: 65.62%] [Generator loss: 0.8146%]\n",
            "14169 [Discriminator loss: 0.6718%, acc.: 58.20%] [Generator loss: 0.7965%]\n",
            "14170 [Discriminator loss: 0.6766%, acc.: 57.81%] [Generator loss: 0.8032%]\n",
            "14171 [Discriminator loss: 0.6555%, acc.: 60.16%] [Generator loss: 0.8224%]\n",
            "14172 [Discriminator loss: 0.6581%, acc.: 62.11%] [Generator loss: 0.8007%]\n",
            "14173 [Discriminator loss: 0.6703%, acc.: 60.16%] [Generator loss: 0.8214%]\n",
            "14174 [Discriminator loss: 0.6646%, acc.: 62.89%] [Generator loss: 0.8117%]\n",
            "14175 [Discriminator loss: 0.6606%, acc.: 65.23%] [Generator loss: 0.8011%]\n",
            "14176 [Discriminator loss: 0.6492%, acc.: 64.84%] [Generator loss: 0.8154%]\n",
            "14177 [Discriminator loss: 0.6811%, acc.: 57.03%] [Generator loss: 0.7902%]\n",
            "14178 [Discriminator loss: 0.6681%, acc.: 54.30%] [Generator loss: 0.7849%]\n",
            "14179 [Discriminator loss: 0.6845%, acc.: 53.91%] [Generator loss: 0.8038%]\n",
            "14180 [Discriminator loss: 0.6910%, acc.: 53.52%] [Generator loss: 0.7980%]\n",
            "14181 [Discriminator loss: 0.6637%, acc.: 63.28%] [Generator loss: 0.7887%]\n",
            "14182 [Discriminator loss: 0.6531%, acc.: 61.33%] [Generator loss: 0.7637%]\n",
            "14183 [Discriminator loss: 0.6901%, acc.: 54.30%] [Generator loss: 0.8086%]\n",
            "14184 [Discriminator loss: 0.6429%, acc.: 65.62%] [Generator loss: 0.7968%]\n",
            "14185 [Discriminator loss: 0.6644%, acc.: 61.33%] [Generator loss: 0.8092%]\n",
            "14186 [Discriminator loss: 0.6597%, acc.: 62.50%] [Generator loss: 0.7996%]\n",
            "14187 [Discriminator loss: 0.6714%, acc.: 58.98%] [Generator loss: 0.7893%]\n",
            "14188 [Discriminator loss: 0.6555%, acc.: 60.94%] [Generator loss: 0.8013%]\n",
            "14189 [Discriminator loss: 0.6577%, acc.: 60.16%] [Generator loss: 0.8020%]\n",
            "14190 [Discriminator loss: 0.6527%, acc.: 62.50%] [Generator loss: 0.8190%]\n",
            "14191 [Discriminator loss: 0.6873%, acc.: 57.42%] [Generator loss: 0.7995%]\n",
            "14192 [Discriminator loss: 0.6529%, acc.: 62.89%] [Generator loss: 0.7954%]\n",
            "14193 [Discriminator loss: 0.6513%, acc.: 64.45%] [Generator loss: 0.8152%]\n",
            "14194 [Discriminator loss: 0.6674%, acc.: 59.77%] [Generator loss: 0.8323%]\n",
            "14195 [Discriminator loss: 0.6628%, acc.: 59.77%] [Generator loss: 0.8039%]\n",
            "14196 [Discriminator loss: 0.6650%, acc.: 58.98%] [Generator loss: 0.8001%]\n",
            "14197 [Discriminator loss: 0.6723%, acc.: 56.64%] [Generator loss: 0.8123%]\n",
            "14198 [Discriminator loss: 0.6680%, acc.: 61.33%] [Generator loss: 0.8052%]\n",
            "14199 [Discriminator loss: 0.6707%, acc.: 53.91%] [Generator loss: 0.7871%]\n",
            "14200 [Discriminator loss: 0.6605%, acc.: 63.28%] [Generator loss: 0.7851%]\n",
            "14201 [Discriminator loss: 0.6658%, acc.: 58.59%] [Generator loss: 0.7850%]\n",
            "14202 [Discriminator loss: 0.6737%, acc.: 55.86%] [Generator loss: 0.7915%]\n",
            "14203 [Discriminator loss: 0.6553%, acc.: 61.72%] [Generator loss: 0.8014%]\n",
            "14204 [Discriminator loss: 0.6486%, acc.: 63.67%] [Generator loss: 0.8040%]\n",
            "14205 [Discriminator loss: 0.6574%, acc.: 56.64%] [Generator loss: 0.8119%]\n",
            "14206 [Discriminator loss: 0.6759%, acc.: 56.64%] [Generator loss: 0.7891%]\n",
            "14207 [Discriminator loss: 0.6819%, acc.: 54.69%] [Generator loss: 0.7887%]\n",
            "14208 [Discriminator loss: 0.6561%, acc.: 63.28%] [Generator loss: 0.7836%]\n",
            "14209 [Discriminator loss: 0.6620%, acc.: 61.72%] [Generator loss: 0.7729%]\n",
            "14210 [Discriminator loss: 0.6648%, acc.: 58.59%] [Generator loss: 0.7739%]\n",
            "14211 [Discriminator loss: 0.6701%, acc.: 54.30%] [Generator loss: 0.7943%]\n",
            "14212 [Discriminator loss: 0.6519%, acc.: 64.45%] [Generator loss: 0.7874%]\n",
            "14213 [Discriminator loss: 0.6590%, acc.: 61.72%] [Generator loss: 0.7907%]\n",
            "14214 [Discriminator loss: 0.6639%, acc.: 59.38%] [Generator loss: 0.7969%]\n",
            "14215 [Discriminator loss: 0.6726%, acc.: 58.20%] [Generator loss: 0.7957%]\n",
            "14216 [Discriminator loss: 0.6735%, acc.: 55.08%] [Generator loss: 0.7968%]\n",
            "14217 [Discriminator loss: 0.6454%, acc.: 62.89%] [Generator loss: 0.7676%]\n",
            "14218 [Discriminator loss: 0.6561%, acc.: 62.50%] [Generator loss: 0.7991%]\n",
            "14219 [Discriminator loss: 0.6715%, acc.: 58.59%] [Generator loss: 0.7945%]\n",
            "14220 [Discriminator loss: 0.6763%, acc.: 57.81%] [Generator loss: 0.7978%]\n",
            "14221 [Discriminator loss: 0.6939%, acc.: 51.56%] [Generator loss: 0.8011%]\n",
            "14222 [Discriminator loss: 0.6778%, acc.: 54.30%] [Generator loss: 0.8322%]\n",
            "14223 [Discriminator loss: 0.6612%, acc.: 62.11%] [Generator loss: 0.7949%]\n",
            "14224 [Discriminator loss: 0.6737%, acc.: 57.81%] [Generator loss: 0.8078%]\n",
            "14225 [Discriminator loss: 0.6610%, acc.: 61.33%] [Generator loss: 0.8056%]\n",
            "14226 [Discriminator loss: 0.6755%, acc.: 57.42%] [Generator loss: 0.7934%]\n",
            "14227 [Discriminator loss: 0.6595%, acc.: 62.11%] [Generator loss: 0.7973%]\n",
            "14228 [Discriminator loss: 0.6687%, acc.: 58.20%] [Generator loss: 0.8082%]\n",
            "14229 [Discriminator loss: 0.6548%, acc.: 60.16%] [Generator loss: 0.8391%]\n",
            "14230 [Discriminator loss: 0.6760%, acc.: 56.25%] [Generator loss: 0.8310%]\n",
            "14231 [Discriminator loss: 0.6678%, acc.: 58.98%] [Generator loss: 0.7911%]\n",
            "14232 [Discriminator loss: 0.6769%, acc.: 57.03%] [Generator loss: 0.7995%]\n",
            "14233 [Discriminator loss: 0.6530%, acc.: 64.06%] [Generator loss: 0.7847%]\n",
            "14234 [Discriminator loss: 0.6863%, acc.: 57.03%] [Generator loss: 0.8027%]\n",
            "14235 [Discriminator loss: 0.6707%, acc.: 57.03%] [Generator loss: 0.8159%]\n",
            "14236 [Discriminator loss: 0.6689%, acc.: 58.98%] [Generator loss: 0.8399%]\n",
            "14237 [Discriminator loss: 0.6653%, acc.: 59.77%] [Generator loss: 0.7971%]\n",
            "14238 [Discriminator loss: 0.6686%, acc.: 58.98%] [Generator loss: 0.7894%]\n",
            "14239 [Discriminator loss: 0.6545%, acc.: 59.38%] [Generator loss: 0.8011%]\n",
            "14240 [Discriminator loss: 0.6718%, acc.: 58.20%] [Generator loss: 0.7754%]\n",
            "14241 [Discriminator loss: 0.6906%, acc.: 54.30%] [Generator loss: 0.7785%]\n",
            "14242 [Discriminator loss: 0.6686%, acc.: 58.98%] [Generator loss: 0.8019%]\n",
            "14243 [Discriminator loss: 0.6601%, acc.: 62.50%] [Generator loss: 0.8065%]\n",
            "14244 [Discriminator loss: 0.6749%, acc.: 54.69%] [Generator loss: 0.8043%]\n",
            "14245 [Discriminator loss: 0.6473%, acc.: 62.89%] [Generator loss: 0.8175%]\n",
            "14246 [Discriminator loss: 0.6634%, acc.: 61.33%] [Generator loss: 0.8365%]\n",
            "14247 [Discriminator loss: 0.6603%, acc.: 60.16%] [Generator loss: 0.8037%]\n",
            "14248 [Discriminator loss: 0.6739%, acc.: 58.98%] [Generator loss: 0.7964%]\n",
            "14249 [Discriminator loss: 0.6741%, acc.: 57.81%] [Generator loss: 0.7822%]\n",
            "14250 [Discriminator loss: 0.6833%, acc.: 55.08%] [Generator loss: 0.8088%]\n",
            "14251 [Discriminator loss: 0.6454%, acc.: 63.28%] [Generator loss: 0.8184%]\n",
            "14252 [Discriminator loss: 0.6739%, acc.: 57.03%] [Generator loss: 0.8203%]\n",
            "14253 [Discriminator loss: 0.6611%, acc.: 62.11%] [Generator loss: 0.8046%]\n",
            "14254 [Discriminator loss: 0.6574%, acc.: 59.77%] [Generator loss: 0.8064%]\n",
            "14255 [Discriminator loss: 0.6726%, acc.: 58.98%] [Generator loss: 0.7983%]\n",
            "14256 [Discriminator loss: 0.6670%, acc.: 57.81%] [Generator loss: 0.8249%]\n",
            "14257 [Discriminator loss: 0.6497%, acc.: 60.55%] [Generator loss: 0.7988%]\n",
            "14258 [Discriminator loss: 0.6703%, acc.: 58.98%] [Generator loss: 0.7826%]\n",
            "14259 [Discriminator loss: 0.6730%, acc.: 58.59%] [Generator loss: 0.7903%]\n",
            "14260 [Discriminator loss: 0.6718%, acc.: 57.81%] [Generator loss: 0.7826%]\n",
            "14261 [Discriminator loss: 0.6669%, acc.: 57.42%] [Generator loss: 0.7722%]\n",
            "14262 [Discriminator loss: 0.6832%, acc.: 59.38%] [Generator loss: 0.7760%]\n",
            "14263 [Discriminator loss: 0.6771%, acc.: 56.25%] [Generator loss: 0.7913%]\n",
            "14264 [Discriminator loss: 0.6555%, acc.: 61.33%] [Generator loss: 0.8243%]\n",
            "14265 [Discriminator loss: 0.6466%, acc.: 63.67%] [Generator loss: 0.8044%]\n",
            "14266 [Discriminator loss: 0.6585%, acc.: 62.50%] [Generator loss: 0.8066%]\n",
            "14267 [Discriminator loss: 0.6527%, acc.: 64.06%] [Generator loss: 0.7858%]\n",
            "14268 [Discriminator loss: 0.6590%, acc.: 62.50%] [Generator loss: 0.8272%]\n",
            "14269 [Discriminator loss: 0.6685%, acc.: 58.98%] [Generator loss: 0.8037%]\n",
            "14270 [Discriminator loss: 0.6601%, acc.: 58.59%] [Generator loss: 0.8222%]\n",
            "14271 [Discriminator loss: 0.6878%, acc.: 51.56%] [Generator loss: 0.8026%]\n",
            "14272 [Discriminator loss: 0.6479%, acc.: 67.19%] [Generator loss: 0.7887%]\n",
            "14273 [Discriminator loss: 0.6513%, acc.: 64.06%] [Generator loss: 0.8162%]\n",
            "14274 [Discriminator loss: 0.6606%, acc.: 61.33%] [Generator loss: 0.8022%]\n",
            "14275 [Discriminator loss: 0.6630%, acc.: 62.11%] [Generator loss: 0.7990%]\n",
            "14276 [Discriminator loss: 0.6800%, acc.: 52.34%] [Generator loss: 0.7976%]\n",
            "14277 [Discriminator loss: 0.6857%, acc.: 55.08%] [Generator loss: 0.7938%]\n",
            "14278 [Discriminator loss: 0.6639%, acc.: 59.77%] [Generator loss: 0.7898%]\n",
            "14279 [Discriminator loss: 0.6890%, acc.: 52.73%] [Generator loss: 0.8042%]\n",
            "14280 [Discriminator loss: 0.6565%, acc.: 65.23%] [Generator loss: 0.7781%]\n",
            "14281 [Discriminator loss: 0.6776%, acc.: 57.81%] [Generator loss: 0.7978%]\n",
            "14282 [Discriminator loss: 0.6831%, acc.: 55.08%] [Generator loss: 0.7767%]\n",
            "14283 [Discriminator loss: 0.6837%, acc.: 54.69%] [Generator loss: 0.7768%]\n",
            "14284 [Discriminator loss: 0.6671%, acc.: 61.33%] [Generator loss: 0.7903%]\n",
            "14285 [Discriminator loss: 0.6689%, acc.: 55.86%] [Generator loss: 0.8117%]\n",
            "14286 [Discriminator loss: 0.6535%, acc.: 61.72%] [Generator loss: 0.7967%]\n",
            "14287 [Discriminator loss: 0.6700%, acc.: 56.64%] [Generator loss: 0.8110%]\n",
            "14288 [Discriminator loss: 0.6722%, acc.: 55.47%] [Generator loss: 0.7682%]\n",
            "14289 [Discriminator loss: 0.6742%, acc.: 55.47%] [Generator loss: 0.7893%]\n",
            "14290 [Discriminator loss: 0.6498%, acc.: 60.55%] [Generator loss: 0.7789%]\n",
            "14291 [Discriminator loss: 0.6674%, acc.: 60.16%] [Generator loss: 0.7929%]\n",
            "14292 [Discriminator loss: 0.6392%, acc.: 63.67%] [Generator loss: 0.7882%]\n",
            "14293 [Discriminator loss: 0.6503%, acc.: 60.16%] [Generator loss: 0.8076%]\n",
            "14294 [Discriminator loss: 0.6592%, acc.: 55.86%] [Generator loss: 0.7869%]\n",
            "14295 [Discriminator loss: 0.6710%, acc.: 59.38%] [Generator loss: 0.7794%]\n",
            "14296 [Discriminator loss: 0.6639%, acc.: 55.47%] [Generator loss: 0.8048%]\n",
            "14297 [Discriminator loss: 0.6839%, acc.: 57.81%] [Generator loss: 0.7805%]\n",
            "14298 [Discriminator loss: 0.6539%, acc.: 63.67%] [Generator loss: 0.8161%]\n",
            "14299 [Discriminator loss: 0.6698%, acc.: 57.03%] [Generator loss: 0.8015%]\n",
            "14300 [Discriminator loss: 0.6555%, acc.: 62.11%] [Generator loss: 0.7986%]\n",
            "14301 [Discriminator loss: 0.6701%, acc.: 56.64%] [Generator loss: 0.8259%]\n",
            "14302 [Discriminator loss: 0.6743%, acc.: 61.33%] [Generator loss: 0.8044%]\n",
            "14303 [Discriminator loss: 0.6523%, acc.: 64.06%] [Generator loss: 0.8134%]\n",
            "14304 [Discriminator loss: 0.6601%, acc.: 60.55%] [Generator loss: 0.8276%]\n",
            "14305 [Discriminator loss: 0.6479%, acc.: 64.06%] [Generator loss: 0.8156%]\n",
            "14306 [Discriminator loss: 0.6545%, acc.: 63.67%] [Generator loss: 0.8201%]\n",
            "14307 [Discriminator loss: 0.6646%, acc.: 58.20%] [Generator loss: 0.8168%]\n",
            "14308 [Discriminator loss: 0.6654%, acc.: 58.20%] [Generator loss: 0.8270%]\n",
            "14309 [Discriminator loss: 0.6697%, acc.: 58.20%] [Generator loss: 0.8205%]\n",
            "14310 [Discriminator loss: 0.6446%, acc.: 66.41%] [Generator loss: 0.8067%]\n",
            "14311 [Discriminator loss: 0.6747%, acc.: 61.72%] [Generator loss: 0.7955%]\n",
            "14312 [Discriminator loss: 0.6707%, acc.: 57.81%] [Generator loss: 0.7987%]\n",
            "14313 [Discriminator loss: 0.6529%, acc.: 62.11%] [Generator loss: 0.8167%]\n",
            "14314 [Discriminator loss: 0.6614%, acc.: 57.42%] [Generator loss: 0.7984%]\n",
            "14315 [Discriminator loss: 0.6552%, acc.: 61.72%] [Generator loss: 0.8113%]\n",
            "14316 [Discriminator loss: 0.6567%, acc.: 63.28%] [Generator loss: 0.8203%]\n",
            "14317 [Discriminator loss: 0.6692%, acc.: 58.59%] [Generator loss: 0.7934%]\n",
            "14318 [Discriminator loss: 0.6461%, acc.: 63.28%] [Generator loss: 0.7811%]\n",
            "14319 [Discriminator loss: 0.6635%, acc.: 60.16%] [Generator loss: 0.8074%]\n",
            "14320 [Discriminator loss: 0.6834%, acc.: 52.73%] [Generator loss: 0.7871%]\n",
            "14321 [Discriminator loss: 0.6558%, acc.: 62.11%] [Generator loss: 0.7935%]\n",
            "14322 [Discriminator loss: 0.6766%, acc.: 56.25%] [Generator loss: 0.7739%]\n",
            "14323 [Discriminator loss: 0.6457%, acc.: 64.84%] [Generator loss: 0.8123%]\n",
            "14324 [Discriminator loss: 0.6593%, acc.: 60.55%] [Generator loss: 0.8067%]\n",
            "14325 [Discriminator loss: 0.6492%, acc.: 65.23%] [Generator loss: 0.7880%]\n",
            "14326 [Discriminator loss: 0.6535%, acc.: 62.11%] [Generator loss: 0.8130%]\n",
            "14327 [Discriminator loss: 0.6875%, acc.: 52.73%] [Generator loss: 0.8068%]\n",
            "14328 [Discriminator loss: 0.6574%, acc.: 60.94%] [Generator loss: 0.8122%]\n",
            "14329 [Discriminator loss: 0.6536%, acc.: 60.94%] [Generator loss: 0.8051%]\n",
            "14330 [Discriminator loss: 0.6672%, acc.: 60.55%] [Generator loss: 0.7878%]\n",
            "14331 [Discriminator loss: 0.6783%, acc.: 51.95%] [Generator loss: 0.8060%]\n",
            "14332 [Discriminator loss: 0.6634%, acc.: 59.38%] [Generator loss: 0.7961%]\n",
            "14333 [Discriminator loss: 0.6688%, acc.: 61.72%] [Generator loss: 0.7981%]\n",
            "14334 [Discriminator loss: 0.6616%, acc.: 57.03%] [Generator loss: 0.8038%]\n",
            "14335 [Discriminator loss: 0.6521%, acc.: 64.84%] [Generator loss: 0.8072%]\n",
            "14336 [Discriminator loss: 0.6585%, acc.: 59.77%] [Generator loss: 0.8256%]\n",
            "14337 [Discriminator loss: 0.6494%, acc.: 66.02%] [Generator loss: 0.8158%]\n",
            "14338 [Discriminator loss: 0.6420%, acc.: 67.19%] [Generator loss: 0.7968%]\n",
            "14339 [Discriminator loss: 0.6631%, acc.: 59.77%] [Generator loss: 0.7843%]\n",
            "14340 [Discriminator loss: 0.6694%, acc.: 60.16%] [Generator loss: 0.8131%]\n",
            "14341 [Discriminator loss: 0.6551%, acc.: 61.72%] [Generator loss: 0.7897%]\n",
            "14342 [Discriminator loss: 0.6653%, acc.: 56.25%] [Generator loss: 0.8162%]\n",
            "14343 [Discriminator loss: 0.6667%, acc.: 56.64%] [Generator loss: 0.8032%]\n",
            "14344 [Discriminator loss: 0.6864%, acc.: 51.56%] [Generator loss: 0.7956%]\n",
            "14345 [Discriminator loss: 0.6695%, acc.: 58.59%] [Generator loss: 0.7686%]\n",
            "14346 [Discriminator loss: 0.6740%, acc.: 58.98%] [Generator loss: 0.7779%]\n",
            "14347 [Discriminator loss: 0.6825%, acc.: 56.64%] [Generator loss: 0.8230%]\n",
            "14348 [Discriminator loss: 0.6798%, acc.: 54.69%] [Generator loss: 0.8118%]\n",
            "14349 [Discriminator loss: 0.6413%, acc.: 65.23%] [Generator loss: 0.7915%]\n",
            "14350 [Discriminator loss: 0.6776%, acc.: 58.59%] [Generator loss: 0.8038%]\n",
            "14351 [Discriminator loss: 0.6759%, acc.: 55.08%] [Generator loss: 0.8058%]\n",
            "14352 [Discriminator loss: 0.6571%, acc.: 62.89%] [Generator loss: 0.7893%]\n",
            "14353 [Discriminator loss: 0.6516%, acc.: 63.28%] [Generator loss: 0.7892%]\n",
            "14354 [Discriminator loss: 0.6773%, acc.: 55.86%] [Generator loss: 0.7874%]\n",
            "14355 [Discriminator loss: 0.6756%, acc.: 57.42%] [Generator loss: 0.7883%]\n",
            "14356 [Discriminator loss: 0.6604%, acc.: 60.94%] [Generator loss: 0.7930%]\n",
            "14357 [Discriminator loss: 0.6542%, acc.: 60.55%] [Generator loss: 0.8031%]\n",
            "14358 [Discriminator loss: 0.6635%, acc.: 55.86%] [Generator loss: 0.7932%]\n",
            "14359 [Discriminator loss: 0.6518%, acc.: 64.84%] [Generator loss: 0.7792%]\n",
            "14360 [Discriminator loss: 0.6642%, acc.: 60.94%] [Generator loss: 0.8151%]\n",
            "14361 [Discriminator loss: 0.6620%, acc.: 57.03%] [Generator loss: 0.8262%]\n",
            "14362 [Discriminator loss: 0.6865%, acc.: 53.91%] [Generator loss: 0.7969%]\n",
            "14363 [Discriminator loss: 0.6607%, acc.: 61.72%] [Generator loss: 0.7795%]\n",
            "14364 [Discriminator loss: 0.6712%, acc.: 56.25%] [Generator loss: 0.7867%]\n",
            "14365 [Discriminator loss: 0.6563%, acc.: 63.28%] [Generator loss: 0.7991%]\n",
            "14366 [Discriminator loss: 0.6677%, acc.: 56.25%] [Generator loss: 0.7958%]\n",
            "14367 [Discriminator loss: 0.6780%, acc.: 60.94%] [Generator loss: 0.7808%]\n",
            "14368 [Discriminator loss: 0.6607%, acc.: 58.98%] [Generator loss: 0.7925%]\n",
            "14369 [Discriminator loss: 0.6728%, acc.: 54.69%] [Generator loss: 0.7944%]\n",
            "14370 [Discriminator loss: 0.6569%, acc.: 62.50%] [Generator loss: 0.8008%]\n",
            "14371 [Discriminator loss: 0.6630%, acc.: 59.77%] [Generator loss: 0.8000%]\n",
            "14372 [Discriminator loss: 0.6632%, acc.: 58.98%] [Generator loss: 0.8055%]\n",
            "14373 [Discriminator loss: 0.6619%, acc.: 62.50%] [Generator loss: 0.8000%]\n",
            "14374 [Discriminator loss: 0.6777%, acc.: 52.73%] [Generator loss: 0.7688%]\n",
            "14375 [Discriminator loss: 0.6608%, acc.: 62.50%] [Generator loss: 0.7944%]\n",
            "14376 [Discriminator loss: 0.6580%, acc.: 64.45%] [Generator loss: 0.7957%]\n",
            "14377 [Discriminator loss: 0.6666%, acc.: 64.06%] [Generator loss: 0.7895%]\n",
            "14378 [Discriminator loss: 0.6665%, acc.: 58.20%] [Generator loss: 0.7852%]\n",
            "14379 [Discriminator loss: 0.6633%, acc.: 58.59%] [Generator loss: 0.7904%]\n",
            "14380 [Discriminator loss: 0.6743%, acc.: 56.25%] [Generator loss: 0.8022%]\n",
            "14381 [Discriminator loss: 0.6519%, acc.: 63.28%] [Generator loss: 0.8166%]\n",
            "14382 [Discriminator loss: 0.6689%, acc.: 61.33%] [Generator loss: 0.8010%]\n",
            "14383 [Discriminator loss: 0.6531%, acc.: 62.89%] [Generator loss: 0.7640%]\n",
            "14384 [Discriminator loss: 0.6887%, acc.: 56.64%] [Generator loss: 0.7793%]\n",
            "14385 [Discriminator loss: 0.6498%, acc.: 63.67%] [Generator loss: 0.7915%]\n",
            "14386 [Discriminator loss: 0.6701%, acc.: 57.81%] [Generator loss: 0.7781%]\n",
            "14387 [Discriminator loss: 0.6646%, acc.: 60.16%] [Generator loss: 0.7716%]\n",
            "14388 [Discriminator loss: 0.6817%, acc.: 53.91%] [Generator loss: 0.7924%]\n",
            "14389 [Discriminator loss: 0.6508%, acc.: 64.06%] [Generator loss: 0.7872%]\n",
            "14390 [Discriminator loss: 0.6820%, acc.: 55.86%] [Generator loss: 0.7766%]\n",
            "14391 [Discriminator loss: 0.6666%, acc.: 60.16%] [Generator loss: 0.7882%]\n",
            "14392 [Discriminator loss: 0.6674%, acc.: 59.77%] [Generator loss: 0.8185%]\n",
            "14393 [Discriminator loss: 0.6747%, acc.: 57.42%] [Generator loss: 0.7969%]\n",
            "14394 [Discriminator loss: 0.6678%, acc.: 59.77%] [Generator loss: 0.7975%]\n",
            "14395 [Discriminator loss: 0.6766%, acc.: 57.03%] [Generator loss: 0.7931%]\n",
            "14396 [Discriminator loss: 0.6489%, acc.: 64.06%] [Generator loss: 0.7892%]\n",
            "14397 [Discriminator loss: 0.6597%, acc.: 58.59%] [Generator loss: 0.7947%]\n",
            "14398 [Discriminator loss: 0.6815%, acc.: 54.30%] [Generator loss: 0.8144%]\n",
            "14399 [Discriminator loss: 0.6710%, acc.: 60.94%] [Generator loss: 0.7987%]\n",
            "14400 [Discriminator loss: 0.6686%, acc.: 59.77%] [Generator loss: 0.7985%]\n",
            "14401 [Discriminator loss: 0.6586%, acc.: 63.28%] [Generator loss: 0.7841%]\n",
            "14402 [Discriminator loss: 0.6574%, acc.: 58.98%] [Generator loss: 0.7944%]\n",
            "14403 [Discriminator loss: 0.6659%, acc.: 58.98%] [Generator loss: 0.8239%]\n",
            "14404 [Discriminator loss: 0.6513%, acc.: 64.84%] [Generator loss: 0.8001%]\n",
            "14405 [Discriminator loss: 0.6541%, acc.: 63.28%] [Generator loss: 0.8063%]\n",
            "14406 [Discriminator loss: 0.6486%, acc.: 64.45%] [Generator loss: 0.8020%]\n",
            "14407 [Discriminator loss: 0.6537%, acc.: 62.89%] [Generator loss: 0.8176%]\n",
            "14408 [Discriminator loss: 0.6452%, acc.: 64.45%] [Generator loss: 0.8055%]\n",
            "14409 [Discriminator loss: 0.6593%, acc.: 61.33%] [Generator loss: 0.8237%]\n",
            "14410 [Discriminator loss: 0.6711%, acc.: 60.16%] [Generator loss: 0.7957%]\n",
            "14411 [Discriminator loss: 0.6363%, acc.: 62.89%] [Generator loss: 0.8003%]\n",
            "14412 [Discriminator loss: 0.6603%, acc.: 62.89%] [Generator loss: 0.8094%]\n",
            "14413 [Discriminator loss: 0.6772%, acc.: 55.08%] [Generator loss: 0.8093%]\n",
            "14414 [Discriminator loss: 0.6626%, acc.: 58.59%] [Generator loss: 0.8226%]\n",
            "14415 [Discriminator loss: 0.6696%, acc.: 56.64%] [Generator loss: 0.8392%]\n",
            "14416 [Discriminator loss: 0.6710%, acc.: 58.98%] [Generator loss: 0.7951%]\n",
            "14417 [Discriminator loss: 0.6885%, acc.: 54.30%] [Generator loss: 0.7661%]\n",
            "14418 [Discriminator loss: 0.6660%, acc.: 58.98%] [Generator loss: 0.7996%]\n",
            "14419 [Discriminator loss: 0.6573%, acc.: 59.38%] [Generator loss: 0.7898%]\n",
            "14420 [Discriminator loss: 0.6532%, acc.: 60.16%] [Generator loss: 0.8064%]\n",
            "14421 [Discriminator loss: 0.6702%, acc.: 57.42%] [Generator loss: 0.7981%]\n",
            "14422 [Discriminator loss: 0.6646%, acc.: 58.59%] [Generator loss: 0.7896%]\n",
            "14423 [Discriminator loss: 0.6707%, acc.: 57.42%] [Generator loss: 0.8220%]\n",
            "14424 [Discriminator loss: 0.6667%, acc.: 62.50%] [Generator loss: 0.8162%]\n",
            "14425 [Discriminator loss: 0.6665%, acc.: 58.98%] [Generator loss: 0.7804%]\n",
            "14426 [Discriminator loss: 0.6651%, acc.: 56.64%] [Generator loss: 0.8169%]\n",
            "14427 [Discriminator loss: 0.6427%, acc.: 62.50%] [Generator loss: 0.8282%]\n",
            "14428 [Discriminator loss: 0.6737%, acc.: 57.81%] [Generator loss: 0.8055%]\n",
            "14429 [Discriminator loss: 0.6655%, acc.: 59.38%] [Generator loss: 0.7866%]\n",
            "14430 [Discriminator loss: 0.6964%, acc.: 52.73%] [Generator loss: 0.8198%]\n",
            "14431 [Discriminator loss: 0.6631%, acc.: 62.11%] [Generator loss: 0.8229%]\n",
            "14432 [Discriminator loss: 0.6634%, acc.: 67.19%] [Generator loss: 0.8177%]\n",
            "14433 [Discriminator loss: 0.6731%, acc.: 60.16%] [Generator loss: 0.7704%]\n",
            "14434 [Discriminator loss: 0.6710%, acc.: 57.81%] [Generator loss: 0.8125%]\n",
            "14435 [Discriminator loss: 0.6702%, acc.: 56.64%] [Generator loss: 0.8153%]\n",
            "14436 [Discriminator loss: 0.6630%, acc.: 58.98%] [Generator loss: 0.8179%]\n",
            "14437 [Discriminator loss: 0.6589%, acc.: 60.94%] [Generator loss: 0.7907%]\n",
            "14438 [Discriminator loss: 0.6608%, acc.: 60.55%] [Generator loss: 0.7789%]\n",
            "14439 [Discriminator loss: 0.6778%, acc.: 56.64%] [Generator loss: 0.8054%]\n",
            "14440 [Discriminator loss: 0.6541%, acc.: 64.06%] [Generator loss: 0.7973%]\n",
            "14441 [Discriminator loss: 0.6594%, acc.: 62.11%] [Generator loss: 0.7994%]\n",
            "14442 [Discriminator loss: 0.6590%, acc.: 62.50%] [Generator loss: 0.8094%]\n",
            "14443 [Discriminator loss: 0.6618%, acc.: 60.55%] [Generator loss: 0.8158%]\n",
            "14444 [Discriminator loss: 0.6654%, acc.: 62.89%] [Generator loss: 0.8269%]\n",
            "14445 [Discriminator loss: 0.6576%, acc.: 59.77%] [Generator loss: 0.7966%]\n",
            "14446 [Discriminator loss: 0.6895%, acc.: 56.25%] [Generator loss: 0.7626%]\n",
            "14447 [Discriminator loss: 0.6598%, acc.: 62.89%] [Generator loss: 0.7931%]\n",
            "14448 [Discriminator loss: 0.6604%, acc.: 62.89%] [Generator loss: 0.7964%]\n",
            "14449 [Discriminator loss: 0.6457%, acc.: 66.02%] [Generator loss: 0.7981%]\n",
            "14450 [Discriminator loss: 0.6642%, acc.: 58.98%] [Generator loss: 0.8170%]\n",
            "14451 [Discriminator loss: 0.6605%, acc.: 59.77%] [Generator loss: 0.7768%]\n",
            "14452 [Discriminator loss: 0.6617%, acc.: 60.94%] [Generator loss: 0.8000%]\n",
            "14453 [Discriminator loss: 0.6562%, acc.: 62.50%] [Generator loss: 0.8322%]\n",
            "14454 [Discriminator loss: 0.6849%, acc.: 52.73%] [Generator loss: 0.8095%]\n",
            "14455 [Discriminator loss: 0.6492%, acc.: 63.28%] [Generator loss: 0.7837%]\n",
            "14456 [Discriminator loss: 0.6763%, acc.: 56.25%] [Generator loss: 0.7903%]\n",
            "14457 [Discriminator loss: 0.6695%, acc.: 61.33%] [Generator loss: 0.7772%]\n",
            "14458 [Discriminator loss: 0.6681%, acc.: 55.08%] [Generator loss: 0.7903%]\n",
            "14459 [Discriminator loss: 0.6713%, acc.: 57.81%] [Generator loss: 0.8183%]\n",
            "14460 [Discriminator loss: 0.6748%, acc.: 58.98%] [Generator loss: 0.7788%]\n",
            "14461 [Discriminator loss: 0.6595%, acc.: 62.11%] [Generator loss: 0.7808%]\n",
            "14462 [Discriminator loss: 0.6582%, acc.: 61.33%] [Generator loss: 0.7761%]\n",
            "14463 [Discriminator loss: 0.6641%, acc.: 58.98%] [Generator loss: 0.7921%]\n",
            "14464 [Discriminator loss: 0.6441%, acc.: 66.41%] [Generator loss: 0.7873%]\n",
            "14465 [Discriminator loss: 0.6374%, acc.: 66.41%] [Generator loss: 0.7964%]\n",
            "14466 [Discriminator loss: 0.6493%, acc.: 59.38%] [Generator loss: 0.8268%]\n",
            "14467 [Discriminator loss: 0.6512%, acc.: 60.16%] [Generator loss: 0.8009%]\n",
            "14468 [Discriminator loss: 0.6646%, acc.: 58.20%] [Generator loss: 0.7899%]\n",
            "14469 [Discriminator loss: 0.6631%, acc.: 62.89%] [Generator loss: 0.7859%]\n",
            "14470 [Discriminator loss: 0.6636%, acc.: 59.77%] [Generator loss: 0.7989%]\n",
            "14471 [Discriminator loss: 0.6825%, acc.: 54.30%] [Generator loss: 0.7906%]\n",
            "14472 [Discriminator loss: 0.6710%, acc.: 59.77%] [Generator loss: 0.7849%]\n",
            "14473 [Discriminator loss: 0.6571%, acc.: 58.98%] [Generator loss: 0.7962%]\n",
            "14474 [Discriminator loss: 0.6579%, acc.: 60.16%] [Generator loss: 0.8297%]\n",
            "14475 [Discriminator loss: 0.6596%, acc.: 61.72%] [Generator loss: 0.8324%]\n",
            "14476 [Discriminator loss: 0.6640%, acc.: 58.20%] [Generator loss: 0.8047%]\n",
            "14477 [Discriminator loss: 0.6634%, acc.: 58.98%] [Generator loss: 0.8036%]\n",
            "14478 [Discriminator loss: 0.6560%, acc.: 60.94%] [Generator loss: 0.7997%]\n",
            "14479 [Discriminator loss: 0.6461%, acc.: 66.41%] [Generator loss: 0.7894%]\n",
            "14480 [Discriminator loss: 0.6408%, acc.: 62.50%] [Generator loss: 0.7747%]\n",
            "14481 [Discriminator loss: 0.6530%, acc.: 65.62%] [Generator loss: 0.7778%]\n",
            "14482 [Discriminator loss: 0.6490%, acc.: 64.06%] [Generator loss: 0.7744%]\n",
            "14483 [Discriminator loss: 0.6643%, acc.: 62.50%] [Generator loss: 0.7917%]\n",
            "14484 [Discriminator loss: 0.6578%, acc.: 60.94%] [Generator loss: 0.7968%]\n",
            "14485 [Discriminator loss: 0.6706%, acc.: 59.38%] [Generator loss: 0.8050%]\n",
            "14486 [Discriminator loss: 0.6607%, acc.: 60.55%] [Generator loss: 0.7930%]\n",
            "14487 [Discriminator loss: 0.6718%, acc.: 58.20%] [Generator loss: 0.8068%]\n",
            "14488 [Discriminator loss: 0.6764%, acc.: 54.30%] [Generator loss: 0.7894%]\n",
            "14489 [Discriminator loss: 0.6636%, acc.: 59.77%] [Generator loss: 0.8199%]\n",
            "14490 [Discriminator loss: 0.6821%, acc.: 55.08%] [Generator loss: 0.7905%]\n",
            "14491 [Discriminator loss: 0.6456%, acc.: 62.11%] [Generator loss: 0.7981%]\n",
            "14492 [Discriminator loss: 0.6597%, acc.: 59.38%] [Generator loss: 0.7911%]\n",
            "14493 [Discriminator loss: 0.6750%, acc.: 55.86%] [Generator loss: 0.7790%]\n",
            "14494 [Discriminator loss: 0.6575%, acc.: 60.55%] [Generator loss: 0.7911%]\n",
            "14495 [Discriminator loss: 0.6510%, acc.: 62.50%] [Generator loss: 0.8076%]\n",
            "14496 [Discriminator loss: 0.6467%, acc.: 62.11%] [Generator loss: 0.8022%]\n",
            "14497 [Discriminator loss: 0.6773%, acc.: 55.86%] [Generator loss: 0.8016%]\n",
            "14498 [Discriminator loss: 0.6713%, acc.: 57.03%] [Generator loss: 0.8244%]\n",
            "14499 [Discriminator loss: 0.6661%, acc.: 62.11%] [Generator loss: 0.8169%]\n",
            "14500 [Discriminator loss: 0.6740%, acc.: 59.38%] [Generator loss: 0.8018%]\n",
            "14501 [Discriminator loss: 0.6714%, acc.: 55.86%] [Generator loss: 0.7986%]\n",
            "14502 [Discriminator loss: 0.6635%, acc.: 59.38%] [Generator loss: 0.8026%]\n",
            "14503 [Discriminator loss: 0.6685%, acc.: 57.81%] [Generator loss: 0.8143%]\n",
            "14504 [Discriminator loss: 0.6500%, acc.: 62.50%] [Generator loss: 0.8284%]\n",
            "14505 [Discriminator loss: 0.6631%, acc.: 60.94%] [Generator loss: 0.8090%]\n",
            "14506 [Discriminator loss: 0.6636%, acc.: 58.20%] [Generator loss: 0.7836%]\n",
            "14507 [Discriminator loss: 0.6789%, acc.: 55.47%] [Generator loss: 0.7983%]\n",
            "14508 [Discriminator loss: 0.6497%, acc.: 62.11%] [Generator loss: 0.7988%]\n",
            "14509 [Discriminator loss: 0.6631%, acc.: 58.98%] [Generator loss: 0.8236%]\n",
            "14510 [Discriminator loss: 0.6714%, acc.: 60.94%] [Generator loss: 0.8141%]\n",
            "14511 [Discriminator loss: 0.6672%, acc.: 58.98%] [Generator loss: 0.8115%]\n",
            "14512 [Discriminator loss: 0.6586%, acc.: 58.98%] [Generator loss: 0.8019%]\n",
            "14513 [Discriminator loss: 0.6673%, acc.: 58.59%] [Generator loss: 0.8113%]\n",
            "14514 [Discriminator loss: 0.6626%, acc.: 60.55%] [Generator loss: 0.8039%]\n",
            "14515 [Discriminator loss: 0.6636%, acc.: 59.77%] [Generator loss: 0.7992%]\n",
            "14516 [Discriminator loss: 0.6566%, acc.: 57.81%] [Generator loss: 0.8056%]\n",
            "14517 [Discriminator loss: 0.6572%, acc.: 62.50%] [Generator loss: 0.7911%]\n",
            "14518 [Discriminator loss: 0.6421%, acc.: 66.41%] [Generator loss: 0.7917%]\n",
            "14519 [Discriminator loss: 0.6747%, acc.: 59.77%] [Generator loss: 0.7990%]\n",
            "14520 [Discriminator loss: 0.6534%, acc.: 66.02%] [Generator loss: 0.7797%]\n",
            "14521 [Discriminator loss: 0.6750%, acc.: 55.86%] [Generator loss: 0.7950%]\n",
            "14522 [Discriminator loss: 0.6699%, acc.: 57.42%] [Generator loss: 0.7858%]\n",
            "14523 [Discriminator loss: 0.6574%, acc.: 61.72%] [Generator loss: 0.7788%]\n",
            "14524 [Discriminator loss: 0.6669%, acc.: 60.94%] [Generator loss: 0.7811%]\n",
            "14525 [Discriminator loss: 0.6738%, acc.: 58.59%] [Generator loss: 0.7877%]\n",
            "14526 [Discriminator loss: 0.6693%, acc.: 59.77%] [Generator loss: 0.7981%]\n",
            "14527 [Discriminator loss: 0.6697%, acc.: 57.42%] [Generator loss: 0.8082%]\n",
            "14528 [Discriminator loss: 0.6559%, acc.: 64.06%] [Generator loss: 0.8300%]\n",
            "14529 [Discriminator loss: 0.6623%, acc.: 60.55%] [Generator loss: 0.8004%]\n",
            "14530 [Discriminator loss: 0.6785%, acc.: 58.20%] [Generator loss: 0.7996%]\n",
            "14531 [Discriminator loss: 0.6704%, acc.: 60.94%] [Generator loss: 0.7989%]\n",
            "14532 [Discriminator loss: 0.6487%, acc.: 64.45%] [Generator loss: 0.8084%]\n",
            "14533 [Discriminator loss: 0.6642%, acc.: 59.77%] [Generator loss: 0.8059%]\n",
            "14534 [Discriminator loss: 0.6555%, acc.: 60.16%] [Generator loss: 0.8146%]\n",
            "14535 [Discriminator loss: 0.6529%, acc.: 61.33%] [Generator loss: 0.7893%]\n",
            "14536 [Discriminator loss: 0.6791%, acc.: 58.20%] [Generator loss: 0.7964%]\n",
            "14537 [Discriminator loss: 0.6686%, acc.: 59.38%] [Generator loss: 0.7867%]\n",
            "14538 [Discriminator loss: 0.6695%, acc.: 57.81%] [Generator loss: 0.7966%]\n",
            "14539 [Discriminator loss: 0.6664%, acc.: 57.42%] [Generator loss: 0.7880%]\n",
            "14540 [Discriminator loss: 0.6831%, acc.: 53.52%] [Generator loss: 0.7861%]\n",
            "14541 [Discriminator loss: 0.6743%, acc.: 55.86%] [Generator loss: 0.7774%]\n",
            "14542 [Discriminator loss: 0.6700%, acc.: 59.38%] [Generator loss: 0.8018%]\n",
            "14543 [Discriminator loss: 0.6729%, acc.: 58.20%] [Generator loss: 0.8218%]\n",
            "14544 [Discriminator loss: 0.6755%, acc.: 59.38%] [Generator loss: 0.8140%]\n",
            "14545 [Discriminator loss: 0.6586%, acc.: 63.28%] [Generator loss: 0.8099%]\n",
            "14546 [Discriminator loss: 0.6728%, acc.: 57.03%] [Generator loss: 0.7949%]\n",
            "14547 [Discriminator loss: 0.6603%, acc.: 66.02%] [Generator loss: 0.8457%]\n",
            "14548 [Discriminator loss: 0.6635%, acc.: 60.94%] [Generator loss: 0.7976%]\n",
            "14549 [Discriminator loss: 0.6774%, acc.: 60.16%] [Generator loss: 0.8083%]\n",
            "14550 [Discriminator loss: 0.6731%, acc.: 57.81%] [Generator loss: 0.8031%]\n",
            "14551 [Discriminator loss: 0.6713%, acc.: 57.81%] [Generator loss: 0.8058%]\n",
            "14552 [Discriminator loss: 0.6586%, acc.: 60.94%] [Generator loss: 0.8126%]\n",
            "14553 [Discriminator loss: 0.6635%, acc.: 62.11%] [Generator loss: 0.7945%]\n",
            "14554 [Discriminator loss: 0.6777%, acc.: 56.64%] [Generator loss: 0.8201%]\n",
            "14555 [Discriminator loss: 0.6650%, acc.: 62.11%] [Generator loss: 0.7907%]\n",
            "14556 [Discriminator loss: 0.6683%, acc.: 60.94%] [Generator loss: 0.7940%]\n",
            "14557 [Discriminator loss: 0.6546%, acc.: 62.50%] [Generator loss: 0.7656%]\n",
            "14558 [Discriminator loss: 0.6535%, acc.: 62.11%] [Generator loss: 0.7904%]\n",
            "14559 [Discriminator loss: 0.6883%, acc.: 55.47%] [Generator loss: 0.7666%]\n",
            "14560 [Discriminator loss: 0.6874%, acc.: 51.95%] [Generator loss: 0.7836%]\n",
            "14561 [Discriminator loss: 0.6776%, acc.: 54.69%] [Generator loss: 0.7989%]\n",
            "14562 [Discriminator loss: 0.6670%, acc.: 58.20%] [Generator loss: 0.8091%]\n",
            "14563 [Discriminator loss: 0.6515%, acc.: 65.23%] [Generator loss: 0.7912%]\n",
            "14564 [Discriminator loss: 0.6423%, acc.: 64.45%] [Generator loss: 0.7964%]\n",
            "14565 [Discriminator loss: 0.6460%, acc.: 66.41%] [Generator loss: 0.7991%]\n",
            "14566 [Discriminator loss: 0.6630%, acc.: 57.81%] [Generator loss: 0.7838%]\n",
            "14567 [Discriminator loss: 0.6691%, acc.: 61.33%] [Generator loss: 0.7996%]\n",
            "14568 [Discriminator loss: 0.6947%, acc.: 51.17%] [Generator loss: 0.8037%]\n",
            "14569 [Discriminator loss: 0.6668%, acc.: 57.03%] [Generator loss: 0.8105%]\n",
            "14570 [Discriminator loss: 0.6402%, acc.: 66.41%] [Generator loss: 0.7926%]\n",
            "14571 [Discriminator loss: 0.6789%, acc.: 55.08%] [Generator loss: 0.7763%]\n",
            "14572 [Discriminator loss: 0.6638%, acc.: 56.25%] [Generator loss: 0.8011%]\n",
            "14573 [Discriminator loss: 0.6573%, acc.: 60.55%] [Generator loss: 0.8096%]\n",
            "14574 [Discriminator loss: 0.6643%, acc.: 59.77%] [Generator loss: 0.8023%]\n",
            "14575 [Discriminator loss: 0.6357%, acc.: 68.75%] [Generator loss: 0.7784%]\n",
            "14576 [Discriminator loss: 0.6705%, acc.: 59.77%] [Generator loss: 0.7864%]\n",
            "14577 [Discriminator loss: 0.6671%, acc.: 58.98%] [Generator loss: 0.8221%]\n",
            "14578 [Discriminator loss: 0.6514%, acc.: 63.28%] [Generator loss: 0.7893%]\n",
            "14579 [Discriminator loss: 0.6691%, acc.: 58.59%] [Generator loss: 0.7977%]\n",
            "14580 [Discriminator loss: 0.6592%, acc.: 59.38%] [Generator loss: 0.8206%]\n",
            "14581 [Discriminator loss: 0.6706%, acc.: 60.55%] [Generator loss: 0.7886%]\n",
            "14582 [Discriminator loss: 0.6629%, acc.: 63.67%] [Generator loss: 0.7965%]\n",
            "14583 [Discriminator loss: 0.6769%, acc.: 55.86%] [Generator loss: 0.8035%]\n",
            "14584 [Discriminator loss: 0.6749%, acc.: 55.08%] [Generator loss: 0.8141%]\n",
            "14585 [Discriminator loss: 0.6760%, acc.: 58.98%] [Generator loss: 0.8291%]\n",
            "14586 [Discriminator loss: 0.6731%, acc.: 61.33%] [Generator loss: 0.7785%]\n",
            "14587 [Discriminator loss: 0.6752%, acc.: 57.03%] [Generator loss: 0.7950%]\n",
            "14588 [Discriminator loss: 0.6621%, acc.: 60.94%] [Generator loss: 0.7916%]\n",
            "14589 [Discriminator loss: 0.6551%, acc.: 62.89%] [Generator loss: 0.7973%]\n",
            "14590 [Discriminator loss: 0.6486%, acc.: 60.55%] [Generator loss: 0.8101%]\n",
            "14591 [Discriminator loss: 0.6557%, acc.: 62.50%] [Generator loss: 0.7971%]\n",
            "14592 [Discriminator loss: 0.6643%, acc.: 57.81%] [Generator loss: 0.7997%]\n",
            "14593 [Discriminator loss: 0.6640%, acc.: 55.08%] [Generator loss: 0.7951%]\n",
            "14594 [Discriminator loss: 0.6591%, acc.: 64.06%] [Generator loss: 0.7919%]\n",
            "14595 [Discriminator loss: 0.6684%, acc.: 56.25%] [Generator loss: 0.8061%]\n",
            "14596 [Discriminator loss: 0.6766%, acc.: 53.91%] [Generator loss: 0.7869%]\n",
            "14597 [Discriminator loss: 0.6655%, acc.: 57.81%] [Generator loss: 0.7871%]\n",
            "14598 [Discriminator loss: 0.6621%, acc.: 59.38%] [Generator loss: 0.8247%]\n",
            "14599 [Discriminator loss: 0.6505%, acc.: 60.94%] [Generator loss: 0.8110%]\n",
            "14600 [Discriminator loss: 0.6922%, acc.: 54.69%] [Generator loss: 0.7939%]\n",
            "14601 [Discriminator loss: 0.6670%, acc.: 56.25%] [Generator loss: 0.8170%]\n",
            "14602 [Discriminator loss: 0.6688%, acc.: 58.20%] [Generator loss: 0.8070%]\n",
            "14603 [Discriminator loss: 0.6584%, acc.: 61.33%] [Generator loss: 0.8132%]\n",
            "14604 [Discriminator loss: 0.6660%, acc.: 56.25%] [Generator loss: 0.8006%]\n",
            "14605 [Discriminator loss: 0.6643%, acc.: 58.98%] [Generator loss: 0.8122%]\n",
            "14606 [Discriminator loss: 0.6497%, acc.: 62.11%] [Generator loss: 0.8481%]\n",
            "14607 [Discriminator loss: 0.6818%, acc.: 53.12%] [Generator loss: 0.7780%]\n",
            "14608 [Discriminator loss: 0.6647%, acc.: 58.59%] [Generator loss: 0.8190%]\n",
            "14609 [Discriminator loss: 0.6462%, acc.: 64.45%] [Generator loss: 0.7956%]\n",
            "14610 [Discriminator loss: 0.6678%, acc.: 61.33%] [Generator loss: 0.8193%]\n",
            "14611 [Discriminator loss: 0.6460%, acc.: 63.28%] [Generator loss: 0.8253%]\n",
            "14612 [Discriminator loss: 0.6491%, acc.: 65.23%] [Generator loss: 0.7982%]\n",
            "14613 [Discriminator loss: 0.6836%, acc.: 51.95%] [Generator loss: 0.7841%]\n",
            "14614 [Discriminator loss: 0.6587%, acc.: 60.94%] [Generator loss: 0.7870%]\n",
            "14615 [Discriminator loss: 0.6535%, acc.: 59.38%] [Generator loss: 0.8016%]\n",
            "14616 [Discriminator loss: 0.6521%, acc.: 62.50%] [Generator loss: 0.8047%]\n",
            "14617 [Discriminator loss: 0.6675%, acc.: 60.94%] [Generator loss: 0.7622%]\n",
            "14618 [Discriminator loss: 0.6390%, acc.: 66.02%] [Generator loss: 0.8020%]\n",
            "14619 [Discriminator loss: 0.6571%, acc.: 55.86%] [Generator loss: 0.8030%]\n",
            "14620 [Discriminator loss: 0.6542%, acc.: 60.94%] [Generator loss: 0.8120%]\n",
            "14621 [Discriminator loss: 0.6698%, acc.: 58.20%] [Generator loss: 0.8207%]\n",
            "14622 [Discriminator loss: 0.6631%, acc.: 60.16%] [Generator loss: 0.7824%]\n",
            "14623 [Discriminator loss: 0.6714%, acc.: 58.59%] [Generator loss: 0.7853%]\n",
            "14624 [Discriminator loss: 0.6566%, acc.: 61.72%] [Generator loss: 0.8482%]\n",
            "14625 [Discriminator loss: 0.6617%, acc.: 64.45%] [Generator loss: 0.8032%]\n",
            "14626 [Discriminator loss: 0.6590%, acc.: 59.38%] [Generator loss: 0.8461%]\n",
            "14627 [Discriminator loss: 0.6640%, acc.: 58.98%] [Generator loss: 0.8008%]\n",
            "14628 [Discriminator loss: 0.6693%, acc.: 59.77%] [Generator loss: 0.8060%]\n",
            "14629 [Discriminator loss: 0.6827%, acc.: 57.42%] [Generator loss: 0.8078%]\n",
            "14630 [Discriminator loss: 0.6664%, acc.: 59.77%] [Generator loss: 0.7865%]\n",
            "14631 [Discriminator loss: 0.6646%, acc.: 59.38%] [Generator loss: 0.8099%]\n",
            "14632 [Discriminator loss: 0.6602%, acc.: 63.28%] [Generator loss: 0.8145%]\n",
            "14633 [Discriminator loss: 0.6489%, acc.: 62.89%] [Generator loss: 0.8125%]\n",
            "14634 [Discriminator loss: 0.6816%, acc.: 57.42%] [Generator loss: 0.7817%]\n",
            "14635 [Discriminator loss: 0.6482%, acc.: 60.94%] [Generator loss: 0.7883%]\n",
            "14636 [Discriminator loss: 0.6677%, acc.: 57.81%] [Generator loss: 0.7932%]\n",
            "14637 [Discriminator loss: 0.6663%, acc.: 58.98%] [Generator loss: 0.7945%]\n",
            "14638 [Discriminator loss: 0.6567%, acc.: 62.11%] [Generator loss: 0.8220%]\n",
            "14639 [Discriminator loss: 0.6752%, acc.: 59.77%] [Generator loss: 0.8043%]\n",
            "14640 [Discriminator loss: 0.6603%, acc.: 59.77%] [Generator loss: 0.7928%]\n",
            "14641 [Discriminator loss: 0.6538%, acc.: 62.11%] [Generator loss: 0.7691%]\n",
            "14642 [Discriminator loss: 0.6594%, acc.: 60.16%] [Generator loss: 0.7856%]\n",
            "14643 [Discriminator loss: 0.6722%, acc.: 55.47%] [Generator loss: 0.7986%]\n",
            "14644 [Discriminator loss: 0.6738%, acc.: 57.81%] [Generator loss: 0.8164%]\n",
            "14645 [Discriminator loss: 0.6584%, acc.: 58.20%] [Generator loss: 0.8018%]\n",
            "14646 [Discriminator loss: 0.6627%, acc.: 60.94%] [Generator loss: 0.8288%]\n",
            "14647 [Discriminator loss: 0.6801%, acc.: 53.52%] [Generator loss: 0.8327%]\n",
            "14648 [Discriminator loss: 0.6513%, acc.: 63.28%] [Generator loss: 0.8300%]\n",
            "14649 [Discriminator loss: 0.6671%, acc.: 56.25%] [Generator loss: 0.8092%]\n",
            "14650 [Discriminator loss: 0.6529%, acc.: 62.50%] [Generator loss: 0.8048%]\n",
            "14651 [Discriminator loss: 0.6544%, acc.: 62.11%] [Generator loss: 0.7923%]\n",
            "14652 [Discriminator loss: 0.6681%, acc.: 56.64%] [Generator loss: 0.7857%]\n",
            "14653 [Discriminator loss: 0.6438%, acc.: 69.53%] [Generator loss: 0.7933%]\n",
            "14654 [Discriminator loss: 0.6705%, acc.: 58.98%] [Generator loss: 0.7977%]\n",
            "14655 [Discriminator loss: 0.6663%, acc.: 55.86%] [Generator loss: 0.7853%]\n",
            "14656 [Discriminator loss: 0.6781%, acc.: 55.47%] [Generator loss: 0.8157%]\n",
            "14657 [Discriminator loss: 0.6797%, acc.: 57.03%] [Generator loss: 0.7888%]\n",
            "14658 [Discriminator loss: 0.6400%, acc.: 64.06%] [Generator loss: 0.8085%]\n",
            "14659 [Discriminator loss: 0.6519%, acc.: 63.28%] [Generator loss: 0.7988%]\n",
            "14660 [Discriminator loss: 0.6715%, acc.: 58.20%] [Generator loss: 0.8296%]\n",
            "14661 [Discriminator loss: 0.6755%, acc.: 55.86%] [Generator loss: 0.7950%]\n",
            "14662 [Discriminator loss: 0.6559%, acc.: 58.20%] [Generator loss: 0.8316%]\n",
            "14663 [Discriminator loss: 0.6925%, acc.: 50.00%] [Generator loss: 0.8337%]\n",
            "14664 [Discriminator loss: 0.6681%, acc.: 55.47%] [Generator loss: 0.7997%]\n",
            "14665 [Discriminator loss: 0.6852%, acc.: 53.91%] [Generator loss: 0.7873%]\n",
            "14666 [Discriminator loss: 0.6662%, acc.: 59.77%] [Generator loss: 0.8050%]\n",
            "14667 [Discriminator loss: 0.6732%, acc.: 56.25%] [Generator loss: 0.7923%]\n",
            "14668 [Discriminator loss: 0.6582%, acc.: 63.28%] [Generator loss: 0.8112%]\n",
            "14669 [Discriminator loss: 0.6501%, acc.: 61.72%] [Generator loss: 0.8093%]\n",
            "14670 [Discriminator loss: 0.6656%, acc.: 60.16%] [Generator loss: 0.8173%]\n",
            "14671 [Discriminator loss: 0.6873%, acc.: 55.47%] [Generator loss: 0.8036%]\n",
            "14672 [Discriminator loss: 0.6733%, acc.: 56.25%] [Generator loss: 0.8082%]\n",
            "14673 [Discriminator loss: 0.6624%, acc.: 62.89%] [Generator loss: 0.7859%]\n",
            "14674 [Discriminator loss: 0.6761%, acc.: 57.03%] [Generator loss: 0.8045%]\n",
            "14675 [Discriminator loss: 0.6874%, acc.: 53.12%] [Generator loss: 0.7812%]\n",
            "14676 [Discriminator loss: 0.6482%, acc.: 62.89%] [Generator loss: 0.7883%]\n",
            "14677 [Discriminator loss: 0.6706%, acc.: 57.42%] [Generator loss: 0.8178%]\n",
            "14678 [Discriminator loss: 0.6744%, acc.: 56.64%] [Generator loss: 0.7920%]\n",
            "14679 [Discriminator loss: 0.6629%, acc.: 60.16%] [Generator loss: 0.8352%]\n",
            "14680 [Discriminator loss: 0.6880%, acc.: 55.47%] [Generator loss: 0.8077%]\n",
            "14681 [Discriminator loss: 0.6571%, acc.: 61.33%] [Generator loss: 0.8073%]\n",
            "14682 [Discriminator loss: 0.6880%, acc.: 57.03%] [Generator loss: 0.7832%]\n",
            "14683 [Discriminator loss: 0.6526%, acc.: 63.28%] [Generator loss: 0.8057%]\n",
            "14684 [Discriminator loss: 0.6653%, acc.: 56.64%] [Generator loss: 0.7745%]\n",
            "14685 [Discriminator loss: 0.6683%, acc.: 57.81%] [Generator loss: 0.7870%]\n",
            "14686 [Discriminator loss: 0.6816%, acc.: 49.61%] [Generator loss: 0.8016%]\n",
            "14687 [Discriminator loss: 0.6430%, acc.: 64.84%] [Generator loss: 0.8133%]\n",
            "14688 [Discriminator loss: 0.6742%, acc.: 57.81%] [Generator loss: 0.8158%]\n",
            "14689 [Discriminator loss: 0.6806%, acc.: 57.81%] [Generator loss: 0.8157%]\n",
            "14690 [Discriminator loss: 0.6583%, acc.: 65.23%] [Generator loss: 0.7798%]\n",
            "14691 [Discriminator loss: 0.6770%, acc.: 51.17%] [Generator loss: 0.8102%]\n",
            "14692 [Discriminator loss: 0.6588%, acc.: 58.59%] [Generator loss: 0.7863%]\n",
            "14693 [Discriminator loss: 0.6568%, acc.: 55.86%] [Generator loss: 0.8282%]\n",
            "14694 [Discriminator loss: 0.6695%, acc.: 59.38%] [Generator loss: 0.7993%]\n",
            "14695 [Discriminator loss: 0.6538%, acc.: 62.89%] [Generator loss: 0.8020%]\n",
            "14696 [Discriminator loss: 0.6671%, acc.: 61.72%] [Generator loss: 0.8087%]\n",
            "14697 [Discriminator loss: 0.6514%, acc.: 65.23%] [Generator loss: 0.8163%]\n",
            "14698 [Discriminator loss: 0.6593%, acc.: 58.98%] [Generator loss: 0.7844%]\n",
            "14699 [Discriminator loss: 0.6550%, acc.: 60.55%] [Generator loss: 0.8249%]\n",
            "14700 [Discriminator loss: 0.6799%, acc.: 55.86%] [Generator loss: 0.8056%]\n",
            "14701 [Discriminator loss: 0.6611%, acc.: 60.55%] [Generator loss: 0.8181%]\n",
            "14702 [Discriminator loss: 0.6528%, acc.: 60.16%] [Generator loss: 0.8005%]\n",
            "14703 [Discriminator loss: 0.6727%, acc.: 56.64%] [Generator loss: 0.8183%]\n",
            "14704 [Discriminator loss: 0.6617%, acc.: 60.16%] [Generator loss: 0.7997%]\n",
            "14705 [Discriminator loss: 0.6781%, acc.: 56.25%] [Generator loss: 0.7859%]\n",
            "14706 [Discriminator loss: 0.6662%, acc.: 58.20%] [Generator loss: 0.7808%]\n",
            "14707 [Discriminator loss: 0.6769%, acc.: 57.03%] [Generator loss: 0.7859%]\n",
            "14708 [Discriminator loss: 0.6642%, acc.: 59.77%] [Generator loss: 0.7948%]\n",
            "14709 [Discriminator loss: 0.6623%, acc.: 58.20%] [Generator loss: 0.7943%]\n",
            "14710 [Discriminator loss: 0.6699%, acc.: 58.59%] [Generator loss: 0.8121%]\n",
            "14711 [Discriminator loss: 0.6515%, acc.: 59.77%] [Generator loss: 0.8047%]\n",
            "14712 [Discriminator loss: 0.6829%, acc.: 53.12%] [Generator loss: 0.7900%]\n",
            "14713 [Discriminator loss: 0.6573%, acc.: 58.59%] [Generator loss: 0.7854%]\n",
            "14714 [Discriminator loss: 0.6800%, acc.: 56.25%] [Generator loss: 0.7843%]\n",
            "14715 [Discriminator loss: 0.6682%, acc.: 56.25%] [Generator loss: 0.7754%]\n",
            "14716 [Discriminator loss: 0.6629%, acc.: 57.42%] [Generator loss: 0.7596%]\n",
            "14717 [Discriminator loss: 0.6648%, acc.: 59.77%] [Generator loss: 0.7865%]\n",
            "14718 [Discriminator loss: 0.6607%, acc.: 60.16%] [Generator loss: 0.8291%]\n",
            "14719 [Discriminator loss: 0.6840%, acc.: 54.30%] [Generator loss: 0.7825%]\n",
            "14720 [Discriminator loss: 0.6620%, acc.: 61.33%] [Generator loss: 0.8201%]\n",
            "14721 [Discriminator loss: 0.6748%, acc.: 54.69%] [Generator loss: 0.8201%]\n",
            "14722 [Discriminator loss: 0.6715%, acc.: 58.59%] [Generator loss: 0.7813%]\n",
            "14723 [Discriminator loss: 0.6514%, acc.: 64.06%] [Generator loss: 0.7834%]\n",
            "14724 [Discriminator loss: 0.6603%, acc.: 61.33%] [Generator loss: 0.8124%]\n",
            "14725 [Discriminator loss: 0.6565%, acc.: 64.06%] [Generator loss: 0.8061%]\n",
            "14726 [Discriminator loss: 0.6570%, acc.: 60.94%] [Generator loss: 0.7950%]\n",
            "14727 [Discriminator loss: 0.6512%, acc.: 61.33%] [Generator loss: 0.7911%]\n",
            "14728 [Discriminator loss: 0.6629%, acc.: 60.94%] [Generator loss: 0.8002%]\n",
            "14729 [Discriminator loss: 0.6625%, acc.: 62.11%] [Generator loss: 0.7897%]\n",
            "14730 [Discriminator loss: 0.6458%, acc.: 62.11%] [Generator loss: 0.7832%]\n",
            "14731 [Discriminator loss: 0.6502%, acc.: 60.94%] [Generator loss: 0.8036%]\n",
            "14732 [Discriminator loss: 0.6581%, acc.: 57.81%] [Generator loss: 0.8136%]\n",
            "14733 [Discriminator loss: 0.6752%, acc.: 58.98%] [Generator loss: 0.7960%]\n",
            "14734 [Discriminator loss: 0.6647%, acc.: 62.11%] [Generator loss: 0.7957%]\n",
            "14735 [Discriminator loss: 0.6585%, acc.: 60.94%] [Generator loss: 0.7892%]\n",
            "14736 [Discriminator loss: 0.6503%, acc.: 59.77%] [Generator loss: 0.8181%]\n",
            "14737 [Discriminator loss: 0.6635%, acc.: 59.77%] [Generator loss: 0.7853%]\n",
            "14738 [Discriminator loss: 0.6627%, acc.: 60.94%] [Generator loss: 0.8131%]\n",
            "14739 [Discriminator loss: 0.6532%, acc.: 60.16%] [Generator loss: 0.8028%]\n",
            "14740 [Discriminator loss: 0.6541%, acc.: 62.89%] [Generator loss: 0.7767%]\n",
            "14741 [Discriminator loss: 0.6726%, acc.: 58.59%] [Generator loss: 0.8011%]\n",
            "14742 [Discriminator loss: 0.6613%, acc.: 58.20%] [Generator loss: 0.7999%]\n",
            "14743 [Discriminator loss: 0.6476%, acc.: 62.11%] [Generator loss: 0.8094%]\n",
            "14744 [Discriminator loss: 0.6413%, acc.: 66.80%] [Generator loss: 0.8286%]\n",
            "14745 [Discriminator loss: 0.6629%, acc.: 60.94%] [Generator loss: 0.8294%]\n",
            "14746 [Discriminator loss: 0.6683%, acc.: 57.42%] [Generator loss: 0.8310%]\n",
            "14747 [Discriminator loss: 0.6518%, acc.: 64.06%] [Generator loss: 0.8051%]\n",
            "14748 [Discriminator loss: 0.6607%, acc.: 60.55%] [Generator loss: 0.8139%]\n",
            "14749 [Discriminator loss: 0.6490%, acc.: 62.89%] [Generator loss: 0.8258%]\n",
            "14750 [Discriminator loss: 0.6677%, acc.: 59.77%] [Generator loss: 0.7854%]\n",
            "14751 [Discriminator loss: 0.6731%, acc.: 58.98%] [Generator loss: 0.7908%]\n",
            "14752 [Discriminator loss: 0.6553%, acc.: 61.33%] [Generator loss: 0.7790%]\n",
            "14753 [Discriminator loss: 0.6821%, acc.: 57.42%] [Generator loss: 0.7846%]\n",
            "14754 [Discriminator loss: 0.6839%, acc.: 55.08%] [Generator loss: 0.7919%]\n",
            "14755 [Discriminator loss: 0.6726%, acc.: 55.47%] [Generator loss: 0.7792%]\n",
            "14756 [Discriminator loss: 0.6693%, acc.: 60.16%] [Generator loss: 0.8362%]\n",
            "14757 [Discriminator loss: 0.6611%, acc.: 57.42%] [Generator loss: 0.8128%]\n",
            "14758 [Discriminator loss: 0.6657%, acc.: 60.94%] [Generator loss: 0.7756%]\n",
            "14759 [Discriminator loss: 0.6754%, acc.: 57.03%] [Generator loss: 0.8045%]\n",
            "14760 [Discriminator loss: 0.6687%, acc.: 58.98%] [Generator loss: 0.7631%]\n",
            "14761 [Discriminator loss: 0.6678%, acc.: 59.77%] [Generator loss: 0.7827%]\n",
            "14762 [Discriminator loss: 0.6549%, acc.: 59.77%] [Generator loss: 0.7954%]\n",
            "14763 [Discriminator loss: 0.6712%, acc.: 59.38%] [Generator loss: 0.7933%]\n",
            "14764 [Discriminator loss: 0.6801%, acc.: 54.69%] [Generator loss: 0.8300%]\n",
            "14765 [Discriminator loss: 0.6548%, acc.: 60.55%] [Generator loss: 0.7851%]\n",
            "14766 [Discriminator loss: 0.6744%, acc.: 58.98%] [Generator loss: 0.7849%]\n",
            "14767 [Discriminator loss: 0.6733%, acc.: 57.42%] [Generator loss: 0.8121%]\n",
            "14768 [Discriminator loss: 0.6665%, acc.: 60.16%] [Generator loss: 0.7889%]\n",
            "14769 [Discriminator loss: 0.6702%, acc.: 57.81%] [Generator loss: 0.8016%]\n",
            "14770 [Discriminator loss: 0.6785%, acc.: 60.94%] [Generator loss: 0.7931%]\n",
            "14771 [Discriminator loss: 0.6491%, acc.: 64.84%] [Generator loss: 0.7879%]\n",
            "14772 [Discriminator loss: 0.6650%, acc.: 57.03%] [Generator loss: 0.8089%]\n",
            "14773 [Discriminator loss: 0.6666%, acc.: 62.11%] [Generator loss: 0.8202%]\n",
            "14774 [Discriminator loss: 0.6760%, acc.: 58.59%] [Generator loss: 0.7961%]\n",
            "14775 [Discriminator loss: 0.6629%, acc.: 57.81%] [Generator loss: 0.8161%]\n",
            "14776 [Discriminator loss: 0.6636%, acc.: 62.89%] [Generator loss: 0.8199%]\n",
            "14777 [Discriminator loss: 0.6561%, acc.: 61.72%] [Generator loss: 0.7979%]\n",
            "14778 [Discriminator loss: 0.6498%, acc.: 64.06%] [Generator loss: 0.8089%]\n",
            "14779 [Discriminator loss: 0.6788%, acc.: 55.47%] [Generator loss: 0.8188%]\n",
            "14780 [Discriminator loss: 0.6681%, acc.: 57.81%] [Generator loss: 0.7929%]\n",
            "14781 [Discriminator loss: 0.6587%, acc.: 59.38%] [Generator loss: 0.8121%]\n",
            "14782 [Discriminator loss: 0.6579%, acc.: 62.89%] [Generator loss: 0.8050%]\n",
            "14783 [Discriminator loss: 0.6518%, acc.: 60.94%] [Generator loss: 0.8077%]\n",
            "14784 [Discriminator loss: 0.6577%, acc.: 60.94%] [Generator loss: 0.7979%]\n",
            "14785 [Discriminator loss: 0.6580%, acc.: 60.94%] [Generator loss: 0.8036%]\n",
            "14786 [Discriminator loss: 0.6660%, acc.: 58.20%] [Generator loss: 0.7868%]\n",
            "14787 [Discriminator loss: 0.6673%, acc.: 58.20%] [Generator loss: 0.8366%]\n",
            "14788 [Discriminator loss: 0.6609%, acc.: 61.72%] [Generator loss: 0.8200%]\n",
            "14789 [Discriminator loss: 0.6629%, acc.: 60.55%] [Generator loss: 0.8054%]\n",
            "14790 [Discriminator loss: 0.6627%, acc.: 57.42%] [Generator loss: 0.7925%]\n",
            "14791 [Discriminator loss: 0.6445%, acc.: 61.72%] [Generator loss: 0.8069%]\n",
            "14792 [Discriminator loss: 0.6618%, acc.: 62.50%] [Generator loss: 0.8013%]\n",
            "14793 [Discriminator loss: 0.6565%, acc.: 62.11%] [Generator loss: 0.8081%]\n",
            "14794 [Discriminator loss: 0.6805%, acc.: 55.86%] [Generator loss: 0.8130%]\n",
            "14795 [Discriminator loss: 0.6739%, acc.: 55.86%] [Generator loss: 0.8116%]\n",
            "14796 [Discriminator loss: 0.6493%, acc.: 66.02%] [Generator loss: 0.8015%]\n",
            "14797 [Discriminator loss: 0.6519%, acc.: 65.23%] [Generator loss: 0.7671%]\n",
            "14798 [Discriminator loss: 0.6735%, acc.: 54.30%] [Generator loss: 0.8405%]\n",
            "14799 [Discriminator loss: 0.6620%, acc.: 63.28%] [Generator loss: 0.8010%]\n",
            "14800 [Discriminator loss: 0.6528%, acc.: 62.89%] [Generator loss: 0.8127%]\n",
            "14801 [Discriminator loss: 0.6910%, acc.: 54.69%] [Generator loss: 0.8108%]\n",
            "14802 [Discriminator loss: 0.6653%, acc.: 62.50%] [Generator loss: 0.7952%]\n",
            "14803 [Discriminator loss: 0.6769%, acc.: 57.42%] [Generator loss: 0.7794%]\n",
            "14804 [Discriminator loss: 0.6684%, acc.: 57.03%] [Generator loss: 0.7869%]\n",
            "14805 [Discriminator loss: 0.6461%, acc.: 61.72%] [Generator loss: 0.7940%]\n",
            "14806 [Discriminator loss: 0.6564%, acc.: 63.28%] [Generator loss: 0.7800%]\n",
            "14807 [Discriminator loss: 0.6657%, acc.: 57.42%] [Generator loss: 0.7686%]\n",
            "14808 [Discriminator loss: 0.6804%, acc.: 57.03%] [Generator loss: 0.8064%]\n",
            "14809 [Discriminator loss: 0.6499%, acc.: 62.89%] [Generator loss: 0.7839%]\n",
            "14810 [Discriminator loss: 0.6825%, acc.: 57.03%] [Generator loss: 0.8161%]\n",
            "14811 [Discriminator loss: 0.6574%, acc.: 62.50%] [Generator loss: 0.8042%]\n",
            "14812 [Discriminator loss: 0.6732%, acc.: 57.42%] [Generator loss: 0.8180%]\n",
            "14813 [Discriminator loss: 0.6751%, acc.: 58.59%] [Generator loss: 0.7816%]\n",
            "14814 [Discriminator loss: 0.6442%, acc.: 66.41%] [Generator loss: 0.8026%]\n",
            "14815 [Discriminator loss: 0.6808%, acc.: 55.86%] [Generator loss: 0.7943%]\n",
            "14816 [Discriminator loss: 0.6618%, acc.: 61.33%] [Generator loss: 0.8147%]\n",
            "14817 [Discriminator loss: 0.6482%, acc.: 62.89%] [Generator loss: 0.8138%]\n",
            "14818 [Discriminator loss: 0.6674%, acc.: 55.86%] [Generator loss: 0.8084%]\n",
            "14819 [Discriminator loss: 0.6474%, acc.: 65.23%] [Generator loss: 0.8100%]\n",
            "14820 [Discriminator loss: 0.6796%, acc.: 55.08%] [Generator loss: 0.7847%]\n",
            "14821 [Discriminator loss: 0.6582%, acc.: 59.38%] [Generator loss: 0.7882%]\n",
            "14822 [Discriminator loss: 0.6520%, acc.: 62.89%] [Generator loss: 0.8079%]\n",
            "14823 [Discriminator loss: 0.6701%, acc.: 58.98%] [Generator loss: 0.7966%]\n",
            "14824 [Discriminator loss: 0.6570%, acc.: 58.59%] [Generator loss: 0.8286%]\n",
            "14825 [Discriminator loss: 0.6752%, acc.: 59.77%] [Generator loss: 0.7731%]\n",
            "14826 [Discriminator loss: 0.6799%, acc.: 53.12%] [Generator loss: 0.7844%]\n",
            "14827 [Discriminator loss: 0.6815%, acc.: 55.86%] [Generator loss: 0.7785%]\n",
            "14828 [Discriminator loss: 0.6605%, acc.: 61.33%] [Generator loss: 0.7798%]\n",
            "14829 [Discriminator loss: 0.6613%, acc.: 59.38%] [Generator loss: 0.7762%]\n",
            "14830 [Discriminator loss: 0.6622%, acc.: 62.50%] [Generator loss: 0.8070%]\n",
            "14831 [Discriminator loss: 0.6833%, acc.: 58.20%] [Generator loss: 0.7779%]\n",
            "14832 [Discriminator loss: 0.6824%, acc.: 53.52%] [Generator loss: 0.7968%]\n",
            "14833 [Discriminator loss: 0.6462%, acc.: 68.75%] [Generator loss: 0.8246%]\n",
            "14834 [Discriminator loss: 0.6729%, acc.: 56.64%] [Generator loss: 0.8015%]\n",
            "14835 [Discriminator loss: 0.6791%, acc.: 55.08%] [Generator loss: 0.8076%]\n",
            "14836 [Discriminator loss: 0.6545%, acc.: 62.50%] [Generator loss: 0.8200%]\n",
            "14837 [Discriminator loss: 0.6685%, acc.: 59.38%] [Generator loss: 0.7921%]\n",
            "14838 [Discriminator loss: 0.6896%, acc.: 52.34%] [Generator loss: 0.8037%]\n",
            "14839 [Discriminator loss: 0.6428%, acc.: 64.84%] [Generator loss: 0.8271%]\n",
            "14840 [Discriminator loss: 0.6711%, acc.: 60.16%] [Generator loss: 0.8178%]\n",
            "14841 [Discriminator loss: 0.6492%, acc.: 65.23%] [Generator loss: 0.8096%]\n",
            "14842 [Discriminator loss: 0.6775%, acc.: 56.25%] [Generator loss: 0.7832%]\n",
            "14843 [Discriminator loss: 0.6698%, acc.: 58.59%] [Generator loss: 0.8023%]\n",
            "14844 [Discriminator loss: 0.6521%, acc.: 63.67%] [Generator loss: 0.8087%]\n",
            "14845 [Discriminator loss: 0.6773%, acc.: 57.81%] [Generator loss: 0.8137%]\n",
            "14846 [Discriminator loss: 0.6518%, acc.: 61.72%] [Generator loss: 0.7692%]\n",
            "14847 [Discriminator loss: 0.6792%, acc.: 56.25%] [Generator loss: 0.7956%]\n",
            "14848 [Discriminator loss: 0.6698%, acc.: 60.94%] [Generator loss: 0.8048%]\n",
            "14849 [Discriminator loss: 0.6617%, acc.: 59.38%] [Generator loss: 0.8059%]\n",
            "14850 [Discriminator loss: 0.6722%, acc.: 57.42%] [Generator loss: 0.7490%]\n",
            "14851 [Discriminator loss: 0.6474%, acc.: 62.11%] [Generator loss: 0.8122%]\n",
            "14852 [Discriminator loss: 0.6739%, acc.: 60.55%] [Generator loss: 0.7950%]\n",
            "14853 [Discriminator loss: 0.6627%, acc.: 61.72%] [Generator loss: 0.8200%]\n",
            "14854 [Discriminator loss: 0.6665%, acc.: 56.25%] [Generator loss: 0.8178%]\n",
            "14855 [Discriminator loss: 0.6596%, acc.: 59.38%] [Generator loss: 0.8135%]\n",
            "14856 [Discriminator loss: 0.6579%, acc.: 63.67%] [Generator loss: 0.7823%]\n",
            "14857 [Discriminator loss: 0.6792%, acc.: 54.30%] [Generator loss: 0.7927%]\n",
            "14858 [Discriminator loss: 0.6637%, acc.: 62.89%] [Generator loss: 0.8123%]\n",
            "14859 [Discriminator loss: 0.6807%, acc.: 52.34%] [Generator loss: 0.8088%]\n",
            "14860 [Discriminator loss: 0.6657%, acc.: 58.59%] [Generator loss: 0.7836%]\n",
            "14861 [Discriminator loss: 0.6714%, acc.: 58.59%] [Generator loss: 0.7918%]\n",
            "14862 [Discriminator loss: 0.6683%, acc.: 57.81%] [Generator loss: 0.8137%]\n",
            "14863 [Discriminator loss: 0.6666%, acc.: 59.38%] [Generator loss: 0.7828%]\n",
            "14864 [Discriminator loss: 0.6864%, acc.: 53.52%] [Generator loss: 0.8173%]\n",
            "14865 [Discriminator loss: 0.6622%, acc.: 58.20%] [Generator loss: 0.8226%]\n",
            "14866 [Discriminator loss: 0.6637%, acc.: 61.33%] [Generator loss: 0.8071%]\n",
            "14867 [Discriminator loss: 0.6406%, acc.: 63.67%] [Generator loss: 0.8058%]\n",
            "14868 [Discriminator loss: 0.6765%, acc.: 55.08%] [Generator loss: 0.8085%]\n",
            "14869 [Discriminator loss: 0.6688%, acc.: 58.20%] [Generator loss: 0.8224%]\n",
            "14870 [Discriminator loss: 0.6785%, acc.: 54.30%] [Generator loss: 0.8046%]\n",
            "14871 [Discriminator loss: 0.6705%, acc.: 62.50%] [Generator loss: 0.8127%]\n",
            "14872 [Discriminator loss: 0.6775%, acc.: 54.30%] [Generator loss: 0.8094%]\n",
            "14873 [Discriminator loss: 0.6589%, acc.: 58.20%] [Generator loss: 0.8052%]\n",
            "14874 [Discriminator loss: 0.6557%, acc.: 62.11%] [Generator loss: 0.7948%]\n",
            "14875 [Discriminator loss: 0.6734%, acc.: 56.64%] [Generator loss: 0.8153%]\n",
            "14876 [Discriminator loss: 0.6595%, acc.: 60.16%] [Generator loss: 0.8029%]\n",
            "14877 [Discriminator loss: 0.6718%, acc.: 59.38%] [Generator loss: 0.7938%]\n",
            "14878 [Discriminator loss: 0.6566%, acc.: 62.89%] [Generator loss: 0.7925%]\n",
            "14879 [Discriminator loss: 0.6715%, acc.: 58.98%] [Generator loss: 0.7872%]\n",
            "14880 [Discriminator loss: 0.6694%, acc.: 61.72%] [Generator loss: 0.8061%]\n",
            "14881 [Discriminator loss: 0.6933%, acc.: 55.47%] [Generator loss: 0.8026%]\n",
            "14882 [Discriminator loss: 0.6695%, acc.: 58.59%] [Generator loss: 0.8043%]\n",
            "14883 [Discriminator loss: 0.6708%, acc.: 58.59%] [Generator loss: 0.8163%]\n",
            "14884 [Discriminator loss: 0.6657%, acc.: 60.55%] [Generator loss: 0.8060%]\n",
            "14885 [Discriminator loss: 0.6407%, acc.: 63.67%] [Generator loss: 0.8092%]\n",
            "14886 [Discriminator loss: 0.6707%, acc.: 58.98%] [Generator loss: 0.8179%]\n",
            "14887 [Discriminator loss: 0.6805%, acc.: 57.03%] [Generator loss: 0.7916%]\n",
            "14888 [Discriminator loss: 0.6652%, acc.: 61.72%] [Generator loss: 0.7677%]\n",
            "14889 [Discriminator loss: 0.6622%, acc.: 59.38%] [Generator loss: 0.7727%]\n",
            "14890 [Discriminator loss: 0.6580%, acc.: 64.84%] [Generator loss: 0.8358%]\n",
            "14891 [Discriminator loss: 0.6616%, acc.: 59.77%] [Generator loss: 0.7973%]\n",
            "14892 [Discriminator loss: 0.6908%, acc.: 52.34%] [Generator loss: 0.8414%]\n",
            "14893 [Discriminator loss: 0.6568%, acc.: 62.89%] [Generator loss: 0.8228%]\n",
            "14894 [Discriminator loss: 0.6820%, acc.: 53.91%] [Generator loss: 0.7696%]\n",
            "14895 [Discriminator loss: 0.6653%, acc.: 61.72%] [Generator loss: 0.8048%]\n",
            "14896 [Discriminator loss: 0.6883%, acc.: 51.56%] [Generator loss: 0.7865%]\n",
            "14897 [Discriminator loss: 0.6685%, acc.: 55.86%] [Generator loss: 0.8198%]\n",
            "14898 [Discriminator loss: 0.6723%, acc.: 58.59%] [Generator loss: 0.8018%]\n",
            "14899 [Discriminator loss: 0.6513%, acc.: 62.11%] [Generator loss: 0.8008%]\n",
            "14900 [Discriminator loss: 0.6390%, acc.: 65.62%] [Generator loss: 0.8030%]\n",
            "14901 [Discriminator loss: 0.6852%, acc.: 56.64%] [Generator loss: 0.7894%]\n",
            "14902 [Discriminator loss: 0.6434%, acc.: 66.41%] [Generator loss: 0.7812%]\n",
            "14903 [Discriminator loss: 0.6738%, acc.: 55.08%] [Generator loss: 0.7951%]\n",
            "14904 [Discriminator loss: 0.6737%, acc.: 57.03%] [Generator loss: 0.7847%]\n",
            "14905 [Discriminator loss: 0.6572%, acc.: 60.94%] [Generator loss: 0.8083%]\n",
            "14906 [Discriminator loss: 0.6736%, acc.: 56.64%] [Generator loss: 0.7867%]\n",
            "14907 [Discriminator loss: 0.6669%, acc.: 60.16%] [Generator loss: 0.7976%]\n",
            "14908 [Discriminator loss: 0.6671%, acc.: 60.16%] [Generator loss: 0.8059%]\n",
            "14909 [Discriminator loss: 0.6589%, acc.: 57.03%] [Generator loss: 0.7925%]\n",
            "14910 [Discriminator loss: 0.6599%, acc.: 62.89%] [Generator loss: 0.7970%]\n",
            "14911 [Discriminator loss: 0.6730%, acc.: 54.30%] [Generator loss: 0.7904%]\n",
            "14912 [Discriminator loss: 0.6751%, acc.: 55.47%] [Generator loss: 0.7951%]\n",
            "14913 [Discriminator loss: 0.6511%, acc.: 63.28%] [Generator loss: 0.8250%]\n",
            "14914 [Discriminator loss: 0.6541%, acc.: 62.50%] [Generator loss: 0.8166%]\n",
            "14915 [Discriminator loss: 0.6588%, acc.: 63.67%] [Generator loss: 0.7747%]\n",
            "14916 [Discriminator loss: 0.6754%, acc.: 58.20%] [Generator loss: 0.8073%]\n",
            "14917 [Discriminator loss: 0.6561%, acc.: 63.28%] [Generator loss: 0.8126%]\n",
            "14918 [Discriminator loss: 0.6661%, acc.: 61.33%] [Generator loss: 0.7872%]\n",
            "14919 [Discriminator loss: 0.6621%, acc.: 56.64%] [Generator loss: 0.7990%]\n",
            "14920 [Discriminator loss: 0.6841%, acc.: 53.91%] [Generator loss: 0.7788%]\n",
            "14921 [Discriminator loss: 0.6770%, acc.: 58.98%] [Generator loss: 0.7991%]\n",
            "14922 [Discriminator loss: 0.6579%, acc.: 62.11%] [Generator loss: 0.8080%]\n",
            "14923 [Discriminator loss: 0.6651%, acc.: 59.77%] [Generator loss: 0.8228%]\n",
            "14924 [Discriminator loss: 0.6760%, acc.: 57.81%] [Generator loss: 0.8014%]\n",
            "14925 [Discriminator loss: 0.6594%, acc.: 59.77%] [Generator loss: 0.7952%]\n",
            "14926 [Discriminator loss: 0.6686%, acc.: 55.86%] [Generator loss: 0.7920%]\n",
            "14927 [Discriminator loss: 0.6606%, acc.: 59.77%] [Generator loss: 0.7836%]\n",
            "14928 [Discriminator loss: 0.6580%, acc.: 60.55%] [Generator loss: 0.8124%]\n",
            "14929 [Discriminator loss: 0.6683%, acc.: 57.03%] [Generator loss: 0.7803%]\n",
            "14930 [Discriminator loss: 0.6693%, acc.: 56.64%] [Generator loss: 0.7881%]\n",
            "14931 [Discriminator loss: 0.6752%, acc.: 57.03%] [Generator loss: 0.7932%]\n",
            "14932 [Discriminator loss: 0.6563%, acc.: 64.45%] [Generator loss: 0.8131%]\n",
            "14933 [Discriminator loss: 0.6692%, acc.: 55.86%] [Generator loss: 0.8135%]\n",
            "14934 [Discriminator loss: 0.6715%, acc.: 55.86%] [Generator loss: 0.7887%]\n",
            "14935 [Discriminator loss: 0.6483%, acc.: 64.84%] [Generator loss: 0.7903%]\n",
            "14936 [Discriminator loss: 0.6635%, acc.: 58.20%] [Generator loss: 0.8176%]\n",
            "14937 [Discriminator loss: 0.6868%, acc.: 50.78%] [Generator loss: 0.8048%]\n",
            "14938 [Discriminator loss: 0.6526%, acc.: 63.67%] [Generator loss: 0.7810%]\n",
            "14939 [Discriminator loss: 0.6627%, acc.: 59.38%] [Generator loss: 0.7738%]\n",
            "14940 [Discriminator loss: 0.6783%, acc.: 57.03%] [Generator loss: 0.7796%]\n",
            "14941 [Discriminator loss: 0.6456%, acc.: 62.11%] [Generator loss: 0.8029%]\n",
            "14942 [Discriminator loss: 0.6653%, acc.: 57.03%] [Generator loss: 0.7962%]\n",
            "14943 [Discriminator loss: 0.6628%, acc.: 62.11%] [Generator loss: 0.7895%]\n",
            "14944 [Discriminator loss: 0.6635%, acc.: 62.89%] [Generator loss: 0.7922%]\n",
            "14945 [Discriminator loss: 0.6511%, acc.: 62.89%] [Generator loss: 0.7982%]\n",
            "14946 [Discriminator loss: 0.6761%, acc.: 59.77%] [Generator loss: 0.7796%]\n",
            "14947 [Discriminator loss: 0.6471%, acc.: 60.94%] [Generator loss: 0.7881%]\n",
            "14948 [Discriminator loss: 0.6443%, acc.: 64.45%] [Generator loss: 0.7719%]\n",
            "14949 [Discriminator loss: 0.6765%, acc.: 53.91%] [Generator loss: 0.7777%]\n",
            "14950 [Discriminator loss: 0.6738%, acc.: 57.42%] [Generator loss: 0.7734%]\n",
            "14951 [Discriminator loss: 0.6748%, acc.: 57.03%] [Generator loss: 0.7731%]\n",
            "14952 [Discriminator loss: 0.6488%, acc.: 62.89%] [Generator loss: 0.8069%]\n",
            "14953 [Discriminator loss: 0.6653%, acc.: 59.77%] [Generator loss: 0.8014%]\n",
            "14954 [Discriminator loss: 0.6518%, acc.: 64.06%] [Generator loss: 0.7882%]\n",
            "14955 [Discriminator loss: 0.6643%, acc.: 60.55%] [Generator loss: 0.7805%]\n",
            "14956 [Discriminator loss: 0.6699%, acc.: 55.47%] [Generator loss: 0.7908%]\n",
            "14957 [Discriminator loss: 0.6366%, acc.: 63.67%] [Generator loss: 0.7730%]\n",
            "14958 [Discriminator loss: 0.6645%, acc.: 62.50%] [Generator loss: 0.8149%]\n",
            "14959 [Discriminator loss: 0.6375%, acc.: 64.45%] [Generator loss: 0.8214%]\n",
            "14960 [Discriminator loss: 0.6590%, acc.: 61.33%] [Generator loss: 0.8236%]\n",
            "14961 [Discriminator loss: 0.6546%, acc.: 63.28%] [Generator loss: 0.8374%]\n",
            "14962 [Discriminator loss: 0.6592%, acc.: 60.55%] [Generator loss: 0.8093%]\n",
            "14963 [Discriminator loss: 0.6568%, acc.: 63.28%] [Generator loss: 0.7779%]\n",
            "14964 [Discriminator loss: 0.6681%, acc.: 57.42%] [Generator loss: 0.8089%]\n",
            "14965 [Discriminator loss: 0.6618%, acc.: 58.98%] [Generator loss: 0.8042%]\n",
            "14966 [Discriminator loss: 0.6652%, acc.: 59.77%] [Generator loss: 0.8238%]\n",
            "14967 [Discriminator loss: 0.6518%, acc.: 60.94%] [Generator loss: 0.7885%]\n",
            "14968 [Discriminator loss: 0.6677%, acc.: 57.42%] [Generator loss: 0.7561%]\n",
            "14969 [Discriminator loss: 0.6662%, acc.: 60.55%] [Generator loss: 0.7609%]\n",
            "14970 [Discriminator loss: 0.6464%, acc.: 63.67%] [Generator loss: 0.8081%]\n",
            "14971 [Discriminator loss: 0.6862%, acc.: 55.08%] [Generator loss: 0.8047%]\n",
            "14972 [Discriminator loss: 0.6641%, acc.: 57.03%] [Generator loss: 0.7860%]\n",
            "14973 [Discriminator loss: 0.6574%, acc.: 57.42%] [Generator loss: 0.7996%]\n",
            "14974 [Discriminator loss: 0.6584%, acc.: 62.50%] [Generator loss: 0.8022%]\n",
            "14975 [Discriminator loss: 0.6949%, acc.: 53.12%] [Generator loss: 0.8135%]\n",
            "14976 [Discriminator loss: 0.6688%, acc.: 59.77%] [Generator loss: 0.8084%]\n",
            "14977 [Discriminator loss: 0.6515%, acc.: 64.06%] [Generator loss: 0.7879%]\n",
            "14978 [Discriminator loss: 0.6450%, acc.: 66.02%] [Generator loss: 0.8047%]\n",
            "14979 [Discriminator loss: 0.6785%, acc.: 56.25%] [Generator loss: 0.7955%]\n",
            "14980 [Discriminator loss: 0.6844%, acc.: 53.91%] [Generator loss: 0.7950%]\n",
            "14981 [Discriminator loss: 0.6716%, acc.: 55.86%] [Generator loss: 0.7889%]\n",
            "14982 [Discriminator loss: 0.6822%, acc.: 56.25%] [Generator loss: 0.7950%]\n",
            "14983 [Discriminator loss: 0.6604%, acc.: 64.45%] [Generator loss: 0.8103%]\n",
            "14984 [Discriminator loss: 0.6918%, acc.: 54.69%] [Generator loss: 0.7817%]\n",
            "14985 [Discriminator loss: 0.6790%, acc.: 55.86%] [Generator loss: 0.7898%]\n",
            "14986 [Discriminator loss: 0.6509%, acc.: 62.50%] [Generator loss: 0.8008%]\n",
            "14987 [Discriminator loss: 0.6737%, acc.: 56.64%] [Generator loss: 0.8115%]\n",
            "14988 [Discriminator loss: 0.6571%, acc.: 60.16%] [Generator loss: 0.7921%]\n",
            "14989 [Discriminator loss: 0.6477%, acc.: 67.97%] [Generator loss: 0.8477%]\n",
            "14990 [Discriminator loss: 0.6518%, acc.: 60.94%] [Generator loss: 0.8383%]\n",
            "14991 [Discriminator loss: 0.6600%, acc.: 61.72%] [Generator loss: 0.7988%]\n",
            "14992 [Discriminator loss: 0.6528%, acc.: 62.50%] [Generator loss: 0.8151%]\n",
            "14993 [Discriminator loss: 0.6718%, acc.: 57.42%] [Generator loss: 0.8064%]\n",
            "14994 [Discriminator loss: 0.6560%, acc.: 62.50%] [Generator loss: 0.7954%]\n",
            "14995 [Discriminator loss: 0.6543%, acc.: 62.11%] [Generator loss: 0.8103%]\n",
            "14996 [Discriminator loss: 0.6733%, acc.: 56.64%] [Generator loss: 0.7931%]\n",
            "14997 [Discriminator loss: 0.6730%, acc.: 58.20%] [Generator loss: 0.8144%]\n",
            "14998 [Discriminator loss: 0.6749%, acc.: 58.20%] [Generator loss: 0.8029%]\n",
            "14999 [Discriminator loss: 0.6646%, acc.: 56.64%] [Generator loss: 0.7928%]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSEslD-708yK",
        "colab_type": "code",
        "outputId": "1bfb5788-f4aa-46c5-f1fc-ddf865453586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# Display some random generated images\n",
        "plot_generated_images(generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEyCAYAAABu5MwMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}