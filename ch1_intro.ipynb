{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch1_intro.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lblogan14/Python_Deep_Learning/blob/master/ch1_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZBiohU7OFDV",
        "colab_type": "text"
      },
      "source": [
        "#Introduction to PyTorch\n",
        "PyTorch is an open source python deep learning framework, developed primarily by Facebook that has been gaining momentum recently. It provides the **Graphics Processing Unit (GPU)**, an accelerated multidimensional array (or **tensor**) operation, and computational graphs.\n",
        "\n",
        "Begin with a toy example:\n",
        "\n",
        "1. Prepare Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-pDdnlEO849",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "harZjoAYO-3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
        "                      names=['sepal_length',\n",
        "                             'sepal_width',\n",
        "                             'petal_length',\n",
        "                             'petal_width',\n",
        "                             'species'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvCLVFgcPUnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['species'] = pd.Categorical(dataset['species']).codes\n",
        "dataset = dataset.sample(frac=1, random_state=1234)\n",
        "\n",
        "train_input = dataset.values[:120, :4]\n",
        "train_target = dataset.values[:120, 4]\n",
        "\n",
        "test_input = dataset.values[120:, :4]\n",
        "test_target = dataset.values[120:, 4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3FKfBvsQovK",
        "colab_type": "text"
      },
      "source": [
        "This code downloads the Iris dataset and loads into the pandas DataFrame, and then shuffles the DataFrame rows and split the code into numpy arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srDC46Q2Q62o",
        "colab_type": "text"
      },
      "source": [
        "2. Define a simple neural network (make sure the PyTorch is installed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUmnsvXtRCJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwpNmxnIRQWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "\n",
        "hidden_units = 5\n",
        "\n",
        "net = torch.nn.Sequential(torch.nn.Linear(4, hidden_units),\n",
        "                          torch.nn.ReLU(),\n",
        "                          torch.nn.Linear(hidden_units, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sSbYPxxRed-",
        "colab_type": "text"
      },
      "source": [
        "This defines a feedforward network with one hidden layer with five units, a ReLU activation function, and an output layer with three units.\n",
        "\n",
        "Note that the target data is *one-hot encoded*. This means that each class of the flower will be represented as an array (`Iris Setosa = [1, 0, 0], Iris\n",
        "Versicolour = [0, 1, 0], and Iris Virginica = [0, 0, 1]`), and one\n",
        "element of the array will be the target for one unit of the output layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8kL5UjWVWgb",
        "colab_type": "text"
      },
      "source": [
        "3. Define an optimizer and a loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TorFM3sVdJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), \n",
        "                            lr=0.1,\n",
        "                            momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjlypYd0VsKG",
        "colab_type": "text"
      },
      "source": [
        "4. Train the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuX5vsRjVtcZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "178ab2e8-8790-4b0a-bfaf-3d1dc0f184ad"
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  inputs = torch.autograd.Variable(torch.Tensor(train_input).float())\n",
        "  targets = torch.autograd.Variable(torch.Tensor(train_target).long())\n",
        "  \n",
        "  optimizer.zero_grad()\n",
        "  out = net(inputs)\n",
        "  loss = criterion(out, targets)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  \n",
        "  if epoch == 0 or (epoch+1)% 10 == 0:\n",
        "    print('Epoch %d Loss: %.4f' % (epoch+1, loss.item()))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss: 1.2181\n",
            "Epoch 10 Loss: 0.6745\n",
            "Epoch 20 Loss: 0.2447\n",
            "Epoch 30 Loss: 0.1397\n",
            "Epoch 40 Loss: 0.1001\n",
            "Epoch 50 Loss: 0.0855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOXIYJ9XWYOu",
        "colab_type": "text"
      },
      "source": [
        "Here, the training takes 50 epochs.\n",
        "\n",
        "A few things need to be mentioned here:\n",
        "1. Create the **torch variable** that are **input** and **target** \n",
        "2. Zero the gradients or the optimizer to prevent accumulation from the previous iterations\n",
        "3. Propagate the loss value back through the network (*backpropagation*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuwwcnIAX2UB",
        "colab_type": "text"
      },
      "source": [
        "5. Test the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlZZlZTWX4fH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys5eB25AX5fo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8cc3550b-2218-444f-ddbd-44ad785e49b7"
      },
      "source": [
        "inputs = torch.autograd.Variable(torch.Tensor(test_input).float())\n",
        "targets = torch.autograd.Variable(torch.Tensor(test_target).long())\n",
        "\n",
        "optimizer.zero_grad()\n",
        "out = net(inputs)\n",
        "_, predicted = torch.max(out.data, 1)\n",
        "\n",
        "error_count = test_target.size - np.count_nonzero((targets==predicted).numpy())\n",
        "print('Errors: %d; Accuracy: %d%%' % (error_count, \n",
        "                                      100*torch.sum(targets==predicted)/test_target.size))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Errors: 0; Accuracy: 100%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}